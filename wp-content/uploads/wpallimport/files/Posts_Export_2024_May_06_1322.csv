ID,Title,Content,"Image URL","Image Filename","Image Path","Image ID","Image Title","Image Caption","Image Description","Image Alt Text","Image Featured","Attachment URL","Attachment Filename","Attachment Path","Attachment ID","Attachment Title","Attachment Caption","Attachment Description","Attachment Alt Text"
951,"Materialize + dbt Allows Users to Transform Real-Time Data with Ease","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""13px||27px|||"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" custom_padding=""11px||2px|||"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" global_colors_info=""{}""]<p>Data is complicated. (That’s why it’s called ‘data science’). Managing its use and flow remains challenging and when data pipeline management is added the complexity increases. Organizations are continuously moving the data between one another and it is no surprise that the meaning of values or individual tables of your data warehouse can be lost in the process.</p>
<p>Keeping track of who changed what would avoid the mess caused when processes such as refactoring overlap with each other causing pipelines to break. Using dbt, known as data build tool, your teams can be fully in charge of the transformation step in the ETL pipelines and seamlessly test, version-control, and track their data transformations.</p>
<p>dbt works wonderfully with batch data transformations but when it comes to transforming streaming data in real-time, that’s a whole different breed because batching data at all times is unsuitable. Analytics engineers have always suffered to access streaming data. They had to either work on multiple notebooks or use Scala, but not anymore!</p>
<p>Materialize, which holds its place as the first SQL-based platform that allows users to work with streaming data, has developed an adapter for dbt. As I’m writing this, it’s still in the beta testing phase but it will probably be available for production use cases very soon.</p>
<p>Finally, analysts can make use of Materialize as a data warehouse and transform real-time streaming data, build SQL pipelines, and be in charge of streaming analytics as users and creators. But what led to this integration</p>
<p>The Challenges of the Current Approach to Real-Time Analytic</p>
<p>Most analytics production use cases can be completed easily through batch-based tooling. However, when it comes to real-time use cases, the processes are difficult to maintain, especially with the ongoing scaling. Increased volumes ask for tools made for streaming.</p>
<p>Real-time use cases might be encountered rarely but they come with expensive consequences. Imagine the damage it would cause the lack of proper access to real-time data during inventory management or risk detection situations.</p>
<p>An alternative option might be the use of Lambda views to retrieve some kind of real-time analysis, but this is effective until a certain point with small volumes of data. Then, the performance starts to diminish because we have extended the limits of SQL optimization.</p>
<p>Why Aren’t Analysts Using the Current Streaming Tooling?</p>[/et_pb_text][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""gcid-14d09003-d3d5-438a-886e-78950859f2c4"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" custom_margin=""||21px|||"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""24px"" header_2_font_size_last_edited=""on|tablet"" locked=""off"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93,%22gcid-14d09003-d3d5-438a-886e-78950859f2c4%22:%91%22text_text_color%22%93}""]<h2>The Challenges of the Current Approach to Real-Time Analytics</h2>[/et_pb_text][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" locked=""off"" global_colors_info=""{}""]<p>Most analytics production use cases can be completed easily through batch-based tooling. However, when it comes to real-time use cases, the processes are difficult to maintain, especially with the ongoing scaling. Increased volumes ask for tools made for streaming.</p>
<p>Real-time use cases might be encountered rarely but they come with expensive consequences. Imagine the damage it would cause the lack of proper access to real-time data during inventory management or risk detection situations.</p>
<p>An alternative option might be the use of Lambda views to retrieve some kind of real-time analysis, but this is effective until a certain point with small volumes of data. Then, the performance starts to diminish because we have extended the limits of SQL optimization.</p>[/et_pb_text][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""gcid-14d09003-d3d5-438a-886e-78950859f2c4"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" custom_margin=""||21px|||"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""24px"" header_2_font_size_last_edited=""on|tablet"" locked=""off"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93,%22gcid-14d09003-d3d5-438a-886e-78950859f2c4%22:%91%22text_text_color%22%93}""]<h2>Why Aren’t Analysts Using the Current Streaming Tooling?</h2>[/et_pb_text][/et_pb_column][/et_pb_row][et_pb_row column_structure=""1_2,1_2"" module_class=""align-items-center-desktop"" _builder_version=""4.17.1"" _module_preset=""default"" width=""100%"" custom_padding=""3px||4px|||"" locked=""off"" global_colors_info=""{}""][et_pb_column type=""1_2"" _builder_version=""4.17.1"" _module_preset=""default"" global_colors_info=""{}""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|tablet"" locked=""off"" global_colors_info=""{}""]<p>Are there other tools that help process and stream real-time data? Yes. Are analysts working with them? No. Well, at least most of them don’t because it’s not their part of their range of skills. Most analysts aren’t familiar in writing transformations in tools such as Kafka Streams. That would ask for them to code on Scala or Java and much more technical knowledge.</p>
<p>Therefore, this process is done by data engineers who are familiar with these tools and manage transformations from the start with the setting of pipelines. So analysts rely on their output and can’t really contribute much to streaming data transformations even though they could add an immense value if they did.</p>
<p>The question is that arises is: “What’s stopping them from doing so without having to learn how to use these tools?” SQL has the answer. If streaming analytics is made more accessible to analysts and those well-versed in SQL, there will be a significant improvement in analysis speed, data quality, and a reduction of silos among data teams.</p>[/et_pb_text][/et_pb_column][et_pb_column type=""1_2"" _builder_version=""4.17.1"" _module_preset=""default"" global_colors_info=""{}""][et_pb_image src=""https://blueorange.digital/wp-content/uploads/2022/04/image-63.png"" title_text=""image (63)"" _builder_version=""4.17.1"" _module_preset=""default"" global_colors_info=""{}""][/et_pb_image][/et_pb_column][/et_pb_row][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" custom_padding=""27px||2px|||"" locked=""off"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""gcid-14d09003-d3d5-438a-886e-78950859f2c4"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" custom_margin=""||21px|||"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""24px"" header_2_font_size_last_edited=""on|tablet"" locked=""off"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93,%22gcid-14d09003-d3d5-438a-886e-78950859f2c4%22:%91%22text_text_color%22%93}""]<h2>Introducing dbt + Materialize</h2>[/et_pb_text][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" locked=""off"" global_colors_info=""{}""]<p>This duo is definitely going to take data science and analytics companies to the next stage, but what are some of the exciting use cases that users can jump right into? Streaming real-data might benefit many functionalities but two impressive cases are these:</p>
<ul>
<li><strong>Real-time dashboards.</strong> Data analysts will have ownership of the transformation processes that are based on live insights for external and internal customers.</li>
<li><strong>Operational functions.</strong> Take email lists as an example. Batch-based processes are great for updating email lists, but for cases like spam detection, a streaming approach is needed.</li>
</ul>
<p>Materialize completely removes the need to go through streaming data modeling and grant users the ownership of real-time transformation workflows, similar to what one would do with a batch-based alternative. Also, the background of users matters in order to reap the full benefits of this integration.</p>[/et_pb_text][/et_pb_column][/et_pb_row][et_pb_row column_structure=""1_2,1_2"" module_class=""align-items-center-desktop "" _builder_version=""4.17.1"" _module_preset=""default"" width=""100%"" custom_margin=""8px|auto||auto||"" custom_padding=""17px||4px|||"" locked=""off"" global_colors_info=""{}""][et_pb_column type=""1_2"" _builder_version=""4.17.1"" _module_preset=""default"" global_colors_info=""{}""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""gcid-14d09003-d3d5-438a-886e-78950859f2c4"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" custom_margin=""||21px|||"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""24px"" header_2_font_size_last_edited=""on|tablet"" locked=""off"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93,%22gcid-14d09003-d3d5-438a-886e-78950859f2c4%22:%91%22text_text_color%22%93}""]<h2>Introducing dbt + Materialize</h2>[/et_pb_text][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" locked=""off"" global_colors_info=""{}""]<p>This duo is definitely going to take data science and analytics companies to the next stage, but what are some of the exciting use cases that users can jump right into? Streaming real-data might benefit many functionalities but two impressive cases are these.</p>[/et_pb_text][/et_pb_column][et_pb_column type=""1_2"" _builder_version=""4.17.1"" _module_preset=""default"" global_colors_info=""{}""][et_pb_image src=""https://blueorange.digital/wp-content/uploads/2022/04/Image-2.png"" title_text=""Image 2"" _builder_version=""4.17.1"" _module_preset=""default"" global_colors_info=""{}""][/et_pb_image][/et_pb_column][/et_pb_row][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" custom_padding=""27px||2px|||"" locked=""off"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""gcid-14d09003-d3d5-438a-886e-78950859f2c4"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" custom_margin=""||21px|||"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""24px"" header_2_font_size_last_edited=""on|tablet"" locked=""off"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93,%22gcid-14d09003-d3d5-438a-886e-78950859f2c4%22:%91%22text_text_color%22%93}""]<h2>Materialize + dbt (for Materialize users)</h2>[/et_pb_text][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" locked=""off"" global_colors_info=""{}""]<p>On the other side, Materialize users should dedicate a little bit of time to grasping dbt. Making use of dbt, users can scale Materialze pipelines with the help of macros. They assist in deploying and parametrizing views, and together with other features, in shortening the time spent to execute processes.</p>
<p>For instance, you can use a Jinja loop for iterating over a similar statement and avoid creating hundreds of create source statements. In the words of Andy, Head of Community at Materialize, dbt can be explained as:</p>
<p><em><strong>“dbt is the best way to manage your Materialize deployment. With dbt, you can optimize your workflow with version control, macros, testing, and documentation.”</strong></em></p>[/et_pb_text][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""gcid-14d09003-d3d5-438a-886e-78950859f2c4"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" custom_margin=""||21px|||"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""24px"" header_2_font_size_last_edited=""on|tablet"" locked=""off"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93,%22gcid-14d09003-d3d5-438a-886e-78950859f2c4%22:%91%22text_text_color%22%93}""]<h2>In a Nutshell</h2>[/et_pb_text][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" locked=""off"" global_colors_info=""{}""]<p>There exist many questions and issues with the batch paradigm that haven’t even been raised because they can’t be solved with this system. However, as the streaming workflows are made accessible to more data team members, the processes will get smoother, and these issues will be voiced and solved properly.</p>
<p>Working with data might be daunting and exhausting at times. Blue Orange is equipped with a team of data scientists who take the hard work off your shoulders and help you optimize those sophisticated data pipelines and turn them into digestible insights. Schedule a free 15-minute consultation with us here.</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/03/Materialize-DBT-Blog-Cover-e1649849198419.png,Materialize-DBT-Blog-Cover-e1649849198419.png,/www/blueorangem_500/public/wp-content/uploads/2022/03/Materialize-DBT-Blog-Cover-e1649849198419.png,362,Materialize-DBT-Blog-Cover,,,,https://blueorange.digital/wp-content/uploads/2022/03/Materialize-DBT-Blog-Cover-e1649849198419.png,,,,,,,,
2735,"Databricks Lakehouse for Financial Services Helps FSIs Leverage Data Wisely","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>Data-driven innovation finds its place in another industry. That of Financial Services Institutions (FSIs). Even though it sounds quite uncommon at first, this is a novelty we’ll get used to pretty quickly. Actually, there is a vast amount of data within these institutions, which makes this only a little surprising. If it wasn’t for the vendor lock-in and complex legacy architectures that impede AI and data from becoming essential business factors, we’d have seen such developments earlier.</p>
<p>Understanding the need for a prompt solution, Databricks has recently launched Databricks Lakehouse for Financial Services, a modern data platform well-suited for capital markets, banking, and insurance sectors to serve various customer use cases. Customers can easily benefit from solutions that address their specific business and technical requirements.</p>
<p>“For Financial Service Institutions around the world looking to modernize and innovate, the two most important assets are no longer its capital or sheer scale, but its data and its people,” said Junta Nakai, RVP, financial services global industry leader at Databricks. He added that Lakehouse for Financial Services unifies these two core elements in a single data platform that allows a seamless flow of data throughout the cloud securely.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Introducing Lakehouse for Financial Services</h2>
<p>Lakehouse for Financial Services focuses on bridging the connection between people and data with the help of its versatile capabilities such as open standards and certified implementation partners, data model frameworks, open standards, and pre-built solutions accelerators. Lakehouse tackles some essential issues such as:</p>
<ul>
<li><strong>Vendor lock-in risk. </strong>FSIs are constantly impeded by a limited number of technologies and data formats. Lakehouse allows teams to utilize the tools they prefer since it relies on open standards and open-source. </li>
<li><strong>Multi-cloud.</strong> Partnering up with Lakehouse is compatible and <a href=""https://databricks.com/company/partners/cloud-partners"">provides support for popular cloud vendors</a> allowing a multi-cloud infrastructure and preventing systemic risks.</li>
<li><strong>Access to Real-time data for BI.</strong> Lakehouse surpasses all the obstacles raised from traditional architectures by facilitating the access of data analysts and data teams to recent, real-time data.  </li>
<li><strong>Support for diverse data sets.</strong> Critical use-cases usually include an ample amount of unstructured data sets such as text and images. Lakehouse removes the data sets limits that occur in traditional data warehouses by working with unstructured, structured, and semi-structured data sets, and allowing advanced <a href=""https://databricks.com/blog/2021/05/26/introducing-delta-sharing-an-open-protocol-for-secure-data-sharing.html"">data sharing</a>. </li>
<li><strong>Use cases including AI.</strong> Implementing AI in financial ecosystems is challenging due to the regulations, the legacy processes, and the siloed infrastructures. Lakehouse provides AI transparency using MLflow and other tools and has even implemented AI for <a href=""https://databricks.com/glossary/model-risk-management"">model risk management</a> to cope with risks that arise from model errors.</li>
</ul>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh3.googleusercontent.com/5OMbvXIhp1AEs1Xq1MLyCdmYa_nnDaXuUkF_32g_0okghTKM62aDtMCGDj3BbxVt4Nk8GvgZ8FKw8GMTCC9somfTAnKdP8vnzNPrrLYTtfgGkza0kyBOPzbD6BIUouD4nPhR_QfQ"" alt="""" /><br />
<figcaption><strong>Hyper-Personalization <a href=""https://databricks.com/it/blog/2022/03/03/hyper-personalization-accelerator-for-banks-and-fintechs-using-credit-card-transactions.html"">by Databricks</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>What Makes Lakehouse for Financial Services Efficient in Tackling These Challenges?</h2>
<p>Lakehouse for Financial Services was built to allow seamless navigation of data within the organization and improved functionality of financial services with innovative and moderated risk management solutions suitable even in highly-regulated environments. Here are six features of Lakehouse that assist in this:</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Pre-built Solution Accelerators for Financial Services Use Cases</h2>
<p>Databricks offers 14 financial services solution accelerators that combine with Lakehouse to successfully tackle sophisticated but common use cases. Six common use cases that we could distinguish are:</p>
<ul>
<li><strong>Transaction Enrichment.</strong> Retail banking can prevent fraudulent actions and develop a more accurate customer segmentation by implementing a geospatial data library and hyper-personalization. </li>
<li><strong>Market Surveillance and Post-Trade Analysis.</strong> Asset managers can produce transactional cost analyses and backtest their investing tactics and strategies by using a library that brings together market data and separate data sources. </li>
<li><strong>Regulatory Reporting.</strong> This Lakehouse accelerator follows the respective open sharing protocols and open data standards to streamline the flow of regulatory data. </li>
<li><strong>GDPR Compliance. </strong>Compliance is made easier by dealing with the technical aspects more simply and maintaining strict audit capabilities.</li>
<li><strong>Common Data Models.</strong> Organizations can seamlessly standardize data by using certain accelerators and framework sets.</li>
</ul>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/OnA238HIHt_V5j91y1fH1OT-3hzHmHE-Dg5vHcEMG_b0PaVMKP4EH2t_EHTUIePhPMt32m-kQ3DuixDXtDq8puqWEQWad8JQMqeEPwSW8wsdVTkE8vP4TWI506W0HI8YvF-vEQEw"" alt="""" /><br />
<figcaption><strong><a href=""https://databricks.com/blog/2021/10/22/how-bread-standardized-on-the-lakehouse-with-databricks-delta-lake.html"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Industry Open Source Projects</h2>
<p>Databricks recently became part of FINOS (FinTech Open Source Foundation) which involves other worldwide FSIs such as JP Morgan and Goldman Sachs. This intends to expand the cooperation and development in the field of financial services, and offer a simplified and secure transmission of financial data in the banking systems.</p>
<p>Part of Databricks’s goal to standardize data by facilitating accessibility and providing advanced insights is also the integration of Data Lake functionalities with the LEGEND ecosystem. The latter allows financial analysts to consider financial calculations in relation to data and build efficient data pipelines without extra costs.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Facilitated Deployment of the Lakehouse Environment</h2>
<p>The security standards can be easily automated by customers while using Lakehouse for Financial Services. The scripts and utility libraries developed specifically for financial services to automate notebooks’ setup and tackle other issues, including governance and security issues. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>A Data Model Framework For Standardizing Data</h2>
<p>Organizations face different hurdles when standardizing data. Besides incorporating accelerators, organizations can use a framework for common data models provided by Lakehouse. For instance, Lakehouse integrates with Financial Regulation (FIRE) with the help of one solution accelerator, which aids the data standardization process and allows the distribution of data to downstream tools. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Open Data Sharing</strong></h2>
<p>Databricks launched Delta Sharing in 2021 as an open protocol that assisted in the secure process of data exchange among organizations in real-time without being limited to the sharing capabilities of the platforms containing the data. For instance, <a href=""https://www.ticksmith.com/"">Ticksmith</a> was an early adopter of Delta Sharing which now allows FSIs to handle data products in a single environment from inception to delivery. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h4>Implementation Partners</h4>
<p>Avanade is also another company with which Databricks is cooperating to be able to ship risk management solutions to FSIs. The joint solution produced by this partnership is built on Azure Databricks and allows customers to put data into value-at-risk (VaR) models in a manageable manner. </p>
<p>Databricks has further deepened its efforts to provide enhanced data regulation and management solutions by partnering up with Deloitte FinServ Governed Data Platform, which focuses on creating one source of truth for financial institutions while involving<a href=""https://blueorange.digital/predictive-analytics/""> predictive analysis</a>, NLP, business intelligence, AI/ML and visualization.  </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h3>Final Thoughts</h3>
<p>Lakehouse for Financial Services aims to innovate the way financial institutions handle data and execute their processes. Including a wide array of solution accelerators, data model frameworks, and implementation partners, Databricks promises a smooth sailing towards standardization of data and implementation of AI. </p>
<p>Blue Orange Digital can help you discover further the data solutions that exist for your organization during a 15-minutes free consultation call. Book <a href=""https://blueorange.digital/contact-us/"">here</a>.</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Databricks-Lakehouse-cover-image.png,Databricks-Lakehouse-cover-image.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Databricks-Lakehouse-cover-image.png,2738,Databricks-Lakehouse-cover-image,,,,https://blueorange.digital/wp-content/uploads/2022/05/Databricks-Lakehouse-cover-image.png,,,,,,,,
2752,"How Does Machine Learning Help In Business Transformation?","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>The widespread use of cloud computing, the increase of compute power, and the invention of machine learning (ML) solutions that are easy to develop and adopt are giving businesses the tools to grow faster. Machine learning can contribute to many areas of the business from research to forecasting and software development. Gartner <a href=""https://www.gartner.com/en/newsroom/press-releases/2018-04-25-gartner-says-global-artificial-intelligence-business-value-to-reach-1-point-2-trillion-in-2018"">predicts</a> that the AI-derived business values will reach $3.9 trillion by 2022. </p>
<p>Machine learning is seen as an undeniable instrument for growth that can be deployed in many aspects of a business from enhancing customer experience to boosting innovation, reducing fraud, and optimizing business operations. This is an overview of how major companies have implemented machine learning to reach their goals, and how you can do the same. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Using Machine Learning to Improve Customer Experience </strong></h2>
<p>Machine learning is giving organizations the tools to shift their relationship with customers to a better state. By incorporating machine learning solutions in your organization you can form a clearer understanding of the customers' behavior and suggest appropriate solutions based on their historical data or reaction to previously shown options. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh3.googleusercontent.com/4rnnvodQUYDr55hDx92OS626I7IOXslN8pcpVedtSrm8E2PBUQD504jguw3dxHxdBM4x0NgVUns0QcSBe7ZP8QoQdPLkgOmWQCW_YF4w0srL39rOetm5MpQEt6dDgpUJMbNz4XvQ7Ji1Vxqz0g"" alt="""" /><br />
<figcaption><strong><a href=""https://financesonline.com/machine-learning-statistics/"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<p>Machine Learning surpasses manual responses and gives quicker and more efficient customer support. If you reach out to companies that rely on the human workforce to offer customer service, you have to wait in line for several minutes until an agent is free. Using <a href=""https://blueorange.digital/automate-customer-service-with-chatbots/"">machine learning chatbots</a> each customer will get an answer to their query in seconds and reduce the waiting time. </p>
<p>Aramex, a company in the global logistics and transportation industry spanned across 604 locations in the world, could digitize and enhance its customer experience through machine learning solutions. Inawisdom, another AWS partner (Blue Orange Digital is a <a href=""https://partners.amazonaws.com/partners/0010h00001cABiwAAG/"">certified AWS partner </a>too), helped Aramex eliminate nearly 40% of inbound calls by lowering their transit time application from 2.5 seconds to 200 milliseconds and increasing the shipment accuracy by 74%. This was done by using <a href=""https://blueorange.digital/reduce-time-to-market-with-aws-sagemaker-no-code-ml-interface/"">Amazon SageMaker</a> and other AWS services to inspect the shipment process in real-time through data ingestion and predictive analysis.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Optimize Business Operations By Implementing Machine Learning  </h2>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<p>The hardest part about optimizing business operations stands in processing large amounts of data before making decisions. Machine learning can achieve this in record time and automate processes as well as predict business outcomes. By implementing machine learning businesses can automate manual operations such as finding customers, recruiting, research, and even improving communications.  </p>
<p>Machine learning can be used to automate several IT operations which means that unexpected problems can be solved in minimal time. This leaves time for staff to do meaningful work that can’t be automated easily (yet). In one of our <a href=""https://blueorange.digital/cptcasestudies/machine-learning-hiring-platform/"">case studies</a>, we explain how we were able to help a talent analytics company to improve and automate its services. </p>
<p>Uiba, is a company dedicated to helping mid and large-sized organizations to complete their workforce with new staff and build high-performing teams in minimal time and with maximal productivity. We designed and built their platform with all the features that allowed companies to filter through employees based on team, role, and employee, as well as optimize talent distribution for more productivity. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh5.googleusercontent.com/U1KUWrrkNGaTs_MIR_sAtV2xpdR5M3QYyWTRI_FjgG1oRrK34yRYBRwBbhaWnrshmKqugJrr4V03kyixE1vWHeen3IFqKBDNUsxuLF2W-FbnMtKqfY1CUXscNBHBS3ej6ajKMrdy4PP1uUChaQ"" alt="""" /><br />
<figcaption><strong><a href=""https://truelist.co/blog/machine-learning-statistics/"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Machine Learning Helps You Accelerate Innovation</strong></h2>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<p>Sometimes valuable team members can’t contribute to certain processes due to their lack of expertise but machine learning solutions are offering more and more ways for different team members to access machine learning solutions and improve apps, services, and products. Machine Learning produces optimal solutions for clients and saves time in the process. </p>
<p>Cloud-computing tools and <a href=""https://blueorange.digital/what-are-modern-data-stack-mds-technologies/"">modern data stack technologies</a> have made it easier for companies to gather, manage, transform and interpret data which means that almost any problem can be solved much faster than before as long as there is historical data where machine learning models can be based on. </p>
<p>Amazon Robotics, which is used in Amazon fulfillment centers to speed up the fulfillment processes, has deployed machine learning and artificial intelligence solutions to maximize the automatization process with complete efficiency. By using <a href=""https://aws.amazon.com/sagemaker/"">Amazon SageMaker </a>they were able to build their Intent Detection System fueled by deep learning to reduce costs, increase productivity, and scale the process further. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Final Thoughts</strong></h2>
<p>Machine Learning can be incorporated in <a href=""https://blueorange.digital/industries/"">multiple sectors</a> including retail, healthcare, IoT, agriculture, finance, real estate, talents analytics, construction, energy, and e-commerce, and bring a total transformation in business operations. </p>
<p>At Blue Orange Digital we have applied machine learning to all these sectors with realistic results and have helped organizations scale faster. You can view a full list of <a href=""https://blueorange.digital/cptcasestudies/"">our case studies </a>and schedule a short and <a href=""https://blueorange.digital/contact-us/"">free 15-minute call </a>to discover how we can help you apply machine learning or any of our other solutions to your business.</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Blog-Post-Cover-Images-1200-x-675-px-1.png,Blog-Post-Cover-Images-1200-x-675-px-1.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Blog-Post-Cover-Images-1200-x-675-px-1.png,2753,Blog-Post-Cover-Images-1200-x-675-px-1,,,,https://blueorange.digital/wp-content/uploads/2022/05/Blog-Post-Cover-Images-1200-x-675-px-1.png,,,,,,,,
2758,"What Is Sentiment Analysis and Its Application on dbt Models from Python","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>Integrating sentiment analysis into your application or software helps work with human emotions and filter feedback faster or generate meaningful and helpful responses. Understanding what exactly customers want and their overview of your business is crucial but going through massive piles of reviews manually to discover this is time-consuming and not practical. </p>
<p>Sentiment analysis utilizes Natural Language Process (NLP) to analyze statements and classify them based on the emotions they evoke as positive, negative, or neutral. Sentiment analysis can process reviews, tickets, feedback, survey responses, job applications, and other types of content. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/DcFtDvNG2K7guxdoyVGp5E_l8eWiA9ErRIaP6J5T5X4Ys-1KrZiAALKVOWLHRaEEzwWW5oKg_myAL2t1re-d3suXShr3kCUPlr_P1Gq6UY4p6IAb-lw4oACFB7IN1blmR17XXIny"" alt="""" /><br />
<figcaption><strong><a href=""https://expressanalytics.com/blog/social-media-sentiment-analysis/"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>What is Sentiment Analysis and Its Types?</strong></h2>
<p>Sentiment Analysis includes the process of recognizing a positive, negative or neutral sentiment in written form content. Businesses and organizations use it to gather customer data, identify customers’ main pain points, or measure the reputation of a brand. </p>
<p>Sentiment analysis takes into account not only the specific vocabulary used by customers but also emoticons and punctuation signs to identify their feelings, intentions, and urgency. When running sentiment analysis, you should keep in mind the interpretation of statements and your specific goals. There are four types of sentiment analysis you can perform:</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Emotion Detection</strong></h2>
<p>Emotion Detection analyzes statements to discover more than the polarity of emotions. It focuses on finding what feelings the statements convey, such as anger, sadness, frustration or happiness. In these cases, systems could use advanced machine learning algorithms or lexicons (lists of words that characterize a particular emotion). The only issue that arises with lexicons is the fact that customers could use a negative word for a positive experience and vice-versa. </p>
<p><strong>For example: </strong></p>
<p>“You’ve killed it with this product!” vs. “This software is killing my site's loading speed!!”</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Aspect-based Sentiment Analysis</strong></h2>
<p>For businesses or organizations offering services or products, aspects-based analysis comes at help for understanding how customers feel for a specific aspect of your product or service. An aspects-based analysis helps you distinguish between positive and negative statements based on certain features that you offer. For example, if you’re selling computers when a customer says <em>“the laptop is constantly freezing”</em> you can classify that as a negative review based on aspects-based sentiment analysis. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Intent Sentiment Analysis</strong></h2>
<p>The intent analysis focuses on discovering the intent that lies behind the statements. Customers might be simply browsing around or searching for solutions. Classifying their feedback based on their intent is important when considering retargeting them through ads or responding to their queries accurately.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh3.googleusercontent.com/wmyuqycDoL0_SN60c9f0bWkK5xCiBfmtczbgSBUKXLg1XLFFEBFDt_v2Ee7EG5RT8xbggrWsKLPGlVu4Htm_kdK-iAWMw-gazAkurZ77A89TkUzMtDoDR3wwzFCd3_msEUxi6XER"" alt="""" /><br />
<figcaption><strong><a href=""https://www.reddit.com/r/Python/comments/a44y3o/sentiment_analysis_on_the_subreddits_of_various/"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Running Sentiment Analysis using Python</strong></h2>
<p>Python is widely used for its practicality to perform accurate sentiment analysis on <a href=""https://blueorange.digital/materialize-dbt-allows-users-to-transform-real-time-data-with-ease/"">dbt models</a> or other types of models. However, all sentiment workflows begin with data loading and then its subsequent processes such as tokenizing, removing stop words, and normalizing. </p>
<ul>
<li><strong>Tokenizing</strong> takes entire reviews or long paragraphs and chunks them down into sentences and words</li>
<li><strong>Removing stopwords</strong> like “but”, “and” or “if” facilitates the understanding and processing of data</li>
<li><strong>Normalization </strong>includes the standardization of forms of words into one form (using lemmatization or stemming)</li>
</ul>
<p><a href=""https://blog.fal.ai/sentiment-analysis-on-your-dbt-models/"">Here </a>is an excellent practical example of using Python to run a sentiment analysis on dbt models. It involves the use of Hugging Face transformers and Zendesk tickets to analyze the experience of customers while booking a hotel room. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Final Thoughts</h2>
<p>Being able to identify the sentiment of customer statements will help you classify reviews and feedback for further improvement of your products or services. At Blue Orange Digital, we have implemented sentiment analysis to remove biases from the hiring process when reviewing applications among other cases. Our data scientists can devise systems that will aid your organization in scaling up or in making an accurate evaluation of itself. Simply book a short (and free) 15-minute consultation call <a href=""/contact-us/"">here </a>and let’s talk more in-depth about it. </p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Blog-Post-Cover-Images-3.png,Blog-Post-Cover-Images-3.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Blog-Post-Cover-Images-3.png,2768,Blog-Post-Cover-Images-3,,,,https://blueorange.digital/wp-content/uploads/2022/05/Blog-Post-Cover-Images-3.png,,,,,,,,
2762,"#420: Cannabis and Machine Learning, a Joint Venture","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2>Cannabis growers and sellers are rolling in and cashing out on machine learning</h2>
<p>Regardless of scale, cannabis growers and sellers are doing business in a notably challenging environment. While they are dealing with ever-changing regulatory measures, they also need to navigate complex labor compliance issues and banking restrictions. On top of the typical business and supply chain operations, this emerging market is still unsettled legally, economically, and facing increasingly severe weather.  As a result, cannabis product companies and the agriculture industry at large, are looking to machine learning’s ability to predict, optimize, and analyze as they embrace the future of agricultural technology.</p>
<h2>Challenges in the AgTech and cannabis industry</h2>
<p>Cannabis-based producers must tackle complex agricultural issues:</p>
<p><strong>Growers:</strong></p>
<ul>
<li>Manage pests and disease</li>
<li>Design efficient nutritional plans</li>
<li>Ensure ideal environmental conditions </li>
<li>Optimize output while minimizing overhead</li>
<li>Legal regulatory compliance</li>
</ul>
<p><strong>Sellers:</strong></p>
<ul>
<li>Understand and organize complex distribution processes</li>
<li>Coordinate manufacturers, farmers, brands, and customer demand</li>
<li>Make decisions for future growth and expansion</li>
<li>Multi-state tax structures and regulations</li>
</ul>
<p>For dealing with the operational side of growing, as well as for tackling the marketing side of selling, cannabis-based product companies can now leverage powerful data. This data fuels machine-learning-capable software that can <em>predict</em> <em>the future</em> by way of modern algorithms and data-processing architectures.</p>
<h2>The following characteristics of cloud-based ecosystems are powering machine learning solutions:</h2>
<ul>
<li><strong>Sensors and hardware for extracting information are cheaper</strong>
<ul>
<li>The increased popularity and success of IoT solutions make it possible to deploy, connect, and establish vast networks of smart devices. This localized streaming data is a crucial component for the accuracy of predictive data models.</li>
</ul>
</li>
<li><strong>Computing and storage resources are increasingly affordable</strong>
<ul>
<li>Competition among cloud vendors invites innovation and development at a low cost. Anyone can build and deploy ML solutions in the cloud, given that they have access to enough data. Furthermore, all cloud providers use a pay-as-you-go model allowing customers to only pay for what they use and require.</li>
</ul>
</li>
<li><strong>Algorithms and data processing frameworks are widely available</strong>
<ul>
<li>Many data processing tasks (all the way from collection to analysis) can easily be updated and automated with cloud-based tools. Similarly, pre-trained ML models and neural network architectures can be repurposed using old knowledge on new problems.</li>
</ul>
</li>
</ul>
<p>Such a rich ecosystem of tools, frameworks and cheap data collecting devices have turned ML in agriculture into a viable, cost-efficient solution for the toughest challenges. No wonder that data-powered optimization is currently reshaping the entire agriculture sector, well beyond cannabis farming.</p>
<p>Below are a few brief ways predictive modeling solutions are being applied by both cannabis growers and sellers.</p>
<h2>For Growers: Predictive models for operational improvements</h2>
<h2><strong>Potency</strong></h2>
<p>Accurately understanding the chemical makeup of the cannabis plant is a crucial necessity for respecting regulatory measures. <a href=""https://blueorange.digital/why-prediction-is-so-important-for-business/"">Predictive models</a> can incorporate spectroscopy, x-ray imaging techniques, and machine learning to accurately identify cannabinoids and thus label cannabis varieties. Even in cases when the available data was insufficient, <a href=""https://www.sciencedaily.com/releases/2020/09/200929123516.htm"">researchers </a>were still able to cluster cannabis strains into distinct categories (medicinal, recreational, combined, industrial) based on their chemical properties. Not only do such models enable a better understanding of cannabis potency at all stages of the supply chain, but they represent a safeguard of quality and health for the end consumers. </p>
<h2><strong>Yield Prediction</strong></h2>
<p>Collecting localized, real-time data from crops (humidity, temperature, light) is the first step in understanding both artificial and natural growing environments. However, knowing what to plant and what actions to take during growing may not be enough. Incorporating a variety of data sources and building complex models that account for hundreds of features (from soil type and rainfall to leaf-level healthiness measures) improves the accuracy of predictive models. The models then output numeric yield estimates that provide farmers with <a href=""https://blueorange.digital/blog-optimization-modeling/"">optimized solutions</a> for the best return on investment.</p>
<h2><strong>Threat Prediction</strong></h2>
<p>Historical crop performance is not a reliable indicator for upcoming threats and diseases. Instead, automated prediction models can be used to keep crops under constant monitoring in both natural and artificial environments. Threat prediction models rely on a variety of techniques, ranging from image recognition to analysis of weather time-series data. Thereby enabling the system to forecast upcoming threats, <a href=""https://blueorange.digital/preventing-fraud-with-anomaly-detection/"">detect anomalies</a>, and help farmers recognize early signs. Taking action before it is too late empowers them to minimize loss and maximize crop quality.</p>
<h2>For Sellers: Leverage historical customer data for marketing &amp; supply chain optimization</h2>
<h2><strong>Customer Lifetime Value</strong></h2>
<p><a href=""https://blueorange.digital/3-best-machine-learning-models-to-predict-customer-lifetime-value-cltv/"">Customer Lifetime Value (CLTV)</a> is one of the crucial measures that influence sales and marketing efforts. Modern predictive algorithms are already able to predict future relationships between individuals and businesses. These algorithms can either classify customers (e.g. low spending, high spending, medium spending) into different clusters or even predict quantifiable estimates of their future spendings. Such a fine-grained understanding of customers and their spending habits provides sellers a way to easily identify and nurture high-value customers. </p>
<h2><strong>Customer Segmentation</strong></h2>
<p><a href=""https://blueorange.digital/cptcasestudies/marketing-optimization-for-energy-company/"">Segmentation</a> lies at the foundation of well-targeted marketing efforts. Both pre-built solutions, as well as custom-made algorithms, are able to distinguish between hundreds of relevant customer features. These features can be engineered from all kinds of internal and external data sources: web activity data, past purchase history, even social media activity. This data results in customers being grouped according to a set of characteristics that they share. This allows not only micro-targeting of marketing efforts but also improves the efficiency of distribution channels.</p>
<h2>Is the joint venture between cannabis and machine learning blowing smoke? </h2>
<p>Like any agricultural endeavor, growing and selling a crop like cannabis comes with a variety of challenges.  Machine learning is removing the barriers to efficient production and distribution.  Companies are looking beyond manual analysis to analyze the constraints and parameters involved in operational performance. They are switching to machine learning to optimize their efforts.  At the same time, the marketing side of selling cannabis is becoming increasingly complex and digital, another call to bring in the power of big data. As consumers’ tastes get progressively sophisticated, the variety of products and competition get more fierce. Removing future uncertainty in all these areas with the capabilities of prediction, anomaly detection, multi-variable optimization, and more through machine learning is helping cannabis companies roll in huge profits. </p>
<p>We live in a world where data is leading a revolution in all industries: the public sector, health, manufacturing, and the supply chain. Developments in the agricultural sector are no exception: data-powered solutions are driving innovation by assisting farmers with their most challenging decisions. Predictive tools are used to leverage local data collected in real-time, thus removing the fear of uncertainty from operational processes. Digital, data-powered agricultural optimization is already reshaping the entire cannabis industry.</p>
<p>Originally Published: <a href=""https://www.unite.ai/420-joint-venture-of-cannabis-and-machine-learning/"">https://www.unite.ai/420-joint-venture-of-cannabis-and-machine-learning/</a></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/420-post-blog-cover-2.png,420-post-blog-cover-2.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/420-post-blog-cover-2.png,2764,420-post-blog-cover-2,,,,https://blueorange.digital/wp-content/uploads/2022/05/420-post-blog-cover-2.png,,,,,,,,
2770,"The Data Race Against The Pandemic, Together","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2>How ML and data were crucial in fighting COVID-19 in 2020 as a united global community.</h2>
<p>2020 was a year like no other. The global pandemic brought along countless challenges for governments, health organizations, and frontline workers. As the virus rapidly spread across continents and lockdown measures hardened on a weekly basis, an entire world joined the fight. Academic labs, companies, startups, foundations, NGOs, and tech communities have united on a global level in an unprecedented display of collaborative problem-solving. </p>
<p>Data science tools, ML-powered algorithms, and AI solutions have played a crucial role in responding to the global pandemic. Tech communities have transformed the global challenge into an opportunity to innovate and tackled a large variety of challenging topics. Some of the proposed software initiatives are worth taking a second look at. </p>
<h2><strong>Data science tools and ML-powered software to assist researchers and health workers</strong></h2>
<p>All global efforts to combat the COVID-19 spread in 2020 had one thing in common: the need to collect, analyze, and take decisions on real-time outbreak data. Whether for biomedical, epidemiological, or socioeconomic purposes, data science has been one of the main tools assisting researchers and policymakers to tackle pandemic-related challenges. At the same time, ML-powered software took the spotlight for all kinds of innovative applications.</p>
<p>The most researched COVID-19-related application of 2020 was medical imaging for screening and detection of infected patients. Since ML algorithms are already popular in the health sector, it was only expected of scientists to develop ML models for identifying different stages of the disease. According to a <a href=""https://arxiv.org/pdf/2010.07036.pdf"">survey</a> published in late September 2020 more than two dozen ML approaches are used to diagnose COVID-19 based on X-Ray and CT scan images. </p>
<p>AI-powered solutions were also very popular in an attempt to bring life back to normal and keep frontline workers safe. IoT-based <a href=""https://smartxhub.com/tablet-temperature-screening-brochure/"">thermal screening applications</a> and contactless screening solutions based on cloud technologies have become ubiquitous in <a href=""https://futureiot.tech/taiwan-hospital-taps-ai-iot-and-cloud-to-keep-away-covid-19/"">hospitals</a> all across the globe. Social distancing monitors based on computer vision methods were also researched extensively, given their utility in both <a href=""https://landing.ai/landing-ai-creates-an-ai-tool-to-help-customers-monitor-social-distancing-in-the-workplace/"">public spaces</a> and <a href=""http://rayvision.ai/"">work environments</a>. </p>
<p>Lastly and perhaps most importantly, <a href=""https://coronavirus-resources.esri.com/#get-data"">real-time data</a> acquired throughout the pandemic was crucial for policymakers, governments, and organizations in monitoring, managing, and communicating the impact of the outbreak. Without proper statistical tools and data science capabilities, making sense of outbreak data would have been impossible. Like never before, 2020 has shown it clearly: data and data-driven decisions can have immediate political and economic consequences. </p>
<h2><strong>Open-source initiatives</strong></h2>
<p>2020 was the year that proved how important open cooperation is. How despite challenges on a global scale, people of different cultures and backgrounds could still come together to produce innovative, sometimes life-saving solutions. </p>
<p>What is a better way to celebrate the spirit of cooperation than by celebrating the open-source momentum of 2020?</p>
<p>Researchers, scientists, makers, and developers all across the world have joined forces for one of the most productive years of the open-source industry. Maybe don’t quote us on this one, but trust us: 2020 saw some truly amazing and powerful open source initiatives. At least a few thousands can be found on a <a href=""https://github.com/search?q=coronavirus+OR+covid19"">quick search on Github</a>, and there are many others out there.</p>
<p>The Data Scientists at <a href=""http://predictivehealthcare.pennmedicine.org/"">Penn Medicine</a>’s Predictive Healthcare have applied predictive analytics to build the COVID-19 Hospital Impact Model for Epidemics (<a href=""https://penn-chime.phl.io/"">CHIME</a>). With support and contributions from the <a href=""https://codeforphilly.org/"">CodeForPhilly community</a>, the application was <em>“designed to assist hospitals and public health officials with understanding hospital capacity needs as they relate to the COVID pandemic”.  </em>The tool used an epidemiological modeling technique to provide estimates for daily capacity planning needs (aka <em>short term forecasting</em>). The predicted numbers included daily hospitalizations, patients needing ventilation, and ICU admissions. By using this tool, hospitals could better understand and plan for fluctuating demands caused by the virus and avoid equipment shortages.</p>
<p>On the old continent, the <a href=""https://www.covid19dataportal.org/"">European COVID-19 Data Platform</a> sought to enable rapid collection and sharing of research data, in its effort to accelerate coronavirus research. In Paris, a freshly founded research laboratory called <a href=""https://jogl.io/"">Just One Giant Lab</a> puts open-source tools and data at the core of their OpenCovid19 mission: bringing together developers, engineers, data scientists, and healthcare experts for developing low-cost solutions against the pandemic.</p>
<p>Opening up data for scientific research has been the main trend of 2020. From the early days of the COVID-19 spread, John Hopkins University has been making infection data freely available to the world (together with its now popular <a href=""https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6"">interactive dashboard</a>). At the same time, journals and publications started <a href=""https://knowledge.exlibrisgroup.com/Summon/Content_Corner/Supporting_Resources/List_of_COVID-19_and_Temporarily_Free_Resources"">openly sharing their publications</a>, while independent research laboratories became less secretive about their results.</p>
<p>Fighting COVID-19 brought together the open-source (software and hardware) communities to contribute to a greater goal. Whether for assisting front-line workers, for providing governments and policymakers with real-time data, or for research purposes, 2020 has made it clear: open source software and open data are key to collective innovations, especially throughout a global crisis.</p>
<h2>Bring it on, 2021!</h2>
<p>Looking back at 2020 and at the impressive contributions of the tech community, we can draw the following conclusions for the years to come.</p>
<h2><strong>Data quality is extremely important </strong></h2>
<p>We didn’t really need a global crisis to realize this, but here it is. All data science and research efforts against the pandemic shared a common denominator. They all heavily relied on multiple data sources, collected and communicated in real-time. Virus data has powered mobile apps, spread tracking dashboards, and state of the art research. The same data quality rule applied to all of them: garbage in, garbage out. Whenever building data-driven solutions, the quality of the data is the most important aspect of the whole development process.</p>
<h2><strong>Data Science has confirmed its status as a powerful and important discipline</strong></h2>
<p>As Francesca Dominici, the co-director of the Harvard Data Science Initiative <a href=""https://news.harvard.edu/gazette/story/2020/09/harvard-journal-keeps-data-scientists-connected-during-covid/"">puts it</a>: </p>
<blockquote class=""wp-block-quote""><p><em>“I think that the pandemic has definitely increased the appreciation of data science as an important discipline that can help us solve enormous challenges impacting society.”</em></p>
<p><cite>Francesca Dominici, the co-director of the Harvard Data Science Initiative</cite></p></blockquote>
<p>Understanding, acknowledging, and dealing with uncertainty has become part of our daily lives. Given the tough circumstances of 2020, data science and statistical modeling have become go-to tools for understanding and making the right decisions in times of uncertainty. We have all been firsthand witnesses to the various consequences of a global crisis. It is time we acknowledged the power that lies in our hands and to do what the tech community did best in 2020: transform a global challenge into an opportunity for innovation.</p>
<h2><strong>Data-driven innovation will never cease to amaze us</strong></h2>
<p>At the beginning of a new decade, we can come together and truly celebrate innovation. The state of technology has advanced to a point where it truly has the chance to make a difference and impact our lives for the better. </p>
<p>These inspiring use cases keep us in awe and give us trust in the community, the tools, and the overall tech ecosystem. ML, AI, and Data Science have proven themselves as extremely useful tools for humanity and society and the path forward is only following a positive trend: it will only get better, more performant, and more ethical. </p>
<p>Bring it on, 2021!</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/2020-recap-blog-cover-1.png,2020-recap-blog-cover-1.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/2020-recap-blog-cover-1.png,2772,2020-recap-blog-cover-1,,,,https://blueorange.digital/wp-content/uploads/2022/05/2020-recap-blog-cover-1.png,,,,,,,,
2776,"Snowflake and AWS Partnership Update Improves Delivery and Demand Forecasting","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>If you’re an Amazon seller, you know the importance of data to select what products to list on the market. As expenses and savings increase for different products, navigating through market needs and offering exactly what your audience seeks depends heavily on data, and today we have big news on these services!</p>
<p>Snowflake, the advanced data company which is growing at an immense pace, recently <a href=""https://investors.snowflake.com/news/news-details/2022/Snowflake-Extends-Relationship-with-AWS-to-Improve-Demand-Forecasting-and-Delivery-for-the-Consumer-Packaged-Goods-Industry/default.aspx"">announced another update </a>of its partnership with Amazon Web Services (AWS). Sellers in the retail space or consumed packaged goods (CPG) industry now have more data to digest for advanced demand forecasting and better delivery processes. </p>
<p>The announcement states that customers will now be able to bring the data concerning demand forecast generated from Amazon Forecast and Amazon purchase order (PO) together in Snowflake’s Retail Data Cloud. But how does this help businesses and affect their conversions, and what are Retail Data Cloud, Amazon Forecast, and Amazon purchase order data?</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/Ht1RZafoPPWCXaVjOALClD_2q-PrjtVWvVL6BMruMF-sf_al-rqb3yZFKUquBKMoprT7kyGv5ds4vyoEdbL1Fi8EZPrpoDl74f6CR4qUeQwlWOg18uFWImXWUYYlC3BLukgSag8SBJm7HvxV2w"" alt="""" /><br />
<figcaption><strong><a href=""https://investors.snowflake.com/news/news-details/2022/Snowflake-Extends-Relationship-with-AWS-to-Improve-Demand-Forecasting-and-Delivery-for-the-Consumer-Packaged-Goods-Industry/default.aspx"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Understanding Retail Data Cloud, Amazon Forecast &amp; PO</h2>
<p>Retail brands and CPGs won’t have to study data separately anymore. After this announcement, they will be able to pull the data from third-party data providers together with data from Amazon PO into one platform: <a href=""https://www.snowflake.com/"">Snowflake</a>. No more delayed decisions will be taken due to the long periods it takes to move or copy data, and everything will be controlled from a single point in Snowflake known as the Retail Data Cloud. Let’s take a closer examination of it and other elements: </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Retail Data Cloud</strong></h2>
<p>Launched back in March 2022, <a href=""https://www.snowflake.com/blog/snowflake-new-retail-data-cloud/"">Snowflake’s Retail Data Cloud </a>is the result of the unification between Snowflake, its data platform, industry-specific data sets, and partner-delivered solutions. Retailers, distributors, manufacturers, and industry technology providers can utilize their own data and access new data for more data-based decisions.   </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh4.googleusercontent.com/28aeusylq7Xm_5OXR0QJQo_EtMN8fgoXRZaowXXwnrTvgMBpmMLoZefUc0-j6bVMwOvUgKXFq6EEpb-j90PNafWGSBMeDPHUxf6s8qD1z8b0wcHq2KyK1pSnbMvQLw9UJeLG67C7AL6KL8i8Gw"" alt="""" /><br />
<figcaption><strong><a href=""https://docs.aws.amazon.com/forecast/latest/dg/what-is-forecast.html"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Amazon Forecast</strong></h2>
<p>Using the power of machine learning (ML), Amazon Forecast is a fully managed service that produces advanced forecasts and requires minimal to no grasp of machine learning experience to utilize it. This is made possible by feeding historical data and time-series data into it.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Purchase Order (PO)</h2>
<p><a href=""https://www.amazon.com/gp/help/customer/display.html?nodeId=201633590#:~:text=Business%20users%20can%20enter%20PO,shipping%20label%20or%20packing%20slip."">Purchase orders</a> (POs) resemble invoices since they consist of a list of products or services but their distinction from invoices is that they are prepared by buyers entailing what they are seeking to buy. A PO is important for accurate tracking of sales data. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>How Can Businesses Benefit from This Update? </h2>
<p>Rosemary Hua, Global Head of Retail &amp; CPG at Snowflake said that “Amazon.com has revolutionized how retail and CPG businesses sell and deliver to consumers and, similarly, Snowflake has had a profound impact on empowering businesses to optimize their operations and seamlessly collaborate on data. Together, Snowflake and AWS can streamline data-driven inventory management for items sold on Amazon.” A few perks we can name for retail and CPG customers are: </p>
<ul>
<li><strong>Easier Tracking of Changes’ Impact.</strong> In order to stay coherent with the manufacturer's standards, tracking the changes in products dimension and weight is important, and this has now become easier. </li>
<li><strong>PO Importing.</strong> Importing Amazon PO data into <a href=""https://blueorange.digital/why-people-are-excited-about-snowflake/"">Snowflake </a>facilitates the access and shareability of data. </li>
<li><strong>Increased Accuracy. </strong>The integration allows more accurate forecasts thanks to the involvement of machine learning models from Amazon Forecast. </li>
<li><strong>Improve OTIF. </strong>On-time in-full (OTIF) metrics are enhanced for better organic ranking, and an accurate track of product’s stock to lower chargeback expenses. </li>
<li><strong>Increased SKU (Stock-Keeping Unit) Match with Sales. </strong>Vendors are able to match forecasts with SKU sales to avoid revenue loss from a lack of stock for fast-selling products.  </li>
</ul>
<h2><strong>Final Thoughts</strong></h2>
<p>The competitive retail and CPG industry can be challenged only through a data-driven approach, and we believe tools offered by companies like Snowflake can really change the game. The latest announcement helps Amazon sellers make more data-driven decisions that are customer-centric. </p>
<p>As acknowledged partners of AWS and Snowflake, at Blue Orange Digital we have developed data-driven solutions that include predictive analysis, <a href=""https://blueorange.digital/services/#analytics"">machine learning</a>, data transformation, and other data science approaches to steer businesses on their path to steady growth. Schedule a free 15-minutes consultation with us <a href=""https://blueorange.digital/contact-us/"">here </a>to learn how we can help you and your organization.</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Snowflake-AWS-Partnership-Update-Improves-Delivery-Demand-Forecasting-Blue-Orange-Digital.png,Snowflake-AWS-Partnership-Update-Improves-Delivery-Demand-Forecasting-Blue-Orange-Digital.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Snowflake-AWS-Partnership-Update-Improves-Delivery-Demand-Forecasting-Blue-Orange-Digital.png,2777,Snowflake-AWS-Partnership-Update-Improves-Delivery-Demand-Forecasting-Blue-Orange-Digital,,,,https://blueorange.digital/wp-content/uploads/2022/05/Snowflake-AWS-Partnership-Update-Improves-Delivery-Demand-Forecasting-Blue-Orange-Digital.png,,,,,,,,
2781,"Off-the-shelf vs Custom Machine Learning Models?","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2><strong>When is building better than buying an off-the-shelf solution?</strong></h2>
<p>Companies can engage in different approaches to model development. From fully managed ML services, all the way to custom models. Depending on business requirements, available expertise, and planning constraints, they must make a choice: should they develop custom solutions from scratch? Or should they choose an off-the-shelf service?</p>
<p>&nbsp;</p>
<p>For all stages of ML workloads, a decision must be met concerning how the different puzzle pieces will fit together. From data collection, preparation, and visualization, all the way to feature engineering, model training, and evaluation, machine learning engineers repeatedly ask themselves the same question: Will it be a custom implemented solution, written and developed from scratch? Or will it be an off-the-shelf service?</p>
<p>&nbsp;</p>
<p>But when is building better than buying an off-the-shelf solution? The main differentiating factors between the two approaches: preprocessing efforts, development speed, and the required expertise.</p>
<h2>Things to consider when determining to use off-the-shelf or custom machine learning models?</h2>
<p>&nbsp;</p>
<h2>Preprocessing efforts</h2>
<p>&nbsp;</p>
<p>ML projects are facing all kinds of challenges, but perhaps the biggest challenge is the availability of training data. The lack of training data can stop a project before it even starts. Before a project even starts, it can face significant preprocessing costs from collecting data, labeling data, cleaning, and preprocessing efforts. This is the well-known trap in which many ML projects fail: preprocessing ends up taking 80% of the resources allocated, whereas few resources are left for the actual model training and evaluation.</p>
<p>&nbsp;</p>
<p>Off-the-shelf solutions alleviate the strains and pains of preprocessing efforts. They are built to perform the most common operations with only a little configuration required. The best thing about them is: off-the-shelf solutions exist for all stages of ML workloads.</p>
<p>&nbsp;</p>
<p>On the other hand, custom-made implementations usually require more preprocessing efforts. That does not mean that they need to be dismissed entirely: they are still required to finetune a certain ML stage to the specifics of the problem being solved. An especially dirty dataset may require some special kind of cleanup rules. At the same time, a specific feature set may require custom feature engineering, just as neural architectures may require slight adjustments. In this case, custom solutions built from scratch are likely to cover all needs.</p>
<p>&nbsp;</p>
<h2><strong>Development speed </strong></h2>
<p>&nbsp;</p>
<p>Off-the-shelf solutions focus on configuration rather than implementation. Instead of allocating resources to figuring out <em>what</em> should be done, ML teams will focus on <em>how</em> the different puzzle pieces will fit together. This approach allows companies, researchers, and engineers to quickly implement prototypes and proofs of concept. Instead of reinventing the wheel, off-the-shelf solutions make it possible to leverage existing knowledge, thus saving development time.</p>
<p>&nbsp;</p>
<p>Custom-made solutions implemented from scratch are known to be much slower wrt development speed. This is due to their increased maintenance needs: engineers must figure out both the <em>what</em> and the <em>how</em> of the solution. Likewise, the more complex the solution, the more time resources are required to ensure its scalability and availability whilst in production. From this perspective, custom-made solutions and time efforts are directly proportional: the more complex a solution, the more time it will require.</p>
<p>&nbsp;</p>
<p>Usually, however, the truth is somewhere in the middle: an existing codebase will be refactored and adapted to the current project's needs. Such is the case of the well-known transfer learning approach to model training.</p>
<p>&nbsp;</p>
<h2>Expertise</h2>
<p>&nbsp;</p>
<p>Just as there are multiple layers at which Machine Learning is done, there are multiple levels of expertise at which ML models can be developed, ranging from code-free interfaces all the way to building models from scratch.</p>
<p>&nbsp;</p>
<p>Off-the-shelf solutions exist for which very little machine learning expertise is required. By utilizing intuitive interfaces and even drag and drop approaches, it has become extremely simple for anyone (from business analysts to software engineers) to build and deploy some kind of machine learning model. While this simple approach to model development may work for prototyping purposes, it is unlikely to meet the requirements of production systems.</p>
<p>&nbsp;</p>
<p>Expertise is still required to properly configure, set up, and maintain off-the-shelf solutions in production. Workarounds, code-patches, connecting to different API interfaces, and dealing with deployment issues are common tasks required to ensure models’ performance in production environments.</p>
<p>&nbsp;</p>
<p>Custom-made solutions are usually implemented at an infrastructural level and there is no way around it: expertise is definitely required. Depending on the company size and project goals, multidisciplinary teams may be required for maintaining production systems. Data scientists, ML engineers, and business analysts come together to make sense of inference results and maintain production models.</p>
<p>&nbsp;</p>
<h2><strong>What should you use: an </strong>off-the-shelf or custom machine learning model?</h2>
<p>&nbsp;</p>
<p>An ML solution will be built of many individual components and services which need to come together as a cohesive solution. It is never about going 100% custom or going 100% off-the-shelf since different business problems require different solutions. More often than not, ML-based solutions are built by a mix of the two: off-the-shelf services to extract general insights, combined with custom models for increased accuracy and modeling domain-specific knowledge.</p>
<p>The trick is knowing when to implement custom solutions from scratch and which parts of the project can leverage the benefits of off-the-shelf services. This vastly depends on the type of problem being tackled, the business requirements, the data available, and the overall constraints of the development environment.</p>
<p>For more on AI and technology trends, see <a href=""https://www.linkedin.com/in/joshmiramant/"">Josh Miramant</a>, CEO of Blue Orange Digital’s data-driven solutions for <a href=""https://blueorange.digital/cptcasestudies/supply-chain-revenue-predictions-for-pharmaceuticals/"">Supply Chain</a>, <a href=""https://blueorange.digital/cptcasestudies/digital-transformation-of-government-documents/"">Healthcare Document Automation</a>, and <a href=""https://blueorange.digital/cptcasestudies/"">more.</a></p>
<p><strong>You also might like:</strong></p>
<p>&nbsp;</p>
<p><a href=""https://www.unite.ai/6-steps-to-get-insights-from-social-media-with-natural-language-processing/"">Use NLP to classify comments on social Media</a></p>
<p><a href=""https://www.unite.ai/how-language-processing-is-being-enhanced-through-googles-open-source-bert-model/"">How Language Processing is Being Enhanced Through Google’s Open Source BERT Model</a>  </p>
<p>Originally Posted: <a href=""https://www.unite.ai/off-the-shelf-vs-custom-machine-learning-models/"">https://www.unite.ai/off-the-shelf-vs-custom-machine-learning-models/</a></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Off-the-shelf-vs-custom-models.png,Off-the-shelf-vs-custom-models.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Off-the-shelf-vs-custom-models.png,2782,Off-the-shelf-vs-custom-models,,,,https://blueorange.digital/wp-content/uploads/2022/05/Off-the-shelf-vs-custom-models.png,,,,,,,,
2787,"3 Best Machine Learning Models to Predict Customer Lifetime Value (CLTV)","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2>Customer Lifetime Value (CLTV)</h2>
<p>CLTV, the projected revenue of a customer over the lifetime of engagements, is one of the most important metrics that help businesses keep track of their performance. On the customer-facing front, it provides a way to better understand customers and their relationship to the business. Marketing teams have a powerful tool for better channeling their efforts, while sales teams can easily identify and nurture high-value customers. At the same time, CLTV also offers businesses a way to improve their internal decision-making process: from allocating marketing spend, to minimizing potential losses and preventing churning. </p>
<p>Modern CLTV systems are already able to predict future relationships between individual customers and a business. With the advance of predictive modeling, algorithms for estimating CLTV have become increasingly popular and even more so, increasingly powerful. Both research and industry efforts have helped shape large-scale systems that can score hundreds of millions of users on a daily basis. Since CLTV estimations benefit countless business and product use cases, interest in CLTV estimation models is only increasing.</p>
<p>We’ve shortly touched on this topic before, but without giving too many technical details. Back then, we made the distinction between traditional RFM models and machine learning models for calculating the CLTV. We’ve emphasized the importance of <a href=""https://blueorange.digital/marketing-optimization-with-unified-data/"">unified data architectures</a>, which enable ML models. But today we are not talking about data. Instead, we will focus on the ML models that can be used to predict CLTV values.</p>
<h2><strong>1. Clustering Models</strong></h2>
<p>A way to think about the CLTV estimation problem is to frame it as a clustering problem. In this case, the problem is an unsupervised learning problem: there are no labels available for training, meaning that the models will <em>simply</em> learn how to distinguish between different groups of users, depending on the features that represent them. </p>
<p>The features describing each user usually go well beyond their purchase history. Web activity, engagement scores, and even third-party data sources are commonly used for training clustering models. One common challenge when implementing a clustering model arises when the number of features is larger than the number of samples. This is also known as the curse of dimensionality and is likely to result in low model performance.</p>
<p>The prediction of an exact CLTV value for each user is out of scope when tackling CLTV as a clustering problem. However, that does not make the clustering insights any less valuable. Clustering users makes it possible to identify different user segments and to take action accordingly. When looking closely at users within the same group, they are likely to also share common spending habits, which have a direct influence on their CLTV.</p>
<p>A popular approach to clustering is the k-means algorithm. This is provided out-of-the-box by most providers of ML services in the cloud. AWS SageMaker provides an <a href=""https://docs.aws.amazon.com/sagemaker/latest/dg/k-means.html"">improved version of the algorithm</a>, which is optimized to run in a distributed manner on large-scale datasets. One decision that needs to be taken before running the k-means algorithm is the number of clusters. This can depend on various business goals and dynamics.</p>
<p>In the case of the CLTV clustering using k-means, an idea would be to cluster users into 3 different groups: LowCLTV, MediumCLTV, HighCLTV. Knowing that users within the same group share a set of common characteristics can enable more accurate <a href=""https://blueorange.digital/cptcasestudies/marketing-optimization-for-energy-company/"">marketing and sales strategies.</a></p>
<p>But perhaps the most exciting use-case for clustering is to use clustering as a preliminary step before training other machine learning models. Each of these clusters can be assigned a label, and further multi-classification models can be used to classify users into one of the already found clusters. This brings us to a slightly different formulation of the CLTV estimation problem.</p>
<h2><strong>2. Multi-class Classification</strong></h2>
<p>Tackling the CLTV estimation problem as multi-class classification assumes having access to a labeled dataset. This would make the problem a supervised learning problem, in which each user entry in the training dataset has a label assigned to it. Remember the three clusters that we have proposed above? That could be a way to generate labels for an unlabelled dataset.</p>
<p>Another way to generate labels for training data is to define a number of distinct classes and come up with a formula (based on existing user features) that computes a new feature (e.g. called <em>class</em>). By adding that newly computed feature to the dataset, the data becomes labeled and ready for model training. The most common caveat when tackling multi-class classification problems is the so-called class imbalance problem, which happens when some classes are less present in the dataset. This makes it hard for the model to learn the representative features of that class.</p>
<p>Random Forests are a powerful approach to tackling multi-class classification problems (and beyond!). They are not sensitive to missing values and unlike other algorithms, they can handle nonlinear features. However, the results of random forests are not as easily interpretable by humans, since the result is an average built over the outcome of many decision trees. This may make training Random Forests models hard to debug.</p>
<p>Formulating the CLTV estimation as a multi-class classification problem may not be the most appropriate way to formulate the CLTV problem. Since the problem is naturally a regression problem (the goal being to estimate a continuous value), classification usually serves only as an intermediate learning step in multi-stage training pipelines. Also commonly encountered is the practice of chaining multiple models as part of the training phase.</p>
<p>An example of a working industry system is the one <a href=""https://www.kdd.org/kdd2016/papers/files/adf0755-vanderveldAbr.pdf"">implemented at Groupon</a> as early as 2016. They used a two-stage learning system, in which Random Forests were first used for tackling a classification task and then regression (yes, this model can do both). At first, the classification is done to classify between users, predicting whether or not they are going to make a purchase (binary classification). Secondly, regression is done to estimate the exact value of their next purchase but only trained on the dataset with users who have been classified as positive in the first classification task.</p>
<p>Let’s find out more about the state-of-the-art regression models used for CLTV estimation.</p>
<h2><strong>3. Regression Models</strong></h2>
<p>When formulating the problem as a regression problem, we are training models that are meant to learn and predict continuous values. This is the most natural formulation of the CLTV estimation problem.</p>
<p>A high performing algorithm for tackling regression problems is the XGBoost algorithm. This algorithm belongs to a specific class of learning algorithms, known as ensemble learning. The main idea behind ensemble learning is that multiple weak learners are trained, and their predictions are combined before further training more weak learners. This leads to robust and well-performing estimators, which benefit from the weak learners’ ability to cancel out their erroneous estimations.</p>
<p>There are many advantages to using the XGBoost algorithm for regression tasks. It is inherently built for parallel, distributed computation and it is optimized for model performance and computational speed. On top of that, it is open source and provided by all <a href=""https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html"">cloud-based ML service providers</a>. No wonder that the algorithm has been performing well in competitions across a variety of ML tasks: from computer vision to NLP and to speech processing. For CLTV estimation, XGBoost has already been implemented for applications in <a href=""https://dl.acm.org/doi/pdf/10.1145/3167918.3167925?casa_token=mgDokZhN9n0AAAAA:g2H_EZAZ1vmPC9ea_OfKsTLlorrZuqZri_3CkUcIqZ0Ewak9cFHkJs7680_8BYY_rhw_rccVUxc"">gaming</a>, banking, and even in the <a href=""https://link.springer.com/chapter/10.1007/978-981-15-5243-4_12"">telecom and IT sectors</a>.</p>
<p>An important decision that impacts the accuracy of the regression models is the size of the time window that is used for training them. This, once again, depends on various business dynamics and use cases. Some companies may find it relevant to train on historical data going back as much as 2 years. Others may want to train on very recent data, only a few months old. Some may even choose to train and evaluate multiple models. Like this, a better understanding of the seasonality of time series data can be obtained. </p>
<h2><strong>Conclusion</strong></h2>
<p>The Machine Learning methods for solving the CLTV estimation problem continue to evolve and gain interest from both industry and academia. There are different perspectives from which this problem can be tackled, offering businesses the opportunity to model CLTV according to their specific needs and use cases. </p>
<p>However, the choice of the Machine Learning method for solving CLTV estimation needs to take into account the different aspects of the machine learning systems in which it is implemented. Like we’ve seen above, the availability and dimensions of the training datasets, the required accuracy of the predictions, and the integration of the methods with other models are all common decisions that need to be taken. End-to-end machine learning solutions are only precise (and useful) when they directly match the nature of the data they are built on and the nature of the business use cases that need to be improved.</p>
<p>Blue Orange Digital can develop custom machine learning pipelines, adapted to solve your individual business needs and to perform in the most demanding environments. We can deploy large-scale, distributed solutions using state-of-the-art methods and algorithms. Let us explore your data and get in touch with our team of engineers today!</p>
<hr class=""wp-block-separator"" />
<p><a href=""https://blueorange.digital/contact-us/""><em>Schedule 15-min</em></a><em> with a Blue Orange Digital Solution Architect to discuss which option is right for your data sources and future goals.</em></p>
<hr class=""wp-block-separator"" />
<p>Other Resources:</p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><a href=""https://blueorange.digital/marketing-optimization-with-unified-data/""><img class=""wp-image-4310"" src=""https://blueorange.digital/wp-content/uploads/2020/02/Case-Study-Bulk-Cover-Photos-1024x536.png"" alt=""Marketing Optimization with Unified Data"" /></a><br />
<figcaption>Marketing Optimization with Unified Data</figcaption>
</figure>
</div>
<hr class=""wp-block-separator"" />
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img class=""wp-image-6307"" src=""https://blueorange.digital/wp-content/uploads/2020/11/0Josh_-1024x1024.png"" alt="""" width=""177"" height=""177"" /></figure>
</div>
<p>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC.</p>
<p>Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. As an example of thought leadership, Miramant has been featured in IBM ThinkLeaders, Dell Technologies, Global Banking &amp; Finance Review, the IoT Council of Europe, among others. He can be reached at contact@blueorange.digital.</p>
<p>Blue Orange Digital is recognized as a “<strong>Top AI Development and Consultant Agency</strong>,” by Clutch and YahooFinance, for innovations in predictive analytics, automation, and optimization with machine learning in NYC. </p>
<p>They help organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things.</p>
<hr class=""wp-block-separator"" />
<p>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for <a href=""https://blueorange.digital/cptcasestudies/supply-chain-revenue-predictions-for-pharmaceuticals/"">Supply Chain</a>, <a href=""https://blueorange.digital/cptcasestudies/digital-transformation-of-government-documents/"">Healthcare Document Automation</a>, and <a href=""https://blueorange.digital/cptcasestudies/"">more.</a></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Models-for-CLTV-1.jpg,Models-for-CLTV-1.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/Models-for-CLTV-1.jpg,2796,Models-for-CLTV-1,,,,https://blueorange.digital/wp-content/uploads/2022/05/Models-for-CLTV-1.jpg,,,,,,,,
2788,"5 Ways Machine Learning Is Revolutionizing the Energy and Utility Industry","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>The energy sector has seen continuous interest in data-driven solutions for tackling energy consumption, demand, and production problems. The increased popularity of smart sensors and collectors has resulted in massive amounts of data, which in turn has created endless opportunities for modern predictive technologies. Machine learning tools are fast, efficient and accurate and can provide an understanding of most intricate data sources. Businesses in the energy sector have <a href=""https://www.mdpi.com/1996-1073/12/7/1301"">identified</a> this opportunity and leverage their predictive powers for a wide range of applications. Below we list the main benefits of machine learning solutions and back them up with some examples of successful applications.</p>
<h2><strong>1. Increased Malfunction Prevention and Reduced Equipment Downtime</strong></h2>
<p>Machine learning solutions give energy providers a reliable way to monitor the proper functioning of their machines and devices. As part of preventive maintenance measures, algorithms for failure probability modeling are crucial for the immediate detection of potential glitches.</p>
<p>When analytic models are provided with access to baseline functioning conditions and to real-time sensor and tracker data, they become a safe-guard for smooth operations. Once a probable failure is identified, human operators can be alerted and costly mistakes avoided.</p>
<p>Reducing equipment downtime and preventing malfunctioning errors will help prevent massive outages. Also, companies can make decisions based on a solid model that helps them optimize maintenance costs and efficiently use their resources.</p>
<h2><strong>2. Accurate Demand Forecasts </strong></h2>
<p>The ability to forecast demand across consumers is a fundamental aspect of the energy economy. But finding the right balance between supply and demand can be a real challenge, given that massive amounts of data are involved, and that multiple data sources need to be interpreted altogether (e.g. weather and historical consumption data).</p>
<p>Machine learning algorithms have predictive superpowers that allow them to systematically process large amounts of electricity trading data. Modern storage solutions make it possible to easily tackle heterogeneous data sources and the models become more and more accurate with time. The more data they are fed, the better the predictions are.</p>
<p>Accurate demand predictions improve all aspects of demand management. This leads to an optimized energy flow between providers and consumers and to minimize costs on both sides.</p>
<h2><strong>3. Reduced Operational Costs</strong></h2>
<p>There are plenty of areas in the energy sector where machine learning solutions are crucial for improving operational efficiency and thus cutting costs. Applications range from performance monitoring and smart alerting systems to price scheme optimization and forecasting of solar / wind conditions. </p>
<p>Such intelligent solutions can deal with the complex nature of power grid systems and react in real-time to a live data stream. They ensure power grid stability and reliability, they are available 24/7 and require little to no human intervention. Lastly, by modeling the intricate dependencies among various participants (consumers, producers, storage facilities), they bring companies important competitive advantages, that would otherwise be expensive to achieve.</p>
<p>Thus, the aggregation, analysis, and interpretation of energy data translate to increased efficiency for a fraction of the cost.</p>
<h2><strong>4. Informed Business Decisions</strong></h2>
<p>Business decisions backed by quantitative data analysis have become the norm in many industries, thanks to the power of machine learning tools. For some sectors, the complex sources of information are simply not usable without a proper business intelligence platform.</p>
<p>The energy sector is no exception to this rule, given the challenging and sometimes contradictory objectives that need to be cared for. When trying to balance out functional performance, competitive pricing schemes, environmental impact, and grid efficiency, only advanced analytics can help find the right answer. </p>
<p>Machine learning supports informed decision making in multiple areas, from pricing to production and selling. Advanced recommendation systems aid human decision-makers and insights obtained from data can be used by all involved stakeholders.</p>
<h2><strong>5. Better Data Access &amp; Quality</strong></h2>
<p>Building machine learning solutions requires access to large amounts of data. The energy sector is particularly rich in data, but its convoluted nature also makes it hard to interpret.</p>
<p>When energy data is prepared for machine learning, it is usually collected, aggregated and made available for training in storage locations that are optimized for quick access and real-time inference. This also makes it easily accessible for BI and visualization tools. This is a valuable side-effect of machine learning solutions since data access becomes possible to multiple stakeholders, beyond the data science team.</p>
<p>When business intelligence is enabled and available, organizations can be sure they are making informed decisions and have the correct overview of their operational aspects.</p>
<h2>Summary: Energy and Utility Optimization</h2>
<p>Blue Orange Digital has extensive experience developing machine learning algorithms, analytic models and custom big data solutions. We have previously tackled problems in the energy sector (read more about our <a href=""https://blueorange.digital/cptcasestudies/advanced-sensor-analytics-platform/"">advanced sensor analytics platform</a>) and we are always happy to help companies understand the power of their data.</p>
<p>Drop us an email below and let us know about your project!</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/BERT.png,BERT.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/BERT.png,3953,BERT,,,,https://blueorange.digital/wp-content/uploads/2022/05/BERT.png,,,,,,,,
2789,"It’s a Bird, It’s a Plane, It’s a Classified Flying Object","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p><em>How Computer Vision Is Used To Classify Objects. Featuring an in-depth explanation and interview with AiBUY about their computer vision classification applications in retail and eCommerce.</em></p>
<h2>The task</h2>
<p>Image classification is one of the fundamental computer vision tasks. Just as humans can categorize images and objects into distinct classes, different applications require machines to distinguish among different object categories. Given an input image and a set of predefined labels (e.g. {bird, plane, superman}), a classification algorithm should be able to identify image features and assign a class score to the image.</p>
<p>That sounds relatively easy, doesn’t it? Well, yes, until you are reminded of how computers perceive images: as matrices containing numbers. </p>
<figure class=""wp-block-image""><img src=""https://lh3.googleusercontent.com/9HfqTe0C3dYIFpobk7y5hUomolzGXILnI_5l98vnA_Ckq5133SIoxcHARqD2rS5ZvCw5s3M9DiVvy9MBNWFcN6IYwAoVSBgqI0j8gsYfGwbZA2jJXaNJ7a-Ulv7fIJsxD457h6sG"" alt=""The semantic gap: humans can easily perceive image contents and categorize objects. However, algorithms need to deal with image representations and learn meaning based on numbers alone. Impressive, right?"" /><br />
<figcaption><em>Image by Author</em><br />The <em>semantic gap</em>: humans can easily perceive image contents and categorize objects. However, algorithms need to deal with image representations and learn meaning based on numbers alone. Impressive, right?</figcaption>
</figure>
<p>Apart from the semantic gap, there are plenty of other challenges when tackling image classification: background clutter, different illumination settings, and occlusion are just a few. However, thanks to advanced neural network architectures and to largely available computational power, image classification is considered a solved problem. Both machine learning algorithms and deep learning methods provide high accuracy on image classification tasks, <a href=""https://arstechnica.com/science/2018/12/how-computers-got-shockingly-good-at-recognizing-images/"">sometimes</a> even more reliable than humans.</p>
<p>Pretty neat, right? Let us take a closer look at how it all became possible.</p>
<h2><strong>Background &amp; history</strong></h2>
<p>Image classification algorithms have the following goal: they need to identify relevant patterns in images, and to ensure those patterns are discriminative, i.e. can be used to distinguish among different object classes. </p>
<p>Historically, image contents were summarized by so-called feature vectors. These were manually defined, and their extraction was the very first step of a learning pipeline. The hand-crafting of features could be achieved by a variety of algorithms, each responsible for different image aspects. For example, keypoint detectors and descriptors (such as FAST, SIFT, SURF) could represent salient regions in an image, while others aimed to encode texture, shape, or color aspects of the input image. Once these features have been extracted, the image would be represented by a vector, which served as input to the machine learning algorithm.</p>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/d_tT5erbYo-9m8OInvPPK_BIFRWOGWiuK5WK4KM_Qt8iWWf3wk3_6KaeIS7DhuJfj77fjul7rrspj_5QUR0XkWsF9qcNVkw3XQGWde0WdThmjsy8ewuBpThA0dbfMUQndCAFtIgz"" alt="""" /><br />
<figcaption><em>Image by Author</em></p>
<p>Different descriptors are defined for an image, encoding different image aspects. The process is simplified, for the purpose of the illustration. Adapted from: <a href=""https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/"">'Deep Learning for Computer Vision'</a> by Adrian Rosebrock.</figcaption>
</figure>
<p>However, there were a few issues with manually crafting features: first of all, the quality of the extracted features had a direct impact on the performance of the classifier. Secondly, extensive domain knowledge was required in order to assemble discriminative feature vectors. This made the tackling of image classification tasks only available to domain experts that could define relevant class descriptors.</p>
<h2>Convolutional neural networks</h2>
<p>Convolutional Neural Networks do not require the handcrafting of features from input images. Instead, the features are learned automatically throughout the training of the (deep) neural networks. This is made possible by a series of mathematical operations applied to the input image (in the most basic architecture, a series of <em>convolution</em> and <em>pooling,</em> applied in this order). At each layer in the neural network, the input image is transformed into a different representation, which encodes significant features in the image. The first layers of the network learn representations of basic (low-level) features, such as edges and corners. Further down the network, layers output representations of more specific features, corresponding to parts of the object: wheels, windows, eyes, beaks. After the last layer, the representations are high-level and allow a clear separation between different objects: the network has learned to distinguish among the different classes.</p>
<p>The process described above is known as hierarchical feature learning: starting from low-level features and up to high-level features, the convolutional neural networks learn representations of concepts that build on top of each other. This is very similar to how humans perceive objects in their environment: an airplane is built of components (wings, engines, fuselage, landing gear) and those components can be further broken down into distinguishable features.</p>
<p>The architectural design of convolutional neural networks has a few serious implications on the learning process. Firstly, the handcrafting of features can be skipped, since the features can now be learned by the network without any expert intervention. Secondly, the hierarchical learning of features allows the use of advanced training techniques, such as transfer learning.</p>
<h2>Use cases</h2>
<p>Vision systems are some of the most popular digital sensing systems, that are as common in industrial use as they are in daily life. Surveillance cameras, infrared scanning systems, and LiDAR technologies are all built on the capacity to model 2D and 3D environment information. Visual sensing technology lays the foundation for multidisciplinary development, from research engineering projects to large-scale industrial ventures.</p>
<h2>Shoppable on-screen media technology</h2>
<p><a href=""https://aibuy.io/"">AiBUY</a> is an onscreen shopping tool that utilizes computer vision to recognize products within images and videos, in real-time. Currently, they are focusing on the onscreen detection of fashion items and embedding the shopping tool to enable immediate purchase without being redirected or leaving the screen. A user would simply be watching their favorite content when an AiBUY enabled shopping tool would prompt the viewer with purchasing the items in view. </p>
<p>During an interview with AiBUY’s CTO, Ryan C. Scott, he explained how it works, saying, “The AiBUY system is based on a TensorFlow framework and uses Python as the main language. The training dataset holds about 400,000 images with excellent categorical markup, aggregated and prepared with the help of scripts, supplemented by 1,200,000 images of mixed or poor categorical markup quality from external Affiliate Network companies.”</p>
<p>Scott continues with more exclusive behind the scenes on how they built it, saying, “Firstly the focus was on detecting a person and their gender. Secondarily adding various other classes e.g. if a woman, then dresses, blouses, etc,” similar to nested categories on most fashion sites. The detected images are then searched within a given retailer’s integrated catalog and the most relevant products are recommended. Scott explains, “By integrating directly with the retailer’s eCommerce platform, we import and synchronize the product information and ensure data like inventory levels and product variance selections are maintained.” Noting one of the latest improvements was “the use of the Annoy library(by Spotify) to improve the performance functionality in searches of nearest neighbors for product classification.” Nonetheless, as Scott humbly remarks “we are always reviewing our codebase to find potential bottlenecks so we can continuously evolve and adapt to the ever-changing outer world.” </p>
<h2>Ready To Use Neural Architectures</h2>
<p>Multiple deep neural architectures have been used over the years for tackling image classification. The <a href=""http://www.image-net.org/"">ImageNet challenge</a> offered researchers a chance to show the world their architectural breakthroughs: AlexNet, VGGNet, GoogleLeNet. Year after year, the performance of the models got better, and newer models (ResNet, DenseNet) brought up new learning concepts (such as residual learning), which pushed the performance even higher. </p>
<p>Intricate deep architectures have become ubiquitous and are used for state-of-the-art computer vision tasks. But does that mean that they need to be implemented from scratch?</p>
<p>Luckily not!</p>
<p>Ready to use architectures are provided by all deep learning frameworks. <a href=""https://pytorch.org/docs/stable/torchvision/models.html"">PyTorch</a>, <a href=""https://keras.rstudio.com/articles/applications.html"">Keras</a>, <a href=""https://www.tensorflow.org/js/models"">TensorFlow</a> - they all offer alternatives for tackling image classification (and other computer vision tasks). </p>
<p>Both pre-trained models and barebone architectures are available. They can be either fine-tuned to a smaller dataset or trained from scratch when a lot of data is available.</p>
<p>Looking for an image classification solution yourself? Tell us about your image classification trials and tribulations and you could be featured in our next interview series! If you have a specific question that needs more of a personal perspective, <a href=""mailto:contact@blueorange.digital"">get in touch</a>. </p>
<hr class=""wp-block-separator"" />
<p><em>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for </em><a href=""https://blueorange.digital/cptcasestudies/supply-chain-revenue-predictions-for-pharmaceuticals/""><em>Supply Chain</em></a><em>, </em><a href=""https://blueorange.digital/cptcasestudies/digital-transformation-of-government-documents/""><em>Healthcare Document Automation</em></a><em>, and </em><a href=""https://blueorange.digital/cptcasestudies/""><em>more</em></a><em>.</em></p>
<hr class=""wp-block-separator"" />
<p><em>Follow me on </em><a href=""https://twitter.com/BlueOrangeData""><em>Twitter</em></a><em> or </em><a href=""https://www.linkedin.com/in/joshmiramant/""><em>LinkedIn</em></a><em>. Check out my </em><a href=""https://blueorange.digital/""><em>website</em></a><em>.</em></p>
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img src=""https://lh5.googleusercontent.com/dBhC97s6wW8mcamSFSNiYfm2WiBEDBzT-Hezn54EK5qY-VtaAZ0QZv2S1pR-9kFO3QQfRfgCGnSmRMvTAoBf6j7QO8appFG2C5Jl3RIZhWT0HKIaaoCTX-5fBCfMz3Uq1Uj57frR"" alt="""" width=""162"" height=""162"" /></figure>
</div>
<p><em>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things. </em></p>
<p><em>Featured on IBM ThinkLeaders, Dell Technologies, and CUInsight. Recognized as NYC's Top 10 AI Development and Custom Software Development Agencies by Clutch and YahooFinance for his contributions to NLP, AI, and Machine Learning. Specializing in predictive maintenance, unified data lakes, anomaly detection, supply chain/grid/marketing/sales optimization, recommendation systems, among other </em><a href=""https://blueorange.digital/services/""><em>ML solutions</em></a><em> for a multitude of </em><a href=""https://blueorange.digital/industries/""><em>industries</em></a><em>.</em></p>
<hr class=""wp-block-separator"" />
<p><em>Visit </em><a href=""https://blueorange.digital/""><em>blueorange.digital</em></a><em> for more information and to view </em><a href=""https://blueorange.digital/cptcasestudies/""><em>Case Studies.</em></a></p>
<p>Originally Posted on <a href=""https://aibusiness.com/author.asp?section_id=796&amp;doc_id=762282"">https://aibusiness.com/</a></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Semantic-Gap.png,Semantic-Gap.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Semantic-Gap.png,2791,"Semantic Gap",,,,https://blueorange.digital/wp-content/uploads/2022/05/Semantic-Gap.png,,,,,,,,
2895,"How Google’s Open Source BERT Model is Enhancing NLP","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>Bidirectional Encoder Representations from Transformers, otherwise known as BERT; is a training model that has drastically improved the efficiency and effect of NLP models. Now that Google has made BERT models open source it allows for the improvement of NLP models across all industries. In the article, we take a look at how BERT is making NLP into one of the most powerful and useful AI solutions in today's world. </p>
<h2>Applying BERT models to Search</h2>
<p>Google’s search engine is world-renowned for its ability to present relevant content and they have made this natural language processing program open source to the world.</p>
<p>The ability of a system to read and interpret natural language is becoming more and more vital as the world exponentially produces new data. Google’s library of word meanings, phrases, and general ability to present relevant content, is OPEN SOURCE. Beyond natural language processing, their BERT model has the ability to extract information from large amounts of unstructured data and can be applied to create search interfaces for any library.</p>
<p>In this article, we will compare before and after BERT enhanced search results and dissect an application in the energy sector.</p>
<p>BERT (Bidirectional Encoder Representations from Transformers) is a pre-training approach proposed by the <a href=""https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html"">Google AI Language</a> group, developed to overcome a common issue of early NLP models: the lack of sufficient training data.</p>
<p>Let us elaborate, without going into too much detail:</p>
<h2>Training Models</h2>
<p>Low-level (e.g. named entity recognition, topic segmentation) and high-level (e.g. sentiment analysis, speech recognition) NLP tasks require task-specific annotated datasets. While they are hard to come by and expensive to assemble, labeled datasets play a crucial role in the performance of both shallow and deep neural network models. High-quality inference results could only be achieved when millions or even billions of annotated training examples were available. And that was a problem that made many NLP tasks unapproachable. That is until BERT was developed.</p>
<p>BERT is a general-purpose language representation model, trained on large corpora of unannotated text. When the model is exposed to large amounts of text content, it <em>learns</em> to understand context and relationships between words in a sentence. Unlike previous learning models that only represented meaning at a word level (<em>bank</em> would mean the same in “bank account” and “grassy bank”), BERT actually cares about context. That is, what comes before and after the word in a sentence. Context turned out to be a major missing capability of NLP models, with a direct impact on model performance. Designing a context-aware model such as BERT is known by many as the beginning of a new era in NLP.</p>
<p>Training BERT on large amounts of text content is a technique known as <em>pre-training</em>. This means that the model’s weights are adjusted for general text understanding tasks and that more fine-grained models can be built on top of it. The authors have proved the superiority of such a technique when they employed BERT-based models on 11 NLP tasks and have achieved state-of-the-art results.</p>
<h2><strong>Pre-Trained Models</strong></h2>
<p>The best thing is: pre-trained BERT models are open source and publicly available. This means that anyone can tackle NLP tasks and build their models on top of BERT. Nothing can beat that, right? Oh, wait: this also means that NLP models can now be trained (fine-tuned) on smaller datasets, without the need of training from scratch. The beginning of a new era, indeed.</p>
<p>These pre-trained models help companies cut down the cost and time to deploy for NLP models to be used internally or externally. The effectiveness of well-trained NLP models is emphasized by Michael Alexis, CEO of a virtual team-culture building company, teambuilding.com. </p>
<p><em>“The biggest benefit of NLP is the scalable and consistent inference and processing of information.”   - </em><em>Michael Alexis CEO of </em><a href=""https://teambuilding.com/""><em>teambuilding.com</em></a></p>
<p>Michael states how NLP can be applied to culture fostering programs such as icebreakers or surveys. A company can gain valuable insight into how company culture is doing by analyzing the responses of employees. This is achieved not only through just analyzing text but analyzing the annotation of text. Essentially the model also “reads between the lines” to draw inferences on emotion, feel, and overall outlook. BERT can aid in situations such as this one by pretraining models with a basis of indicators that it can go off to uncover the nuances of language and provide more accurate insights.  </p>
<h2>Improving queries</h2>
<p>The capability to model context has turned BERT into an NLP hero and has revolutionized Google Search itself. Below is a quote from the Google Search product team and their testing experiences, while they were tuning BERT to understand the intent behind a query.</p>
<blockquote class=""wp-block-quote""><p><em>“Here are some of the examples that demonstrate BERT’s ability to understand the intent behind your search. Here’s a search for “2019 brazil traveler to USA needs a visa.” The word “to” and its relationship to the other words in the query are particularly important to understanding the meaning. It’s about a Brazilian traveling to the U.S. and not the other way around. Previously, our algorithms wouldn't understand the importance of this connection, and we returned results about U.S. citizens traveling to Brazil. With BERT, Search is able to grasp this nuance and know that the very common word “to” actually matters a lot here, and we can provide a much more relevant result for this query.”<br /></em><em>- <a href=""https://www.blog.google/products/search/search-language-understanding-bert/"">Understanding searches better than ever before</a>, by Pandu Nayak, Google Fellow and Vice Presient of Search.</em></p>
</blockquote>
<figure class=""wp-block-image alignnone size-full wp-image-172304""><img class=""wp-image-172304"" src=""https://www.unite.ai/wp-content/uploads/2020/08/BERT-Search-example.png"" alt=""BERT Search example"" /><br />
<figcaption>BERT search example, before and after. Source <b><i><a href=""https://www.blog.google/products/search/search-language-understanding-bert/"">blog</a></i></b></figcaption>
</figure>
<p>In our last piece on <a href=""https://blueorange.digital/bold-nlp-and-ocr-use-cases/""><strong>NLP and OCR</strong></a>, we have illustrated some NLP uses in the real-estate sector. We have also mentioned how “NLP tools are ideal information extraction tools”. Let us look at the energy sector and see how disruptive NLP technologies like BERT enable new application use cases. </p>
<h2>Applications of NLP in the Energy Sector</h2>
<h2><strong>NLP models can extract information from large amounts of unstructured data</strong></h2>
<p>One way in which NLP models can be used is for the extraction of critical information from unstructured text data. Emails, journals, notes, logs, and reports are all examples of text data sources that are part of businesses’ daily operations. Some of these documents may prove crucial in organizational efforts to increase operational efficiency and reduce costs. </p>
<p>When aiming to implement <strong>wind turbine predictive maintenance,</strong> <strong>failure reports </strong>may contain critical information about the behavior of different components. But since different wind turbine manufacturers have different data collection norms (i.e. maintenance reports come in different formats and even languages), manually identifying relevant data items could quickly become expensive for the plant owner. <strong>NLP tools can extract relevant concepts, attributes, and events from unstructured content.</strong> Text analytics can then be employed to find correlations and patterns in different data sources. This gives plant owners the chance to implement predictive maintenance based on quantitative measures identified in their failure reports.</p>
<h2><strong>NLP models can provide natural language search interfaces</strong></h2>
<p>Similarly, geoscientists working for oil and gas companies usually need to review many documents related to past drilling operations, well logs, and seismic data. Since such documents also come in different formats and are usually spread across a number of locations (both physical and digital), they waste a lot of time looking for the information in the wrong places. A viable solution in such a case would be an <strong>NLP-powered search interface,</strong> which would allow users to look up data in natural language. Then, an NLP model could correlate data across hundreds of documents and return a set of answers to the query. The workers can then validate the output based on their own expert knowledge and the feedback would further improve the model. </p>
<p>However, there are also technical considerations for deploying such models. One aspect would be that industry-specific jargon can confuse traditional learning models that do not have the appropriate semantic understanding. Secondly, the models’ performance may be affected by the size of the training dataset. This is when pre-trained models such as BERT can prove beneficial. Contextual representations can model the appropriate word meaning and remove any confusion caused by industry-specific terms. By using pre-trained models, it is possible to train the network on smaller datasets. This saves time, energy, and resources that would have otherwise been necessary for training from scratch.</p>
<h2><strong>What about your own business? </strong></h2>
<p>Can you think of any NLP tasks that might help you cut down on costs and increase operational efficiency?</p>
<p>The <a href=""https://blueorange.digital/"">Blue Orange Digital</a> data science team is happy to tweak BERT for your benefit too!</p>
<hr class=""wp-block-separator"" />
<p>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for <a href=""https://blueorange.digital/cptcasestudies/supply-chain-revenue-predictions-for-pharmaceuticals/"">Supply Chain</a>, <a href=""https://blueorange.digital/cptcasestudies/digital-transformation-of-government-documents/"">Healthcare Document Automation</a>, and <a href=""https://blueorange.digital/cptcasestudies/"">more</a>.</p>
<hr class=""wp-block-separator"" />
<p><em>Follow me on </em><a href=""https://twitter.com/BlueOrangeData""><em>Twitter</em></a><em> or </em><a href=""https://www.linkedin.com/in/joshmiramant/""><em>LinkedIn</em></a><em>. Check out my </em><a href=""https://blueorange.digital/""><em>website</em></a><em>. </em></p>
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img class=""wp-image-5323"" src=""https://blueorange.digital/wp-content/uploads/2020/05/Josh-Miramant-CEOpng-1024x1024.png"" alt=""Josh Miramant- CEO"" width=""195"" height=""195"" /><br />
<figcaption>Josh Miramant- CEO</figcaption>
</figure>
</div>
<p><em> </em>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He is a serial entrepreneur and software engineer that has built and scaled 3 startups. He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things. </p>
<p>Featured on IBM ThinkLeaders, Dell Technologies, and NYC’s Top 10 AI Development and Custom Software Development Agencies as reviewed on Clutch and YahooFinance for his contributions to NLP, AI, and Machine Learning. Specializing in predictive maintenance, unified data lakes, supply chain/grid/marketing/sales optimization, anomaly detection, recommendation systems, among other ML solutions for a multitude of industries.  </p>
<p>Visit <a href=""https://blueorange.digital/"">blueorange.digital</a> for more information and <a href=""https://blueorange.digital/cptcasestudies/"">Case Studies</a>.</p>
<p>Originally published: <a href=""https://www.unite.ai/how-language-processing-is-being-enhanced-through-googles-open-source-bert-model/"">Unite.AI</a></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/BERT.png,BERT.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/BERT.png,3953,BERT,,,,https://blueorange.digital/wp-content/uploads/2022/05/BERT.png,,,,,,,,
2897,"Executive’s Guide to BI Tools","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2>Data Visualization Software Comparison</h2>
<p>The Blue Orange Guide to BI Tools is meant to give executives and business leaders a high-level overview of the BI tool landscape and help them start on the (potentially tough) journey of choosing the appropriate one for their needs.</p>
<p>We will compare 11 popular BI options for usability, comprehensiveness, affordability, and overall satisfaction. Hear candid and blunt reviews from CEO Josh Miramant and CTO Colin Van Dyke, on behalf of the Blue Orange team’s personal experience working with each tool. Different projects, clients, and data sources call for different feature options, so we have become well versed in each one’s pros and cons over the years. We based our ordering firstly by trusted industry research like Gartner reports, secondarily on our own additional research, and thirdly on our personal experience.</p>
<p>Our engineers and data scientists use these programs daily to consult with clients on their needs and desires for their custom dashboard creations. As you’ll see here, many of the software solutions still require a level of expertise and training to get to the highest levels of performance. Rather than recruit and train highly specialized temporary staff for a project that can be completed in less than a year, get expert help now.</p>
<p>If, after reading this, you are still having a hard time deciding which one will be the best option for your company. Just ask.</p>
<p>If you want us to do the project for you. Just ask.</p>
<h2>Featuring 11 popular BI tool options:</h2>
<ol>
<li><a href=""https://blueorange.digital/executives-guide-to-bi-tools/#Microsoft-Power-BI"">Microsoft Power BI</a></li>
<li><a href=""https://blueorange.digital/executives-guide-to-bi-tools/#Tabeau"">Tableau</a></li>
<li><a href=""https://blueorange.digital/executives-guide-to-bi-tools/#QlikView"">QlikView</a></li>
<li><a href=""https://blueorange.digital/executives-guide-to-bi-tools/#Sisense"">Sisense</a></li>
<li><a href=""https://blueorange.digital/executives-guide-to-bi-tools/#Tibco-Spotfire"">Tibco Spotfire</a></li>
<li><a href=""https://blueorange.digital/executives-guide-to-bi-tools/#Looker"">Looker</a></li>
<li><a href=""https://blueorange.digital/executives-guide-to-bi-tools/#Domo"">Domo</a></li>
<li><a href=""https://blueorange.digital/executives-guide-to-bi-tools/#Google-Data-Studio"">Google Data Studio</a></li>
<li><a href=""https://blueorange.digital/executives-guide-to-bi-tools/#Amazon-QuickSight"">Amazon QuickSight</a></li>
<li><a href=""https://blueorange.digital/executives-guide-to-bi-tools/#Chartio"">Chartio</a></li>
<li><a href=""https://blueorange.digital/executives-guide-to-bi-tools/#Metabase"">Metabase</a></li>
</ol>
<p>-</p>
<p>Business Intelligence tools are crucial for any organization that wishes to leverage data in order to make more informed business decisions. They allow analysts to turn both internal and external data into valuable insights. Moreover, they are an organization’s common platform for using, discussing, and acting on data.</p>
<p>While many features are common across BI products, choosing the proper one depends on a business’s goals and use case. Some may have a need for advanced reporting and easy drag-and-drop data exploration, while others are looking to empower their data scientists with access to complex models. It all boils down to identifying those needs and the relevant features that address them.</p>
<p>Over the past 13 consecutive years, Gartner has performed an annual <a href=""https://www.gartner.com/en/documents/3980852/magic-quadrant-for-analytics-and-business-intelligence-p"">objective assessment</a> of business intelligence platforms. The image below summarizes their 2020 results. Various BI solutions on the market are distinguished according to multiple capability areas, ranging from user experience to advanced visualization support and deployment possibilities.</p>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/1HOyDSjO19akP_0aXHmvHOIpRS5GXHLX6X0a41Xa_aNBZHP5zDktzj7RRJjRPJY7g4lCQxmNbYQjTI2Jrob0mJ2oApUfAUrGe3N3Yuyr3LqmEFrfH87OrK5m7gJXNHn1GIb7InqM"" alt="""" /></figure>
<p>We break down the Gartner ranking and consider the BI solutions (while adding some of our own suggestions) that offer the most support for a full analytics workflow. In this sense, we focus on the following capabilities, which we consider crucial: data source connectivity, support for complex data models and ease of access to advanced analytics.</p>
<p>Let's begin!</p>
<h2>An Executive's Guide to BI Tools</h2>
<h2>Data Visualization Software Comparison</h2>
<h2 id=""Microsoft-Power-BI"">1. Microsoft Power BI</h2>
<figure class=""wp-block-image""><img src=""https://lh4.googleusercontent.com/APKS-BJNxGKQntTV2MBmo_1du1fyQSVRYP57hYMa1OBjqFPG_8IwApCTbqAfd1xUmjIvpR1VLCG_cSkp7t_5x10qTPv97KsqjLspA2o2D15SbFQLSFXJ7--JWZdJ-gHAa-PpVdxX"" alt="""" />
<p>&nbsp;</p>
<p>&nbsp;</p>
<figcaption><a href=""https://www.google.com/url?q=https://powerbi.microsoft.com/en-us/get-started/&amp;sa=D&amp;ust=1585923036160000&amp;usg=AFQjCNErbcnawv8J7kSDwtZIo02VHwK5OA"" target=""_blank"" rel=""noreferrer noopener"">https://powerbi.microsoft.com/en-us/get-started/</a></figcaption>
</figure>
<p>Microsoft proposes a BI solution that can be deployed either in the cloud (on Azure) or on-premise: <a href=""https://powerbi.microsoft.com/en-us/"">Power BI</a>. The tool has gotten <a href=""https://www.gartner.com/en/documents/3900992/magic-quadrant-for-analytics-and-business-intelligence-p"">positive reviews</a> regarding its “ease of use for complex types of analysis.” It comes with out-of-the-box advanced analytical algorithms that enable powerful features such as <a href=""https://docs.microsoft.com/en-us/power-bi/service-insights"">Quick Insights</a>. This gives organizations access to real-time dashboards and visualizations of data events and insights available as they happen.</p>
<p><img class=""wp-image-4645"" src=""https://blueorange.digital/wp-content/uploads/2020/03/Colin-Van-Dyke.png"" alt="""" style=""float: left;"" /></p>
<p class=""has-background has-very-light-gray-background-color"">Blue Orange’s Opinion:<br />“Comparable to Tableau but wins out for me due to the better integration with Azure products. It’s gotten so much better in the last 2-3 years but still carries some legacy bloat. PowerBI has the best Self Service ETL offering of the lot from a technical implementation standpoint. Being the best doesn't mean it’s perfect, it runs into the same problems as the rest of them on more complex data integration jobs. I like the ease of which it can link to Excel, Azure cloud and SQL Server.”</p>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2>Power BI- Pros</h2>
<ul>
<li>Affordability: Free Tier with constant upvoted updates and the paid version is very reasonably priced.</li>
<li>Custom and Interactive Visualizations: You can use Power BI custom visualizations in your reports and dashboards. The range of custom visualizations includes KPIs, maps, charts, graphs, R script visuals, etc. We also can interact with the easy drag and drop visualizations by applying filters, making selections in it, etc.</li>
<li>Data Accessibility, Connectivity, and Integration: It offers data connectivity to data files (such as XML, JSON), Microsoft Excel, SQL Server databases, Azure sources, cloud-based sources, online services such as Google Analytics, Facebook, etc. You can access or embed that data or reports anytime, from anywhere, from any platform and as many times as you want.[<a href=""https://powerbi.microsoft.com/en-us/get-started/"">1</a>] [<a href=""https://data-flair.training/blogs/power-bi-advantages-and-disadvantages/"">2</a>]</li>
</ul>
<h2>Power BI - Cons</h2>
<ul>
<li>Too Basic, yet too complicated. Power BI is the easiest to use BI tool if you are using it simply to import data and create reports. However, it can get confused by complex table relationships, so data models must be carefully created to have more unique fields. Anything beyond creating basic reports requires the user to have more complex knowledge and skill to navigate the crowded user interface of options.</li>
<li>Limited Customizations for Visuals and Formulas: In most cases, you might not feel the need to configure and optimize visualizations in Power BI. But even if you do, users have limited options for what they can change in visuals. Formulas using DAX, are also temperamental and difficult to work with.</li>
<li>Scaling Issues of Large Data Volumes: Power BI has a limit of ingesting data at a time which is approximately 2 GBs of data. If you wish to import and use data of even greater volumes, you need to extend your free version to a paid version of Power BI. Also, users have reported that Power BI takes a little more than usual time or even hangs while processing millions of rows and columns of data. [<a href=""https://data-flair.training/blogs/power-bi-advantages-and-disadvantages/"">2</a>]</li>
</ul>
<h2 id=""Tabeau"">2. Tableau</h2>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img src=""https://lh6.googleusercontent.com/P9kLdYk3yDNlQLZWdiYnScKArzheZUdjdIeqF69ldSuLm4sUcUUQXwxiIQ7lpdSAGFS-uH8rAzHLn49tAyCfH_ovnV925oTFtWJB-CR6FR5_bM3VMyCgl1wfus2BpQbSREXxpolL"" alt="""" /> </figure>
</div>
<p>&nbsp;</p>
<p class=""has-background has-very-light-gray-background-color"">https://www.tableau.com/</p>
<p>One of the most popular BI tools is <a href=""https://www.tableau.com/"">Tableau</a> and its powerful <a href=""https://www.tableau.com/products"">suite of products</a> providing Desktop and Server deployments. Without requiring any coding skills, it enables users to easily access, visualize and manipulate large amounts of data. The wide range of visualization options that go beyond the basic plot types makes it particularly suitable for interactive, rich presentations of data insights. While it does ensure a common platform for all workers in an organization to talk about data, it may not be the right tool for advanced data transformations and pipelines.</p>
<div class=""wp-block-image"">
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img class=""wp-image-6307"" src=""https://blueorange.digital/wp-content/uploads/2020/11/0Josh_-1024x1024.png"" alt="""" width=""177"" height=""177"" /></figure>
</div>
<p class=""has-background has-very-light-gray-background-color"">CEO Josh Miramant</p>
<p class=""has-background has-very-light-gray-background-color"">Blue Orange’s Opinion:<br />“It’s a clear industry leader. Full-featured and capable, but with a healthy layer of bloat. Similar to PowerBI, it’s offering a lot and that comes with complexity. Their dashboard style customization is poor. They also break their product up into confusing tiers, dragging you into upgrades opaque pricing. One example is the Tableau Server vs using custom data patterns. It can be slow with big data volumes. On the positive side, their dashboards are flexible and intuitive. ”</p>
<h3></h3>
<h3></h3>
<h3></h3>
<h3></h3>
<h3>Tableau - Pros</h3>
<ul>
<li>Usability: Tableau Desktop endeavors to do more than make charts, but rather to show “live visual analytics.” A slick interface with drag and drop buttons allows the user to quickly be able to spot trends in the data.</li>
<li>Connectivity: There is a lengthy list of supported data sources, including Microsoft Excel, Google Analytics, Box and PDF files. Tableau enjoys the ability to connect with pretty much any type of database, as well as use a whole range of data blending options, to output into an even bigger selection of charts. Dashboard visualizations can be easily shared, and are mobile-friendly. The package supports establishing connections with several information sources, like HADOOP, SAP and sound unit Technologies, that improves information analytics quality and allows the making of a unified, informative dashboard. Such a dashboard grants access to the desired info for any user, even on their mobile.</li>
<li>Ease of Use: The tool’s intuitive manner of making graphics and an easy interface permit non-dev users to utilize the fundamental app’s practicality to the fullest. Users organize data into catchy diagrams in a very drag-and-drop method that facilitates info analyzing and eliminates the necessity for the assistance of an IT department for pattern building. The strong community forum then fills the gaps and allows users to share their expertise and experience.</li>
<li>Highest Performance: Apart from the Tableau’s high visual image practicality, users rate its overall performance as strong and reliable. The tool conjointly operates quickly even on huge information.</li>
</ul>
<h3>Tableau - Cons</h3>
<ul>
<li>Expensive: Tableau Desktop becomes an expensive option for a single user as it costs $70 per month that is billed on an annual basis, making this more expensive than other competing solutions after the free trial offer. On balance, it also includes the associated application of Tableau Prep under the Tableau Creator package.</li>
<li>Usability: Too Complex. On one hand, the tool provides best-in-class info visual interpretation with limitless potential, on the other hand its reporting capabilities require extensive time and resources to train employees on correct preparation, implementation, and maintenance. Several operations need the creation of SQL queries, that are not possible without the services of a talented developer. Untrained business users will not be as effective without the out help of IT.</li>
<li>Connectivity: The software’s potential to integrate endlessly, comes with security problems, embedment problems, and has restricted capabilities for result sharing. [<a href=""https://www.tableau.com/"">3</a>]</li>
</ul>
<h2 id=""QlikView"">3. QlikView</h2>
<figure class=""wp-block-image""><img src=""https://lh4.googleusercontent.com/CXP5eLc25cEZqN51XfjCrJQF3pxg0qzPG5_dspswUUYYCZCKwk9Rqpl2-1T6eM_8YtcdUpf85vtNAjkBGlEoZ8JnbEgAST3oUpSgkyxM0BRSfTseA5KW_4jmZw05atyUUr9RO4pS"" alt="""" /> </figure>
<p>&nbsp;</p>
<p class=""has-background has-very-light-gray-background-color"">https://www.qlik.com/</p>
<p><a href=""https://www.qlik.com/us/products/qlikview"">QlikView</a> is an all-around analytics solution, complete with advanced reporting and visualization tools as well as hands-on data analysis opportunities. It is based on an in-memory data storage engine that can integrate multiple big data sources and can be deployed either in the cloud or on-premise. It offers extensive support for scalability and integration with other <a href=""https://www.qlik.com/us/products/analytics-products#ValueAddedProducts"">Qlik services</a>, which makes it the “analytics solution that evolves with your business.”</p>
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img class=""wp-image-6307"" src=""https://blueorange.digital/wp-content/uploads/2020/11/0Josh_-1024x1024.png"" alt="""" width=""177"" height=""177"" /></figure>
</div>
<p>&nbsp;</p>
<p class=""has-background has-very-light-gray-background-color"">CEO Josh Miramant</p>
<p class=""has-background has-very-light-gray-background-color"">Blue Orange’s Opinion:<br />“This was my favorite tool to work with until I worked with Looker. QlikView is the most intuitive to build dashboards in and loading data is very smooth. I like QlikView but find the rest of the tools clunky and over engineered. As with most of these tools QlikSense leaves lots to be desired on record linkage and aggregation building. I now prefer PowerBI or Tableau, but QlikView is a whole other thing. It can get sluggish with large data sets.”</p>
<h2>QlikView - Pros</h2>
<ul>
<li>Associative Engine: Advanced data preparation and connectivity allows you to explore data from various angles and to gain new unexpected insights ad hoc.</li>
<li>Visually highlighted dashboards. Dashboards and guided analytics are visually highlighted for the user during the data exploration process</li>
<li>Developer’s platform offers customers the ability to extend QlikView with other products from their portfolio and various tools and resources are provided for developers.</li>
</ul>
<h2>QlikView Cons</h2>
<ul>
<li>Learning curve</li>
<li>Dashboard not comprehensive[<a href=""https://www.edureka.co/blog/tableau-vs-qlikview/"">4</a>]</li>
</ul>
<h2 id=""Sinsense"">4. Sisense</h2>
<figure class=""wp-block-image""><img src=""https://lh5.googleusercontent.com/BSm1dc_Gh0SzKucbWoL_ljsOY5TP05tbgYocui8XjE-nsqxLvn5Cn6l32ziFWB7XVCDPaSenIkW8N6o8zrFYoL1mZFYDAuAing1FQkN6Z1ZRXCAxAJifYqBb5wnbOv0_gUKtGGIF"" alt="""" /> </figure>
<p>&nbsp;</p>
<p><a href=""https://www.google.com/url?q=https://www.sisense.com/dashboard-examples/supply-chain/&amp;sa=D&amp;ust=1585923036160000&amp;usg=AFQjCNEB7aquqHZNa5Ec6Vdpi1hHmwiYIQ"" target=""_blank"" rel=""noreferrer noopener"">https://www.sisense.com/dashboard-examples/supply-chain/</a></p>
<p><a href=""https://www.sisense.com/"">Sisense</a> introduces itself as the “<em>end-to-end BI solution</em>”. On the back-end side, it enables advanced data cleansing, transformation pipelines, and analytics algorithms to be built on top of various data sources. This brings additional flexibility in the way data is being handled, which goes beyond the simple visualizations (but may also require expert knowledge). On the front-end side, it enables business users to create visualizations and quickly spin up reporting dashboards. The Sisense <a href=""https://www.sisense.com/marketplace/"">ecosystem</a> can also be extended with 3rd party tools and integrations, which makes the tool available for a wide range of business use cases.</p>
<h2>Sisense - Pros</h2>
<ul>
<li>Rapid deployment</li>
<li>Incorporates AI</li>
<li>On-premise and cloud-based option.</li>
<li>Sisense works well with large datasets using a columnar database approach without requiring very expensive hardware.</li>
<li>Sisense’s Elasticube™ allows users to take data snapshots.</li>
<li>Dashboards provide users with good widgets, varied chart types, and informative KPI and metrics views.</li>
</ul>
<h2>Sisense - Cons</h2>
<ul>
<li>The Elasticube™ isn’t that user-friendly. It’s difficult to create for the average user and requires a lot of technical expertise. In many cases, users must write SQL code, even though Sisense promotes its “codeless reporting.”</li>
<li>Drains your power, space, and some of your most precious resources i.e. time and money to set up, configure, and coach staff.</li>
<li>Dashboards are only interactive on the web and are not shareable, which amplifies the disappointment that you can’t schedule reports that can be sent via email.</li>
<li>Opaque pricing: Sisense doesn’t publish its pricing on its website anymore, so prospects don’t know how much Sisense’s software costs without contacting them. [<a href=""https://www.yurbi.com/blog/straight-talk-review-of-sisense-the-pros-and-cons/"">5</a>]</li>
</ul>
<h2 id=""Tibco-Spotfire"">5. Tibco Spotfire</h2>
<figure class=""wp-block-image""><img src=""https://lh4.googleusercontent.com/yC_SDjijG4GjVdvMPjJ9VrB8vdgL45o8JbPYznU1_kan9y7lm1pgJLwy23moMPUhcE1p9CXMVPbQ6Gkv06JNH1gG4CAz1pAFyB3PCYlxkIbe9yFAjOQzriM9nTiJhM8kRtEdstsw"" alt="""" />
<p>&nbsp;</p>
<p>&nbsp;</p>
<figcaption><a href=""https://www.google.com/url?q=https://www.tibco.com/products/tibco-spotfire/learn/demos&amp;sa=D&amp;ust=1585923036161000&amp;usg=AFQjCNHx2zW00dG5qlywWDRxRLBZ3UdbhQ"" target=""_blank"" rel=""noreferrer noopener"">https://www.tibco.com/</a></figcaption>
</figure>
<p>TIBCO Spotfire® is a data visualization platform that utilizes predictive analytics. In addition to data viz, it includes data-wrangling capabilities, predictive analytics, location analytics, and real-time streaming analytics.</p>
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img class=""wp-image-6307"" src=""https://blueorange.digital/wp-content/uploads/2020/11/0Josh_-1024x1024.png"" alt="""" width=""177"" height=""177"" /></figure>
</div>
<p class=""has-background has-very-light-gray-background-color"">Blue Orange’s Opinion:<br />“We had a client request Tibco Spotfire for an app which deals with patients' chronic health issues. Our embedded Jasper reports provided insights to care providers. Through that project, I decided that I’ll only use it if I must. I don’t like much about it. It’s capable but opinionated. Their in-memory data processing is much less than necessary. It has clunky APIs and their versioning and documentation is a mess.”</p>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2>Tibco Spotfire - Pros:</h2>
<ul>
<li>Exceptional response</li>
<li>The server is easy to manage.</li>
<li>Single sign-on works seamlessly.</li>
<li>Visualizer.js is strong.</li>
</ul>
<h2>Tibco Spotfire - Cons:</h2>
<ul>
<li>Not as glossy as Tableau.</li>
<li>Poor API</li>
<li>Lacks training and support materials. [<a href=""https://www.trustradius.com/business-intelligence-bi"">6</a>]</li>
</ul>
<h2 id=""Looker""><strong>6. Looker</strong></h2>
<figure class=""wp-block-image""><img src=""https://lh3.googleusercontent.com/Dze0Wi32-tOQWT1WV-Gg8Cd3WIWNJ5nTyqC9RHjJTns0iJmpBzcbgZ404-LNb2Djaf5dDfcBMx7CN3x2IsXvdPKmgSWTBW2jynMgVEHJ8GCnJ-d8269LUOlHsiwpK5rfopEemJVn"" alt="""" />
<p>&nbsp;</p>
<p>&nbsp;</p>
<figcaption><a href=""https://www.google.com/url?q=https://looker.com/blog/how-we-looker-at-looker&amp;sa=D&amp;ust=1585923036162000&amp;usg=AFQjCNHuOJAwcfwapL-in31PVGStTrLMPA"" target=""_blank"" rel=""noreferrer noopener"">https://looker.com/</a></figcaption>
</figure>
<p><a href=""https://looker.com/"">Looker</a> offers a cloud-based BI platform that is most suited for building analytical applications. Native support for cloud analytics databases enables engineers to explore and (re)model data before exposing it to further services and applications. The <a href=""https://looker.com/platform/directory"">looker blocks</a> - pre-built (yet customizable) pieces of code - allow a quick start with different analytics tasks. However, the lack of a point-and-click approach to data modeling <a href=""https://www.gartner.com/en/documents/3900992/magic-quadrant-for-analytics-and-business-intelligence-p"">may limit</a> the adoption of the tool to organizations with an in-house IT department. They were acquired by Google in 2019.</p>
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img class=""wp-image-4645"" src=""https://blueorange.digital/wp-content/uploads/2020/03/Colin-Van-Dyke.png"" alt=""CTO Colin Van Dyke"" width=""177"" height=""177"" />
<p>&nbsp;</p>
<p>&nbsp;</p>
<figcaption>CTO Colin Van Dyke</figcaption>
</figure>
</div>
<p class=""has-background has-very-light-gray-background-color"">Blue Orange’s Opinion:<br />“I love the ease of Looker compared to the bloat of a number of other tools. They have great embedding and template configurations. A close leader with Qlikview, it’s very simple for us but can run into performance issues with big data. It’s also less flexible compared to Tableau or Power BI but this can be it’s benefit. It does most things better and the edge cases are harder to customize for. It focuses on the BI UI and not the data provisioning as much as others, for that reason it’s a great tool to layer on top of a data pipeline. This is my favorite tool in most cases. The biggest downside is the price. It’s a premium product and they price it as such.”</p>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2>Looker - Pros</h2>
<ul>
<li>Usability: Provides data modelling language which helps users study the relationship between different datasets.</li>
<li>Accessibility: The handsome reports, graphs and charts can easily be made and instantly shared via e-mails, URLs, and saved on the cloud.</li>
<li>Robust: It supports more than 25 types of data like<a href=""https://data-flair.training/blogs/sql-tutorial/""> SQL</a>,<a href=""https://data-flair.training/blogs/apache-hive-tutorial/""> Hive</a>, Vertica, BigQuery etc. Playful discovery of data sources, layers, and data manipulation.</li>
<li>Compatible with Mac OS and Windows.</li>
</ul>
<h2>Looker- Cons</h2>
<ul>
<li>Difficult to share data with 3rd party users.</li>
<li>The pricing is somewhat high, but if you are a larger company it might be worth it.</li>
<li>Lacks visualization options and enhanced capabilities with scheduling reports.</li>
<li>Learning curve for how to work with development and live versions of the models. [<a href=""https://looker.com/"">7</a>]</li>
</ul>
<h2 id=""Domo""><strong>7. Domo</strong></h2>
<figure class=""wp-block-image""><img src=""https://lh3.googleusercontent.com/JKI04AYRjLcPFp7D31PjeE8VHfVNIyjvz1VKCn7IpW31d-ZeZMVnjYhZHZJ5cMjM8HkyuEhQAQyHwRpsXkZUZyYv5LeY5u__B9OxEdrvF4VS2HVaD8VqX5xuwlpoZcX2DtvZt8dN"" alt="""" />
<p>&nbsp;</p>
<p>&nbsp;</p>
<figcaption><a href=""https://www.google.com/url?q=https://www.domo.com/roles/marketing&amp;sa=D&amp;ust=1585923036163000&amp;usg=AFQjCNF368ycfE2mKSMGSoKXVnfUlwCWJA"" target=""_blank"" rel=""noreferrer noopener"">https://www.domo.com/</a></figcaption>
</figure>
<p><a href=""https://www.domo.com/"">Domo</a> is the modern analytics platform that offers rapid deployment of intuitive dashboards and is mostly targeted to non-technical users. It offers the <a href=""https://www.domo.com/product/etl-tools"">Magic ETL drag-and-drop</a> which is an example of a simple &amp; intuitive, yet powerful data transformation tool. The ease of use has turned Domo into a <a href=""https://www.gartner.com/en/documents/3900992/magic-quadrant-for-analytics-and-business-intelligence-p"">popular choice</a> for deployment in business lines in isolation from IT. However, since the platform can only be deployed in the cloud, it lacks the offline analysis feature, which may be incompatible with some organizations’ business models.</p>
<h2>Domo - Pros</h2>
<ul>
<li>Intuitive Dashboards: This BI tool consolidates different data sets into a single easy-to-read dashboard with drop-down menus separating individual visualizations.</li>
<li>Automatically suggested BI Visualizations: Go from raw data to charts, graphs, maps, etc., with automatically suggested visualizations. You can refine the data, annotate for further commentary or discussions, or refine and control who has access to it.</li>
<li>Database Connectivity: Drag-and-drop Magic ETL tool enables you to prepare your data with basic to no SQL. Generate multi-dataset reports in a single graphic visualization from a range of database sources securely and easily.</li>
<li>Advanced Analysis: Your Data Scientists are aided by Domo’s AI engine to utilize artificial intelligence, machine learning, natural language processing, etc, to alert and notify about changes in KPIs or create predictive models.</li>
<li>Support: Domo’s open cloud platform is an ecosystem of pre-built apps(or build your own and share it), connector APIs and dashboards.</li>
<li>Mobile Access: The platform offers a native mobile app that offers access to everything you can utilize on the desktop site.[<a href=""https://www.datapine.com/articles/best-bi-tools-software-review-list"">8</a>][<a href=""https://www.selecthub.com/business-intelligence-tools/domo/?from_category=69"">9</a>]</li>
</ul>
<h2>Domo - Cons</h2>
<ul>
<li>Domo is not built for newcomers as the learning curve can be steep, but they do offer training, therefore, be prepared to learn.</li>
<li>Expensive and Nontransparent Pricing: Assume it’s the most expensive solution on our list, according to the available information on the web. [<a href=""https://www.datapine.com/articles/best-bi-tools-software-review-list"">8</a>]</li>
<li>Does not support all SQL queries</li>
<li>Does not fetch real-time data in reports</li>
<li>Does not offer functionalities such as dashboard creation and OLAP</li>
<li>Limited functionality with respect to pivot reports</li>
<li>Users cannot save filters on cards or collections. A new page or subpage has to be created each time there is a card or group for the same filter condition [<a href=""https://www.selecthub.com/business-intelligence-tools/domo/?from_category=69"">9</a>]</li>
</ul>
<h2 id=""Google-Data-Studio"">8. Google Data Studio</h2>
<figure class=""wp-block-image""><img src=""https://lh5.googleusercontent.com/A8ll-rqYkf1o8gB37KL-BAg-jZlgxr-1BG9fyPmifPXEQHyaccStz2OcrgwlwY08TchBs9RRalh0bWosQhc_qdIRR5gabu03N8PqkCxLUxEpg1DFt5UsEdHLYDfY_EZu5rCNanp6"" alt="""" />
<p>&nbsp;</p>
<p>&nbsp;</p>
<figcaption><a href=""https://www.google.com/url?q=https://datastudio.google.com/gallery?category%3Dmarketing&amp;sa=D&amp;ust=1585923036163000&amp;usg=AFQjCNHQJen60WHL8hEgqos5PRMg4sG74w"" target=""_blank"" rel=""noreferrer noopener"">https://datastudio.google.com/gallery</a></figcaption>
</figure>
<p>Google offers a no-charge option for visual analytics: <a href=""https://cloud.google.com/solutions/business-intelligence/"">Google Data Studio</a>, suitable for both advanced and basic use cases. It gives users the opportunity to collaborate (similar to Google Docs) while building data-reports and takes away all IT provisioning worries since it all happens on Google’s secure platform. The seamless integration with other Google services like <a href=""https://cloud.google.com/bigquery#bigquery-ml"">BigQuery ML</a> and <a href=""https://cloud.google.com/bi-engine/docs/"">BI Engine</a> makes it a viable choice for building end-to-end cloud BI solutions.</p>
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img class=""wp-image-4645"" src=""https://blueorange.digital/wp-content/uploads/2020/03/Colin-Van-Dyke.png"" alt=""CTO Colin Van Dyke"" width=""177"" height=""177"" />
<p>&nbsp;</p>
<p>&nbsp;</p>
<figcaption>CTO Colin Van Dyke</figcaption>
</figure>
</div>
<p class=""has-background has-very-light-gray-background-color"">Blue Orange’s Opinion:<br />“Good for rapid prototyping and internal dashboarding. Its best feature is its deep integration with GPC (BigQuery and BI Engine). It’s not really on the same playing field as the others so I’ll leave it brief.”</p>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2></h2>
<h2>Google Data Studio - Pros:</h2>
<ul>
<li>Customize colors, fonts, size, labels, and borders in charts and graphs, then drag and drop into reports that match your brand.</li>
<li>Unlimited data, unlimited pages and metrics with handy features like summary subheadings, easy search, and integrated comments or notes.</li>
<li>Effortless sharing and speed, akin to what you’d expect out of google.</li>
<li>Embed Dashboards into HTML environments by simply copying and pasting the iframe snippet.</li>
</ul>
<h2>Google Data Studio - Cons:</h2>
<ul>
<li>Reports shared online aren’t editable, read-only.</li>
<li>Can’t manage timing frequency of automated reports.</li>
<li>Charts and reports can only be from one data source at a time. No data blends</li>
<li>Developer resources will be needed to automate the data prep and import.</li>
<li>Connects well with other google products to mostly work with marketing and social media data. Other data will have to go through google sheets, which will require a developer.</li>
<li>Limited and average customizable visualizations. [<a href=""https://espacionegocios.com.ar/data-studio-visualizar-informacion-de-negocio-13487/"">10</a>]</li>
<li></li>
</ul>
<h2 id=""Amazon-Quicksight"">9. Amazon QuickSight</h2>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img src=""https://lh4.googleusercontent.com/OTnequHBwXCFcTgwourGz4mdWsZE_zkbxYH9tslcDr891M4bndWbXsLauK5b4zOtF51uC856xBgo2yfH6oxu9BJGWp1okbiTjPtWv8CKIIGuw76FkqoRUePvOnb2hO0Ly7BiC1iV"" alt="""" />
<p>&nbsp;</p>
<p>&nbsp;</p>
<figcaption><a href=""https://www.google.com/url?q=https://aws.amazon.com/blogs/big-data/embed-interactive-dashboards-in-your-application-with-amazon-quicksight/&amp;sa=D&amp;ust=1585923036164000&amp;usg=AFQjCNGcc1Ve9Oy5_aezp9lKC-zvWXQKjA"" target=""_blank"" rel=""noreferrer noopener"">https://aws.amazon.com/blogs/big-data/embed-interactive-dashboards-in-your-application-with-amazon-quicksight/</a></figcaption>
</figure>
</div>
<p>As one of the <a href=""https://blueorange.digital/the-cloud-war/"">top cloud service providers</a>, Amazon also offers cloud-based analytics and a fully managed BI service: <a href=""https://aws.amazon.com/quicksight/"">Amazon QuickSight</a>. It is possible to seamlessly access data from underlying <a href=""https://aws.amazon.com/blogs/big-data/building-securing-and-managing-data-lakes-with-aws-lake-formation/"">data lakes</a> (which, in our opinion, are crucial for modern predictive analytics) and to leverage machine learning models provided by <a href=""https://docs.aws.amazon.com/sagemaker/"">SageMaker</a>. The powerful and scalable calculation engine is the foundation stone of a robust BI architecture while the “pay for what you use” pricing model brings organizations important competitive advantages.</p>
<h2>Amazon QuickSight - Pros:</h2>
<ul>
<li>Usability: Easy integration with one of the world’s leading databases, AWS, and other non-AWS data sources is the real winner here. This lightweight and serverless BI tool can be used for clever and niche dashboards.</li>
<li>Price: Only paying for what you use is very cost effective.</li>
<li>Usability: Good for creating basic reporting by the business user. Start getting your business insights immediately.</li>
<li>Performance: Optimized storage method for fast reporting which can be shared across all users in the account.</li>
</ul>
<h2>Amazon QuickSight - Cons:</h2>
<ul>
<li>Basic: You can not use it as a primary reporting tool as many of the features are missing.</li>
<li>Usability: For complex business reports, users need the help of an IT person.</li>
<li>Access: Sharing reports to other environments or with a 3rd party user is complex.[<a href=""https://www.trustradius.com/products/amazon-quicksight/reviews"">11</a>]</li>
</ul>
<h2 id=""Chartio"">10. Chartio</h2>
<figure class=""wp-block-image""><img src=""https://lh3.googleusercontent.com/ktuJwpa9SoXltt-lyGjks2_BqMB0jsf3_9szJU6VV-6DcHTwbAHeag4mL9fdNm4O2Rv4P1WOsrfV-FbPfvjs3VgaAA5D_W-XRrfGw_e7QzkLwDQ_tkpuVofEDNmDDCjxcNLQgHbr"" alt="""" />
<p>&nbsp;</p>
<p>&nbsp;</p>
<figcaption><a href=""https://www.google.com/url?q=https://chartio.com/product/dashboards/&amp;sa=D&amp;ust=1585923036177000&amp;usg=AFQjCNFzVcQJVYUqhxmQevgO_nVQ_LdcAg"" target=""_blank"" rel=""noreferrer noopener"">https://chartio.com/product/dashboards/</a></figcaption>
</figure>
<p><a href=""https://chartio.com/"">Chartio</a> joins the list of lightweight BI tools with a simple mission statement: make data accessible to everyone within an organization. Data access, exploration, transformation, and visualization are all possible via intuitive drag-and-drop interfaces (it even has a <a href=""https://chartio.com/product/visual-sql/"">visual SQL builder</a>). While some of the functionality may be lacking for power SQL users, the reduced implementation times might be an important advantage for organizations that require agile data insights.</p>
<h2>Chartio - Pros:</h2>
<ul>
<li>Dashboard: A very organized way of tracking data and trends for your company</li>
<li>Support: Great customer service</li>
<li>Usability: Flexible and relatively easy to use without SQL skills</li>
<li>Integrations: It integrates with Segment, so it can pull in data from many other products/platforms.</li>
</ul>
<h2>Chartio - Cons:</h2>
<ul>
<li>Layout outdated</li>
<li>Sometimes some of the pages/reports were a little busy.</li>
<li>Creating dashboards is easy to do, hard to make look good.[<a href=""https://www.getapp.com/business-intelligence-analytics-software/a/chartio/reviews/"">12</a>]</li>
</ul>
<p>&nbsp;</p>
<h2 id=""Metabase"">11. Metabase</h2>
<figure class=""wp-block-image""><img src=""https://lh3.googleusercontent.com/YRrgo5f7iFdRvj1zyzl_fVgwkY_AW0uSRMyOVPP4OAXn-ydZomjmHLTDDyXTzRkAJCzM5PAsKgbPbz5p7uW02SGApza0fyyVqAQe1D518kN7u_d1VLhAn88rGAsb2y5QSl1B3B8K"" alt="""" />
<p>&nbsp;</p>
<p>&nbsp;</p>
<figcaption><a href=""https://www.google.com/url?q=https://www.metabase.com/blog/dashboard-filters/&amp;sa=D&amp;ust=1585923036178000&amp;usg=AFQjCNEZxG3j2D_8GYBR0nXLC9_1E3aErQ"" target=""_blank"" rel=""noreferrer noopener"">https://www.metabase.com/blog/dashboard-filters/</a></figcaption>
</figure>
<p>Looking for an open-source BI solution? <a href=""https://www.metabase.com/"">Metabase</a> is a lightweight yet powerful tool that is optimized for self-hosting (i.e. easy to install, upgrade, and maintain) and thus allows an organization’s analytics workload to live close to its data. With an <a href=""https://www.metabase.com/blog/Hosted-Metabase/index.html"">upcoming cloud version</a> already announced, the deployment options will cover a wider range of business requirements. While no SQL knowledge is required for advanced reporting, some extra tech efforts might be needed for tuning slow data warehouses and optimizing a large number of queries.</p>
<h2>Metabase - Pros:</h2>
<ul>
<li>Clear and intuitive visualizations</li>
<li>Free and open-source with an active developer community</li>
<li>Multiple ways by which you can set up Metabase on cloud platforms</li>
<li>Variety of databases you can connect to</li>
<li>Reminders, or “pulses”, that can be programmatically sent out.</li>
</ul>
<h2>Metabase - Cons:</h2>
<ul>
<li>Local version to quickly get up and running is only available for Mac</li>
<li>Inability to create complex questions without the use of MySQL</li>
<li>No”plug-and-play” connectors you can easily use to integrate data from a SaaS system</li>
<li>Need to do some data mapping to get started. [<a href=""https://blog.anant.us/business-intelligence-tools-we-recommend-1-4-metabase/"">13</a>]</li>
</ul>
<p>&nbsp;</p>
<h2>Which BI tool for your business?</h2>
<p>Picking the right BI tool for your business doesn’t have to be a daunting task! Get expert help picking the right one for your company with Blue Orange Digital, which has just been listed as one of the top software development companies in New York. At <a href=""https://blueorange.digital/"">Blue Orange Digital</a>, our mission is to help companies get a grasp of their data and make it do the work for them. We have vast experience setting up data-centric architectures and implementing modern analytics solutions.</p>
<p>Overwhelmed?</p>
<p>You’re not alone. Many companies we speak with are still developing their BI strategies. The good news: you still have great opportunities to build an advantage with your data. The bad news: your staff may not have the skills and capacity to execute a modern data strategy. <a href=""https://blueorange.digital/contact-us/"">Contact</a> Blue Orange today to discuss your data opportunities.</p>
<p>Expert knowledge is available to you and your team and is only one <a href=""mailto:contact@blueorange.digital"">email</a> away! Don’t hesitate to get in touch, we are always excited to hear about your projects! <a href=""https://blueorange.digital/contact-us/"">Schedule</a> a quick 15-minute discovery call.</p>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Executives-Guide-to-BI-tools.png,Executives-Guide-to-BI-tools.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Executives-Guide-to-BI-tools.png,2898,Executives-Guide-to-BI-tools,,,,https://blueorange.digital/wp-content/uploads/2022/05/Executives-Guide-to-BI-tools.png,,,,,,,,
2922,"Data Architecture: Legacy Edition","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.22.0"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" hover_enabled=""0"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}"" sticky_enabled=""0""]<h2>What is BI?</h2>
<p>Business intelligence is best defined by its end goal: Making better business decisions. In Wikipedia’s parlance, BI “enables more effective strategic, tactical, and operational insights and decision-making” [<a href=""https://www.google.com/url?q=https://docs.google.com/document/d/1wg3DlkMck6NWu_PRicSixpCiRLrNk2Wc1p5KcX4rttg/edit%23heading%3Dh.qgxikwy59nv&amp;sa=D&amp;ust=1568313476407000"">3</a>]. To do this, we need two things: data and a way to understand it.</p>
<h2>Data Architecture Matters</h2>
<p>So, making good, well-informed decisions is the goal. Performing queries, drawing graphs, training models and making predictions are some of the ways of moving towards this goal. But without accurate, accessible, and relevant data there is nothing to apply analytics on. For these tools to be truly meaningful and effective, your whole organization needs to deploy a modern data architecture.</p>
<p>Traditional BI has required businesses to invest in sophisticated infrastructure and expensive development projects, as well as cover the continual support costs to allow it to be reactive to changing business needs. Think having to request a monthly sales report from IT or internally managing a server network, which all too often devolves into <a href=""https://www.google.com/url?q=https://www.youtube.com/watch?v%3DFy3rjQGc6lA&amp;sa=D&amp;ust=1568313476408000"">this</a>.</p>
<p>Major advances in tooling, along with sophisticated data processing, have democratized the job of analytics, moving it from IT to business stakeholders. But let’s start with how the traditional approach to BI data processing evolved.</p>
<h2>Legacy Data Architecture: Evolved System</h2>
<p>This is your brain...on a legacy data pipeline.</p>
<figure class=""wp-block-image""><img class=""wp-image-2337"" src=""https://blueorange.digital/wp-content/uploads/2019/09/etl.png"" alt="""" /></figure>
<p>Figure 1: Legacy Dataflow (Blue Orange Sales team design again)</p>
<p>Figure 1 shows how a typical legacy data pipeline would look. This is usually not planned, but rather the result of evolving business needs. As more and more external services are added, and more independent internal teams make use of the data, the architecture evolves into a complex tangled spider web of data connections. Each team has to figure out what data is available, where to find it, what each column and field actually mean (the data semantics) and do its best (using custom code and legacy ETL software) to pull it all together so they can perform their computations.</p>
<p>This works initially. However, as the company grows it becomes increasingly hard to manage. The process is very error-prone and requires significant, costly coordination and effort from each team. The end result is fragile and inaccurate. If any service, whether internal or external changes at all, the code either breaks or, worse yet, produces inaccurate results.</p>
<p>On top of the architectural and design challenges, today much more data is produced than the systems were initially designed for, further stressing the legacy approach. Traffic is increasing, analytics is becoming more prevalent and information-rich, and media is now ubiquitous (e.g. screenshots, recording mouse movements, images, and video). If that isn’t enough, large third party sources of data, both free and premium, are also needed to enrich internal data sets. Every addition requires more code, more ETL operations, and ultimately much more processing.</p>
<p>Processing all this data cost-effectively is the next challenge. Employing advanced processing on this growing mass data makes server loads difficult to balance. Similar to a power grid, designing computing power to meet peak load requirements means that full utilization only occurs for part of the day or week. The result is expensive server allocations that often sit idle.</p>
<p>Finally, since the data is stored and only made available through proprietary services (designed by and for engineers), leveraging this data relies on direct support from engineering and IT. Any special information, query, or graph required by a decision-maker will need coordination and assistance from an engineer or data scientist. Even data discovery becomes a major hurdle. Management, and even the engineers who run the system, struggle to know what data is available, what data would prove useful, what the data means, and how to access it. The result is simplistic, slow decision making and a slow-moving organization.</p>
<h2>Legacy Challenges</h2>
<p>To summarize the challenges facing a legacy data pipeline:</p>
<ul>
<li>Hard to scale - difficult data discovery, data access, etc.</li>
<li>Error-prone.</li>
<li>Exclusive data access to specialists.</li>
<li>Expensive to maintain.</li>
<li>Redundancy of data and code.</li>
<li>Wasteful and costly computing allocation.</li>
</ul>
<p>&nbsp;</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/evo-of-data-architecture-.jpeg,evo-of-data-architecture-.jpeg,/www/blueorangem_500/public/wp-content/uploads/2022/05/evo-of-data-architecture-.jpeg,2923,evo-of-data-architecture-,,,,https://blueorange.digital/wp-content/uploads/2022/05/evo-of-data-architecture-.jpeg,,,,,,,,
2938,"The Cloud War","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>Ranking of Cloud Service Providers for Machine Learning Solutions</p>
<p><em>“It all happens in the cloud. So that you don’t have to worry about the infrastructure, but focus on the quality of your solution.”</em></p>
<p>The promise made by cloud vendors is as valid now as it was almost two decades ago. With an ever-increasing adoption rate, cloud computing has enabled both users and enterprises in the IT world to leverage powerful infrastructures in a cost-efficient, hassle-free manner. The desire to increase their market share is motivating the providers to continually improve their offers. For the cloud service consumers, this translates to safer, more reliable, and increased performance of their cloud-based solutions. </p>
<p>In the AI sector, businesses of all sizes also benefit from such rapid development of cloud services. AI tools that used to be available only to a few large enterprises are now available to anybody, from the curious student to the experienced engineer. The only requirement is an internet connection!</p>
<p>But the question of which vendor to choose for a cloud-based Machine Learning solution is one that requires thorough research and a deep understanding of what the different ecosystems offer. This ranking guide gives the ML Solution Architect an overview of what we consider to be the most important criteria of reliable cloud service providers. </p>
<p>Since the market share is dominated by Amazon Web Services, Google Cloud Platform, and Microsoft Azure, we are going to focus on them in our comparison.</p>
<h2><strong>1. Availability of specialized hardware</strong></h2>
<p>Let’s start with the obvious. Big Data requires big (if not huge) computational and storage capabilities. Two of the most sought out cloud resources are Compute Instances and Storage Services. GPU based Compute Instances are often required for Machine Learning since GPUs allow massive parallel computation due to their high memory bandwidth. Similarly, storage systems also play a crucial role and are optimized for speed in order to keep up with the processing capabilities of the GPUs.</p>
<p>Since different AI projects have different needs, it is mandatory for the ML Solution Architect to have freedom of choice in the customization of their infrastructure components. Additionally, these resources need to be made available in a dynamic, scale on-demand manner, in order to minimize costs and maximize efficiency.</p>
<p>Since all 3 providers have a vast offer of customization at an infrastructure level, we score a tie for this category. </p>
<h2><strong>2. Availability of pre-configured environments</strong></h2>
<p>Being able to configure custom machine learning infrastructures is a basic need when building scalable data processing systems. However, when experimenting with new algorithms or building custom models, it is not uncommon for ML engineers to want to spin up a pre-configured environment in minutes. We consider this capability to be a truly important aspect. </p>
<p>In this sense, all 3 providers offer pre-configured VM instances that use the latest releases of machine learning (and deep learning!) libraries and which run out of the box.</p>
<p>Google’s <a href=""https://cloud.google.com/deep-learning-vm/"">solution</a> is based on  Debian 9 ""Stretch"" while Microsoft Azure provides <a href=""https://azuremarketplace.microsoft.com/en-us/marketplace/apps/microsoft-dsvm.linux-data-science-vm-ubuntu"">Data Science Virtual Machines</a> based on Linux (Ubuntu 16.04 LTS and CentOS 7.4) and Windows Server 2016. The <a href=""https://aws.amazon.com/machine-learning/amis/"">AWS Deep Learning AMIs</a> are built for Amazon Linux 2018.03, Windows 2016, and multiple Ubuntu 16.04. </p>
<p>The pre-configured VM instances allow rapid prototyping without worrying about software compatibility issues. Just check out which VM images support your favorite data analytics tools and spin up a fresh machine learning environment!</p>
<h2><strong>3. Learnability and Availability of Online Resources</strong></h2>
<p>The consumers of ML cloud services are data professionals responsible for designing, implementing, and maintaining big data solutions. But even the most experienced Data Freak might be left scratching his head when faced with the multitude of cloud services available.</p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-2622"" src=""https://blueorange.digital/wp-content/uploads/2019/11/picture1-1024x607.jpg"" alt="""" /><br />
<figcaption><strong>Confused? Choosing a cloud service for your next Big Data Solution should not be hard! Online resources might be helpful in this matter.</strong><br /><strong>Source: </strong><a href=""http://www.theawsblog.com/""><strong>www.theawsblog.com</strong></a></figcaption>
</figure>
</div>
<p>We consider the availability of online resources to be an important factor in the adoption of a specific provider for your business needs. In the end, this translates to how fast you (or the new Data Solutions Architect in your team) will become productive.</p>
<p>How do the three top cloud service providers aid data professionals to quickly master their ML ecosystems?</p>
<h2><strong><em>Tutorials and Quickstart Guides</em></strong></h2>
<p><a href=""https://cloud.google.com/gcp/getting-started/"">All</a> <a href=""https://azure.microsoft.com/en-us/get-started/"">three</a> <a href=""https://aws.amazon.com/getting-started/tutorials/"">providers</a> make it really simple for engineers to get started with machine learning projects. However, AWS scores a bit better, given its <a href=""https://aws.amazon.com/getting-started/use-cases/"">Use Cases</a> section in which successful big data solutions are showcased, including a thorough overview and step-by-step analysis of their architecture. </p>
<h2><strong><em>Community Forums</em></strong></h2>
<p>The <a href=""https://forums.aws.amazon.com/index.jspa"">AWS Developer Forums</a> is an active platform for professionals to exchange knowledge and help one another. A forum category for each of the provided cloud services makes it really easy to find information. </p>
<p>Similarly well structured is the <a href=""https://social.msdn.microsoft.com/Forums/en-US/home?category=windowsazureplatform"">MSDN Forum</a> where issues related to Azure cloud services are also well categorized. However, the community seems not to be so tight-night and many of the Azure-related topics are spread across multiple online platforms.</p>
<p>The <a href=""https://cloud.google.com/support/docs/groups"">Google Cloud Discuss</a> page on the other hand is still based on the good old Google Groups platform. A bit more digging is required to reach a specific topic since the cloud services are only roughly gathered into topics.</p>
<h2><strong><em>Developer Training Programmes</em></strong></h2>
<p>As of November 2019, <a href=""https://aws.amazon.com/certification/certified-machine-learning-specialty/"">AWS</a> and <a href=""https://cloud.google.com/training/data-ml"">GCP</a> are the only cloud service providers that offer certifications with a focus on Machine Learning. This time Microsoft Azure falls behind with its limited <a href=""https://www.microsoft.com/en-us/learning/azure-exams.aspx"">certification offer</a>. </p>
<h2><strong>4. MLOps Tooling</strong></h2>
<p>“<em>What to do when the DevOp Engineer calls in sick</em>”</p>
<p>Maybe your business is still iterating to reach the most optimized custom ML infrastructure. Or maybe you haven’t hired that certified DevOp Engineer yet. Or even better, you’re sick and tired of the <a href=""https://aws.amazon.com/blogs/machine-learning/deploy-trained-keras-or-tensorflow-models-using-amazon-sagemaker/"">“Undifferentiated Heavy Lifting”</a>.</p>
<p>Does that mean that your Data Science Team has to take a break? No way!</p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-2629"" src=""https://blueorange.digital/wp-content/uploads/2019/11/picture2-1024x725.png"" alt="""" /><br />
<figcaption><strong>Amazon SageMaker is a service that allows management of the full ML model life cycle. Without worrying about infrastructure nor software dependency conflicts!</strong></figcaption>
</figure>
</div>
<p>All vendors offer MLaaS (Machine Learning as a Service) support for continuous ML development: <a href=""http://aws.amazon.com/sagemaker"">Amazon SageMaker</a>, <a href=""https://azure.microsoft.com/en-gb/services/machine-learning-service/"">Microsoft Azure ML Services</a>, <a href=""https://cloud.google.com/ml-engine/docs/technical-overview"">Google Cloud AI Platform</a> (previously “ML Engine”). This allows data scientists to tune, train, and host models without worrying about setting up their virtual environments. They are already installed and usually come with the latest versions of the most popular data science tools. </p>
<p>An exhaustive comparison of the MLaaS services can be found <a href=""https://www.altexsoft.com/blog/datascience/comparing-machine-learning-as-a-service-amazon-microsoft-azure-google-cloud-ai-ibm-watson/"">here</a>. For the purpose of our ranking, however, AWS scores an extra point again: it is the only service that provides <a href=""https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html"">built-in ML algorithms</a>.  </p>
<p>Knowing the differences between the three cloud vendors allows you to make better choices for your next ML endeavor. The following summarizes the above ranking and gives an overview of our criteria.</p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-2630"" src=""https://blueorange.digital/wp-content/uploads/2019/11/picture3-1.png"" alt="""" /><br />
<figcaption><strong>Our criteria for choosing ML cloud service providers.</strong></figcaption>
</figure>
</div>
<p>What do you usually consider when you set up your infrastructure? Let us know in the comments below and maybe we’ll add it to our list :) </p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/article.png,article.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/article.png,2939,article,,,,https://blueorange.digital/wp-content/uploads/2022/05/article.png,,,,,,,,
2944,"Cloud Architecture: Build vs. Buy?","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2>What type of organizations should build their own cloud infrastructure, which should go with a platform like Snowflake?</h2>
<h2>Introduction</h2>
<p style=""font-weight: 400;"">More and more organizations are relying on public cloud services. However, being in the cloud does not mean the same thing for all. Some organizations choose to implement and maintain their own cloud architectures. Others prefer to use entirely managed services, such as Snowflake’s cloud data platform. While the former has complete control over the architectures they are using, the latter enjoy never having to worry about infrastructure maintenance.</p>
<p style=""font-weight: 400;"">So what’s important when considering the <i><em style=""font-weight: inherit;"">“build vs buy”</em></i> decision? Is maintaining your own cloud architecture a way for tech-savvy organizations to flex and show off their skills? Or is it really a must, given managed services’ lack of flexibility? When is one more suitable than the other?</p>
<p style=""font-weight: 400;"">A variety of decision factors need to be accounted for when choosing a cloud-based architecture. We distinguish and discuss the following types of considerations: infrastructure, data, and people.</p>
<h2>Infrastructural Considerations</h2>
<h2><b><strong style=""font-style: inherit;"">Migration Status &amp; Goals</strong></b></h2>
<p style=""font-weight: 400;"">Migrating to the cloud is an iterative process that happens gradually, over time. Organizations find themselves at different levels of cloud adoption, depending on how long ago they have started their journey. The cloud migration is powered by very specific business goals and deciding to build or buy can serve the exact same goals. This is a good time to distinguish and understand the differences between buying and building data architectures for the cloud.</p>
<p style=""font-weight: 400;"">Organizations that find themselves at the beginning of the cloud migration process have the most flexibility in choosing between buying and building. This decision should match the goals of their migration strategy. If they are migrating in order to cut down on maintenance costs, buying a managed service such as Snowflake is likely to help along that direction. By removing the need of maintenance and infrastructure setup, less time and resources will be needed for low-level maintenance.</p>
<p style=""font-weight: 400;"">On the other hand, if the migration goals are to counteract the limitations of on-premise, legacy systems and to develop custom architectures, building and owning a unique data architecture for the cloud is the way to go. Organizations that are already maintaining in-house environments are likely to have resources and expertise for maintaining their own infrastructure in the cloud.</p>
<p>Executive's Guide to BI Tools</p>
<h2><b><strong style=""font-style: inherit;"">Infrastructure Complexity</strong></b></h2>
<p style=""font-weight: 400;"">The complexity of an organization’s data architecture plays a crucial role in their long-term cloud strategy. It determines which cloud services need to be integrated, which tools need to be used, and how much expertise is required for their maintenance.</p>
<p style=""font-weight: 400;"">Simple data architectures usually serve common purposes. They allow the ingestion, transformation, storage, querying, and visualization of data. While on-premise architectures are only limited by technical limitations of the tools being used (such as storage or compute power), in the cloud there are literally no limits to what can be accomplished. The only prerequisite being that these data architectures are built to take advantage of the cloud capabilities. Only then, operational requirements such as scalability, availability, and data protection can be reached.</p>
<p style=""font-weight: 400;"">For the most common data processing purposes, these problems have been solved by tools such as Snowflake. Buying a Snowflake architecture means buying a proven solution that has worked for thousands of other users. Since their cloud data platform is built to make the most out of the cloud, there’s no need to optimize nor try to improve the architecture.</p>
<p style=""font-weight: 400;"">For custom requirements, however, tools like Snowflake may not offer enough flexibility. In that case, it makes more sense to build architectures that serve those specific processing needs. However, such advice needs to be taken with a grain of salt. While simply building an architecture for the cloud may easily be achieved, it’s the maintenance and optimization that make the difference. This all falls under the direct responsibility of your team.</p>
<p style=""font-weight: 400;"">Then other times your organization may not be ready to change too much at once and a custom hybrid work-around solution may get you through till it gets too complicated and expensive to maintain. At some point, it makes more financial sense to update the whole system. If you are here or if you don't know how much you could be saving by switching, get a data audit by Blue Orange Digital, a Top AI Development Partner.</p>
<h2>Data Considerations</h2>
<h2><b><strong style=""font-style: inherit;"">Data sources and types</strong></b></h2>
<p style=""font-weight: 400;"">An architecture’s complexity is directly impacted by the particularities of the data being processed. This includes the different data types being handled, the variety of data sources, and the processes around that data. While these are things that change with an organizations’ evolution, it only makes sense to think about the data considerations in terms of future needs.</p>
<p style=""font-weight: 400;"">Buying Snowflake makes sense when there is a need to handle multiple data sources and multiple data types. By leveraging its data lake technology, Snowflake allows dealing with both structured and unstructured data out of the box. Their data warehouse is also tightly integrated with the data lake and allows quick access to pre-processed data. At the same time, ETL workloads are built to run concurrently, in a distributed manner, while making use of all cloud capabilities. Such functionalities ensure the performance of current AND future data processing pipelines.</p>
<p style=""font-weight: 400;"">Building data architectures makes the most sense when the data sources have a low potential to change in the future. A low number of data sources, few data types, and basic processing requirements should not result in complex services configurations. Since data lakes and data warehouses are still provided by all cloud vendors, they can be coupled together and implemented according to particular wishes. At the same time, this offers more flexibility and the ability to implement custom processing pipelines.</p>
<p style=""font-weight: 400;""><i><em style=""font-weight: inherit;"">See Also: </em></i><i><em style=""font-weight: inherit;"">Is Machine Learning the Right Solution?</em></i></p>
<p>4 Keys to ML Project Success</p>
<h2>People Considerations</h2>
<h2><b><strong style=""font-style: inherit;"">Team size and experience</strong></b></h2>
<p style=""font-weight: 400;"">The availability of engineering staff is the most impactful factor in the decision of buying vs building. Building an architecture is only possible when skills and expertise with different cloud services are available. Similarly, the maintenance and optimization of a cloud platform are only possible when a dedicated team of engineers continually keeps a close eye on the performance of the different services.</p>
<p style=""font-weight: 400;"">Organizations with existing IT departments are most likely to develop expertise for building their own cloud platforms. On the other hand, small companies without any internal IT support are most likely to benefit from buying a managed service such as Snowflake. By reducing the need for maintenance, they can only train (or hire) engineering staff to work on their data and applications. With all the infrastructure needs managed for them, they can still enjoy the benefits of running in the cloud, without the need of handling any operational tools and processes.</p>
<h2><b><strong style=""font-style: inherit;"">Team roles</strong></b></h2>
<p style=""font-weight: 400;"">Skilled IT personnel are needed for a variety of tasks across a cloud data platform. From setting up a cloud architecture to building data transformation pipelines and visualizing data to customizing and connecting different BI dashboard tools.</p>
<p style=""font-weight: 400;"">Since different organizations have different data access requirements, it is mandatory to understand the roles of the different team members. Who needs access to data? Why do they need access to data? Should the data be accessible via code only, or are visualization dashboards also needed?</p>
<p style=""font-weight: 400;"">When building, a significant part of the team is responsible for the conception and the maintenance of the cloud architecture. At first, they need to plan and identify a suitable cloud architecture. Secondly, they need to build, configure, and piece together a variety of tools and cloud services. Last but not least, the team is responsible for the maintenance of the whole architecture, which includes dealing with failures and ensuring operational requirements.</p>
<p style=""font-weight: 400;"">When buying, the team can only focus on accessing, interpreting, and visualizing data. On implementing applications, custom tools, and connecting dashboards that can then be further used by non-technical users. This is one of the most sought after Snowflake benefits: <i><em style=""font-weight: inherit;"">it allows skilled engineers to focus more on extracting business value from data, rather than spend time configuring and maintaining the underlying infrastructure.</em></i></p>
<h2><b><strong style=""font-style: inherit;"">Conclusion</strong></b></h2>
<p style=""font-weight: 400;"">Building a cloud data architecture is not a decision that has an impact on the present only. Instead, it is something that is meant to be reliable in the future and to accommodate both current and future business needs. For this reason, our decision guideline takes you through a few different perspectives that are relevant when setting up a data-centric cloud architecture. Identifying your business needs, internal processes, team growth perspectives, are all factors that will lead to the best decision.</p>
<p style=""font-weight: 400;"">Are you currently deciding whether or not to build your own cloud architecture? Are you considering buying a managed service, like Snowflake? Our team of experienced cloud architects and data engineers can assist you with your decision</p>
<p style=""font-weight: 400;""><a href=""/contact-us/""><i><em style=""font-weight: inherit;"">Schedule 15-min</em></i></a><i><em style=""font-weight: inherit;""> with a Blue Orange Digital Solution Architect to discuss which option is right for your data sources and future goals.</em></i></p>
<p style=""font-weight: 400;"">Josh Miramant- CEO Blue Orange Digital</p>
<p style=""font-weight: 400;"">Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC.</p>
<p style=""font-weight: 400;"">Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. As an example of thought leadership, Miramant has been featured in IBM ThinkLeaders, Dell Technologies, Global Banking &amp; Finance Review, the IoT Council of Europe, among others. He can be reached at contact@blueorange.digital.</p>
<p style=""font-weight: 400;"">Blue Orange Digital is recognized as a “<b><strong style=""font-style: inherit;"">Top 10 AI Development and Consultant Agency</strong></b>,” by Clutch and YahooFinance, for innovations in predictive analytics, automation, and optimization with machine learning in NYC.</p>
<p style=""font-weight: 400;"">They help organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things.</p>
<p style=""font-weight: 400;"">For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for Supply Chain, Healthcare Document Automation, and <a href=""/cptcasestudies/"">more.</a></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Snowflake-Build-vs-Buy.png,Snowflake-Build-vs-Buy.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Snowflake-Build-vs-Buy.png,2946,Snowflake-Build-vs-Buy,,,,https://blueorange.digital/wp-content/uploads/2022/05/Snowflake-Build-vs-Buy.png,,,,,,,,
2964,"How Banks Drive Customer Acquisition and Loyalty With Data Analytics","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>Winning more customers in the financial services industry has never been more challenging. Regulators are investigating companies that engage in questionable sales tactics. Customer skepticism after the 2008 crash has never disappeared entirely. That’s why financial services companies are turning to data strategies. Specifically, there are two critical banking problems you can solve with Big Data.</p>
<h2>The Business Problems You Can Solve In Banking Today</h2>
<p>In banking, there are a few ways you can harness data strategy to drive improvement to the bottom line. First, you can use data strategies to increase customer retention. The longer you retain customers, the greater chance you have for cross-selling, referrals, and ongoing fees. Second, you can optimize your customer acquisition process using data. Let’s take a closer look at how financial services companies are using both of these strategies.</p>
<p>Were you expecting us to mention high-frequency trading? Or AI-powered trading strategies? Those strategies can make a difference. However, we consider them to be second-tier strategies. If you do not have customers, trading more efficiently does not matter.</p>
<h2>Improving Bank Customer Retention With A Data-Driven Customer Experience</h2>
<p>Increasing customer retention has a significant impact on profits.<a href=""https://internationalbanker.com/technology/harnessing-data-analytics-in-financial-services-to-drive-customer-loyalty/""> International Banker</a>, Bain &amp; Co research, reports that “increasing customer retention rates by 5% can increase profits by anywhere from 25% to 95%.” That makes sense when you consider the economies of scale that underpin most banks.</p>
<p>In practice, there are several ways to use data to improve results in banks. Take the time-honored practice of offering special discounts to favored customers. In the context of a customer with a mortgage, checking accounts, a line of credit and more, doesn’t it make sense to offer discounts? Not necessarily. McKinsey reports on a bank that used machine learning to analyze discounts.</p>
<p>The result? The current discount practice was wasteful. According to<a href=""https://www.mckinsey.com/industries/financial-services/our-insights/analytics-in-banking-time-to-realize-the-value""> McKinsey</a>, “Bankers claimed that they offered them only to valuable ones and more than made up for them with other, high-margin business. The analytics showed something different: patterns of unnecessary discounts that could easily be corrected. After the unit adopted the changes, revenues rose by 8 percent within a few months.” Questioning established industry practices in banking is difficult. However, you can use data analytics to raise those questions and drive improvement to the bottom line.</p>
<p>This insight demonstrates that improving customer retention is not always about trying a new idea. Instead, you can also use data strategies to question the effectiveness of traditional banking methods. When you apply data analytics to your customer retention, think broadly! Use it to examine existing practices like discounting and pricing as well as evaluate new ideas.</p>
<h2>Driving Customer Acquisition In Financial Services With Data</h2>
<p>Optimizing revenue and retention with your current customer base is critical. However, banks also need new ways to compete for new customers. Historically, banks have not been shy about spending heavily on sales and marketing. However, the financial services industry continues to be a slow adopter for online channels.</p>
<p>A recent<a href=""https://bankingjournal.aba.com/2020/01/your-2020-marketing-spend-digital-vs-traditional/""> industry study</a> of bank marketing budgets found that “the percent of spend allocated to “online channels” increased 71 percent from 2015 to 2017, from seven percent to 12 percent of total marketing spend. (“Total marketing spend” includes such items as sponsorships, corporate donations, and corporate communications).” Given the efficiency of digital marketing, there is a significant opportunity for banks to increase digital marketing effectiveness.</p>
<h2>Questions that can be answered with ML for your bank:</h2>
<ul>
<li>How do I reduce customer churn?</li>
<li>Which indicators are the leading association to churn?</li>
<li>What tactics work best for customer loyalty programs?</li>
<li>Which incentives convert more people to sign-up?</li>
<li>Which customers are the most valuable?</li>
<li>Which offers appeal best in this city, state, income, or education level?</li>
<li>Which offers appeal best to Joe, Rachel, or Elena?</li>
<li>Knowing a viewer is a repeat website visitor, how do I tailor the landing page?</li>
<li>Which marketing campaigns are working?</li>
<li>Which pay-per-click ad is working?</li>
<li>How do I automate the process to find leads, email them, and get customers?</li>
<li>How much value would it bring to my company to invest in ML?</li>
</ul>
<p><em>Ask Blue Orange Digital, we know the answers.</em></p>
<h2>Use Case</h2>
<p>To illustrate what is possible, take note of how a new digital bank is using an indirect strategy to acquire more customers.</p>
<p>BankMobile,  a digital-only US bank, can acquire customers for a fraction of the industry average. According to a<a href=""https://www.fintechfutures.com/2017/07/case-study-bankmobile-bank-of-the-future-now/""> 2017 profile</a>, “On average, it costs traditional banks $300-500 to acquire a new customer, and for us it only costs $9.” The company’s success lies in offering a distinct, low fee product that stands out compared to other options. However, direct customer acquisition was expensive and caused fraud problems.</p>
<p>The bank uses a “Business-to-business-to-consumer” model to leverage partnerships. In BankMobile’s case, they partner with universities and colleges to acquire new customers. As a result, the company has acquired hundreds of thousands of new accounts. From a data perspective, the bank uses a white-label strategy to monitor the effectiveness of these partnerships. Instead of paying for billboards and TV commercials and hoping for the best, the bank can monitor its customer acquisition costs, fraud, and related indicators easily.</p>
<h2>How Will You Harness The Power Of Data In Financial Services?</h2>
<p>Whether you want to optimize profitability with your current customers or focus on attracting new customers, a data strategy has a role to play. Unfortunately, your existing data warehouses and business intelligence functions are too busy to take on this kind of data project. Contact Blue Orange Digital to discuss how we can improve your bank’s customer retention and acquisition with data.</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Banking-How-banks-drive-customer-aquisition-and-loyalty-with-data-analytics.png,Banking-How-banks-drive-customer-aquisition-and-loyalty-with-data-analytics.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Banking-How-banks-drive-customer-aquisition-and-loyalty-with-data-analytics.png,2965,Banking-How-banks-drive-customer-aquisition-and-loyalty-with-data-analytics,,,,https://blueorange.digital/wp-content/uploads/2022/05/Banking-How-banks-drive-customer-aquisition-and-loyalty-with-data-analytics.png,,,,,,,,
2972,"Why Prediction is So Important For Business","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>Chaos and uncertainty make life hard. In business, they cost you time and money. Without predictable revenue, paying your employees and maintaining customer service becomes tricky. If you cannot make sound financial forecasts, you will spend more on financing. If you can’t predict your maintenance needs, you run the risk of suffering through embarrassing equipment failures.</p>
<h2><strong>The Good News About Predictions In Business</strong></h2>
<p>Over the past few years, a new wave of technologies – Big Data analytics, machine learning, and AI – have emerged to make reliable business predictions easy. A decade ago, those technologies were limited to the largest companies in the world: Amazon, Microsoft, and others with armies of technical talent. Those companies have already done the hard work to make business more predictable.</p>
<p>What’s new is that business prediction technology is now available to every company, including yours. You can take technology off the shelf, plug in your data and start to receive accurate business predictions and forecasts in weeks. Let’s take a quick look at three ways companies are harnessing the power of predictions to produce better results.</p>
<h2><strong>The New Way Companies Are Improving Prediction</strong></h2>
<p><strong>1) Improving revenue by making product recommendations</strong></p>
<p>Amazon has a recommendation engine that predicts the products that customers are likely to order. By analyzing millions of transactions, they have made tremendous advances. Consider Netflix. Customers are more likely to stay on as a paying subscriber if they continue to find relevant content to watch.<a href=""https://martechtoday.com/roi-recommendation-engines-marketing-205787""> Netflix’s recommendation engine</a> accounts for 70% of content viewed on the platform. In essence, it predicts the next product (i.e. TV show, movie, documentary, etc) customers would like.</p>
<p><strong>2) Anticipating employee departure with AI</strong></p>
<p>Recruiting new employees is expensive. A newly hired college graduate might take 6-12 months to become a productive contributor. Further, external recruiters add to the cost by applying fees equivalent to 20-30% of an annual salary to recruit professionals. If companies could predict when an employee was likely to leave, managers would have the opportunity to act differently and retain their star employees.</p>
<p>To solve this problem, IBM has developed technology to predict which employees will leave a company with 95% accuracy. With 350,000 employees, IBM has an extensive global workforce so using AI to understand such a large group is feasible. According to<a href=""https://www.cnbc.com/2019/04/03/ibm-ai-can-predict-with-95-percent-accuracy-which-employees-will-quit.html""> CNBC</a>:</p>
<blockquote class=""wp-block-quote""><p>IBM HR has a patent for its “predictive attrition program” which was developed with Watson to predict employee flight risk and prescribe actions for managers to engage employees. Rometty would not explain “the secret sauce” that allowed the AI to work so effectively in identifying workers about to jump (officially, IBM said the predictions are now in the 95 percent accuracy “range”).</p>
</blockquote>
<p>Fortunately, IBM is sharing this new capability with the marketplace. Companies can purchase AI solutions from IBM (and other companies) so that they can predict employee behavior more accurately. Providing insights about which skills are in demand is one of AI’s key predictions. From the company’s perspective, predicting which skills will be needed means you can focus on training and recruiting activities accurately.</p>
<p><strong>3) Improve supply chain management predictability</strong></p>
<p>When you manage a traditional inventory of products, forecasting your day to day inventory needs is crucial. If you get inventory levels wrong, you will disappoint customers, and they will go elsewhere. For companies with a large number of retail locations and individual products, predicting demand is critical.<a href=""https://www.americanexpress.com/us/foreign-exchange/articles/using-AI-in-supply-chain-management/""> American Express</a> notes that, “market-research firm IDC predicts that by 2020, 50 percent of mature supply chains will use AI and advanced analytics for planning.”</p>
<p>As AI-powered predictions take off in popularity, running out of products during Black Friday sales and other significant promotions may vanish.</p>
<h2><strong>What Steps Will You Take To Bring More Predictably To Your Business?</strong></h2>
<p>Intuition and guesswork have their place, but they cannot be successful on their own. If you are going to retain employees, recommend products to buyers and keep the right inventory, you need AI-powered predictions. To bring this capability to your business, you need to make a few simple decisions.</p>
<p><strong>1. Choose one area to improve with prediction technology</strong></p>
<p>Our research suggests there are two areas you should focus on: sales and marketing and supply chain management. By choosing one area for improvement, you can prove the concept and go from there.</p>
<p><strong>2. Assess your data quantity and quality</strong></p>
<p>For modern business predictions to succeed, you need a significant amount of past data to use as a baseline. To get ready, meet with your IT peers to assess the quality (e.g., percentage of data points without errors or percentage of data which has been verified) and quantity of your data.</p>
<p>Not sure where to get started? There is a way to bring prediction technology to life in your company faster. Contact Blue Orange to discuss ways to bring predictable business practices to your organization.</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/advanced-analytics-3-scaled.jpg,advanced-analytics-3-scaled.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/advanced-analytics-3-scaled.jpg,2973,advanced-analytics-3,,,,https://blueorange.digital/wp-content/uploads/2022/05/advanced-analytics-3-scaled.jpg,,,,,,,,
2981,"Business Intelligence Data Science Prediction","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p><em>E-commerce growth and a worldwide pandemic have brought to light the inefficiencies in the modern supply chain, especially the return process. The current return process is costly, inefficient, and wasteful. The following article explores how enabling efficient returns through reverse supply chain development can bring savings and operational improvements.</em></p>
<p>Most companies are failing to get the most out of their reverse supply chain - the flow of goods back to them in the form of returns and recycling.  This is an important area to optimize because approximately<a href=""https://www.supplychainquarterly.com/topics/Strategy/201201reverse/""> 20% of all products</a> purchased in the U.S. are returned to the manufacturer. Fortunately, there are still big wins available in supply chain management, but you need a new opportunity.</p>
<p>In the automotive industry, managing reverse supply chains is a significant challenge due to the volume of vehicle returns. Over 5 million cars were subject to recalls in 2019, according to<a href=""https://www.cars.com/articles/the-10-biggest-recalls-in-2019-416480/""> Cars.com</a>. While recalls affect nearly all brands to some degree, some companies have better success in addressing these problems. A <a href=""https://www.nhtsa.gov/sites/nhtsa.dot.gov/files/documents/18-3122_vehicle_safety_recall_completion_rates_report_to_congress-tag.pdf""> U.S. Department of Transportation report</a> found that Chrysler had the most effective remediation rates in several areas, such as parking brake recalls. When you improve your reverse supply chain effectiveness, you will suffer less waste and a more significant opportunity to sell refurbished products.</p>
<h2>Reverse Supply Chain Technology: 3 Quick Wins</h2>
<p>Manually tracking and managing the reverse supply chain is no longer good enough. A manual approach means you will not generate meaningful data and measurements, making it practically impossible to improve your results. By applying data analytics technology to your supply chain, you can achieve wins in three areas.</p>
<ul>
<li><strong>Reduce returns due to errors and mistakes.</strong> Some customers will return products if the delivered product does not match their expectations. For example, you might deliver a product in the wrong size or color. Technology cuts this reverse supply chain in two ways. Add validation rules during the ordering and fulfillment process means cutting delivery errors at the front end. On the other hand, you can use analytics to better understand the remaining error returns you have.</li>
<li><strong>Speed up movement through the reverse supply chain.</strong> In specific industries like consumer electronics, products quickly lose value over time. In research reported in the<a href=""https://www.researchgate.net/publication/275247814_Reverse_Supply_Chains_for_Commercial_Returns""> California Management Review</a>, “ $1000 of product returns nearly half the asset value (&gt;45%) is lost in the return stream.” Further, time delays in processing returns cause products to lose 10-20% of their value. If you have a significant amount of secondary sales (e.g., refurbished sales), speeding up the reverse supply chain means you can sell more products at higher prices.</li>
<li><strong>Reduce fraud expenses associated with returns.</strong> Unfortunately, fraud is a significant problem with returned products. In the retail industry, “Annual losses from merchandise return fraud are estimated at $27 billion” in 2019, according to<a href=""https://www.globenewswire.com/news-release/2020/01/13/1969700/0/en/NEW-REPORT-FINDS-RETAIL-RETURNS-TOTALED-309-BILLION-IN-2019-IMPACTING-STORES-AND-ECOMMERCE.html""> Appriss Retail research</a>. This fraud expense can be reduced by improving product tracking throughout the shipping and handling process.</li>
</ul>
<p>Better technology means that you can track each product individually as they flow through the return process. As a result, you can pinpoint time delays (e.g., product sits in a warehouse for a week). By gathering better data through RFID tags and GPS, it is possible to identify fraud better. Increasing speed and reducing fraud are two of the most important ways to improve your supply chain. </p>
<p>As stated by Transfix Co-Founder Drew McElroy advanced technologies such as AI, ML, and prescriptive analytics are integral to achieving optimal efficiency within today's supply chain. These technologies allow for high visibility into the supply chain through passive data capture, anomaly detection, and intelligent learning. </p>
<p><em>“The most important ideas for improving today's supply chain and the supply chain of the future are passive data capture, exception management, and intelligent learning. These technologies allow for high visibility, automatic problem resolution, and a system that learns and becomes better with time.”</em></p>
<p><em>-Drew McElroy, Transfix</em></p>
<figure class=""wp-block-image""><img class=""wp-image-5643"" src=""https://blueorange.digital/wp-content/uploads/2020/08/Blog-Format-1024x576.png"" alt=""Reverse Supply Chain"" /><br />
<figcaption>Reverse Supply Chain</figcaption>
</figure>
<h2>How To Achieve These Results: Reverse Supply Chain 1.0 vs. 2.0</h2>
<p>At its most basic level, a reverse supply chain guides a product through a sequence of steps. Start with a simple process - Supply Chain 1.0. In this process, the first step starts with a trigger event (e.g., customer dissatisfaction with the product or product recall). The second step is logistics - transporting the product back to your company. The third step is inspection: assessing the value of the item (i.e., automotive companies often extract specific parts from returned vehicles and resell them). The final step is a disposition - finding a home for the returned product (e.g., landfill, partial recycling, or resale).</p>
<p>Let’s assume that you cannot create new manufacturing processes or equipment. Instead, you need to get everything you can out of what you already have. Data analytics and machine learning can help.</p>
<h2>Prediction</h2>
<p>To make the most of your limited supply chain resources, you need to make better predictions. For example, if you have a network of 5 warehouses across the country, a <a href=""https://towardsdatascience.com/artificial-intelligence-in-supply-chain-management-predictive-analytics-for-demand-forecasting-80d2d512f155"">random forest algorithm</a> can help you better forecast demand and return volumes. With that information, you can contract for increased trucking capacity and avoid products sitting in your warehouse for long periods. This will help companies optimize their assets, enable more on-time deliveries, and effectively manage storage capacity.</p>
<h2>Anomaly detection</h2>
<p>In a reverse supply chain context, anomaly detection helps to find patterns in product defects and then improve your operations accordingly. For example, let’s say your company processed 10,000 returns last month. With anomaly detection, you can quickly identify the most expensive types of returns. A long short-term memory network (i.e., LSTM Network) is a useful tool to compare data across different time series like comparing Q4 2019 to Q4 2018. This approach is helpful if your return volumes are relatively stable. </p>
<h2>Optimization</h2>
<p>Growth modeling is another area where machine learning algorithms can process immense amounts of data from multiple sources and improve optimization. It can be used to help determine the best locations for future warehouses, the best vendors to work with, the best routes to take, and automate many paperwork processes. You can even automate a <a href=""https://blueorange.digital/the-way-to-use-dynamic-pricing-in-ecommerce/"">dynamic pricing model</a> to boost profits on each item sold. Even more solutions are being developed daily from drone management in retail and warehousing, to computer vision-enabled conveyor systems, and multi-sensory 5G location and condition trackers. Advanced analytics and integration support each of these components of complete supply chain management.</p>
<h2>Advanced analytics and integration</h2>
<p>Advanced analytics extend every business’s reach, enabling new product forecasting, demand, and ROI, taking into consideration more variables than ever before. In tandem, integration to e-commerce sites, marketing information, and current product and financial tracking systems is critical to understanding the big picture as the development of a modern supply chain is underway. </p>
<p>These ways to optimize and automate the supply chain are often forgotten when applied in reverse, but critical to the bottom line.</p>
<h2>Where To Go From Here In Optimizing Your Reverse Supply Chain</h2>
<p>Data can be the obstacle or the solution to all these potential benefits. Fortunately, experts-for-hire on this are easy to reach. Blue Orange Digitial, a top-ranked AI development agency in NYC, specializes in cloud data storage solutions and facilitates the development of supply chain optimization. They provide custom solutions to meet each business’s unique needs, but also many pre-built options for supply chain leaders. From a technology point of view, we have outlined several different ways to improve the efficiency of the reverse supply chain. Taken together, these improvements give you Reverse Supply Chain 2.0.</p>
<p>Originally Published: <a href=""https://www.predictiveanalyticsworld.com/machinelearningtimes/why-machine-learning-is-central-to-reverse-supply-chain-2-0/11569/"">https://www.predictiveanalyticsworld.com/machinelearningtimes/why-machine-learning-is-central-to-reverse-supply-chain-2-0/11569/</a></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Reverse-Supply-Chain.jpg,Reverse-Supply-Chain.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/Reverse-Supply-Chain.jpg,2982,Reverse-Supply-Chain,,,,https://blueorange.digital/wp-content/uploads/2022/05/Reverse-Supply-Chain.jpg,,,,,,,,
2988,"The Evolution of Data Architecture: Intro","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>In the beginning, God created the heavens and the earth...which happened to spin off massive amounts of data. Man took that data and started using it to make business decisions. In order to effectively understand the past and make accurate predictions for the future, this data needed to be stored and processed. Thus data architecture came to be. </p>
<p>Allegories aside, we live in an era where data-driven decisions are becoming both requested and required, and the tools to make them increasingly democratized. From machine learning algorithms and neural nets to a simple dashboard built in Google Sheets, finding ways to assemble, visualize and make effective predictions with data is now within the purview of everyone. This access has increased the competitive pressures on both quality and timeframe. We can now quickly ask and answer questions from knowing your daily step count to dynamically pricing e-commerce products that would have required a herculean effort (or been impossible) even a few decades ago. </p>
<p>But underpinning all of these advances and expectations are data architectures and engineering. And the quality and coherence of these architecture patterns will make or break any attempt at advanced analytics.</p>
<h2>Where we're going</h2>
<p>Making good, well-informed decisions is always the end goal. Performing queries, drawing graphs, training models and making predictions are some ways of moving towards this goal. But for these tools to be truly meaningful and effective in a business context, your whole organization needs to deploy a modern data architecture.</p>
<p>A modern data architecture has reliable, accurate data pipes running all the way from the user fumbling through your web site, to adding third party information and services into the mix, conducting analysis, joining disparate data sources, performing enrichments, distributing that data to internal servers, training and deploying machine models, and finally pulling all this data together again to allow the decision-maker to interact, visualize, query and explore it in order to make the best choice.</p>
<p>The basic data lifecycle process looks like this. Specific data is collected, modeled, transformed, and visualized to be put in an actionable business context.</p>
<figure class=""wp-block-image""><img src=""https://docs.google.com/a/blueorange.digital/drawings/d/szTOLxz695-9onmVz521CQw/image?w=624&amp;h=133&amp;rev=1&amp;ac=1&amp;parent=15tfbJQTPjx_GL1dyXFwf_HmCbxUXEX6xoJgz94QA4d0"" alt="""" /></figure>
<p>Figure 1 - High-level overview of data life cycle created by the Blue Orange Sales Team</p>
<p>Or to get more pretty and complicated, here’s a diagram of how we implement the modern data lake pattern:</p>
<figure class=""wp-block-image""><img src=""https://lh3.googleusercontent.com/_049xzIBLFv8Qa3-cHp6VC4Ts4hXK_ejqsWEwfIoMHilNd9ujRB69EVWZ9UKSKgzYiE49aEtOkOpmACEubJbVLzitAFMdlMcfdC8HM3UPoESAaLNIBa74SbWtCPG97cGw6qkM0AZ"" alt="""" /></figure>
<p>Figure 2 (Data Lake Process created by Blue Orange Designers. The people that would actually build your custom dashboards).</p>
<p>So let’s explore, starting with the traditional approach to organizing business intelligence data.</p>
<p><strong><a href=""/contact-us/"">Contact us today!</a></strong></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/evo-of-data-architecture-2-scaled.jpeg,evo-of-data-architecture-2-scaled.jpeg,/www/blueorangem_500/public/wp-content/uploads/2022/05/evo-of-data-architecture-2-scaled.jpeg,2989,evo-of-data-architecture-2,,,,https://blueorange.digital/wp-content/uploads/2022/05/evo-of-data-architecture-2-scaled.jpeg,,,,,,,,
3003,"The 5 Senses of Sensors","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<h2><em>How IoT is able to replicate and manufacture the 5 senses and beyond. Featuring interviews with VANTIQ, Sensome, Pensa Systems, Naked Labs, Genki Instruments, Tanvas, and Microshare.</em></h2>
<p>Sensing technology has become so mature that it is now indispensable to modern life as we know it. Advanced sensor networks are used in many different fields and are undergoing continuous development. Due to <a href=""/services/#technologies_sec"">AI technologies</a>, sensor devices are becoming increasingly intelligent, being able to communicate with one another and develop autonomous behavior. Some even do computing on the edge. By collecting data from homes, buildings, and vehicles, sensors shape a digital version of the environment in which they operate. Like this, they enable applications in literally every existing industry.</p>
<p>Sensing technology spans over all the 5 core human senses, and beyond. Let’s break down digital sensing technology and some of its applications.</p>
<h2>See</h2>
<p>Vision systems are some of the most popular digital sensing systems, that are as common in industrial use as they are in daily life. Surveillance cameras, infrared scanning systems, and LiDAR technologies are all built on the capacity to model 2D and 3D environment information. Visual sensing technology lays the foundation for multidisciplinary development, from research engineering projects to large-scale industrial ventures.</p>
<p>Algorithms that can process visual sensor data enable countless applications. Security systems perform live motion detection, face tracking, and identity recognition. Similarly, self-driving cars assess trajectory in real-time and estimate pedestrian intentions. <a href=""/services/"">Algorithms</a> and visual sensing technology work hand in hand and create opportunities for innovation and development of increasingly mature software products.</p>
<p><a href=""https://vantiq.com/vantiq-use-cases/safety-and-security/"">VANTIQ</a> offers visibility into COVID19 back-to-work safety and security solutions based on real-time video analysis. David Sprinzen, Director of Product Marketing at VANTIQ explains, “intelligent security cameras can flag suspicious activity in real-time, this removes the need for tedious &amp; time-consuming assessment of video footage, mitigating the risk of exposure and contact with threatening persons.” Similarly, their pre-built components —symptom detection, physical distancing, contact tracing, access management, safety compliance, and asset monitoring— enable software developers to rapidly build real-time applications that span a wide range of use-cases and industries. The modern software stack gives end-users easy access to a live monitoring dashboard. Their security solution provides an elegant interplay of visual sensing, hardware, and software capabilities.</p>
<p><a href=""https://www.sensome.com/"">Sensome</a> engineered a micro-sensor that can identify biological tissues instantly, aiding doctors with real-time decisions in assessing and treating blood clots. Sensome CEO and Co-Founder, Franz Bozsak, explains that “their micro-sensor technology integrated with a guidewire can accurately identify blood clot composition by tiny emitted electrical fields. Machine learning algorithms then analyze sensor collected data in real-time and provide doctors with a reliable measure for choosing their intervention tools.” Clinical trials are expected to begin in 2021. This technology has disruptive potential across multiple medical fields, such as ischemic stroke, interventional cardiology, and oncology. Accuracy and success rates of different approaches will be monitored and through machine learning, they will be able to recommend the best retrieval method. In this way, connected medical devices are offering visibility to better patient management.</p>
<p><a href=""https://www.pensasystems.com/"">Pensa Systems</a> uses computer vision drones to manage retail inventory autonomously, helping solve the $1T problem of stockouts. Their drones scan shelves and use AI machine learning to visually recognize individual products automatically, which is a huge upgrade from the clipboard method typically deployed in supermarkets. Mobile phone camera sensors can feed the same automated processing. As Richard Schwartz, CEO of Pensa Systems puts it, ""the goal is to minimize stockouts, optimize product planning, and ultimately increase revenue."" They boast an accuracy rate of 98% for detecting out-of-stock items, Schwartz continues, ""even when tested in more challenging scenarios, like correctly identifying items among competing brands for the same type of product like, Heinz versus French's Mustard or regular soy sauce versus low sodium."" The next phase as Schwartz puts it, will be “roverizing, which achieves scale through substituting what would have been thousands of separate fixed-location sensors or things that had to be collected individually, into one autonomous IoT roving robot that just goes out learns and reports.”</p>
<p><a href=""https://nakedlabs.com/tech"">Naked Labs</a>, who combine data from multiple sensors for their home 3D body scanner to extend the human sense of vision to a new inner perspective of the body’s composition. In order to achieve a 360 degree, head-to-toe body scan, the solution relies on “over 4 million data points stitched together, creating a 3D model of your body with accuracy up to five millimeters in 60 seconds,” explains Thomas Ward, UX Researcher and Head of Customer Experience at Naked Labs. He continues, “Measurements of stereo wave echoes between you and the mirror, essentially create a topographical map of your body. Then circumferences from the 3D scan are used to calculate DXA-based body fat. Providing a digital perspective like never before to discover and track progress.”</p>
<h2>Hear</h2>
<p>Audio sensing technology is as ubiquitous in day to day life, as it is in large-scale industrial projects. By capturing sound vibrations, sensors give shape to the non-visible aspects and events of an environment.</p>
<p>The building blocks of hearing sensors are inspired by the mechanical properties of the human ear. However, they can be calibrated to cover frequencies well beyond those perceivable by humans (such as ultrasounds). Such flexibility has made them available for many industries: they are used in industrial automation, as measurement devices in construction equipment, and as part of medical imaging techniques, among others.</p>
<p>Advanced audio processing capabilities enable the development of increasingly intelligent consumer electronics. Basic signal processing algorithms are responsible for filtering noise, detecting simple patterns, and building recognition models. On top of that, advanced ML enables voice recognition, speaker identification, and natural language processing. Such applications represent the core capabilities of AI-powered personal assistants such as Alexa and Siri.</p>
<p>These advanced models are not only limited to linguistics. Movement and dynamics are also languages they can interpret. <a href=""https://www.genkiinstruments.com/"">Genki</a> Instruments, a music technology company that is the maker of Wave, a smart ring MIDI controller that lets musicians add natural expression to their setup. Music creation today is a largely digital experience, however, Wave allows musicians to use “natural movement to modulate strings, add vibrato, and control dynamics.” The sensors in Wave allow musicians to control their digital audio workstation using six natural gestures with the ring. This solution not only allows artists to record their music but their style.</p>
<h2>Smell</h2>
<p>Olfactory sensors offer researchers endless innovation possibilities, inspired by the complexity of the human olfactory system. Simply put, they are built to capture volatile chemical compounds in the air and aggregate them to identify scent fingerprints. The so-called electronic noses have found their way in a multitude of industries. They are used across manufacturing &amp; cosmetics industries, for environmental control, in clinical diagnosis, as tools for pharmaceutical investigations and food and beverage quality control.</p>
<p><a href=""https://plumelabs.com/en/"">Plume Labs</a> is employing digital olfactory sensors in a quest for a better understanding of air quality around the world. One of their products is a wearable air pollution sensor that offers real-time air quality insights. Their monitoring application enables users to keep an eye on live air conditions across cities. Similarly, their API gives businesses access to live &amp; forecast air pollution data. By aggregating air quality data with a multitude of data sources (population density, road network data), they provide accurate models of air quality data.</p>
<p><a href=""https://inhalio.com/contact-us/"">Inhalio</a> offers automotive &amp; hospitality businesses a chance to integrate digital scent solutions as part of their products and services. Their scent technology platform enables easy control of scent infusion and diffusion tools. A cloud-based dashboard makes it possible to control environment-specific aspects in real-time, by aggregating and interpreting multiple data sources. This is a simple example of how data analytics can complement digital sensing technology.</p>
<h2>Taste</h2>
<p>Digital taste sensors may not be as popular in consumer applications, but they play a crucial role in the pharmaceutical and food industries. They mimic the taste mechanisms of the human palate and are sometimes referred to as “e-tongues” (electronic tongues). They are commonly used to discriminate among substance samples in research labs when relying on human taste is understandably prohibited.</p>
<p>Engineering digital taste goes well beyond simply identifying substances and chemical compounds: it also requires <a href=""/services/"">advanced modeling</a> of reaction cascades, similar to how human receptors react to different tastes. For this, pattern recognition systems interpret the electric output of e-tongues and integrate data from multiple sensors. Afterward, analytical software classifies different types of sensor data into predefined taste fingerprints. This creates an accurate taste model, that is “synchronized” with the human palate and receptors.</p>
<h2>Touch</h2>
<p>Research of touch sensor technologies is nowadays highly motivated by modern consumer applications. This has led to a previously unimaginable variety of touch sensors. Capacitive, resistive, piezoresistive, piezoelectric, infrared, or surface acoustic wave sensors can all detect tactile stimuli in an environment. Their fine-grained capability to model different types of physical interactions gives them a crucial role in industrial, automotive, medical, and consumer applications.</p>
<p>Tactile data is inherently complex since it represents a wide range of physical interaction parameters, such as temperature, shape, texture, or even directional forces. Sensors that collect such <a href=""/services/"">heterogeneous data</a> are only fully usable when the data they generate can be made sense of. This is where advanced data &amp; signal processing comes into play and shapes increasingly fine-grained capabilities.</p>
<p><a href=""https://www.ultraleap.com/company/"">Leap Motion</a> offers haptic interfaces that work without direct physical contact. Instead, they use ultrasound technology to generate a feeling of touch. Ultrasound waves are configured to travel from different directions and arrive at precise focal points in 3D space (usually on the surface of objects or human hands). Combined with their hand-tracking software, they offer a fully interactive 3D model of human hands for virtual reality applications. This kind of haptic interface plays a crucial role in making virtual touch interactions feel real.</p>
<p>Another company revolutionizing touch is <a href=""https://tanvas.co/"">Tanvas</a> who makes a combined touch sensor / haptic actuator for multi-touch devices including touchscreens, tablets, and laptops. The technology, TanvasTouch, enables programmable textures and haptic effects that can be felt with the swipe of a finger. Unlike traditional vibrotactile haptics, “TanvasTouch surface haptics have no moving parts. Instead, the finger’s movement is sensed by an integrated multi-touch sensor, and surface friction is altered using a physical phenomenon called electroadhesion. This effect uses electric fields to increase friction locally as fingers slide across a smooth plane. The technology brings featureless surfaces to life and can produce a wide range of haptic effects including textures of different roughness, pitch, and magnitude, edges of varying sharpness, and virtual bumps of different shapes.” - Phill LoPresti, CEO of Tanvas</p>
<h2>And Beyond</h2>
<p>Sensor-based applications are by no means restricted to the use of the above sensors only. Digital sensing technology displays a high variety of sensor types, each corresponding to increasingly specific use cases. Tens of specific sensors are designed, engineered, and improved <a href=""https://www.gartner.com/en/documents/3947273/hype-cycle-for-sensing-technologies-2019"">every year</a>. The development of specialized sensors is a trend that is likely to continue, given the major role they play in IoT electronic equipment.</p>
<p>The use of sensors is also not limited to a single sensor at a time. On the contrary, AI-enabled devices and applications make use of multiple sensors synchronously. By using complementary data sources, product developers are able to achieve increased accuracy, keep a competitive advantage, and focus on innovation. This is only possible given the predictive power of <a href=""/services/"">ML algorithms</a> and the maturity of data engineering processes.</p>
<p><a href=""https://www.microshare.io/"">Microshare</a>, takes multiple sensor inputs to another level with their smart-building solutions used to monitor hospital cleanliness, saying, ""We aim to provide every building with vital signs like a living breathing organism,” so in other words, “you need all the senses to do this properly."" They offer a suite of capabilities that together, get to ROI that people care about; cost efficiency, sustainability, and satisfied occupants in any type of facility.</p>
<p><em>“I think we are able to manufacture the elements that create that sixth sense of awareness and prediction that the best facilities managers have. This additional sense is obtained through a complete sensor-fed level of awareness, making it tangible and replicable.</em>”-Michael Moran, Microshare, Chief Risk and Sustainability Officer</p>
<h2>Summary: Sensing Technologies need Data Science</h2>
<p>All examples above illustrate a visible trend: sensing technology and data science work hand in hand to provide opportunities for multi-disciplinary applications. Since sensing devices collect large amounts of heterogeneous data, sensing platforms need to aggregate, transform, and interpret rich sensor data. This is only possible using modern data science tools and processing frameworks.</p>
<p>A consistent thread between each of the senses is the need to unify and interpret data to unlock the core value. <a href=""https://blueorange.digital"">Blue Orange Digital</a>, a data science, and transformation company helps extract, unify, and deploy predictive modeling to enable advanced insights and utilize machine learning. They develop custom dashboards and data processing pipelines, allowing sensor network owners to focus on their sensing technology, without worrying about data analysis infrastructure.</p>
<p>Data processing capabilities are more affordable than ever. Companies across industries are gaining access to previously expensive data analytics technology. Modern cloud infrastructure ensures access to computational power, storage is becoming cheaper and cheaper, while data science expertise is widely available. This creates an ideal ecosystem for the integration of sensing technologies and data science.</p>
<p>Originally Published: <a href=""https://www.theinternetofthings.eu/josh-miramant-5-senses-sensors"">https://www.theinternetofthings.eu/josh-miramant-5-senses-sensors</a></p>
<hr class=""wp-block-separator"" />
<p><em>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for </em><em>Supply Chain</em><em>, </em><em>Healthcare Document Automation</em><em>, and </em><a href=""/cptcasestudies/""><em>more</em></a><em>.</em></p>
<hr class=""wp-block-separator"" />
<p><em>Follow me on </em><a href=""https://twitter.com/BlueOrangeData""><em>Twitter</em></a><em> or </em><a href=""https://www.linkedin.com/in/joshmiramant/""><em>LinkedIn</em></a><em>. Check out my </em><a href=""https://blueorange.digital/""><em>website</em></a><em>. </em></p>
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img src=""https://lh5.googleusercontent.com/_RKOgkl6ZF-a87nJNV4QdO-Sood1qX-gqLhfBkCQPQmVx_M5Tov7dQKHIqfSebpodZFi9r2cVwDIN1DqHXEB3GSweinCh0BMcVIMtU4l39EF1xZLh2Rjzyvq9yZoIjfiuskim9Bq"" alt="""" width=""125"" height=""125"" /></figure>
</div>
<p><em>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He is a serial entrepreneur and software engineer that has built and scaled 3 startups. He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things. </em></p>
<p><em>Featured on IBM ThinkLeaders, Dell Technologies, and NYC’s Top 10 AI Development and Custom Software Development Agencies as reviewed on Clutch and YahooFinance for his contributions to NLP, AI, and Machine Learning. Specializing in predictive maintenance, unified data lakes, supply chain/grid/marketing/sales optimization, anomaly detection, recommendation systems, among other ML solutions for a multitude of industries.  </em></p>
<p>Visit <a href=""https://blueorange.digital/"">blueorange.digital</a> for more information and to view <a href=""/cptcasestudies/"">Case Studies</a>.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/5-senses-of-sensors.gif,5-senses-of-sensors.gif,/www/blueorangem_500/public/wp-content/uploads/2022/05/5-senses-of-sensors.gif,3004,5-senses-of-sensors,,,,https://blueorange.digital/wp-content/uploads/2022/05/5-senses-of-sensors.gif,,,,,,,,
3018,"The Science of Real Estate: Matching and Buying","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<h2>Your data knows you best, let it find your dream home.</h2>
The real-estate industry sits on tons of data that goes unused every year. In this article, we discuss how advanced technologies are helping real estate investors, brokers, and companies utilize the mass amount of information within the industry to help people find their dream homes.

In 2017, a <em>Field Actions Science Reports</em> <a href=""https://journals.openedition.org/factsreports/4432"">article</a> addresses the impact of AI, machine learning, and predictive analytics on the real estate sector:

<em>“The practice of AI-powered Urban Analytics is taking off within the real estate industry. Data science and algorithmic logic are close to the forefront of new urban development practices. How close? is the question — experts predict that digitization will go far beyond intelligent building management systems. New analytical tools with predictive capabilities will dramatically affect the future of urban development, reshaping the real estate industry in the process.”</em>

Fast forward to 2020: leaving <a href=""https://emerj.com/ai-sector-overviews/machine-learning-in-real-estate-trends-and-applications/"">hype traps</a> behind, we acknowledge the transformative effects of data literacy, digitalization strategies, and technology advancements. Predictive analytics, machine learning, and AI-powered applications are still leading innovation in a variety of industries, well beyond the real-estate sector. From the most boring ML applications to the most interesting NLP &amp; OCR automation efforts, industry leaders have learned to leverage these powerful tools to their advantage.

Today we catch up with 3 real-estate use cases. They are meant to illustrate how modern software stacks and intuitive interfaces interplay with Machine Learning and data engineering to create unique products and services.

<figure class=""wp-block-video aligncenter""><video src=""https://blueorange.digital/wp-content/uploads/2020/12/Copy-of-House-match-gif.mp4"" controls=""controls"" width=""800"" height=""450"" data-mce-fragment=""1""></video></figure>
<h2>Home buying processes</h2>
Today’s real estate market poses an interesting machine learning challenge: is there a formula for matching the right home-buyers with the right properties at the right prices? Seeking to build accurate home matching and discovery services is what keeps researchers and industry professionals on their toes. With huge data volumes available to them, and inspired by high accuracy of online recommender systems (Netflix, anyone?), home matching engines are seeing constant development, even in the not-so-technically-inclined real estate sector.

<a href=""https://orchard.com/"">Orchard</a> is a broker that leverages modern tech tools to improve home discovery services. By using machine learning algorithms, they come up with an answer to the most pressing question that home buyers ask: “What does my dream house look like?”. Additionally, algorithms may help them answer a follow-up question: “Which compromises are I (not) willing to make?”.

Co-Founder and Chief Product &amp; Marketing Officer, Phil DeGisi clarifies:

“<em>Home Match is the first-ever home search algorithm that lets people choose the features that matter most to them. We ask buyers a series of questions about what they value and consider ""must-haves"" and ""nice to haves"" in a home - such as a kitchen island, pool in the backyard, and commute time within seconds. Orchard assigns a personal match score to every home in the search area. </em>”

Like this, the buyers are matched to legitimate house buying opportunities and the entire process becomes easier for all parties involved.

Users of house matching systems get to enjoy an experience characterized by <em>increased personalization</em> and <em>usability</em>. Search results are ranked according to their profiles and easy-to-use, interactive interfaces replace plain old real estate catalogs.

<em>“Orchard has also developed another industry-first, Photo Switch, which takes these personalized search results and displays them in a more visually useful and personalized way. To do this, Orchard created a machine-learning model to scan photos of every home on the market and determine which rooms are in each photo. This feature is the first of its kind and lets users easily compare their ""must-haves"" all at once. Whether it's a chef's kitchen, a fenced-in backyard, or a cozy living room, home-buyers can now view each room side-by-side in one browser, with the click of a single button.”</em>

Such functionality is only possible due to the seamless interplay of modern tech tools. Web platforms, virtual reality SDKs, image processing algorithms as well as machine learning frameworks all contribute to create a unique real estate experience.

See also:
<div class=""wp-block-image"">
<figure class=""aligncenter""><a href=""https://blueorange.digital/gain-a-competitive-advantage-third-party-data-is-increasing-commercial-real-estate-roi/"" target=""_blank"" rel=""noreferrer noopener""><img class=""wp-image-5490"" src=""https://blueorange.digital/wp-content/uploads/2020/07/third-party-data-in-real-estate-1024x536.gif"" alt=""third party data in real estate"" /></a>&nbsp;

<figcaption>third party data in real estate</figcaption>
</figure></div>
<h2>Commercial real estate valuations</h2>
Another crucial step in commercial real estate is property valuation. Automated Valuation Models are as old as the industry itself, given the task of evaluating properties and establishing pricing schemes. Traditionally, these models were mostly based on historical sales data. However, models relying on past behavior only are missing out on a lot of other data sources.

Predictive analytics and modern data collection infrastructures are built to integrate external data sources and train algorithms based on heterogeneous data types. Instead of using a single data type that offers a limited perspective on a property, unified data architectures offer a 360-degree view and integrate external data sources: market demand, macroeconomic data, rental values, capital markets, jobs, traffic, etc. Since there are no hard limits to the data that can be used by a property valuation model, predictive analytics is a powerful tool available to real estate agencies.

<a href=""https://www.smartcapital.center/"">Smart Capital</a> offers such a modern solution to property valuation. They use predictive analytics for the valuation of real estate properties and promise to deliver a full report within one business day. Their CEO, Laura Krashakova, offers some insights into how they achieve this.

“<em>The technology enables data processing and property valuation in real-time and gives individuals access to data previously available only to local brokers. Local insights such as the popularity of the location, amenities in the area, quality of public transport, proximity to major highways, and foot traffic are now readily available and are scored for ease of comparison.</em>”

There are two aspects that make such a service possible in the first place: the <em>ease of access</em> and the possibility to deliver <em>real-time insights</em>. Mobile &amp; web platforms make it easy for customers to access, upload, and visualize their data, regardless of their location. All that is needed is an internet connection. At the same time, predictive analytics frameworks are crunching data in real-time, at the speed of milliseconds. Once new data events occur, they are collected and included in the latest analysis report. No need to wait for time-consuming, intensive computations, since all of that computation can now happen almost instantly, in the cloud.

Once again, the interplay of modern technologies makes it possible to offer a seamless experience based on real-time insights. At the same time, the variety of external data sources becomes a guarantee for increased valuation accuracy. This saves time, money, and headaches for all parties involved.
<div class=""wp-block-image"">
<figure class=""aligncenter""><a href=""https://blueorange.digital/reit-trends-2020/"" target=""_blank"" rel=""noreferrer noopener""><img class=""wp-image-6449"" src=""https://blueorange.digital/wp-content/uploads/2020/12/Copy-of-REIT-Whitepaper-Blog-Cover-Image-1.png"" alt=""Round Corner: Copy of REIT Whitepaper Blog Cover Image"" /></a>&nbsp;

<figcaption>Real Estate Investment Trust (REIT) White Paper</figcaption>
</figure></div>
<h2>Streamlined loan application processes</h2>
Another commercial real estate process that poses an interesting challenge is the loan application. A challenge not only for the confused homebuyers but for machine learning models as well. Credit approval models need access to all kinds of data, from personal information, to credit history, historical transactions, and employment history. Manually identifying and integrating all these data sources can quickly turn into a tedious, time-consuming, and annoying task. Moreover, manual processing comes with a high risk of erroneous entries throughout the application. These aspects have turned the manual loan application process into a bottleneck for real estate transactions.

If only some automated solution existed to take some of the pain away...

<a href=""https://makeabeeline.com/"">Beeline</a> is a company focused on streamlining the loan application process. Their intuitive mobile interface guides buyers through loan applications in minutes. The entire process takes only 15 minutes and claims to save home buyers a lot of headaches. The way they do this is incredibly simple: their service connects to a variety of personal data sources (such as the bank, pay and tax info), uses natural language processing(NLP) to read and collect info, integrates and analyzes all the data in real-time. Like this, tedious and time-consuming processes are bypassed and home-buyers can enjoy streamlined loan application processes.

How is that possible, you’re wondering?

Their service is only possible by integrating a <em>mobile-first experience</em>, <em>intelligent processing capabilities</em>, as well as state of the art user design. Their loan guide is delivered via a chat interface, which gives the users an easy way to find answers to their questions. NLP algorithms are backing these interactions and help create a personalized experience.

At the same time, automated evaluation algorithms happen in the background, just as the buyer is filling in forms. This shows how automation is key to the success of their service. And the seamless interplay of tech tools is what makes this automation possible in the first place.
<h2>What’s next?</h2>
A powerful mix of tech trends is at the forefront of real estate innovation: increased data availability, advancements in data processing capabilities, and the ubiquity of machine learning algorithms. They all make it possible to tackle the most challenging applications, in an intelligent, automated, and error-free manner.

On top of that, cloud computing capabilities and modern storage architectures make it possible to extract insights from data in real-time, build complex predictive models, and integrate a variety of data sources. All this makes it possible to <em>foresee</em> the future, innovate, and keep a competitive advantage.
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-5707"" src=""https://blueorange.digital/wp-content/uploads/2020/08/streamlines-loan-1024x576.png"" alt="""" /></figure></div>

<hr class=""wp-block-separator"" />

<em>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for </em><em>Supply Chain</em><em>, </em><em>Healthcare Document Automation</em><em>, and </em><a href=""/cptcasestudies/""><em>more</em></a><em>.</em>

<hr class=""wp-block-separator"" />

<div class=""wp-block-image"">
<figure class=""alignleft""><img class=""wp-image-4644"" src=""https://blueorange.digital/wp-content/uploads/2020/03/Josh-Miramant.png"" alt=""CEO Josh Miramant"" />&nbsp;

<figcaption>CEO Josh Miramant</figcaption>
</figure></div>
<em>Follow me on </em><a href=""https://twitter.com/BlueOrangeData""><em>Twitter</em></a><em> or </em><a href=""https://www.linkedin.com/in/joshmiramant/""><em>LinkedIn</em></a><em>. Check out my </em><a href=""https://blueorange.digital/""><em>website</em></a><em>.</em>

<em>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things. </em>

<em>Featured on IBM ThinkLeaders, Dell Technologies, and CUInsight. Recognized as NYC's Top 10 AI Development and Custom Software Development Agencies by Clutch and YahooFinance for his contributions to NLP, AI, and Machine Learning. Specializing in predictive maintenance, unified data lakes, anomaly detection, supply chain/grid/marketing/sales optimization, recommendation systems, among other </em><a href=""/services/""><em>ML solutions</em></a><em> for a multitude of </em><a href=""/industries/""><em>industries</em></a><em>.</em>

<hr class=""wp-block-separator"" />

<em>Visit </em><a href=""https://blueorange.digital/""><em>blueorange.digital</em></a><em> for more information and to view </em><a href=""/cptcasestudies/""><em>Case Studies.</em></a>

</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Copy-of-House-match-gif-1.gif,Copy-of-House-match-gif-1.gif,/www/blueorangem_500/public/wp-content/uploads/2022/05/Copy-of-House-match-gif-1.gif,3020,Copy-of-House-match-gif-1,,,,https://blueorange.digital/wp-content/uploads/2022/05/Copy-of-House-match-gif-1.gif,,,,,,,,
3032,"Machine Learning: An Introduction","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Computers have advanced in many ways since their inception and arguably the most important dimension is in the computational power they provide. It is this increase that ultimately enables machine learning solutions. Machine Learning is an application of artificial intelligence that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. ML brings new techniques across various aspects of business and across many different industries. It brings the ability to automate manual and repetitive tasks and improve the process behind decision making.</p>
<h2>ML vs AI</h2>
<p>You’ve heard the buzz, but you may be asking yourself, what exactly is machine learning? And how does it differ from AI?</p>
<p>ML is a type of computer program or algorithm with the ability to teach itself by analyzing data (inputs) and coming up with a solution (output). What makes machine learning algorithms valuable are the feedback loops--a well-designed algorithm continues to learn from new input data to increase the accuracy of the solution it comes up with. For example, machine learning algorithms in recruiting are used to assess candidates’ personalities, job fit, and resume. ML is essentially statistics and correlations used to make predictions. These predictions become more accurate as more inputs are fed into the system.</p>
<h2>3 Types of ML</h2>
<h4>1. Supervised Learning</h4>
<p>In supervised learning, the algorithm is given a set of correctly labeled input/output example pairs in order to train. The two major types of supervised learning are <strong>regression</strong> and <strong>classification</strong>. Regression involves predicting a quantity by figuring out which features are important for the outcome. Classification involves assigning observations to different categories. </p>
<p>This allows for questions in three formats. Two-class classification (A or B?), multi-class classification (A, B, or C?), and anomaly detection (is this abnormal?). Using these classifications you can ask and answer questions such as; Is this an image of a cat or dog? What is the mood of this tweet? Or, Is this pressure reading atypical?</p>
<h4>2. Unsupervised Learning</h4>
<p>While supervised learning finds patterns in data sets where we know the correct answers, unsupervised learning finds patterns in data sets where we don’t. Unsupervised learning allows us to ask questions about how data is organized and how to compress it. This is achieved through techniques such as <strong>clustering</strong> and <strong>dimensionality reduction</strong>.  For example real estate websites can group their housing listings into neighborhoods so that users can navigate listings easier.</p>
<p>Unsupervised learning allows us to answer two types of questions:</p>
<p>How is this data organized? </p>
<p>How can we represent this data in a compressed format?</p>
<h4>3. Reinforcement Learning</h4>
<p>In reinforcement learning, we do not provide the machine with examples of correct input-output pairs, but we do provide a method for the machine to quantify its performance in the form of a reward signal. The machine tries a bunch of different things and is rewarded when it does something well. Reinforcement learning is useful in cases where the solution space is enormous or infinite, and typically applies in cases where the machine can be thought of as an agent interacting with its environment. An algorithm that can <a href=""https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii"">play video games </a>is an example of reinforcement learning.</p>
<p>Reinforcement Learning is all about the actions the machine can take. The RL algorithm chooses an action based on the factors it has learned to make high reward actions. This process was inspired by how humans and rats respond to rewards and punishment. This makes RL terrific for automated systems. For example an air system can learn to pre-refrigerate the upper floors of an office building before the day gets too hot and takes longer to cool down. This saves money in the long run by having the system use less electricity because it is running and working less.</p>
<p>Here at Blue Orange we have used ML to automate resume screening and shortlist and grade candidates by learning from existing employees’ resumes. First we used a natural language processing ML algorithm to turn the unstructured resume text into relational data. Then we built another ML algorithm that trained itself on prior employees to learn which resume data points (inputs) are correlated with successful employees to produce a shortlist of qualified candidates for the position (output). Instead of just scanning for keywords, we are able to make predictive hiring suggestions to HR. In addition, for firms who use digitized interviews, we can use machine learning technology to assess candidates’ personality and job fit by learning from successful candidates’ facial expressions and word choices. </p>
<p>As technology further integrates into our everyday life, the need for collecting, storing, and analyzing the data we have will only grow in importance. This may seem daunting now, but with foresight ML can be utilized by businesses of all sizes across all industries. So let us tame your business’s data and make it start working for you.</p>
<p><strong> <a href=""/contact-us/"">Contact us today to see how we can help!</a></strong></p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/machine-learning-2.jpeg,machine-learning-2.jpeg,/www/blueorangem_500/public/wp-content/uploads/2022/05/machine-learning-2.jpeg,3033,machine-learning-2,,,,https://blueorange.digital/wp-content/uploads/2022/05/machine-learning-2.jpeg,,,,,,,,
3038,"Churn is Eating Away at Your Profitability. Machine Learning Can Help.","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Estimates vary by study and industry, but experts consistently agree: customer acquisition is more expensive than customer retention. In fact, customer acquisition can run anywhere from <a href=""https://hbr.org/2014/10/the-value-of-keeping-the-right-customers"">5 to 25 times more expensive</a>, and research indicates that <a href=""https://hbr.org/2014/10/the-value-of-keeping-the-right-customers"">increasing retention by 5% can increase profits by 25 to 95%.</a></p>
<p>For traditional financial institutions (FIs), the introduction of new competition from Fintechs will only increase these costs. That’s a problem because <a href=""https://www.qualtrics.com/customer-experience/banking-report/#section3"">according to Qualtrics</a>, only 25% of churning customers warn their bank or credit union in advance, even though the average customer considers their decision for 9 months. In other words, FIs have a window to intervene —  if they can identify customers at risk of churn. Enter machine learning.</p>
<h2><strong>A Better Way to Analyze</strong></h2>
<p>Compared to more traditional (and human-dependent) methods of data analysis, machine learning (ML) is faster, more accurate, and better able to analyze modern companies’ growing wealth of data. ML algorithms learn from data, identifying patterns and refining analytical models without specific instructions. They’re particularly adept at making accurate <em>predictions</em> based on historical data, making them a promising solution to the challenge of churn.</p>
<p>In the last decade, researchers have braved this new frontier, using machine learning to predict churn in industries such as telecoms, banking, and cloud service subscriptions. Their results are encouraging: <a href=""https://thesai.org/Downloads/Volume9No2/Paper_38-Machine_Learning_Techniques_for_Customer_Retention.pdf"">one study</a> found that certain ML techniques can predict churn with over 90% accuracy. Especially when combined with customer life-time value or profitability data, churn predictions enable the strategic deployment of retention measures to protect FIs’ profitability. However, as always...</p>
<h2><strong>The Devil’s in the Data</strong></h2>
<p>ML models of churn essentially categorize customers as either at risk of churn (yes) or not at risk of churn (no), based on a variety of customer data. And some data result in better predictions than others. <a href=""https://link.springer.com/article/10.1140/epjds/s13688-018-0165-5"">A 2018 publication in EPJ Data Science</a>, for example, found that behavioral data such as diversity and regularity of financial activities result in better predictions than demographic features. </p>
<h2><strong>Technical Solution to Customer Churn</strong></h2>
<p>In order to predict which customers will likely churn out in the future, we need to examine data from customers who have previously left to understand their characteristics and behavior. We then use statistical techniques such as regression to figure out which customer features would have predicted churn before it happened and how important those specific features are. By training the model, we can more accurately see if a current customer has the characteristics of a person who would likely leave. </p>
<p>Here is an example of how a churn model of regression works. Specific features (like length of account history or age) are given different weights depending on how well they predict churn. The weighted sum correlates to a probability of the customer churning. When this probability reaches a certain threshold, the customer is considered likely to churn.</p>
<figure class=""wp-block-image is-resized""><img class=""wp-image-2454"" src=""https://blueorange.digital/wp-content/uploads/2019/09/Screen-Shot-2019-09-30-at-3.54.10-PM-1024x743.png"" alt="""" width=""352"" height=""255"" /></figure>
<p>Once the FI knows which customers are at risk of leaving and has insights into potential reasons from the regression and their institutional knowledge, they can alert their customer service team to adapt and engage the high-risk customers before they leave. </p>
<p>Of course, as with any type of analytics, machine learning insights are only as good as the data they are based upon. Data quality and availability are crucial issues for predictive accuracy. Fortunately, given a reasonable amount of historical data, good data scientists can help accurately predict churn.</p>
<h2><strong>Ready to Learn More?</strong></h2>
<p>Blue Orange Digital develops data science, machine learning, and data visualization solutions tailored to your company’s needs. We know leveraging data is not always simple, and that’s where our team of data engineers and experts come in. <a href=""/contact-us/"">Contact us</a> at (530) 454-5830 or contact@blueorange.digital to learn more.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/churn.jpg,churn.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/churn.jpg,3039,churn,,,,https://blueorange.digital/wp-content/uploads/2022/05/churn.jpg,,,,,,,,
3046,"Essential Python Libraries for Machine Learning Projects","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Are you just starting out with your first Machine Learning project and already asking yourself: <em>“Which Python libraries are needed for Machine Learning?”</em>. Getting started with the Python ecosystem and not getting lost on your way can be a daunting task, and we know it.</p>
<p>But we’re here to help and answer your question. We are going to take a look at the essential Python libraries for Machine Learning projects. For each of them, we’ll see which problem the library is meant to solve and how it can help you with various ML tasks. Also, we will try to focus on the libraries’ features that make them most useful in different stages of your ML project.</p>
<p>In this article, we cover <strong>Core Libraries </strong>and <strong>Data Modeling Libraries</strong>, since they represent the fundamental kit for any Machine Learning Python environment. In the second part, we will discuss <strong>Visualization Libraries.</strong></p>
<h2>Core Libraries</h2>
<h3><strong>Numpy</strong></h3>
<div class=""wp-block-image"">
<figure class=""aligncenter is-resized""><img class=""wp-image-3227"" src=""https://blueorange.digital/wp-content/uploads/2019/12/logo_numpy.png"" alt=""NumPy library for the Python programming language"" width=""444"" height=""175"" /><br />
<figcaption>NumPy library for the Python programming language</figcaption>
</figure>
</div>
<p><strong><br /></strong>The first obstacle you encounter when working with big data is the realization that numerical calculations with multidimensional arrays are slow and inefficient. The hero that first aids you against this hurdle is Numpy. Known as the <a href=""https://numpy.org/"">fundamental package</a> for working with multidimensional data, this library enables efficient computing in Python. </p>
<p>The beauty of Numpy lies in its simplicity. The library is defining N-dimensional array objects as the main data structure (allowing homogeneous data types to be stored). Basic operations on this data structure are then provided: indexing, reshaping, sorting &amp; <a href=""https://docs.scipy.org/doc/numpy/reference/routines.array-manipulation.html"">others</a>. </p>
<p>Data engineers love these operations since they enable vectorization, which is an amazing feature: data processing tasks that would normally require <em>loops</em> can be defined by means of basic array expressions. This also means that numerical calculations are executed faster. Under the hood, these may even be distributed across multiple processing nodes for parallel computation.</p>
<p>Such advanced capabilities of handling large multidimensional arrays have turned Numpy into the core dependency for more high-level libraries. </p>
<h2><strong>SciPy</strong></h2>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-3232"" src=""https://blueorange.digital/wp-content/uploads/2019/12/SciPy-Logo.png"" alt=""SciPy library — SciPy.org"" /><br />
<figcaption>SciPy library — SciPy.org</figcaption>
</figure>
</div>
<p>Once you master the above data structures and become a master of computation with multidimensional arrays, you want to perform more advanced statistical analysis.</p>
<p>If we imagine Numpy to be the hero by your side, then we can say that <a href=""https://www.scipy.org/"">Scipy</a> is the hero’s extension pack. Scipy is using Numpy internally for manipulation of low-level data structures (multidimensional arrays) and provides submodules for statistical analysis.</p>
<p>Linear algebra algorithms, sparse matrix manipulation operations, clustering commands, and complex optimizations are all <a href=""https://docs.scipy.org/doc/scipy/reference/"">provided</a> and already implemented. These heavy lifting submodules provide endless possibilities for developing error-prone scientific applications.</p>
<p>These two tools alone already make you ready for some serious scientific computation. But before you start doing that you take a look at your data...</p>
<h2><strong>Pandas</strong></h2>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-3230"" src=""https://blueorange.digital/wp-content/uploads/2019/12/Pandas.png"" alt=""Python Data Analysis Library pandas"" /><br />
<figcaption>Python Data Analysis Library pandas</figcaption>
</figure>
</div>
<p><strong>Python Data Analysis Library pandas</strong><strong><br /></strong><br />Like most data engineers, you will very likely deal with unstructured, dirty or even misaligned data. It is sad, but it is true: your big data usually needs a lot of preprocessing and cleaning before being ready for the machine learning models.</p>
<p><a href=""https://pandas.pydata.org/"">Pandas</a> is an open-source library that makes it easy to manipulate and analyze complex, multidimensional datasets. Really easy! By this point, it should come as no surprise to you that it is also built on top of Numpy and integrates seamlessly with Scipy. </p>
<p>Practically, the tool does not care if your data source is a CSV file, a SQL database or a JSON object. The extensive yet simple to use <a href=""https://pandas.pydata.org/pandas-docs/stable/reference/index.html"">API</a>, allows you to read data from any of these sources with just a method call. Pandas’ main data structures (<em>Dataframes</em> and <em>Series</em>) are optimized for complex manipulation tasks such as filtering and grouping. Last but not least, its plotting functionality allows quick analysis of trends and patterns in your data.</p>
<p>This vast functionality makes the Pandas library an essential tool in any data engineer’s toolbox, one that assists you in the most time-consuming stages of a machine learning project. Building ETL pipelines, preprocessing and cleaning data and doing exploratory data analysis have never been so fun before!</p>
<h2>Data Modeling Libraries</h2>
<h2>Scikit Learn</h2>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-3231"" src=""https://blueorange.digital/wp-content/uploads/2019/12/logo_scikit_learn-300x161.png"" alt=""scikit-learn: machine learning in Python"" /><br />
<figcaption>scikit-learn: machine learning in Python</figcaption>
</figure>
</div>
<p>You’ve successfully cleaned and aligned your data thanks to the superpowers of the Core Libraries. The Exploratory Data Analysis already gave you a few ideas about which machine learning models you want to train on your data. But do you really need to implement all machine learning algorithms from scratch?</p>
<p>No worries, you don’t!</p>
<p><a href=""https://scikit-learn.org/stable/"">Scikit-learn</a> is a comprehensive collection of both supervised and unsupervised algorithms. It provides a straightforward way to configure, train and evaluate different kinds of models with just a few lines of code. Regardless of the type of task that you are tackling, there are at least a handful of <a href=""https://scikit-learn.org/stable/modules/linear_model.html"">pre-configured</a> <a href=""https://scikit-learn.org/stable/modules/mixture.html"">models</a> that are ready to be fitted and a bunch of matching performance measures ready for their <a href=""https://scikit-learn.org/stable/modules/model_evaluation.html"">evaluation</a>. </p>
<p>From classification and regression to clustering and dimensionality reduction, Scikit-learn allows you to quickly prototype and deploy end-to-end learning pipelines. On top of that, the <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"">boosting algorithms</a> and the <a href=""https://scikit-learn.org/stable/modules/ensemble.html"">ensemble methods</a> will enable your model to achieve top-notch performance. </p>
<p>The powerful features of Scikit-learn allow you to quickly implement and integrate Machine Learning solutions into production systems. No wonder that this library has been the industry standard for such a long time!</p>
<p>The above list of libraries allows you to immediately get started with your Machine Learning project in Python. Did we miss any important library on our list? Let us know in the comment section below! Next time we will discuss <strong>Visualization Libraries</strong> and see what options there are to visualize the results of your data analysis.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/header-1.jpg,header-1.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/header-1.jpg,3047,"header (1)",,,,https://blueorange.digital/wp-content/uploads/2022/05/header-1.jpg,,,,,,,,
3061,"Three Ways Venture Capital Firms Add Value Beyond A Check","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>It’s a tough time to be in venture capital. Years ago, VC organizations were the only place for start-ups to get the funding they needed to grow. That’s started to change. In 2018, regulation crowdfunding became more significant in terms of speed to close and funding. For example,<a href=""https://venturebeat.com/2019/01/30/regulation-crowdfunding-performed-solidly-in-2018-heres-the-data/""> Venture Beat</a> found that 60% of start-ups are successful in raising capital through this method compared to a 6.5% success rate with traditional venture capital. It’s true that venture capital currently has an advantage in terms of total capital to invest. However, these alternative funding sources are proliferating.</p>
<p>These developments mean that company founders are starting to question rethink their funding options. To stay competitive, venture capital firms need to bring more to the table.</p>
<p>To attract better deals and enhance the value of your current portfolio, there are three new capabilities you need to develop. Without these, you will be perceived as little more than a checkbook. Add these abilities to your firm, and you will no longer be seen as a financing commodity.</p>
<h2>Capability 1: Data Visualization</h2>
<p>For a growing company, understanding performance is difficult. Usually, small firms lack the business intelligence tools that the Fortune 500 takes for granted. Without these capabilities, your portfolio companies are more likely to underperform since they will not be able to make timely decisions based on accurate data.</p>
<p>For a VC firm, data visualization is a helpful resource; it helps you to understand business performance. For example, rather than spending days each month reviewing customer comments and orders, a data visualization capability can summarize the data. Specifically, we advise VC firms to use data visualization to compare performance across different companies in their portfolio beyond traditional accounting measures.</p>
<blockquote class=""wp-block-quote""><p>Tip: Use data visualization to compare marketing effectiveness across your portfolio companies so you can identify improvements. </p>
</blockquote>
<h2>Capability 2: Predictive Analytics </h2>
<h2>What should you do next?</h2>
<p>That’s one of the most challenging questions in business. Should you emphasize your past strategy or explore a new direction? From a venture capital standpoint, the traditional approach of exclusively relying on intuitive judgments is not good enough. A venture capital portfolio company is already a high-risk operation since such companies are usually developing new technologies and new ways to connect with the marketplace.</p>
<p>Predictive analytics is a vital venture capital capability because it reduces the risk of failure. At<a href=""https://www.complianceweek.com/technology/case-study-how-3m-uses-predictive-analytics/28009.article""> 3M</a>, a multi-billion dollar brand, has used predictive analytics to reduce risk and address compliance issues. As noted in Compliance Week: “3M is using the findings to help prioritize how to address—and get ahead of—conflict of interest matters, as well as where compliance needs to spend more time on education and training..”</p>
<p>3M’s success shows the way forward to manage customer complaints and regulatory requirements. If you have portfolio companies in health care, finance, and other highly regulated industries, look at using predictive analytics to cut your risk.</p>
<h2>Capability 3: Sales Enablement</h2>
<p>As a venture capital investor, you have to be patient with your portfolio companies. Breaking new ground in technology and launching new products is challenging! However, your patience has a limit. You ultimately need to demonstrate returns and find the right opportunity for liquidity.</p>
<p>That’s why you need a way to help your portfolio firms with sales enablement and productivity. Without predictable revenue, your portfolio companies will end up like WeWork and other firms that lack a firm foundation.</p>
<p>There are a few ways you can support sales enablement at portfolio companies while respecting the autonomy of the founders.</p>
<ul>
<li>Process and Training. Technical company founders are sometimes more excited about product development versus sales. To support sales enablement, consider providing sales process training. This could take the form of training staff on a sales methodology that works well in other committees.</li>
<li>Technology. Provide recommendations for sales enablement tools such as customer relationship management tools (e.g., Salesforce) and communications (e.g. Zoom). There are hundreds of sales technologies on the market, so you can help your firms by cutting through the noise.</li>
<li>Continuous Improvement. Assist your portfolio companies to improve sales productivity by using data science. For example, develop reports on best practices for sales development representative (SDR) productivity. Based on those findings, use data to guide sales decision making, such as whether to emphasize growing a sales support team or focus on SDR hiring.</li>
</ul>
<p>Now let’s look at two ways you can add these capabilities to your firm.</p>
<h2>Your Next Step To Get Started</h2>
<p>There are two pathways to bring data science and analytics capabilities to your firm. First, you can adopt the “build” approach – hire a whole department of specialists in data. This approach can work! However, it is slow and expensive to build such a department, especially if it is outside of your firm’s core competency.</p>
<p>The second choice: partner with a data science firm like <a href=""https://blueorange.digital/"">Blue Orange</a>. With this approach, you get data science expertise for your portfolio firms as needed. If you fail to act on building these capabilities, your venture capital firm will fall behind VCs who provide insights as well as funding.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/photo.jpg,photo.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/photo.jpg,3062,photo,,,,https://blueorange.digital/wp-content/uploads/2022/05/photo.jpg,,,,,,,,
3069,"Why Machine Learning is Central to Reverse Supply Chain 2.0","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p><em>E-commerce growth and a worldwide pandemic have brought to light the inefficiencies in the modern supply chain, especially the return process. The current return process is costly, inefficient, and wasteful. The following article explores how enabling efficient returns through reverse supply chain development can bring savings and operational improvements.</em></p>
<p>Most companies are failing to get the most out of their reverse supply chain - the flow of goods back to them in the form of returns and recycling.  This is an important area to optimize because approximately<a href=""https://www.supplychainquarterly.com/topics/Strategy/201201reverse/""> 20% of all products</a> purchased in the U.S. are returned to the manufacturer. Fortunately, there are still big wins available in supply chain management, but you need a new opportunity.</p>
<p>In the automotive industry, managing reverse supply chains is a significant challenge due to the volume of vehicle returns. Over 5 million cars were subject to recalls in 2019, according to<a href=""https://www.cars.com/articles/the-10-biggest-recalls-in-2019-416480/""> Cars.com</a>. While recalls affect nearly all brands to some degree, some companies have better success in addressing these problems. A <a href=""https://www.nhtsa.gov/sites/nhtsa.dot.gov/files/documents/18-3122_vehicle_safety_recall_completion_rates_report_to_congress-tag.pdf""> U.S. Department of Transportation report</a> found that Chrysler had the most effective remediation rates in several areas, such as parking brake recalls. When you improve your reverse supply chain effectiveness, you will suffer less waste and a more significant opportunity to sell refurbished products.</p>
<h2>Reverse Supply Chain Technology: 3 Quick Wins</h2>
<p>Manually tracking and managing the reverse supply chain is no longer good enough. A manual approach means you will not generate meaningful data and measurements, making it practically impossible to improve your results. By applying data analytics technology to your supply chain, you can achieve wins in three areas.</p>
<ul>
<li><strong>Reduce returns due to errors and mistakes.</strong> Some customers will return products if the delivered product does not match their expectations. For example, you might deliver a product in the wrong size or color. Technology cuts this reverse supply chain in two ways. Add validation rules during the ordering and fulfillment process means cutting delivery errors at the front end. On the other hand, you can use analytics to better understand the remaining error returns you have.</li>
<li><strong>Speed up movement through the reverse supply chain.</strong> In specific industries like consumer electronics, products quickly lose value over time. In research reported in the<a href=""https://www.researchgate.net/publication/275247814_Reverse_Supply_Chains_for_Commercial_Returns""> California Management Review</a>, “ $1000 of product returns nearly half the asset value (&gt;45%) is lost in the return stream.” Further, time delays in processing returns cause products to lose 10-20% of their value. If you have a significant amount of secondary sales (e.g., refurbished sales), speeding up the reverse supply chain means you can sell more products at higher prices.</li>
<li><strong>Reduce fraud expenses associated with returns.</strong> Unfortunately, fraud is a significant problem with returned products. In the retail industry, “Annual losses from merchandise return fraud are estimated at $27 billion” in 2019, according to<a href=""https://www.globenewswire.com/news-release/2020/01/13/1969700/0/en/NEW-REPORT-FINDS-RETAIL-RETURNS-TOTALED-309-BILLION-IN-2019-IMPACTING-STORES-AND-ECOMMERCE.html""> Appriss Retail research</a>. This fraud expense can be reduced by improving product tracking throughout the shipping and handling process.</li>
</ul>
<p>Better technology means that you can track each product individually as they flow through the return process. As a result, you can pinpoint time delays (e.g., product sits in a warehouse for a week). By gathering better data through RFID tags and GPS, it is possible to identify fraud better. Increasing speed and reducing fraud are two of the most important ways to improve your supply chain.</p>
<p>As stated by Transfix Co-Founder Drew McElroy advanced technologies such as AI, ML, and prescriptive analytics are integral to achieving optimal efficiency within today's supply chain. These technologies allow for high visibility into the supply chain through passive data capture, anomaly detection, and intelligent learning.</p>
<p><em>“The most important ideas for improving today's supply chain and the supply chain of the future are passive data capture, exception management, and intelligent learning. These technologies allow for high visibility, automatic problem resolution, and a system that learns and becomes better with time.”</em></p>
<p><em>-Drew McElroy, Transfix</em></p>
<figure class=""wp-block-image""><img class=""wp-image-5643"" src=""https://blueorange.digital/wp-content/uploads/2020/08/Blog-Format-1024x576.png"" alt=""Reverse Supply Chain"" />
<p>&nbsp;</p>
<figcaption>Reverse Supply Chain</figcaption>
</figure>
<h2>How To Achieve These Results: Reverse Supply Chain 1.0 vs. 2.0</h2>
<p>At its most basic level, a reverse supply chain guides a product through a sequence of steps. Start with a simple process - Supply Chain 1.0. In this process, the first step starts with a trigger event (e.g., customer dissatisfaction with the product or product recall). The second step is logistics - transporting the product back to your company. The third step is inspection: assessing the value of the item (i.e., automotive companies often extract specific parts from returned vehicles and resell them). The final step is a disposition - finding a home for the returned product (e.g., landfill, partial recycling, or resale).</p>
<p>Let’s assume that you cannot create new manufacturing processes or equipment. Instead, you need to get everything you can out of what you already have. Data analytics and machine learning can help.</p>
<h3>Prediction</h3>
<p>To make the most of your limited supply chain resources, you need to make better predictions. For example, if you have a network of 5 warehouses across the country, a <a href=""https://towardsdatascience.com/artificial-intelligence-in-supply-chain-management-predictive-analytics-for-demand-forecasting-80d2d512f155"">random forest algorithm</a> can help you better forecast demand and return volumes. With that information, you can contract for increased trucking capacity and avoid products sitting in your warehouse for long periods. This will help companies optimize their assets, enable more on-time deliveries, and effectively manage storage capacity.</p>
<h3>Anomaly detection</h3>
<p>In a reverse supply chain context, anomaly detection helps to find patterns in product defects and then improve your operations accordingly. For example, let’s say your company processed 10,000 returns last month. With anomaly detection, you can quickly identify the most expensive types of returns. A long short-term memory network (i.e., LSTM Network) is a useful tool to compare data across different time series like comparing Q4 2019 to Q4 2018. This approach is helpful if your return volumes are relatively stable.</p>
<h3>Optimization</h3>
<p>Growth modeling is another area where machine learning algorithms can process immense amounts of data from multiple sources and improve optimization. It can be used to help determine the best locations for future warehouses, the best vendors to work with, the best routes to take, and automate many paperwork processes. You can even automate a dynamic pricing model to boost profits on each item sold. Even more solutions are being developed daily from drone management in retail and warehousing, to computer vision-enabled conveyor systems, and multi-sensory 5G location and condition trackers. Advanced analytics and integration support each of these components of complete supply chain management.</p>
<h3>Advanced analytics and integration</h3>
<p>Advanced analytics extend every business’s reach, enabling new product forecasting, demand, and ROI, taking into consideration more variables than ever before. In tandem, integration to e-commerce sites, marketing information, and current product and financial tracking systems is critical to understanding the big picture as the development of a modern supply chain is underway.</p>
<p>These ways to optimize and automate the supply chain are often forgotten when applied in reverse, but critical to the bottom line.</p>
<h2>Where To Go From Here In Optimizing Your Reverse Supply Chain</h2>
<p>Data can be the obstacle or the solution to all these potential benefits. Fortunately, experts-for-hire on this are easy to reach. Blue Orange Digitial, a top-ranked AI development agency in NYC, specializes in cloud data storage solutions and facilitates the development of supply chain optimization. They provide custom solutions to meet each business’s unique needs, but also many pre-built options for supply chain leaders. From a technology point of view, we have outlined several different ways to improve the efficiency of the reverse supply chain. Taken together, these improvements give you Reverse Supply Chain 2.0.</p>
<p>Originally Published: <a href=""https://www.predictiveanalyticsworld.com/machinelearningtimes/why-machine-learning-is-central-to-reverse-supply-chain-2-0/11569/"">https://www.predictiveanalyticsworld.com/machinelearningtimes/why-machine-learning-is-central-to-reverse-supply-chain-2-0/11569/</a></p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Reverse-Supply-Chain.jpg,Reverse-Supply-Chain.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/Reverse-Supply-Chain.jpg,2982,Reverse-Supply-Chain,,,,https://blueorange.digital/wp-content/uploads/2022/05/Reverse-Supply-Chain.jpg,,,,,,,,
3084,"Bank Customer Acquisition: Three Data-Driven Strategies That Work","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Winning more bank customers in 2020 and beyond is only going to get more complicated. Advertising on major platforms like Google and Facebook for financial services like insurance is already high. In 2019, the average cost per click for finance and insurance was $3.44 in Google Ads according to<a href=""https://www.wordstream.com/blog/ws/2016/02/29/google-adwords-industry-benchmarks""> Wordstream</a>. If you convert 1% of clicks to customers, your customer acquisition cost is probably above $300. Few industries face higher costs to acquire customers than financial services.</p>
<p>Based on our experience in digital marketing, cost per click and related marketing metrics are likely to increase. Outside of market forces, bank regulators are applying more restrictions on bank sales practices. This means you need to find more ways to attract customers who want to do business with you.</p>
<h2>Case Study: How A Fortune 500 Bank Increased Marketing Effectiveness</h2>
<p>You might think that you have to create a brand new strategy, experiment with new methods, or try something else untested to win today’s financial customer. There’s a place for marketing experimentation. However, optimizing your existing strategy with data is a much safer way to acquire more customers right now.</p>
<p>In our work with a Fortune 500 bank, we helped them build a data strategy focused on acquiring bank customers. By using advanced techniques like the Multi-Armed Bandit, we optimized the bank’s pay per click (PPC) marketing. That means they can stretch each marketing dollar farther. You might offer different financial products; however, you can still use a data-driven customer acquisition strategy. For details, read our case study: Marketing Optimization for Fortune 500 Bank.</p>
<div class=""wp-block-image"">
<figure class=""aligncenter is-resized""><a href=""https://blueorange.digital/cptcasestudies/marketing-optimization-for-fortune-500-bank/""><img class=""wp-image-4673"" src=""https://blueorange.digital/wp-content/uploads/2020/03/Bank-9_16-1024x512.png"" alt="""" width=""512"" height=""256"" /></a><br />
<figcaption><a href=""/cptcasestudy/marketing-optimization-for-fortune-500-bank/"">Case Study: Marketing Optimization for Fortune 500 Bank</a></figcaption>
</figure>
</div>
<h2>Three Ways To Acquire More Bank Customers Using Data</h2>
<p>From our work with financial firms, we have identified a few strategies that reliably boost customer acquisition. Instead of increasing marketing spend and hoping for the best, these strategies reduce customer acquisition guesswork.</p>
<h2>1) Identify The Most Profitable Segments In Your Customer Base So You Can Get More Of Them</h2>
<p>You probably already have a defined customer profile or avatar. However, these profiles tend to be general and demographics (e.g., the residential mortgage target market are couples with a household income over $100,000). With a data strategy, we can go far deeper to identify additional segments. For example, you might find that your bank is acquiring new immigrant customers at a much lower cost than other demographics. Alternatively, you may find that your sales staff perform best at selling credit cards when they offer sign up incentives worth over $100. Finding these segments manually would require a heroic amount of analysis. Using modern machine learning algorithms, you can find highly profitable customer niches more quickly.</p>
<blockquote class=""wp-block-quote""><p><em>Tip: You can also leverage the data capabilities of Google to find more customers. For example, use Google Ad’s “In-Market Audiences” capability to identify customers actively looking for loans. By focusing your marketing on customers who have demonstrated a high degree of interest</em></p>
</blockquote>
<h2>2) Increase The Relevance of Cross-Selling</h2>
<p>In financial services, there are dozens of products you can offer to a customer. Done right, you can cross-sell a customer with checking accounts into higher-margin products like lines of credit. On the other hand, if you are too aggressive or make the wrong offer and your customer may become angry.</p>
<p>A data strategy helps you to refine your selling strategy by mapping the customer journey. For example, let’s say your bank is focused on selling four products: checking accounts, credit cards, mortgages, and student loans. Instead of offering all products to all prospects and hoping for the best, you can use data to plot a logical sequence of offers. For example, start by providing a credit card with a low limit to customers under age 25. After that product has been used for 12 months, follow up to offer a checking account to increase customer loyalty.</p>
<blockquote class=""wp-block-quote""><p><em>Tip: Experiment with your fee structure to improve bank customer retention. According to research reported in</em><a href=""https://bankingjournal.aba.com/2018/08/customer-retention-in-2018/""><em> Banking Journal</em></a><em>, “45% of millennials cited high fees as their main reason for switching banks” in 2018.</em></p>
</blockquote>
<h2>3) Increase Marketing Speed To Acquire More Customers</h2>
<p>Acquiring new customers in banking requires an experimental mindset. You never know which will resonate, at which time. Traditional marketing requires weeks or months of preparation to develop new offers and incentives. In turn, that means that you will only be able to offer a handful of modern marketing offers each year. With a data-driven strategy, you can increase the speed and accuracy of marketing measurements. That matters because it lets you detect problems quickly so that you can move resources to your winners as soon as you find them.</p>
<h2>Take Action To Acquire More Customers</h2>
<p>Changing customer attitudes toward fees, demand for rewards, and higher expectations for customer service are just a few of the factors impacting the financial industry. To keep up with changing customer preferences, you need a marketing and sales system that can pivot quickly. Building a data-driven customer acquisition strategy using statistical models, historical data and machine learning is the best way to go. Contact Blue Orange Digital today to discuss ways to acquire more customers without exceeding your marketing budget.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Banking-Customer-Acquisition.png,Banking-Customer-Acquisition.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Banking-Customer-Acquisition.png,3085,Banking-Customer-Acquisition,,,,https://blueorange.digital/wp-content/uploads/2022/05/Banking-Customer-Acquisition.png,,,,,,,,
3106,"6 Steps To Get Insights From Social Media With NLP","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Sentiment analysis and <a href=""https://www.unite.ai/what-is-natural-language-processing/"">natural language processing</a> (NLP) of social media is a proven way to draw insight from people and society. Instead of asking an analyst to spend weeks reading social media comments and providing a report, sentiment analysis can give you a quick summary. That means you can make decisions faster.</p>
<h2>Why Do You Need Sentiment Analysis and NLP in Social Media?</h2>
<p>You’re living in the age of big data. Take social media users as an example. In<a href=""https://thenextweb.com/contributors/2019/01/30/digital-trends-2019-every-single-stat-you-need-to-know-about-the-internet/""> 2019</a>, there were 3.4 billion active social media users in the world. On<a href=""https://www.youtube.com/intl/en-GB/about/press/""> YouTube</a> alone, one billion hours of video content are watched daily. Every indicator suggests that we will see more data produced over time, not less.</p>
<p>There is simply too much data for you to review manually. Even organizations with large budgets like national governments and global corporations are using data analysis tools, algorithms, and natural language processing.</p>
<p>By using these techniques, you can understand what people are saying about your brand right now. The ability to minimize selection bias and avoid relying on anecdotes mean your decisions will have a firm foundation. That means you will make fewer mistakes as you react to a rapidly changing world.</p>
<h2>Sentiment Analysis &amp; NLP In Action: Hiring, Public Health, and Marketing</h2>
<p>You might be wondering if these data analysis tools are useful in the real world or if they are reliable to use. These tools have been around for over a decade, and they are getting better every year. With NLP and sentiment analysis, you can solve problems faster.</p>
<h2>Save Time During Hiring</h2>
<p>In hiring, finding quality candidates is tough. Workopolis estimates that “as many as 75% of applicants for a given role aren’t actually qualified to do it.” Spending time on those candidates is not productive. Fortunately, natural language processing and analytics can help you identify good-fit candidates so that you can use time productively. That’s why Blue Orange Digital worked with a hedge fund to optimize their human resources process. Using ten years’ worth of applicant data and resumes, the firm now has a sophisticated scoring model to find good-fit candidates.</p>
<h2>Public health and emergencies</h2>
<p>In 2020, we’ve all started to learn the value of large scale public health data analysis due to the rapid spread of COVID. In these crises, detecting changes in social behavior quickly is essential. With NLP, you can analyze social media to evaluate sentiment. For example, a recent<a href=""https://towardsdatascience.com/covid-19-outbreak-tweet-analysis-on-face-masks-27ef5db199dd""> project analyzed over 1,000 tweets</a> using the keyword masks to understand how people are thinking and feeling about masks.</p>
<h2>Marketing</h2>
<p>In marketing, you need to stay informed about how your target market thinks and feels. A<a href=""https://www.researchgate.net/publication/331900728_Twitter_Sentiment_Analysis_A_Case_Study_for_Apparel_Brands""> 2019 study</a> used Twitter sentiment analysis to understand clothing brands: Nike and Adidas better. Analyzing 30,895 English language tweets, the researchers found, “Adidas has more positive sentiment than Nike.” However, over 50% of tweets had a neutral sentiment. That means there is still a significant opportunity to earn more positive mentions from the marketplace.</p>
<figure class=""wp-block-image""><img class=""wp-image-172248"" src=""https://ml8ygptwlcsq.i.optimole.com/fMKjlhs.f8AX~1c8f3/w:740/h:387/q:auto/https://www.unite.ai/wp-content/uploads/2020/08/53.jpg"" alt=""Likes are the new currency, NLP in social media"" /></figure>
<p>Likes are the new currency, NLP in social media</p>
<h2>How Does Sentiment Analysis Work Technically?</h2>
<p>For sentiment analysis to work effectively, there are a few essential technical points to keep in mind.</p>
<h2>1) Develop A Relevant Business Question</h2>
<p>Decide what questions you want to answer and whether these data techniques are a good fit for those questions. Let’s consider two marketing questions</p>
<ul>
<li>Should we launch a marketing partnership with a credit card company to make more sales?</li>
<li>Are we getting returns on our influencer marketing campaigns?</li>
</ul>
<p>The first question concerns strategy and future possibilities, so there will not be much data to analyze. Therefore, we would suggest not attempting to answer this question with sentiment analysis. In contrast, question two is more promising for natural language processing. It still requires further refinement, but you have the start of an appropriate question.</p>
<h2>2) Find Your Data Source</h2>
<p>Your next step is to find a relevant data source to analyze. Ideally, look for data sources that you already have rather than creating something new. For hiring, you probably have a database of applicants and successful hires in your applicant tracking system. In marketing, you can download data from social media platforms using APIs.</p>
<p><em>Tip: Data volume is vital for sentiment analysis to work. As a rule of thumb, your data set should have at least 1,000 examples (e.g., 1,000 tweets or 1,000 applicant profiles). Anything less than that, and you are less likely to obtain statistically meaningful results.</em></p>
<h2>3) Pre-Process Your Data</h2>
<p>Most data sources, especially social media, and user-generated content, require pre-processing before you can work with it. Assuming you are analyzing a text resource, start by removing unnecessary punctuation, characters, and other cleaning text. Spending time on this step will improve the quality of the resulting analysis.</p>
<p>Since more extensive data sets tend to produce better results, use tools to clean the data further. For example, the<a href=""https://iq.opengenus.org/porter-stemmer/""> Porter Stemmer Algorithm</a> is a helpful way to clean up text data. This algorithm helps to identify root words and cut down on noise in your data.</p>
<h2>4) Analyze The Data</h2>
<p>Depending on your goals, there are different software tools and algorithms available to analyze the data. Assuming you are analyzing text, the Naïve Bayes algorithm is the right choice to conduct sentiment analysis.</p>
<h2>5) Critically Evaluate Outputs</h2>
<p>You cannot merely accept the data analysis generated by machines uncritically. Researchers have found that <a href=""https://www.unite.ai/what-is-machine-learning/"">machine learning</a> tools tend to reflect human bias. For example,<a href=""https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G""> Amazon scrapped a human resources algorithm</a> because it discriminated against female candidates. After all, historical data, in this case, was mainly based on men. That’s where your values – like a commitment to inclusion and diversity – need to balance data-driven insights. </p>
<p>This also applies to the outputs yielded by search engines. KISSPatent CEO D’vorah Graeser provides an example of how NLP is improving their search engines results when analyzing information from the World Intellectual Property Organization </p>
<blockquote class=""wp-block-quote""><p><em>“Using NLP is especially relevant and useful when trying to look for patents for new technologies such as blockchain or Artificial Intelligence, which don’t have defined categories in the World Intellectual Property Organization, for example. Being able to search and find patents is important to all innovators because that way they can know who’s working on certain innovations and if their innovations are as unique and new as they think.”</em></p>
<p><em>KISSPatent CEO, D’vorah Graeser</em></p>
</blockquote>
<h2>6) Determine Next Steps</h2>
<p>On its own, sentiment analysis will not change your business. You need to review those insights and make a decision. For example, you may find that you have a growing amount of negative sentiment about your brand online. In that case, you might start a research project to identify customer concerns and then release an improved version of your product.</p>
<h2>Not Sure Where To Get Started with NLP in social media?</h2>
<p>Finding the right data, applying algorithms to that data, and getting usable business insights isn’t easy. After all, large companies with deep resources have made mistakes in their natural language processing projects. That’s why it pays to get an outside perspective on your data. Contact <a href=""https://blueorange.digital/"">Blue Orange Digital</a> today to find out how you can get faster insights from social media and other data in your organization.</p>
<p><strong>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for Supply Chain, Healthcare Document Automation, and more <a href=""/cptcasestudies/"">Case Studies</a>.</strong></p>
<p>Originally Published: <a href=""https://www.unite.ai/6-steps-to-get-insights-from-social-media-with-natural-language-processing/"">https://www.unite.ai/6-steps-to-get-insights-from-social-media-with-natural-language-processing/</a></p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/48.jpg,48.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/48.jpg,3124,48,,,,https://blueorange.digital/wp-content/uploads/2022/05/48.jpg,,,,,,,,
3135,"Make Machine Learning Work for Your Company: An Overview","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>“Machine learning” is hot. Apple is “<a href=""https://www.computerworld.com/article/3439061/apple-is-building-a-machine-learning-system-to-rule-them-ali.html"">building a machine learning system to rule them all</a>.” YouTube uses machine learning to <a href=""https://www.forbes.com/sites/bernardmarr/2019/08/23/the-amazing-ways-youtube-uses-artificial-intelligence-and-machine-learning/#63c3c4c55852"">remove objectionable content</a>, while telecom empires apply ML algorithms for <a href=""https://www.forbes.com/sites/bernardmarr/2019/09/02/the-amazing-ways-telecom-companies-use-artificial-intelligence-and-machine-learning/#777375034cf6"">predictive maintenance and improving network reliability</a>. And, of course, there are <em>plenty</em> of <a href=""https://www.forbes.com/sites/nicolemartin1/2019/08/26/7-must-see-ted-talks-on-ai-and-machine-learning/#3c14e36316d9"">TedTalks</a>. </p>
<p>For all the hype around machine learning, it still seems like a distant and futuristic concept for many in their everyday work lives. However, this technology — which is defined as a computer learning from experience to improve at a task without explicit programming — can be implemented at your company today regardless of size or industry. The underlying thread of ML for business is the potential to help companies operate more efficiently and competitively.</p>
<p>To illustrate this potential, here’s a brief overview of applications:</p>
<h2>Marketing</h2>
<p>The discipline has always been a bit of an art, but machine learning can elevate your creative intuition with a strong scientific foundation. <a href=""https://adexchanger.com/brand-aware/the-reality-of-machine-learning-in-marketing/"">Marketers are already using</a> machine learning to target the right audience at the best time, test different combinations of copy in real-time, and personalize landing pages with optimal product and pricing.</p>
<h2>Human Resources</h2>
<p>In the knowledge economy, finding and retaining the best employees is more important than ever. Fortunately, machine learning can help. Algorithms can be used to remove bias from the hiring process, rank resumes, and identify candidates similar to your most successful employees. <a href=""https://www.hrexchangenetwork.com/hr-tech/articles/ai-in-hr"">It can create custom experiences</a> that attract applicants, automate feedback throughout the hiring process, and even answer candidate questions in real-time. Post-hire, machine learning enables employers to identify <a href=""https://hbr.org/2019/08/better-ways-to-predict-whos-going-to-quit"">which of their employees are most likely to turnover</a> creating an opportunity to intervene. Here’s an interesting case study on how Blue Orange uses ML to solve problems across the hiring process.</p>
<h2>Customer Service</h2>
<p>You’ve probably already experienced machine learning applied to customer service — in the form of chatbots. While not all chatbots incorporate machine learning, the ones that do <a href=""https://www.zendesk.com/blog/machine-learning-used-customer-service/"">can identify</a> when it’s appropriate to use specific responses, gather required information, and escalate to a human agent. Additionally, natural language processing helps human agents <a href=""https://www.fiercepharma.com/marketing/biogen-taps-machine-learning-to-boost-human-customer-service-reps-expertise"">quickly find answers</a> that are buried in heavy text. These applications fundamentally increase customer service speed and customer satisfaction. </p>
<h2>Fraud Prevention and Detection</h2>
<p>Increasingly sophisticated fraud attempts, aided and abetted by new technology, <a href=""https://www.forbes.com/sites/louiscolumbus/2019/07/09/top-9-ways-artificial-intelligence-prevents-fraud/#5fd690c614b4"">call for increasingly sophisticated fraud prevention and detection</a>. Machine learning’s anomaly detection capabilities make it well suited not only for recognizing old patterns of fraudulent activity, but also detecting new types of activity as they emerge. The resulting reduction in chargeback levels is especially valuable for e-commerce businesses.</p>
<h2>Cyber Security</h2>
<p>Likewise, the constant evolution of cyber-attacks renders machine learning <a href=""https://www.entrepreneur.com/article/339509"">an important tool for cyber defense</a>. Because it does not rely on past attack data as much as conventional approaches, machine learning is able to keep pace with hackers and more accurately predict cyber threats. Additionally, the sheer volume of cyber attacks makes machine learning an important tool for managing staffing expenses.</p>
<h2>In Summary</h2>
<p>Machine learning is already an indispensable tool for many industries. If ML is the future of business, then the future is here. </p>
<p>If you want to dig in on specific applications for your business, <a href=""/contact-us/"">feel free to reach out to us today.</a></p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/machine-learning--scaled.jpeg,machine-learning--scaled.jpeg,/www/blueorangem_500/public/wp-content/uploads/2022/05/machine-learning--scaled.jpeg,3138,machine-learning-,,,,https://blueorange.digital/wp-content/uploads/2022/05/machine-learning--scaled.jpeg,,,,,,,,
3147,"Do you recommend Recommendation Engines?","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">

In business, the needle in a haystack problem is a constant challenge. Recommendation Engines are here to help tackle that challenege.

In e-commerce and retail, you offer hundreds or thousands of products. Which is the right product for your customers?

In sales and marketing, you have a large number of prospects in your pipeline. Yet, you only have so many hours in the day. So, you face the challenge of deciding where precisely to focus your effort.

There is a specialized technology powered by AI and Big Data, which makes these challenges much easier to manage, recommendation engines.
<h2>What are recommender systems?</h2>
In its simplest terms, a recommendation engine sorts through many items and predicts the selection most relevant to the user. For consumers, Amazon’s product recommendation engine is a familiar example. In the entertainment world, Netflix has worked hard to develop their engine. Netflix’s recommendation engine has delivered bottom-line benefits:

“[Netflix’s] sophisticated recommendation system and personalized user experience, it has allowed them to save $1 billion per year from service cancellations.” -<a href=""https://martechtoday.com/roi-recommendation-engines-marketing-205787""> The ROI of recommendation engines for marketing</a>

From the end user’s perspective, it is often unclear how recommendation engines work. We’re going to pull the curtain back and explain how they work, starting with the key ingredient: data.
<h2>Recommendation Engines: What data do they use?</h2>
The <a href=""https://www.unite.ai/"">data</a> you need for a recommendation engine depends on your goal. Assume your goal is to increase sales in an e-commerce company. In that case, the bare minimum required data would fall into two categories: a product database and end-user behavior. To illustrate how this works, look at this simple example.
<ul>
 	<li><strong>Company: </strong>USB Accessories, Inc. The company specializes in selling USB accessories and products like cables, thumb drives, and hubs to consumers and businesses.</li>
 	<li><strong>Product Data.</strong> To keep the initial recommendation engine simple, the company limits it to 100 products.</li>
 	<li><strong>User Data.</strong> In the case of an online store, user data will include website analytics information, email marketing, and other sources. For instance, you may find that 50% of customers who buy an external hard drive also buy USB cables.</li>
 	<li><strong>Recommendation Output.</strong> In this case, your recommendation engine may generate a recommendation (or a discount code) to hard drive buyers to encourage them to buy USB cables.</li>
</ul>
In practice, the best recommendation engines use much more data. As a general rule, recommendation engines produce better business results when they have a large volume of data to use.
<h2>How do recommendation engines use your data?</h2>
Many recommendation engines use a handful of techniques to process your data.
<h2>Content-based filtering</h2>
This type of recommendation algorithm combines user preferences and attempts to recommend similar items. In this case, the engine is focused on the product and highlighting related items. This type of recommendation engine is relatively simple to build. It is a good starting point for companies with limited data.
<h2>Collaborative filtering</h2>
Have you asked somebody else for a recommendation before making a purchase? Or considered online reviews in your buying process? If so, you have experienced collaborative filtering. More advanced recommendation engines analyze user reviews, ratings, and other user-generated content to produce relevant suggestions. This type of recommendation engine strategy is powerful because it leverages social proof.
<h2>Hybrid recommenders</h2>
Hybrid recommendation engines combine two or more recommendation methods to produce better results. Returning to the e-commerce example outlined above, let’s say you have acquired user reviews and ratings (e.g., 1 to 5 stars) over the past year. Now, you can use both content-based filtering and collaborative filtering to present recommendations. Combining multiple recommendation engines or algorithms successfully usually takes experimentation. For that reason, it is best considered a relatively advanced strategy.

A recommendation engine is only successful if you feed it with high-quality data. It also cannot perform effectively if you have errors or out of date information in your company database. That’s why you need to invest resources in data quality continuously.
<h2>Case Studies:</h2>
<h2>Hiring Automated: Recommended Candidates</h2>
There are more than 50 applicants on average per job posting, according to Jobvite research. For human resources departments and managers, that applicant volume creates a tremendous amount of work. To simplify the process, Blue Orange implemented a recommendation engine for a fortune 500 hedge fund. This HR automation project helped the company to rank candidates in a standardized way. Using ten years' worth of applicant data and resumes, the firm now has a sophisticated scoring model to find good-fit candidates.

A Hedge Fund in New York City needed to parse resumes that were inconsistent and required OCR to improve their hiring process. Even the best OCR parsing leaves you with messy and unstructured data. Then, as a candidate moves through the application process, humans get involved. Add to the data set free form text reviews of the applicant and both linguistic and personal biases. In addition, each data source is siloed providing limited analytical opportunity.

<strong>Approach:</strong> After assessing multiple companies hiring processes, we have found three consistent opportunities to systematically improve hiring outcomes using NLP machine learning. The problem areas are: correctly structuring candidate resume data, assessing job fit, and reducing human hiring bias. With a cleaned and structured data set, we were able to perform both sentiment analysis on the text and subjectivity detection to reduce candidate bias in human assessment.

<strong>Results:</strong> Using keyword detection classifiers, optical character recognition, and cloud-based NLP engines, we were able to scrub string text and turn it into relational data. With structured data, we provided a fast, interactive, and searchable Business Analytics dashboard in AWS QuickSight.
<h2>E-Commerce: Zageno Medical Supplies</h2>
Another example of recommendation engines being implemented in the real-world comes from Zageno. Zageno is an e-commerce company that does for lab scientists what Amazon does for the rest of us. The caveat is that the needs of lab scientists are exact so the supplies procured for their research must be, as well. The quotes below from our interview with Zageno highlight how they use recommendation engines to deliver the most accurate supplies to lab scientists.
<h2>Q&amp;A: Blue Orange Digital interviews Zageno</h2>
<strong>Question:</strong>

How has your company used a recommendation engine and what sort of results did you see?

<strong>Answer:</strong>

There are two examples of the recommendation engines that ZAGENO employs for its scientific customers. To explain these we felt it best to bullet point them.
<ul>
 	<li><a href=""https://www.zageno.com/c/scientific-score"">ZAGENO's Scientific Score</a>:
<ul>
 	<li>ZAGENO’s Scientific Score is a comprehensive product rating system, specifically developed for evaluating research products. It incorporates several aspects of product data, from multiple sources, to equip scientists with a sophisticated and unbiased product rating for making accurate purchasing decisions.</li>
 	<li>We apply sophisticated machine-learning algorithms to accurately match, group, and categorize millions of products. The Scientific Score accounts for these categorizations, as each product’s score is calculated relative to those in the same category. The result is a rating system that scientists can trust — one that is specific to both product application and product type.</li>
 	<li>Standard product ratings are useful to assess products quickly, but are often biased and unreliable, due to their reliance on unknown reviews or a single metric (e.g. publications). They also provide little detail on experimental context or application. The Scientific Score utilizes a scientific methodology to objectively and comprehensively evaluate research products. It combines all necessary and relevant product information into a single 0—10 rating to support our customers in deciding which product to buy and use for their application — saving hours of product research.</li>
 	<li>To ensure no single factor dominates, we add cut-off points and give more weight to recent contributions. The sheer number of factors we take into account virtually eliminates any opportunity for manipulation. As a result, our score is an objective measure of the quality and quantity of available product information, which supports our customers’ purchasing decisions.</li>
</ul>
</li>
 	<li>Alternative Products:
<ul>
 	<li>Alternative products are defined by the same values for key attributes; key attributes are defined for each category to account for specific product characteristics.</li>
 	<li>We are working on increasing underlying data and attributes and improving the algorithm to improve the suggestions</li>
 	<li>Alternatives product suggestions are intended to help both, scientist and procurement to consider and evaluate potential products, they might not have considered/known otherwise</li>
 	<li>Alternative products are solely defined by product characteristics  and independent of suppliers, brand or other commercial data</li>
</ul>
</li>
</ul>
<strong>Do you recommend recommendation systems? </strong>
<blockquote class=""wp-block-quote"">“Yes, but make sure you are using the right data to base your recommendation on both the quality and quantity reflecting true user expectations. Create transparency because nobody, particularly scientists, will trust or rely on a black box. Share with your users which information is used, how it is weighted, and keep on learning so as to continually improve. Finally, complete the cycle by taking the user feedback that you've collected and bring it back into the system.”

&nbsp;

<cite><em>- Zageno</em></cite></blockquote>
The power of recommendation engines has never been greater. As shown by giants like Amazon and Netflix, recommenders can be directly responsible for increases in revenue and customer retention rates. Companies such as Zageno show that you do not need to be a massive company to leverage the power of recommenders. The benefits of recommendation engines span across many industries such as e-commerce to human resources.
<h2>The Fast Way To Bring Recommendation Engines To Your Company</h2>
Developing a recommendation engine takes data expertise. Your internal IT team may not have the capacity to build this out. If you want to get the customer retention and efficiency benefits of recommendation engines, you don’t have to wait for IT to become less busy. Drop us a line and let us know. The <a href=""https://blueorange.digital/"">Blue Orange Digital</a> data science team is happy to make recommenders work for your benefit too!

For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for Supply Chain, Healthcare Document Automation, and <a href=""/cptcasestudies/"">more</a>.

<hr class=""wp-block-separator"" />

<em>Follow me on </em><a href=""https://twitter.com/BlueOrangeData""><em>Twitter</em></a><em> or </em><a href=""https://www.linkedin.com/in/joshmiramant/""><em>LinkedIn</em></a><em>. Check out my </em><a href=""https://blueorange.digital/""><em>website</em></a><em>. </em>
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img class=""wp-image-5323"" src=""https://blueorange.digital/wp-content/uploads/2020/05/Josh-Miramant-CEOpng-1024x1024.png"" alt=""Josh Miramant- CEO"" width=""155"" height=""155"" /><figcaption>Josh Miramant- CEO</figcaption></figure>
</div>
<em>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He is a serial entrepreneur and software engineer that has built and scaled 3 startups. He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things. </em>

<em>Featured on IBM ThinkLeaders, Dell Technologies, and NYC’s Top 10 AI Development and Custom Software Development Agencies as reviewed on Clutch and YahooFinance for his contributions to NLP, AI, and Machine Learning. Specializing in predictive maintenance, unified data lakes, supply chain/grid/marketing/sales optimization, anomaly detection, recommendation systems, among other ML solutions for a multitude of industries.  </em>

Visit <a href=""https://blueorange.digital/"">blueorange.digital</a> for more information and <a href=""/cptcasestudies/"">Case Studies</a>.

Image source: Canva

Originally published: <a href=""https://www.unite.ai/do-you-recommend-recommendation-engines/"">Unite.AI</a>

</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/reommendation-engines.gif,reommendation-engines.gif,/www/blueorangem_500/public/wp-content/uploads/2022/05/reommendation-engines.gif,3148,reommendation-engines,,,,https://blueorange.digital/wp-content/uploads/2022/05/reommendation-engines.gif,,,,,,,,
3193,"Is Machine Learning the Right Solution?","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<h2>4 Keys to ML Project Success</h2>
<h2><strong>Executive Summary </strong></h2>
<p>In order to capture the desired value from your investment in Machine Learning and Artificial Intelligence, companies need to take a business-centric focus to their technical solutions. Companies find working with data, especially data at high velocities, difficult to manage because they failed to do the proper planning and development before embarking on an AI initiative. There are 4 keys areas of focus to reduce the risk of wasting time and resources on AI and Machine Learning.  </p>
<ul>
<li>Data Infrastructure</li>
<li>Business Objectives</li>
<li>Machine Learning Solutioning</li>
<li>Business Evaluation Feedback</li>
</ul>
<p>Having the proper infrastructure and business goals in place will allow you to measure your success and find the places for greater ROI. To learn more about Blue Orange Digital go to <a href=""https://blueorange.digital/"">blueorange.digital</a>.</p>
<h2><strong>Introduction</strong></h2>
<p>What do terms like Data Science, Machine Learning, and Artificial Intelligence mean to you? If the first answer that comes to your mind is buzz words with abstruse meaning, you have come to the right article. If you walk through the graveyard of poorly executed initiatives you will find these buzzwords on the tombstones. Here at Blue Orange Digital, our goal is to provide you with the blue(orange)print to successfully implement these transformative solutions by providing a different perspective. We take a business-centric focus to your technical problems, working closely with your team as partners, to develop solutions that meet your unique business needs. </p>
<h2><strong>Do you have the right data infrastructure to gain the most value out of investing in Data Science? </strong></h2>
<p>The first step to gaining insights and seeing the value of any data science project is to have the proper upstream data infrastructure to support your mission. Is it possible to perform machine learning and AI on csv files? Maybe, but you are going to waste a lot of time (and money) trying to work around a suboptimal pipeline. There are three capabilities that are the pillars of success before you should consider using ML/AI:</p>
<ul>
<li>Modern, sophisticated data pipeline
<ul>
<li>Moving, cleaning and organizing data into flexible, cost-efficient storage is the key to unlocking the potential of your data for machine learning initiatives</li>
</ul>
</li>
<li>Business Intelligence/Analytics
<ul>
<li>What is the story you want to tell with your data? Your business intelligence suite should be used to define the key performance indicators (KPIs) you hope to achieve. </li>
</ul>
</li>
<li>Decision Support Tools (Dashboards, visualization, etc.)
<ul>
<li>It should be easy for your leadership to clearly analyze and interpret the metrics of your data.</li>
</ul>
</li>
</ul>
<h2><strong>What is the problem we are trying to solve?</strong></h2>
<p><em>This is the most important step in any digital transformation project and should be answered before you consider moving forward. </em>In our experience, business problems are often framed in the ML solution that is needed to solve them. Have you ever walked into a meeting and someone proclaims, “we need NLP!” When the technology is talked about as the solution, you are off to a bad start. <em>The business problem should be an outcome you hope to achieve with clear metrics that you want to measure against, including how success is defined. </em>An example of a good business problem would be, we want to reduce the number of man-hours needed to process incoming documents. Determining the right use cases and business problems will be heavily influenced by the data and analytics you are already capturing.  </p>
<h2><strong>Is Machine Learning the Right Solution? </strong></h2>
<p>With a well-defined business problem, you can now start working through your possible solutions. There is no reason to over-engineer a solution, sometimes a simple regression model or a rules-based algorithm works best. If the problem is more sophisticated than a simple solution can solve, then you can move on to more complex methods.  Since you already have an infrastructure in place, we know you have the right data to properly train a machine learning model. Now it’s time to develop the technical solution. (*note all the needed steps before you reach “we need NLP!”)</p>
<p>There are a couple of different stages to technical solutions to make sure you are answering your business objective. These are universally agreed upon best practices of machine learning architecture and definitions are lifted from the “<a href=""https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Machine-Learning-Lens.pdf?did=wp_card&amp;trk=wp_card"">AWS Well-Architected Framework – Machine Learning Lens.</a>” If you wish to have a deeper understanding of these subjects, we recommend this article as a great read.  </p>
<ol>
<li>Feature Engineering- Feature engineering is a process to select and transform variables when creating a predictive model using machine learning or statistical modeling. Feature engineering typically includes feature creation, feature transformation, feature extraction, and feature selection.</li>
<li>Model Training - In this phase, you select a machine learning algorithm that is appropriate for your problem and then train the ML model. As part of that training, you provide the algorithm with the training data to learn from and set the model parameters to optimize the training process.</li>
<li>Model Evaluation - After the model has been trained, evaluate it to determine if its performance and accuracy will enable you to achieve your business goals. You might want to generate multiple models using different methods and evaluate the effectiveness of each model.</li>
</ol>
<h2><strong>Business Feedback Loop</strong></h2>
<p>By now you are receiving outputs from your solutions that need to be measured against the metrics you chose while framing your business problem. This is where iteration comes into play. Are you getting the metrics you expected? No? Then you need to loop back and rethink your solution. The key here is that the business metrics are driving your decisions, that should be the first step of your review. Next, you may want to ask questions like, are the metrics realistic? Do your current analytics and decision support tools provide the right information? If your goal was to decrease the man-hours needed to perform a task, do we have the right tools to measure that data? What is the appropriate amount of time to validate our findings? Using your data through this business-focused lens you’ll be able to clearly determine the success of your digital transformation initiatives. </p>
<p>About the Author: Matthew Paris, Vice President of Data Science at Blue Orange Digital</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/4-Keys-to-ML-project-success.gif,4-Keys-to-ML-project-success.gif,/www/blueorangem_500/public/wp-content/uploads/2022/05/4-Keys-to-ML-project-success.gif,3198,4-Keys-to-ML-project-success,,,,https://blueorange.digital/wp-content/uploads/2022/05/4-Keys-to-ML-project-success.gif,,,,,,,,
3210,"AI and IoT: Transportation Management in Smart Cities","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>he Smart Cities of today are powered by advanced technologies that are constantly reshaping urban areas. AI and IoT are becoming increasingly integral to how the world operates. Cloud-based services, the Internet of Things, analytics platforms, and many AI tools are changing the way citizens interact with and move within their environment.</p>
<p>These modern technologies, as outlined by <a href=""https://blueorange.digital/"">Blue Orange Digital</a>, a top-ranked AI consulting and development agency in NYC, enable applications ranging from waste management to food supply optimization and healthcare digitization. In the process, they are disrupting entire industries and creating new business opportunities and applications. </p>
<p>Among all urban responsibilities, transportation management poses an interesting problem, even for the most advanced AI tools and technologies. City traffic is a highly dynamic environment, where thousands of participants using different transportation modalities interact in complex manners. On top of that, decisions need to be taken in real-time, in order to ensure the safety and well being of all traffic participants. Activity planning in such an environment is an extremely challenging task. Luckily, AI-powered Smart City technologies are already making great progress in tackling some of the most pressing transportation management issues. </p>
<p>Below is a list of the most common traffic management solutions that IoT and AI technologies are powering.</p>
<h2>Crowdsourced data enables optimized routes for all vehicle types</h2>
<p>Data is power, and this holds true especially for city planners: it has become mandatory that their decisions are backed by data. Information about how different city areas are used by the citizens (mobility data) can provide crucial insights into transportation needs. It offers them an accurate overview of how different city pathways are being used and thus increases the chances for more accurate, citizen-friendly planning.</p>
<p>Crowdsourced data is nowadays ubiquitous and originates in a variety of devices. Our smartphones, tablets, laptops and even cars are all constantly emitting geolocation data. A variety of applications are capturing this data and using it to power consumer-facing services. At the same time, analytics frameworks make it straightforward to extract insights from such heterogeneous data sources. By sharing this data with city administration and city planners, it is possible to capitalize on this rich mobility data in order to improve the planning process. </p>
<p>Think about the most popular bike pathways in your city or the most populated pedestrian areas. Planning without knowledge of how these areas are used would be equivalent to climbing Mount Everest blindfolded, in the dark. Visualization and analytics are definitely needed to bring light to the process and to make sure that all planning decisions are powered by citizen-generated data.</p>
<p>The benefits of crowdsourced mobility data can translate into improved walkability and reduced commute times. For bike riders, this translates to optimized routes and greener pathways, while for the car drivers it means less time spent in city centers, waiting for traffic lights and pedestrians. Mobility data makes it a win-win-win for all traffic participants.</p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-172549"" src=""https://www.unite.ai/wp-content/uploads/2020/08/city-planning-two-1024x576.jpg"" alt="""" /></figure>
</div>
<h2>Computer vision &amp; AI enable pedestrian and vehicle safety</h2>
<p>Ensuring public road safety is a crucial responsibility of transportation management systems. The complex environment created by vehicles and pedestrians needs to be kept under close surveillance, in order to ensure the safety of all traffic participants.</p>
<p>Luckily, technology is available that makes it possible to automate such surveillance tasks and delegate them to software and algorithms. Computer vision and video analytics can be implemented both on roadside cameras, but also on cars. Algorithms can perform computation on the edge and can detect situational and behavioral abnormalities at the moment when they happen. From the automated reading of license plates to detecting walking patterns, a variety of applications become possible thanks to computer vision. When implemented as part of traffic management systems, they can minimize the high risks associated with careless driving and ensure the safety of public pedestrian areas. </p>
<p>Delegating and automated tasks to software have the potential to create a much safer environment for all traffic participants. Computer vision and video analytics are the leading technologies for efforts in this direction.</p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-172550"" src=""https://www.unite.ai/wp-content/uploads/2020/08/city-planning-three--1024x576.jpg"" alt="""" /></figure>
</div>
<h2>IoT Sensors enable accurate traffic monitoring in smart cities</h2>
<p>Understanding traffic is a task that needs to be done in real-time, in order to be able to optimize the traffic flow, both within and outside of urban areas. This involves the identification and communication of accidents, congestion, and temporary roadside obstacles, among other traffic events.</p>
<p>Sensor technologies and advanced wireless communication protocols make it possible for all kinds of vehicles to communicate direction, speed, and travel times. There is no limit to the amount of information that they can communicate, given the increased customizability of IoT devices. Not only can they be attached to any moving object, but they also make it possible to collect and communicate contextual information from the environment. </p>
<p>Sensor-collected data makes it possible to run real-time analytics, that power immediate traffic management decisions. Such an example application is that of adaptive traffic signals, which are not simply programmed, but take into account live traffic information.</p>
<p>The benefits of sensor-based solutions can be translated into active traffic management measures. They enable short-term prediction and control and can lead to reduced congestion and increased traffic fluidity. By helping traffic management institutions cut down on emissions, noise, and travel times, IoT-based sensor technologies play a crucial role in any modern transportation management system.</p>
<h2>What’s next for AI and IoT in smart cities?</h2>
<p>City planners and engineers are now working in increasingly complex environments and need to solve increasingly complex problems. AI and IoT are helping them tackle these problems. Traffic and transportation management poses a modern challenge that would be tricky to tackle without the help of software and algorithms. Additionally, traffic management plays a crucial role in any Smart City since it can easily impact the well functioning of all other city functions.</p>
<p>Luckily, modern technologies make it possible to leverage citizen-generated mobility data in order to tackle such complex tasks. With the increased availability of analytics frameworks, cloud services, and data collection devices, it becomes possible to find modern solutions and integrate real-time data as part of traffic management decisions. </p>
<p>When data is used for decision making and for gaining a better understanding of city travel dynamics, the quality of the management applications also increases. This ensures that traffic control strategies and future infrastructure development projects will accurately match the citizens’ needs. AI and IoT are becoming the new technological norm and that’s a future we are eagerly looking forward to.</p>
<p>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for Supply Chain, Healthcare Document Automation, and <a href=""/cptcasestudies/"">more</a>.</p>
<hr class=""wp-block-separator"" />
<figure class=""wp-block-image""><img src=""https://lh5.googleusercontent.com/Seir2wv5bDadxdPCb2EeZbuivw8ZHNnYfL30n0wu6ET8G5QJNpKfwvhjl59v45_57IZBiVbpLq0WnqPbItUS4Fu7HF4JwWJCirU-ekjxEvHyzj5WFqyct2MV9673-0mvS9E7DLc8"" alt="""" /></figure>
<p><em>Follow me on</em><em> </em><a href=""https://twitter.com/BlueOrangeData""><em>Twitter</em></a><em> </em><em>or </em><a href=""https://www.linkedin.com/in/joshmiramant/""><em>LinkedIn</em></a><em>. </em><em>Check out my</em><em> </em><a href=""https://blueorange.digital/""><em>website</em></a><em>. </em></p>
<p>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He is a serial entrepreneur and software engineer that has built and scaled 3 startups. He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things. </p>
<p>Featured on IBM ThinkLeaders, Dell Technologies, and NYC’s Top 10 AI Development and Custom Software Development Agencies as reviewed on Clutch and YahooFinance for his contributions to NLP, AI, and Machine Learning. Specializing in predictive maintenance, unified data lakes, supply chain/grid/marketing/sales optimization, anomaly detection, recommendation systems, among other ML solutions for a multitude of industries.  <br />Visit <a href=""https://blueorange.digital/"">blueorange.digital</a> for more information and <a href=""/cptcasestudies/"">Case Studies</a>.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/city-planning-cover.jpg,city-planning-cover.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/city-planning-cover.jpg,3211,city-planning-cover,,,,https://blueorange.digital/wp-content/uploads/2022/05/city-planning-cover.jpg,,,,,,,,
3225,"Three Uses of Automation within Supply Chain 4.0","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>The increased availability of advanced technologies has revolutionized the traditional supply chain model. Supply Chain 4.0 responds to modern customer expectations by relying heavily on the Internet of Things (IoT), advanced robotics, big data analytics, and blockchain. These tools enable automation and thus give organizations a chance to close information gaps and optimally match supply and demand.</p>
<blockquote class=""wp-block-quote""><p><em>“The reorganization of supply chains […] is transforming the model of supply chain management from a linear one, in which instructions flow from supplier to producer to distributor to consumer, and back, to a more integrated model in which information flows in an omnidirectional manner to the supply chain.”</em></p>
<p><cite>Understanding Supply Chain 4.0 and its potential impact on global value chains</cite></p></blockquote>
<p>Industry giants like Netflix, Tesla, UPS, Amazon, and Microsoft rely heavily on automation within their supply chain to lead their respective industries. Let us take a closer look at three powerful automation use cases.</p>
<h2>1. Managing demand uncertainty</h2>
<p>A painful aspect of supply chain ecosystems is the demand uncertainty and the inability to accurately forecast demand. Generally, this leads to a set of performance issues, from increased operational cost to excess inventory and suboptimal production capacity. Automation tools can forecast demand, remove uncertainty from the equation, and thus improve operational efficiency at each step along the supply chain.</p>
<p><a href=""https://www.intechopen.com/books/new-trends-in-the-use-of-artificial-intelligence-for-the-industry-4-0/big-data-analytics-and-its-applications-in-supply-chain-management"">Big data analytics (BDA)</a> is an established tool that helps organizations manage demand uncertainty. It consists of data collection &amp; aggregation infrastructure combined with powerful ML algorithms, designed to forecast demand based on historical (or even real-time) data. Modern storage solutions (such as data lakes) make it possible to aggregate data from a variety of sources: market trends, competitor information, and consumer preferences. </p>
<p>ML algorithms continually analyze this rich data to find new patterns, improve the accuracy of demand forecasting, and enhance operational efficiency. This is the recipe that <a href=""https://www.retailbiz.com.au/latest-news/inside-amazons-ai-powered-supply-chain/"">Amazon uses</a> to predict demand for a product before it is purchased and stocked in their warehouse. By examining tweets and posts on websites and social media, they understand customer sentiments about products and have a data-based way to model demand uncertainty. The good news is that such powerful analytics tools are not restricted to industry giants anymore. Out-of-the-box solutions (such as <a href=""https://docs.aws.amazon.com/forecast/latest/dg/what-is-forecast.html"">Amazon Forecast</a>) make such capabilities widely available to all organizations that wish to handle demand uncertainty.</p>
<h2><strong>2. Managing process uncertainties</strong></h2>
<p>Organizations operating in today’s supply chain industry need to handle increasingly complex logistic processes. The competitive environment, together with ever-increasing customer expectations make it imperative to minimize uncertainties across all areas of supply chain management. </p>
<p>From production and inventory, to order management, packing, and shipping of goods, automation tools can tackle uncertainties and minimize process flaws. AI, robotics, and IoT are well-known methods that facilitate an optimal flow of resources, minimize delays, and promote optimized production schedules.</p>
<p><a href=""https://www.linkedin.com/pulse/internet-things-iot-game-changer-supply-chain-industry-sharad-prakash"">Internet of Things (IoT</a>) is playing an important role to overcome process uncertainties in the supply chain. One major IoT application is the accurate tracking of goods and assets. IoT sensors are used for tracking in the warehouse, during loading, in-transit, and unloading phases. This enables applications such as live monitoring, which increase process visibility and enable managers to act on real-time information. It also makes it possible to further optimize a variety of other processes, from loading operations to payment collection.</p>
<p>Since 2012, Amazon fulfillment warehouses use<a href=""https://www.businessinsider.com/kiva-robots-save-money-for-amazon-2016-6""> AI-powered robots</a> that are doing real magic. One can see robots and humans working side by side through wireless communication, handling orders that are unique in size, shape, and weight. Thousands of Wi-Fi connected robots gather merchandise for each individual order. These robots have two powered wheels that let them rotate in place, IR for obstacle detection, and built-in cameras to read QR codes on the ground. Robots use these QR codes to determine their location and direction. Like this, efficiency is increased, the physical activity of employees is reduced and process uncertainty is kept to a minimum.</p>
<p>Another example of how automation helps make process improvements comes from vehicle transport company CFR Rinkens. They have utilized automation in their accounting and billing department to quicken payment processing times, automate invoice creation, and decrease costs due to inaccurate information and delays.</p>
<blockquote class=""wp-block-quote""><p><em>""An area of need that we applied automation was within the accounting department for billing and paying vendors. With tons of invoices coming in and out, automation here ensures nothing falls through the cracks, and clients receive invoices on time providing them with enough time to process payment.""</em></p>
<p><cite><em>-Joseph Giranda CFR Rinkens</em></cite></p></blockquote>
<p>The biggest benefits of automation are transparency, having each step of the supply chain organized, and eliminating grey areas for both clients and businesses.</p>
<h2><strong>3. Synchronization among supply chain partners and customers</strong></h2>
<p>Digital supply chains are characterized by synchronization among hundreds of departments, vendors, suppliers, and customers. In order to orchestrate activities all the way from planning to execution, supply chains require information to be collected, analyzed, and utilized in real-time. A sure way to achieve a fully synchronized supply chain is to leverage the power of automation. </p>
<p>CFR Rinkens uses a dynamic dashboard to keep track of cargo as they deliver vehicles across the world. This dashboard is automatically updated with relevant information that increases transparency and efficiency. High transparency allows for excellent customer service and satisfaction. </p>
<blockquote class=""wp-block-quote""><p><em>""Upon a vehicle's arrival, images are taken and uploaded onto a CFR dashboard that our clients are able to access. All vehicle documents, images, and movements are automatically displayed within this dashboard. This automation helps on the customer service side because it allows for full transparency and accountability for quality control, delivery window times, and real-time visibilty.""</em></p>
<p>&nbsp;</p>
<p><cite><em>-Joseph Giranda CFR Rinkens</em></cite></p></blockquote>
<p>Automation offers an effective solution to the synchronization issue with blockchain. Blockchain is a distributive digital ledger with many applications and can be used for any exchange, tracking or payment. Blockchain allows information to be instantly visible to all supply chain partners and enables a multitude of applications. Documents, transactions, and goods can easily be tracked, payments and pricing can be historically recorded, all in a secure and transparent manner.</p>
<p>The shipping giant FedEx has joined <a href=""https://www.bita.studio/"">Blockchain in Transport Alliance (BiTA)</a> and launched a blockchain-powered pilot program to help solve customer disputes. Similarly, UPS has also joined BiTA as early as 2017, reaching for increased transparency and efficiency among its entire partner network. Such real-life use cases show the potential of blockchain technology and the impact that automation can have on the entire freight industry.</p>
<p>Blockchain increases the transparency of the supply chain and removes information latency for all partners on the network. The resulting benefits include increased productivity and operational efficiency as well as better service levels. Its massive potential makes blockchain a <a href=""https://www.gartner.com/en/newsroom/press-releases/2020-01-23-gartner-says-80--of-supply-chain-blockchain-initiativ"">top priority</a> for supply chain organizations and their digital automation journey.</p>
<h2>Conclusion</h2>
<p>Automation is playing a major role in defining the Supply Chain 4.0 environment. With heavy technological tools available to them, leading organizations are taking serious leaps towards efficiency and productivity. Automation gives them the power to accelerate and optimize the whole end-to-end supply chain journey. It also enables them to use data to their advantage and close information gaps across their network.</p>
<p>Originally Published: <a href=""https://www.unite.ai/three-uses-of-automation-within-supply-chain-4-0/#:~:text=From%20production%20and%20inventory%2C%20to,and%20promote%20optimized%20production%20schedules."">Unite.AI</a> by Blue Orange Digital</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/3-uses-of-automation-in-Supply-Chain.png,3-uses-of-automation-in-Supply-Chain.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/3-uses-of-automation-in-Supply-Chain.png,3226,3-uses-of-automation-in-Supply-Chain,,,,https://blueorange.digital/wp-content/uploads/2022/05/3-uses-of-automation-in-Supply-Chain.png,,,,,,,,
3251,"Letting Your IoT Customer Data Work For You","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>Self-driving cars, payment systems, wearables, cameras, IoT devices, smart industrial machines, and online tools. From software to hardware, intelligent services and connected smart devices played a major role in the data-driven industrial development of the past decade. Nowadays, AI and machine learning analytics allow organizations to discover a new value of such smart devices. Since data in itself is a crucial asset for technically capable organizations, the value of such smart devices is tightly related to the data they generate. And to how you make use of that data.</p>
<p>There are two main directions in which data analytics can be beneficial to an organization. Firstly, internal business workflows can be optimized via the gained data insights. Secondly, customer-oriented product development efforts can be better directed when user data insights are taken into account.</p>
<h2><strong>Internal Benefits</strong></h2>
<p>Insights gained by means of data analytics offer a chance to optimize both <a href=""https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/the-age-of-analytics-competing-in-a-data-driven-world"">costs and revenue</a>. Labor expenses, machine repair &amp; rent fees and even advertising budgets are only a few examples of operational aspects that may easily be improved if data is put to work.</p>
<p>MGI research <a href=""https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/radically-rethink-your-strategy-how-digital-b2b-ecosystems-can-help-traditional-manufacturers-create-and-protect-value"">reports</a> cost reduction of 5 to 15 percent in the case of manufacturing companies that implemented operational analytics. Regarding revenue, data and analytics allow a business to explore new markets, improve distribution channels and properly target customer segments. Moreover, operational decisions do not need to be made in the dark anymore: <a href=""https://en.wikipedia.org/wiki/Data_literacy"">data-literate</a> industry leaders are able to translate data insights into increased employee productivity and keep operational costs to a minimum. As such, data analytics is an extremely powerful tool that translates to a non-negligible competitive advantage.</p>
<h2><strong>External Benefits</strong></h2>
<p>Analyzing customer data creates valuable insights that allow building increasingly personalized products and services. </p>
<p>From the insurance and fintech sectors to health care, retail, and logistics, some of the most useful insights come from behavioral analytics. Data captured in both online and physical environments shed light on the actions of your customers and allow the development of useful features that further improve your products. For example, an online retailer could not implement a functional product recommendation system without fine-grained behavioral data at hand. Products that match the needs of your customers ensure a higher retention rate since they actually build value for the users. Consequently, your product is more likely to be recommended and attract new users. Without thoroughly analyzing and drawing insights from user data, such strong benefits would be impossible to achieve. </p>
<p>But all these benefits are only reserved for those that do the hard work and try to get the customer data to work for them. </p>
<h2>How can you let your own customer data do the work for you? </h2>
<p>The highest performance of the modern analytics framework is only achieved when integrating <em>multiple data sources, i.e. bringing in orthogonal data.</em></p>
<p>The power of orthogonal data is in the fact that it complements existing data sources and helps create a more detailed view of the interaction between your product and its user. Below are a few simple steps you can take to start integrating multiple data sources into your analytics solution.</p>
<h2><strong>Prevent data waste i.e. perform analytics on already collected data</strong></h2>
<p>Let’s take an imaginary example of a plant manager in charge of a production facility. The manufacturing process assumes that humans and robotic arms perform collaborative tasks. The robotic arms are already equipped with sensors informing about current system status and environmental variables, such as humidity, temperature &amp; vibration. The robotic arm is also already tracking and logging the user interactions. Aiming to lower the operating budget, the plant manager sets a specific goal (e.g. lower the number of robotic arms) and decides to hire a data analytics team to help find potential glitches in the workflow. While sending the data to be analyzed, he completely ignores the user interaction data and only asks for insights based on the system usage data.</p>
<p>Such a waste of data!</p>
<p>While humans are unable to discover hidden correlations, the power of machine learning and predictive modeling allows us to achieve just that: unexpected outcomes may be learned by the algorithms when they are fed with seemingly unrelated data.</p>
<h2><strong>Aggregate multiple data types, even if they come from different sources</strong></h2>
<p>The IoT world is populated by smart devices that not only collect large amounts of sensor and usage data but are also able to communicate with each other. Advanced wireless protocols such as <a href=""https://www.develcoproducts.com/wireless-platform/zigbee/"">Zigbee</a> provide a secure mesh network for smart devices to exchange data. The processing and analysis of device data can be done either at a device-level (the so-called <a href=""https://www.cbinsights.com/research/what-is-edge-computing/"">edge computing</a>) or in the cloud. The flexibility of computing options and affordable analytics solutions has enabled IoT platforms to collect ever-increasing amounts of data. This can, for example, break barriers at the <a href=""https://www.mckinsey.com/~/media/McKinsey/Business%20Functions/McKinsey%20Analytics/Our%20Insights/The%20age%20of%20analytics%20Competing%20in%20a%20data%20driven%20world/MGI-The-Age-of-Analytics-Full-report.ashx"">application level</a>:</p>
<blockquote class=""wp-block-quote""><p>“<em>Connected light fixtures, which sense the presence of people in a room and have been sold with the promise of reducing energy usage, generate “data exhaust” that property managers can use to optimize physical space planning</em>”</p>
</blockquote>
<p>However, heterogeneous data sources pose a modern data analytics challenge: specialized analytics tools are needed to be able to process, aggregate and analyze different data types and formats.</p>
<p>Here at Blue Orange Digital, we employ the <a href=""https://aws.amazon.com/big-data/datalakes-and-analytics/"">data lake model</a>, which allows us to build end-to-end analytics solutions without worrying about heterogeneous data types. </p>
<h2><strong>Integrate third-party data</strong></h2>
<p>Valuable insights from data analytics may be obtained when integrating third-party data, i.e. data originating from sources not directly linked to your application scenario. Examples of external sources are social media feeds, mobile geolocation data or even video feeds. Such orthogonal data sources may give meaning to previously unusable sensor data and allow running analytics on a large scale. As an example, AGT International’s <a href=""https://www.agtinternational.com/analytics/deep-web-data-analytics/"">Wearable Analytics Lab</a> has augmented motion sensor data extracted from smartphones with video feeds of facial expressions and audio streams in order to build realistic social analytics models of crowds. This <a href=""https://www.softwareadvice.com/resources/iot-data-analytics-use-cases/#jump-to-video"">shows</a> once again that there are endless possibilities when unleashing the power of orthogonal real-time data.<br />Are you ready to join the industry leaders and employ machine learning and advanced analytical tools for your business needs? We are happy to crunch your data and help you gain crucial insights about your operations and further improve your products.</p>
<p><a href=""/contact-us/"">Drop us a line</a> and let us unleash the power of your customer data!</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/IoT-letting-customer-data-work-for-you.png,IoT-letting-customer-data-work-for-you.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/IoT-letting-customer-data-work-for-you.png,3252,IoT-letting-customer-data-work-for-you,,,,https://blueorange.digital/wp-content/uploads/2022/05/IoT-letting-customer-data-work-for-you.png,,,,,,,,
3261,"7 Incredible IoT Devices and How They Use Your Data","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2>1. Smart Meters</h2>
<p>Citizens of today’s <a href=""https://www.smart-energy.com/magazine-article/from-smart-meters-to-smart-cities/"">smart cities</a> have increased control over their home utilities due to a connected infrastructure of <strong>smart meters</strong>. Low-power hardware devices collect electricity, water, and gas consumption data in <a href=""https://www.power-grid.com/2019/08/27/iot-connectivity-what-it-means-for-smart-metering/#gref"">the cloud</a>, where further analysis and processing can be performed at a large-scale. This enables utility providers to discover <a href=""https://www.scnsoft.com/blog/iot-for-smart-city-use-cases-approaches-outcomes"">consumption patterns</a>, monitor real-time demand and develop more efficient billing mechanisms. For the customer, this translates to higher-quality services and a more accurate consumption overview.</p>
<p>See our Case Study on the Advanced Sensor Analytics Platform for PingThing’s electric utility grid data.</p>
<div class=""wp-block-image"">
<figure class=""aligncenter is-resized""><a href=""https://blueorange.digital/cptcasestudies/supply-chain-revenue-predictions-for-pharmaceuticals/"" target=""_blank"" rel=""noreferrer noopener""><img src=""https://lh6.googleusercontent.com/YQ5zB2O8fRE5PnO87mQ5J3uZK5yX9WZU__CDz3vSSF_coJu9D8f0y_bR2Tk5wcyWCcByipZbMqtWpb9kmf-eLUzeJ1_NwgH00B19qwGAtH8ah2i9NsWjPRSqtOCC3DTy13igH7HX"" alt="""" width=""600"" height=""314"" /></a><br />
<figcaption><strong>Case Study on the Advanced Sensor Analytics Platform for PingThing’s electric utility grid data.</strong></figcaption>
</figure>
</div>
<h2>2. Smart Home Sensors</h2>
<p>Alongside smart meters, inhabitants of smart homes can also choose among a wide variety of <a href=""https://www.postscapes.com/wireless-vent-keen/"">wirelessly interconnected devices</a> that are easy to control and monitor remotely. Such appliances range from WiFi thermostats, AC cooling units, and <a href=""https://tr.farnell.com/switch-on-iot-connected-lighting"">lighting fixtures</a> to humidity and temperature sensors. The generated data can be processed either at a device-level (which can result in immediate actions i.e. turn off lights after 10 minutes of no motion detected) or <a href=""https://www.intechopen.com/books/internet-of-things-iot-for-automated-and-smart-applications/smart-home-systems-based-on-internet-of-things"">aggregated and processed</a> in the cloud. In the long run, this should allow the user to have a better experience, and save both money and resources while living a more environmentally friendly lifestyle.</p>
<h2>3. RFID Inventory Management Chips</h2>
<p><strong>RFID</strong> <strong>tracking chips</strong> are proven tools for product inventory and stock management in logistics and retail. <a href=""https://www.rfidjournal.com/articles/view?19084"">Modern IoT-driven solutions</a> are based on chips attached to goods and packages for <a href=""https://www.scnsoft.com/blog/iot-for-inventory-management"">improved logistics and monitoring</a>. Integrating multivariate sensor data (such as temperature, movement data, and geolocation) gives both the supplier and the customer an exact overview of the delivery conditions. </p>
<p>See our Case Study on Supply Chain &amp; Revenue Predictions for Pharmaceuticals</p>
<div class=""wp-block-image"">
<figure class=""aligncenter is-resized""><a href=""https://blueorange.digital/cptcasestudies/supply-chain-revenue-predictions-for-pharmaceuticals/"" target=""_blank"" rel=""noreferrer noopener""><img src=""https://lh5.googleusercontent.com/1NcVegvk1hYYUdRQ8GPfRPwg2Z8VxEaFGbhCvzq-3z1lj6nHhC63lo0RaHygDOcwaWYOXiE-FGiHD-BuymZenNIyXq5HPr--vureMC1ueNwqdzm5g5pWeH7rIrAjBrd31A3QE9sQ"" alt="""" width=""600"" height=""314"" /></a><br />
<figcaption>Case Study on Supply Chain &amp; Revenue Predictions for Pharmaceuticals</figcaption>
</figure>
</div>
<h2>4. GPS Trackers</h2>
<p>With the increasing popularity of carpooling services &amp; <a href=""https://www.smart-industry.net/public-transport-internet-of-bikes/"">intelligent bike rental systems</a>, companies have learned the importance of mobility data. <strong>GPS-based trackers</strong> provide speed information, location, and direction of <a href=""https://www.postscapes.com/connected-car-devices/"">tracked vehicles</a>, which allow for real-time modeling of the traffic. This turns them into a powerful source of data that enables intelligent traffic routing and monitoring software as well as the development of <a href=""https://www.peerbits.com/blog/vehicle-tracking-system-for-logistics-and-fleet-management-using-lot.html"">fleet management solutions</a>. </p>
<h2>5. Wireless Locks and Monitoring Tools</h2>
<p>From <a href=""https://wireless.electronicspecifier.com/iot-1/iot-connected-bike-lock-enables-real-time-monitoring"">bikes</a> and <a href=""https://www.monnit.com/blog/2016/05/protect-and-monitor-your-boat-with-the-iot-and-monnit/"">boats</a>, to <a href=""https://www.postscapes.com/wireless-door-locks/"">apartment doors</a> and <a href=""https://www.rfidjournal.com/articles/view?19018"">university campuses</a>, unauthorized access can easily be restricted via <strong>intelligent wireless locking devices</strong>. Such tools are usually easy to connect to via a smartphone or website, which makes it possible to monitor your assets from any location around the world. Depending on the chosen device, the security configuration can be done based on motion information, <a href=""https://www.paymill.com/en/blog/how-voice-recognition-is-playing-a-major-role-in-iot-development/"">speech</a> &amp; facial recognition or traditional <a href=""https://www.researchgate.net/publication/333994323_IoT_Assisted_Fingerprint_based_Security_System_using_Raspberry_PI_3"">fingerprint systems</a>.   </p>
<h2>6. Wearables and Consumer Electronics</h2>
<p>The <a href=""https://readwrite.com/2019/03/20/iot-and-ar-are-found-revolutionizing-the-world-of-mobile-apps/"">advances in IoT technologies</a> have enabled devices of all kinds (eyeglasses, wristbands, watches and home assistants) to easily connect and exchange data with one another. As such, <strong>wearables and consumer electronics</strong> have become an important source of data that can be leveraged for the user’s advantage. Health aspects, human behavior and even sleeping patterns can be quantified and interpreted by means of <a href=""https://blog.bosch-si.com/smart-home/environmental-sensing-in-consumer-electronics/"">sensors that communicate via wireless networks</a>. Such information (previously unavailable to us) turns fitness trackers and health monitoring apps into the <a href=""https://blog.bosch-si.com/health/towards-a-healthy-society/"">most popular IoT applications</a>. </p>
<h2>7. Smart Waste Management Solutions</h2>
<p>Yes, you read that right. Garbage data is nowadays used for the implementation of <a href=""https://www.iotforall.com/smart-waste-management/""><strong>intelligent waste management solutions</strong></a>. Since waste management is a complex process consisting of various steps, <a href=""https://www.computer.org/csdl/journal/su/2017/03/07892970/13rRUy3xY6n"">IoT-enabled solutions</a> have allowed the optimization of collection, recycling and <a href=""https://www.ecubelabs.com/solar-powered-trash-compactor/"">disposal</a> processes, among <a href=""https://www.geeksforgeeks.org/iot-and-garbage-monitoring-system/"">others</a>. An example of <a href=""https://sensoneo.com/"">a basic solution</a> assumes using fill sensors placed in trash bins, that correctly inform about bins that are ready to be emptied. The optimization of such a simple step can mean huge reductions of operational costs for waste management companies and less polluted cities for the inhabitants.</p>
<h2>What’s next?</h2>
<p>We have seen some examples of how IoT devices and the data they generate can have a powerful impact on the way businesses operate and on the overall customer experience. These examples are just the tip of the iceberg with today’s rapidly progressing IoT landscape.</p>
<p>If you feel like we’ve missed anything, please <a href=""mailto:contact@blueorange.digital"">send us an email</a> and let us know!</p>
<p><strong>Let's leverage the power of your IoT data together! <a href=""/contact-us/"">Get in touch with us</a> and let us know about your company’s goals.</strong></p>
<p><em>Connect with our factory manufacturing partner, </em><a href=""https://aideq.com/""><em>AidEq</em></a><em>, for smart conveyor systems and industrial automation.</em></p>
<p>Read more on Letting Your IoT Customer Data Work For You</p>
<div class=""wp-block-image"">
<figure class=""aligncenter is-resized""><a href=""https://blueorange.digital/letting-your-iot-customer-data-work-for-you/"" target=""_blank"" rel=""noreferrer noopener""><img src=""https://lh4.googleusercontent.com/AR73yrJLbOFcLCGQVhsSWMZOtFkElr1HL0h2uf9_pXXFdBT8u5mpWxNJcrecXVWwhQaVg3Sr5gz0V-tVIUXGGQjwsh95h3gZ_-9nveYnyUO4a_6aPeRZAaJ6hooZkUiczzBWj1hi"" alt="""" width=""512"" height=""256"" /></a><br />
<figcaption>Letting Your IoT Customer Data Work For You</figcaption>
</figure>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/7-Incredible-IoT-Devices-and-how-they-use-your-data.png,7-Incredible-IoT-Devices-and-how-they-use-your-data.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/7-Incredible-IoT-Devices-and-how-they-use-your-data.png,3263,7-Incredible-IoT-Devices-and-how-they-use-your-data,,,,https://blueorange.digital/wp-content/uploads/2022/05/7-Incredible-IoT-Devices-and-how-they-use-your-data.png,,,,,,,,
3269,"Supp-LIE Chain: How IoT is delivering TRUTH","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2><em>Featuring interviews with industry experts in automation and logistics on the innovations that increase accuracy and efficiency in Supply Chain: Aid Equipment, Hollingsworth, Leaf Logistics, and Tive.</em></h2>
<p>The modern supply chain industry relies on a set of extremely powerful tools for keeping up with customer demand. Autonomous robots carry our products across warehouses. Sensors and trackers keep them under control, all the way from the conveyor belt to our doorsteps. The most common handheld scanners rely on advanced computer vision algorithms and OCR tools. NLP modules make human-robot communication easier than ever. The technical capabilities present in today’s supply chain were a thing of fantasy only a few decades ago.</p>
<p>And yet, it sometimes happens. A package gets lost. The wrong product gets delivered to a confused customer. Shipping is delayed by a few weeks. Something, somewhere along the supply chain goes wrong. Customers are dissatisfied, businesses lose revenue, and logistics partners waste time and resources.</p>
<p>This leaves warehouse managers wondering: “Where did it all go wrong? What can be done to prevent this from happening?” The following applications illustrate the role that different technologies play in alleviating some of the Supp-LIE chain issues.</p>
<figure class=""wp-block-image""><img class=""wp-image-5577"" src=""https://blueorange.digital/wp-content/uploads/2020/07/42-1024x536.jpg"" alt="""" /><br />
<figcaption>Source: Canva</figcaption>
</figure>
<h2>Real-time Monitoring and Tracking</h2>
<p>Monitoring and tracking technologies address an essential concern of warehousing operations: handling products is an error-prone process. Moreover, handling errors easily cascade through the entire supply chain pipeline and cause further costs at different points in time. The ultimate mistake happens once the wrong product has been delivered to the customer. <em>“This isn’t what I ordered”</em> is a painful thing to hear for all parties involved. Apart from unnecessary processing costs incurred all throughout delivery, customer satisfaction is also affected. Monitoring and tracking technologies help prevent such issues and are nowadays ubiquitous tools for inventory management. </p>
<p><a href=""https://www.hollingsworthllc.com/"">Hollingsworth</a>, a leading provider of third-party logistics services, relies on modern IoT and software technologies for real-time monitoring and tracking of products. RFID tracking is the core functionality of their inventory &amp; shipping management systems.</p>
<blockquote class=""wp-block-quote""><p><em>“We use RFID tracking to ensure the accurate product is moving along the supply chain line. We also use a weight tracking service, so if someone says something is missing, we will notify the shipping provider.”</em></p>
</blockquote>
<p>Alongside RFID capabilities, cloud technologies, and shipping management software are used to build task-based workflows. Like this, tracking data becomes available in real-time for both supply managers as well as customers. Knowing and acting on product location in real-time is the functionality that directly impacts the quality of their fulfillment services.</p>
<p>The company also relies on modern robotics for improving retail fulfillment operations. This enables them to automate tasks in order to reduce labor costs, minimize inefficiencies, and reduce overall operational costs. </p>
<figure class=""wp-block-image""><img class=""wp-image-5578"" src=""https://blueorange.digital/wp-content/uploads/2020/07/Intelligent-Conveyor-Systems-1024x536.jpg"" alt="""" /><br />
<figcaption>Source: Canva</figcaption>
</figure>
<h2>Intelligent Conveyor Networks</h2>
<p>Just as industrial automation plays a crucial role in the fourth industrial revolution, so is supply chain automation the driving force behind Supply Chain 4.0. From software to hardware, warehouse managers try to automate the most tedious tasks and delegate them to robots. By integrating AI, robotics, and IoT technologies, automation strategies become a powerful tool to minimize process flaws and optimize entire workflows.</p>
<p>Troy Harris, the co-owner of <a href=""https://aideq.com/"">Aid Equipment</a>, a factory design and install provider with over 40 years of industrial automation clarifies the importance and limits of smart device innovations:</p>
<blockquote class=""wp-block-quote""><p><em>“Now there are so many industrial-grade wireless technologies that are reliable, stable, and fast. This brings flexibility to our warehouses. Warehouse layouts are no longer tied to a pre-planned grid system with wide aisles for oversized equipment. Robots can simply track their own location and manage internal traffic to efficiently pick pieces for boxing.”</em></p>
</blockquote>
<p>Aid Equipment’s conveyor networks integrate with computer vision capabilities, which enable barcode tracking systems to easily detect product identification tags and sort them.</p>
<blockquote class=""wp-block-quote""><p><em>“When you think of a robotic arm that sorts packages based on the scanned barcodes, it must be able to get information immediately in order to react within a millimeter of tolerance. The image capture rate plays a critical role in this when a conveyor system is running at 240 feet/minute and parts are coming by at 4 feet/second so there is limited time before the part gets skipped.” </em></p>
</blockquote>
<p>Harris adds that computational power for these camera systems is also a limiting factor saying:</p>
<blockquote class=""wp-block-quote""><p><em> “A basic camera currently has the capacity to capture  X and Y, or position and SKU, but unfortunately you can't stack on too many other detections like color, size, and shape before eventually you run out of time to compute those features. The desire to detect more complicated features with one or more cameras increases the latency of the sorting arm where even a millisecond makes a huge difference in the overall production rate. More advanced cameras come at a cost and depending on the customer’s budget the ROI of the potential increase in speed may be worth it.”</em></p>
</blockquote>
<h2>Streamlined Shipping Operations</h2>
<p>Sensor technologies have many applications outside the warehouse; they enable supply chain managers to keep track of products while they are in transit. However, the complexities of real-life loading and unloading scenarios require more than tracking and accurate scanning of assets. A well-known risk during cross-docking is that of products being lost, entirely damaged, or simply separated from their pallet. Without an exact location and historical transit data, it would be impossible to ever retrieve these products and they would remain lost forever. Sensors make such information easily available and data analysis tools can quickly parse real-time data flows, to alert about possible failures before they become catastrophic. </p>
<p>The CEO of <a href=""https://tive.co/""><strong>Tive</strong></a>, Krenar Komoni, illustrates how they approached similar issues using advanced sensor technologies and 5G trackers:</p>
<blockquote class=""wp-block-quote""><p><em>“A web of smaller Bluetooth beacons on individual pallets feed information to the 5G tracker device that tracks the shipment as a whole. From this, you are able to tell if any pallets ever get separated from the pack, are forgotten or misplaced. Additional location accuracy lets you pinpoint each shipment  and send notifications of misplaced items before the truck gets 5 miles away like standard trackers.”<br /></em></p>
</blockquote>
<p><a href=""https://tive.co/""><strong>Tive</strong></a>’s 5G trackers are only one component of their solution. They also offer advanced analytics to interpret heterogeneous data, such as location, environmental conditions, and transit events. Like this, all parties involved have a transparent overview of the shipping process and contribute to risk minimization.</p>
<figure class=""wp-block-image""><img class=""wp-image-5576"" src=""https://blueorange.digital/wp-content/uploads/2020/07/41-1024x536.jpg"" alt="""" /><br />
<figcaption>Source: Canva</figcaption>
</figure>
<h2>Predictive Demand Mapping </h2>
<p>Data analytics offers a reliable way to deal with uncertainty in the supply chain. The complex nature of supply chain events and actions makes it imperative to model, evaluate, and understand uncertainty. To illustrate, the possibility of customers returning a product may be influenced by a number of factors. Delivery times, competition prices, or faulty products may each play a role in the customer’s decision to return a product. Understanding customer expectations based on previous purchasing data brings transparency to the entire supply chain. This is exactly what data analytics tools are built to achieve: reduce uncertainty and increase customer satisfaction.</p>
<p><a href=""https://www.leaflogistics.com/"">Leaf Logistics</a> CEO, Anshu Prasad, gives further details on return issues in today’s supply chain:</p>
<blockquote class=""wp-block-quote""><p><em>“Today e-commerce has a 30% return rate and supply chain isn't built for it [...] the future of supply chain will require an integrated return system that must have pre-made options, systems, and routes for returns so the return experience is just as painless as the buying experience.”</em></p>
</blockquote>
<p>Leaf provides a prescriptive analytics platform that enables companies to take a proactive attitude in supply chain management. Instead of using technology to react to events in the past, predictive demand mapping allows decision-makers to see into the future and make informed decisions.</p>
<blockquote class=""wp-block-quote""><p><em>“Supply chains need to optimize for close-loop systems, which will not only increase customer satisfaction but also sustainability. Less time with products sitting around ensures a quicker return to the manufacturer to be able to resell or repurpose the returned product.”</em></p>
</blockquote>
<p>This is by no means an isolated use case for data analytics in the supply chain industries. Companies of all sizes find <a href=""https://theferrarigroup.com/supply-chain-matters-guest-contribution-data-science-in-the-supply-chain-accessible-affordable-and-effective/"">data-driven solutions</a> increasingly affordable and secure. Predictive analytics makes it straightforward to find areas of improvement in the supply chain, stay productive, and cut down on operational costs.   </p>
<h2>Conclusion</h2>
<p>IoT and automation have many applications in the supply chain industry. They enable a wide number of applications, from manufacturing, packaging, to delivery tracking, and the generation of automated reports.</p>
<p>Despite all these tools, the modern supply chain is still seeing constant development. Technologies such as computer vision, natural language processing, or predictive modeling open up new opportunities for countless applications. Successful integration and adoption of these new innovations and of existing systems is key to a full digital transformation, for this, it is recommended to partner with data transformation experts, like <a href=""https://blueorange.digital/"">Blue Orange Digital</a>, a top-ranked AI co-development agency. When high-performing algorithms take care of time-consuming, labor-intensive tasks, organizations can overcome process limitations, stay competitive, and increase the quality of their services. </p>
<hr class=""wp-block-separator"" />
<h3>About The Author:</h3>
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img src=""https://lh4.googleusercontent.com/A-F4_2sh6u9xm-tzQHcP-7h1GDV95amalcXfu_yvQ9GUhh0Of7LqmIvnM9Q4Eo7y3Nb3it1UcQzrKd71EuD99-MeeLLFu-47AEwP9qRFfw83hpzGNTOpFDpWZrgpyky8ARkyho-u"" alt="""" width=""206"" height=""206"" /></figure>
</div>
<p><em>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He is a serial entrepreneur and software engineer that has built and scaled 3 startups. He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things. </em></p>
<p><em>Follow me on </em><a href=""https://twitter.com/BlueOrangeData""><em>Twitter</em></a><em> or </em><a href=""https://www.linkedin.com/in/joshmiramant/""><em>LinkedIn</em></a><em>. Check out my </em><a href=""https://blueorange.digital/""><em>website</em></a><em>. </em></p>
<p>Originally Published at: <a href=""https://www.datadriveninvestor.com/2020/07/20/supp-lie-chain-how-iot-is-delivering-truth/#"">Data Drive Investor</a></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Supp-LIE-Chain-IoT-delivers-TRUTH.jpg,Supp-LIE-Chain-IoT-delivers-TRUTH.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/Supp-LIE-Chain-IoT-delivers-TRUTH.jpg,3271,Supp-LIE-Chain-IoT-delivers-TRUTH,,,,https://blueorange.digital/wp-content/uploads/2022/05/Supp-LIE-Chain-IoT-delivers-TRUTH.jpg,,,,,,,,
3285,"AWS SageMaker: AutoMagically","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2><strong>3 Magical features of SageMaker that keep AWS at the forefront of MLaaS innovation: Data Wrangler, Feature Store, and Pipelines.</strong></h2>
<h2><strong>Intro</strong></h2>
<p>SageMaker is one of the earliest Machine Learning as a Service (MLaaS) offerings that supports end-to-end ML workflows. It offers developers, researchers, and data scientists a way to build, train, and deploy models on managed cloud infrastructure. Since its initial release in 2017, SageMaker has become more than a mere cloud service: it is an entire ecosystem that nowadays offers a variety of functionalities. </p>
<p>The <a href=""https://aws.amazon.com/sagemaker/"">list of SageMaker features</a> is impressive and sees new additions every year. Earlier this year, 3 new services were added to the SageMaker ecosystem. The Data Wrangler, the Feature Store, and the Pipelines. They each address common pain points of ML workflows enabling data scientists and ML engineers to be more productive.</p>
<h2><strong>SageMaker Data Wrangler</strong></h2>
<p>Built into SageMaker Studio, this feature enables developers to tackle one of the most time-consuming ML steps: data pre-processing. It provides a visual interface that makes it possible to import, prepare, transform, featurize, and analyze data without writing any code. This aims to speed up data exploration and preparation and allow developers to focus more on model training and tuning.</p>
<p>Without the Data Wrangler, the data pre-processing steps are tackled using code running in Jupyter notebooks. Depending on the ML problem at hand, this may include one or all of the following: enriching the data with external data sources, engineering custom features, merging attributes, cleaning, and transforming operations. A variety of libraries and software tools are required by data scientists to do the data pre-processing. Some common choices are: scikit-learn, NumPy, Scipy, and Pandas for analysis; matplotlib for visualization. Needless to say, those pre-processing pipelines (and the associated code) can get complex, messy, and hard to maintain.</p>
<p>The Data Wrangler offers a few core functionalities that eliminate the need of writing data-preprocessing code. Firstly, it makes it possible to connect &amp; import data from a variety of sources: Amazon S3, Amazon Athena, and Redshift. Secondly, it allows creating so-called <em>Data Flows, </em>where data preparation steps can be arranged using a drag and drop interface. The Data Flows can automagically handle joins among multiple datasets, which means fewer database queries and data manipulation code that developers need to write. The Data Wrangler also provides a set of predefined data transformation methods (formatting, vectorization, and various embedding methods). Lastly, it offers built-in visualization tools that make it possible to perform exploratory data analysis and understand crucial feature characteristics such as feature correlation and importance scores.</p>
<p>See also:</p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><a href=""https://blueorange.digital/cloud-architecture-build-vs-buy/""><img class=""wp-image-6165"" src=""https://blueorange.digital/wp-content/uploads/2020/11/Snowflake-Build-vs-Buy.png"" alt=""Snowflake - Build vs Buy"" /></a><br />
<figcaption>Cloud Architecture: Build vs Buy</figcaption>
</figure>
</div>
<h2><strong>SageMaker Feature Store</strong></h2>
<p>The Feature Store comes in handy for developers in the model training and tuning phase of an ML workflow. It is a repository that makes it possible to create, share, and manage curated data (features) across different teams and ML tasks. Such functionality is useful in scenarios in which multiple teams are training multiple models based on a common set of features. </p>
<p>Without the Feature Store, data science and ML teams have to face a daunting challenge: they need to keep track of the features used for training their models, all the way from initial development to deployment. It is not uncommon for teams to develop multiple models in parallel and to migrate features from one training session to another. Also, throughout inference, it is crucial to know which features need to be used by models to make predictions. All throughout this process, datasets (and hence feature sets) are also known to be dynamic: external data sources provide new features, attributes get merged into single features, etc. Handling the evolution of features throughout the data preprocessing and model training phases is similar to maintaining code history without a version control system: risky, messy, and..simply impossible.</p>
<p>The Feature Store provides functionality that makes it easy to handle features all throughout the ML pipeline. The promise is that data is only pre-processed once and after features are extracted, they can be reused, shared, and managed across teams, according to their custom needs. It is then possible to index and search through features, and the consistency and standardization of features are ensured. Another crucial function of the Feature Store is that it is compatible with various other AWS services: features can be exported from Athena, Glue, and even the Data Wrangler. </p>
<h2><strong>SageMaker Pipelines</strong></h2>
<p>The Pipelines feature is meant to enable the automation <strong>of the different ML pipeline steps</strong>. It provides a Continuous Integration &amp; Delivery service, which is adapted to ML pipelines and makes it possible to maintain code, data, and models all throughout development and deployment. For developers, this means less time (and code) spent on the orchestration of all SageMaker jobs and easier maintenance of custom training and deployment workflows.</p>
<p>Datasets, models, and ML workflows are all dynamic by nature. Data sources are constantly evolving, pre-processing steps are continuously being improved and countless models are being trained and deployed in parallel. Reproducing results, keeping track of development and production models, and the respective workflows involved in their training and tuning is becoming a time-consuming and risky task. A well functioning ML Ops pipeline is mandatory for ensuring quality assurance and continuous integration and can make the difference between Proof of Concept projects and ML projects running at scale.</p>
<p>The SageMaker Pipelines offers ML Ops teams the tools to take a hold of the variety of SageMaker workflows involved in model training and deployment. Pipelines can be defined from scratch using the Python SDK or they can be built off of built-in templates. Most importantly, workflow pipelines can be visualized, organized, and shared using SageMaker Studio. For each workflow, various metadata is collected and stored (wrt to datasets, model hyperparameters, and even training platform configurations), making ML workflows searchable and reusable.</p>
<h2><strong>Conclusion</strong></h2>
<p>The three new features added to SageMaker bring countless benefits to all stakeholders involved in the ML workflows: engineers, scientists, and analysts. The Data Wrangler minimizes the time spent massaging data and allows developers to focus more on model training and testing. The AWS Feature Store accelerates model development and removes the usual inconsistencies that arise from maintaining personal feature repositories. The SageMaker Pipelines brings CI/CD to Machine Learning and ensures reproducibility of results, as well as easier workflow maintenance.</p>
<p>With the ongoing development of SageMaker, AWS stays at the front of MLaaS innovation. The three additions to SageMaker’s offerings are living proof that AWS sticks to its mission: putting machine learning tools in the hands of every developer and data scientist. </p>
<hr class=""wp-block-separator"" />
<p><a href=""/contact-us/""><em>Schedule 15-min</em></a><em> with a Blue Orange Digital Solution Architect to discuss the possibilities of AWS and SageMaker. Blue Orange Digital is a certified AWS Development Partner.</em></p>
<hr class=""wp-block-separator"" />
<p><strong>About the Author</strong></p>
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img class=""wp-image-5323"" src=""https://blueorange.digital/wp-content/uploads/2020/05/Josh-Miramant-CEOpng-1024x1024.png"" alt=""Josh Miramant- CEO Blue Orange Digital"" width=""166"" height=""166"" /><br />
<figcaption>Josh Miramant-<br />CEO Blue Orange Digital</figcaption>
</figure>
</div>
<p>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC.</p>
<p>Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. As an example of thought leadership, Miramant has been featured in IBM ThinkLeaders, Dell Technologies, Global Banking &amp; Finance Review, the IoT Council of Europe, among others. He can be reached at contact@blueorange.digital.</p>
<p><strong>About Blue Orange Digital</strong></p>
<p>Blue Orange Digital is recognized as a “<strong>Top 10 AI Development and Consultant Agency</strong>,” by Clutch and YahooFinance, for innovations in predictive analytics, automation, and optimization with machine learning in NYC. </p>
<p>They help organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things.</p>
<hr class=""wp-block-separator"" />
<p>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for Supply Chain, Healthcare Document Automation, and <a href=""/cptcasestudies/"">more.</a></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/AutoMagically-1.gif,AutoMagically-1.gif,/www/blueorangem_500/public/wp-content/uploads/2022/05/AutoMagically-1.gif,3287,AutoMagically-1,,,,https://blueorange.digital/wp-content/uploads/2022/05/AutoMagically-1.gif,,,,,,,,
3294,"Why People Are Excited About Snowflake","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2>Introduction</h2>
<p>As one of 2020’s most anticipated public listings, Snowflake Inc. started trading on the 16th of September and snatched the title for the largest software IPO ever recorded. With a market valuation of more than 70$ billion, the data warehousing company makes previous record-holders look cheap by comparison.</p>
<p>The performance of the company on the New York Stock Exchange has raised skepticism about the stock market behavior. While some are still wondering whether or not the market had <a href=""https://www.marketwatch.com/story/ipo-like-its-1999-market-hitting-dot-com-boom-levels-as-snowflake-and-other-cloud-software-stocks-keep-popping-2020-09-17"">lost its mind</a>, investors are attracted by Snowflake’s technology and its promise for the future of data in the cloud. </p>
<p>Snowflake’s valuation comes as a wake-up call for the data warehousing market, where it’s competing directly against big names: legacy database software companies (such as Oracle and IBM) and cloud service providers (Google, Amazon &amp; Microsoft). With its fresh perspective on handling data in the cloud, Snowflake’s slice of the pie is steadily increasing.</p>
<p>But why is this warehousing company attracting customers and investors and what is it about its technology that is so promising for the future?</p>
<h2>Snowflake - what is it? </h2>
<p>Simply put, Snowflake is a database software for the cloud. The company was founded with the goal of alleviating a central pain point of all organizations seeking to better make sense of their data: defining and implementing an architecture for the cloud. With more and more companies moving away from on-premise solutions, compute infrastructures built in the past century need to find a new home in the cloud. Amidst this massive transition, Snowflake’s goal is to soften the process and help companies build better data architectures in the cloud. </p>
<p>Snowflake calls itself a cloud data platform that can be plugged into any of the existing public cloud service providers. In a traditional IaaS, PaaS, SaaS cloud offering, Snowflake bridges the gap between infrastructure and applications by providing out-of-the-box architectures optimized for data workloads.</p>
<p>Its main offering is a completely managed data warehouse that can be deployed onto any public cloud. But the real value lies under the hood: Snowflake’s service runs on an architecture that is optimized for the cloud and maximizes its capabilities. </p>
<h2>Snowflake tackles limitations of legacy cloud data systems</h2>
<p>Snowflake is built to tackle inherent limitations that come with on-premise solutions and with legacy cloud data systems. Both for organizations that already have a cloud environment in place, as well as for organizations still maintaining in-house infrastructures, Snowflake aids them in tackling these two common challenges.</p>
<h2>1. Data Latency</h2>
<p>One limitation of legacy data architectures is data latency. Namely, the time that data needs from ingestion to analysis and insights. Modern workloads require a variety of data sources to be integrated and need to offer support for different data formats. The classic pitfall is when infrastructure clouds resemble legacy data centers, where isolated data warehouses are responsible for different portions of data. Similarly, traditional cloud architectures only load data periodically in batches, running daily, weekly, or monthly. But modern analytics needs require much faster processing and workloads that can serve data engineers in real-time.</p>
<p>In order to match businesses’ hunger for analytics and data processing, optimized cloud architectures are needed. Like this, data engineers, data analysts, and business users alike get instant access to data.</p>
<h2>2. Cloud architectures are not inherently optimized for data</h2>
<p>Architectures built for the cloud require expertise for integrating the right cloud services. While data warehouses and data lakes are offered by most cloud service providers, are they used accordingly?  </p>
<p>For organizations that have already moved to the cloud, simply being in the cloud is not a guarantee of having appropriate data workloads. Making the best out of the cloud-provided architecture means that a variety of tools and services are well configured to work well with one another: data storage solutions, data integration tools, transformation pipelines, and ingestion procedures. </p>
<p>For organizations that are still working on-premise, moving to the cloud solves only half of their problem. Traditional storage and processing capabilities have become outdated given the ever-increasing amounts and sources of data. With more data and data sources available, new business use cases and analytics needs have arisen. Keeping up with these needs is the main requirement of cloud-based data processing frameworks.</p>
<p>Regardless of where they are built, legacy cloud architectures have one thing in common: they are not inherently optimized for efficient data workloads, they require heavy system management efforts and they are fragmented. Fragmented environments mean that the cloud promise “pay for what you use” is actually hard to achieve, having an economic impact on all cloud service users.</p>
<p>This is where Snowflake jumps right in with their cloud data platform. They provide architectures that fully exploit the public clouds’ scale and compute capabilities.</p>
<h2>The Snowflake features</h2>
<p>From an architectural standpoint, the magic behind Snowflake is quite simple: its cloud data platform separates the computational workloads from the storage. At the core of their architecture is the database storage service, around which different service layers are built. This data is unique and stores both structured and semi-structured data into a single source of truth. Virtual warehouses are then built on top of this data, making it possible to have multiple workloads run in parallel while using the same underlying data.</p>
<p>Snowflake’s features really make its cloud data platform unique in terms of data engineering tools and workloads. It assists data engineers and analysts across the entire data workload: from data ingestion all the way to data transformation and delivery.</p>
<p>Below is a high-level overview of Snowflake features that assist data engineers in building better workloads:</p>
<ul>
<li>Allows storage of both structured and semi-structured data. This data then becomes available in its raw form or can be extracted into any desired formats.</li>
<li>Simplifies the process of working with semi-structured data. JSON files can be transformed and loaded using an SQL-like language.</li>
<li>Provides a multi-clustered, shared data architecture that allows data to be loaded at the same time it’s being analyzed. This results in reduced times for analysis and data wrangling.</li>
<li>Allows simultaneous data workloads on the same data source without queuing. Thus, engineers and business analysts are enabled to collaborate when extracting insights from their data.</li>
<li>Provides a vast list of <a href=""https://www.snowflake.com/partner-ecosystem/"">ecosystem partners</a> allow further expansion of the analytics flow with visualization tools and custom BI dashboards</li>
</ul>
<h2>Conclusion &amp; Snowflake benefits</h2>
<p>The main selling point of Snowflake is that it enables cloud architectures that truly implement the “pay for what you use” pricing scheme. On top of that, it’s cloud architectures enable its customers to focus more on data strategy and less on the implementation and maintenance of intricate cloud architectures.</p>
<p>A comprehensive list of benefits for organizations can be seen in the image below:</p>
<figure class=""wp-block-image""><img src=""https://lh4.googleusercontent.com/XmFacWn3TLfvpoesTLlqKtopmdA8tRshd8wo2CEzPl4WOVvMOMWCPlvS3KIjga7UnQWvIHyvMvd8hDp_45Q-LtYvNExr9BVrJ58tTuGtWksns8nH9ET7pqHQDZ2_nlb2vdbJbsK9"" alt="""" /><br />
<figcaption><a href=""https://d1.awsstatic.com/Solution%20Space%20(CRS)/Snowflake_AWS_Field%20Ready_Solution_Brief_LS.pdf""><strong>Source</strong></a></figcaption>
</figure>
<h2>The Fast Way To Get Started with Snowflake</h2>
<p>Blue Orange Digital has vast experience in assisting organizations in their transition towards cloud environments. Developing within Snowflake takes data expertise. Your internal IT team may not have the capacity to build this out. If you want to get a faster ecosystem and the efficiency benefits of the snowflake environment, you don’t have to wait for IT to become less busy. Drop us a line and let us know. The <a href=""https://blueorange.digital/"">Blue Orange Digital</a> data science team is happy to help you get started with Snowflake. </p>
<p>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for Supply Chain, Healthcare Document Automation, and <a href=""/cptcasestudies/"">more</a>.</p>
<hr class=""wp-block-separator"" />
<p>Follow me on <a href=""https://twitter.com/BlueOrangeData"">Twitter</a> or <a href=""https://www.linkedin.com/in/joshmiramant/"">LinkedIn</a>. Check out my <a href=""https://blueorange.digital/"">website</a>.</p>
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img src=""https://lh6.googleusercontent.com/HYmeRn2bLrgDmCybXBzOwaCD9lw8gBLrCIDvnqRRthyauzYLsD2GpJbXfl3oMlaGq5_7WsePuTF6KnwuYyayKxm-G-V7v_p8i6cVHQdxM5WMu257Ef5O6HlKY3JRch-UASBJLkwh"" alt=""Josh Miramant- CEO"" width=""156"" height=""156"" /><br />
<figcaption>Josh Miramant- CEO</figcaption>
</figure>
</div>
<p>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He is a serial entrepreneur and software engineer that has built and scaled 3 startups. He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things. </p>
<p>Featured on IBM ThinkLeaders, Dell Technologies, and NYC’s “Top 10 AI Development and Custom Software Development Agencies” as reviewed on Clutch and YahooFinance. Specializing in predictive maintenance, unified data lakes, supply chain/grid/marketing/sales optimization, anomaly detection, recommendation systems, among other ML solutions for a multitude of industries.  </p>
<p>Visit <a href=""https://blueorange.digital/"">blueorange.digital</a> for more information and <a href=""/cptcasestudies/"">Case Studies</a>.</p>
<p>Main Image source: Canva</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Snowflake-blog.png,Snowflake-blog.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Snowflake-blog.png,3295,Snowflake-blog,,,,https://blueorange.digital/wp-content/uploads/2022/05/Snowflake-blog.png,,,,,,,,
3307,"7 Aspects That Make the Cloud a Safer Place for Your Data","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h5>An important decision all organizations need to make regarding their data is whether to store it on-premise or to host it in the cloud. As of 2019, more than <a href=""https://www.flexera.com/blog/cloud/2019/02/cloud-computing-trends-2019-state-of-the-cloud-survey/#94%20Percent%20of%20Respondents%20Use%20Cloud"">94 %</a> of them have found the answer to this question and rely on the cloud for storing their data. Others are still questioning <a href=""https://resources.idg.com/download/executive-summary/cloud-computing-2018"">the impact</a> that such a decision will have on their business model. But one of the <a href=""https://www.isc2.org/resource-center/reports/cloud-security-report"">most frequent questions</a> asked relates to data security:</p>
<p><em>“What about the security of our data in the cloud?”</em></h5>
<p>Below is a list of 7 aspects that make the cloud storage a safe place for your data:</p>
<h2>1. Data Redundancy &amp; Crash Resilience</h2>
<p>Let’s start with the obvious: the safety of your data relates directly to the safety of the physical data-center(s) where it is stored.</p>
<p>Since cloud vendors store data redundantly, multiple copies of your files reside on a number of data centers spread across the globe. This gives you the certainty that in case of the worst failure (e.g. a physical server is destroyed by a natural disaster) your data is still safe and available. This makes it much easier to recover from disasters.</p>
<p>On the other hand, on-premise data hosting is much riskier from this perspective.</p>
<h2>2. Technical Expertise</h2>
<p>When an organization is already in the business of IT security services, it may be technically capable to handle the security of their own data center.</p>
<p>However, since that may not be the case with most businesses, we can say that the cloud service providers dispose of <a href=""https://www.isc2.org/Research/2019-Cybersecurity-Workforce-Study#"">more technical expertise</a> than the IT department of any organization. When hundreds of cybersecurity professionals are in charge of the security of your data, you can put your security worries aside and focus on your business solution.</p>
<p>In the long run, this can save your organization both time and valuable resources.</p>
<h2>3. Up-to-date Security Software &amp; Standards</h2>
<p>What can be more challenging than maintaining legacy systems? Keeping them secure and fitting with the latest security standards.</p>
<p>Since cloud organizations take security seriously, their software and tools are constantly kept up-to-date. That makes it easier to maintain and patch them according to the<a href=""https://www.microsoft.com/security/blog/2019/11/07/the-new-cve-2019-0708-rdp-exploit-attacks-explained/""> latest security releases</a>. </p>
<p>In the end, this means that your data will be more secure against <a href=""https://www.oracle.com/a/ocom/docs/cloud/cloud-threat-report-2019-infographic.pdf"">cyberattacks</a>.</p>
<h2>4. Layered Data Access </h2>
<p>Since some data is more sensitive than other data, it is often necessary to establish different security schemes. From internal and external firewalls to restricted user access and encryption of your data, the cloud service providers allow you to configure multiple layers of security.</p>
<p>While such services could also be configured on-premise, the cloud infrastructure is built to allow the seamless integration of such features.</p>
<p>This ensures that in the cloud your data will be kept safe from both internal and external threats.</p>
<h2>5. Fine-grained Cybersecurity Tools</h2>
<p>A cloud-based solution for your business means integrating and maintaining a variety of different services. The are various nodes of your infrastructure, be it computing, storage or networking, therefore requiring service-specific security tools.</p>
<p>The cloud providers offer such a wide <a href=""https://www.gartner.com/en/doc/3833968-how-to-evaluate-cloud-service-provider-security"">variety of security tools</a>, for the different services and controls you are renting. These would otherwise be expensive to deploy on-premise. Such tools enable activity monitoring, vulnerability testing, and risk assessment, among others. Moreover, these tools are offered for services at multiple layers (PaaS, IaaS, SaaS).</p>
<p>This means that your organization’s infrastructure can be fully protected by proven security tools.</p>
<h2>6. Configurable Cybersecurity Tools</h2>
<p>While the cybersecurity tools are made available by the cloud service provider, their configuration is the responsibility of their user.</p>
<p>As the <a href=""https://aws.amazon.com/compliance/shared-responsibility-model/"">Shared Responsibility Model</a> suggests, the provider handles the security <strong>of</strong> the cloud, while the customer implements the security <strong>in</strong> the cloud. By means of vendor-provided cybersecurity tools, the customer organization is able to understand, implement and configure the main components of the cloud security solution.</p>
<p>We can even say that the availability of such tools <em>forces</em> their users to consider multiple security aspects at a cloud service level.</p>
<h2>7. Security Training &amp; Certification Programs</h2>
<p>As stated above, the responsibility of data security in the cloud is shared between the vendor and the customer. There is no silver bullet to structuring a <a href=""https://www.oracle.com/cloud/cloud-threat-report/"">cloud security framework</a> and the guidelines of the cloud vendors must be carefully followed by the security expert.</p>
<p>In this sense, the vendors provide extensive documentation and training programs destined for IT professionals that allow them to configure custom security solutions. This high-level guidance allows quickly setting up a cloud security solution without worrying about the low-level details that an on-premise data center would require.</p>
<p>Concerns about data security in the cloud are outdated. In fact, relying on self-maintained data warehousing centers is putting your company at more risk. Migrating your data to the cloud and selecting the best cloud solution for your business should not be a daunting task. The <a href=""/services/"">Blue Orange Digital</a> engineers are ready to assist you with building a secure &amp; affordable cloud solution.</p>
<p>Ready to enjoy the safety of the cloud?<br /><a href=""/contact-us/"">Drop us a line!</a></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/iron-cloud-2-scaled.jpg,iron-cloud-2-scaled.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/iron-cloud-2-scaled.jpg,3324,iron-cloud-2,,,,https://blueorange.digital/wp-content/uploads/2022/05/iron-cloud-2-scaled.jpg,,,,,,,,
3354,"Third-Party Data is Increasing Commercial Real Estate ROI","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2>Gain A Competitive Advantage:</h2>
<p><em>Alternative data</em> is reshaping the way organizations understand, operate, and use data. Across industries, data-powered solutions increase performance by leveraging orthogonal data. Over the last five years, these technological investments have been yielding large returns. The alternative data market has passed its infancy years and is now seeing a lot of activity: technological progress, financial investments, and increased competitiveness among data providers. Such a dynamic ecosystem makes it easy for all organizations to leverage alternative data.</p>
<p>First up, <a href=""/contact-us/"">Blue Orange Digital,</a> a top-ranked AI development and data transformation company in NYC, will guide us through a look at how enrichment with third party data is increasing commercial real estate ROI. As technology is being taken to new levels with the incorporation of consumer data, social media, google trends, sentiment, and more. Exploring what alternative data actually is and how it can be put to use.</p>
<p>Later on, we’ll look at how to find diamonds in the rough and increase ROI in commercial real estate in Diversified Data: Identify Undervalued Properties With Alternative Data Sources.</p>
<h2>Third-Party Data is Increasing Commercial Real Estate ROI</h2>
<p>Commercial Real Estate(CRE) applications can benefit from alternative data since it complements traditional data sources in many ways. Firstly, it accounts for the gaps and inconsistencies in an agency’s own internal data. Such data may be incomplete and lacking perspective, offering limited possibilities for analytics at scale. Secondly, alternative data enables applications that are otherwise unachievable by relying on traditional data sources, thus opening up a whole new world of opportunities. Data-powered services are leading innovation and create entirely new business models, all across the real-estate sector. Many existing CRE use cases demonstrate the powers of alternative data, as we will see later on.</p>
<p>What brings alternative data at the forefront of big data applications today is the maturity of data processing technologies as well as the ever-increasing volumes of data that become available over a variety of channels.</p>
<p>Let us iterate through some of the most common sources of alternative data.</p>
<h2>Web scraped data</h2>
<p>Online traffic is rich in data that is potentially relevant to real-estate: information about potential buyers, house values, and neighborhood amenities can all be found online. Such information can be extracted from websites by means of automated scripts and turned into analyzable data points. Examples of data points that can be obtained by scraping the web include, but are not limited to the following: distance to popular locations, public transit accessibility, as well as restaurant reviews.</p>
<p>CRE analysis tools can leverage such web collected data as part of their evaluation models for properties and entire neighborhoods. They provide an understanding of local dynamics and help model an understanding of the local market. Like this, web-scraped data is filling an important gap and can help shape informed decisions with regards to real estate investments.</p>
<figure class=""wp-block-image""><img class=""wp-image-5614"" src=""https://blueorange.digital/wp-content/uploads/2020/07/4-1024x576.jpg"" alt="""" /></figure>
<h2>Financial records</h2>
<p>Credit card transactions, POS systems, and cash registers all record a variety of financial data: how much, how often, and on what money is being spent. Such data can be collected from both physical and electronic documents. OCR applications make it possible to create digital copies of receipts, invoices, and documents and turn them into structured, analyzable data.</p>
<p>Real-estate has a range of applications where financial transaction data can be used: from marketing campaigns to automated underwriting, and loan score approval. Moreover, when collected and analyzed over extensive time periods, financial data gives an insight into individual consumer behavior. This can help better understand different market segments and their evolution over time.</p>
<h2>Sentiment data</h2>
<p>News segments, social media feeds, and online reviews constitute another important source of alternative data. They can be processed by NLP tools and algorithms then mapped to evaluations, attitudes, and emotions. Like this, it becomes possible to identify patterns between text contents and real estate decisions of potential customers.</p>
<p>Sentiment analysis data completes the inadequate perspective offered by traditional data sets. While it was known on a human level that real-estate investment decisions are not only backed by economic factors, technology has finally quantified some emotional factors as well. By understanding these emotional factors and mapping them to market events, sentiment data makes it possible to better understand real estate markets and the intricate relationships behind them.</p>
<p>A few applications powered by sentiment analysis are chatbots for customer service and automated tenant management. Similarly, NLP models with sentiment analysis capabilities are also at the core of modern property valuation models. From analyzing the sentiments of schools, malls, and emergency services, a property’s value can be affected by the businesses and services surrounding it.</p>
<figure class=""wp-block-image""><img class=""wp-image-5613"" src=""https://blueorange.digital/wp-content/uploads/2020/07/3-1024x576.jpg"" alt="""" /></figure>
<h2>Location tracking</h2>
<p>Humans and their assets move a lot. Location data can offer answers to many questions: where they go, how much time they spend in a specific location, and what movement patterns they follow. GPS systems, mobile smartphones as well as WiFi networks are all designed to handle and collect location data. At the same time, websites, applications, and services are all leveraging location information, since it enables them to offer contextual experiences to their users. The ubiquity of location data has turned it into one of the most powerful sources of alternative data.</p>
<p>The real-estate industry is traditionally focused on “<em>location, location, location.</em>” It is no wonder that leaders in this sector heavily rely on geolocation data for understanding investment risks and opportunities. Location analytics enable a wide range of applications: from real estate planning and development tools to surveillance, tracking, and advertising. With increased access to cutting edge technology, real-estate agencies are now capable of using complex geographic and demographic data to their advantage.</p>
<h2>IoT Data</h2>
<p>The main job that sensors have is to collect data from their environment. This makes them a powerful source of data, and, you guessed it, alternative data. While many sensor applications are built around a specific data type (e.g. temperature monitoring), sensor platforms are increasingly modern and capable of collecting a variety of sensory information. Structured and unstructured data is collected by increasingly capable platforms. These are able to aggregate, process, and exchange sensor data in real-time. This makes IoT data one of the prosperous sources of alternative data.</p>
<p>Commercial Real Estate owners and developers can leverage the rich IoT data ecosystems to their advantage. Whether it is collecting weather data, real-time traffic, or google tracking data; the availability of sensor data enables new applications that would otherwise be impossible using internal data sources alone. Such is the case of real-time threat detection and response surveillance systems. At the same time, the alternative IoT data is at the core of intelligence and interconnectedness of smart buildings.</p>
<figure class=""wp-block-image""><img class=""wp-image-5611"" src=""https://blueorange.digital/wp-content/uploads/2020/07/2-1024x576.jpg"" alt="""" /></figure>
<h2>Conclusion: The Power of Alternative Data</h2>
<p>Alternative data sources are nowadays ubiquitous and leveraged across industries well beyond real-estate. Many factors contribute to their popularity. Firstly, modern data stacks are built to integrate a variety of data sources. This enables agile development when building predictive solutions since external data sets can easily be added or removed “on the fly”. Secondly, the alternative data market is seeing increased growth, since more and more companies are willing to monetize their own internal data and acquire data from third parties. This shows how alternative data sets are indispensable to modern machine learning and data science projects.</p>
<p>In the real estate sector, such a dynamic ecosystem lowers the entry barrier for new data-powered applications and services. As we have seen above, new use cases arise when different data sources are combined and leveraged for one common goal. These innovations can have an impact on all real-estate players, from investors, lenders, and agents to prospective customers. With more and more players joining the alternative data market with innovative data-powered solutions, disruption of the real-estate sector is inevitable.</p>
<p>To go into more depth on how alternative data can be used and implemented check out how Blue Orange Digital was able to utilize third-party data to effectively Identify Undervalued Properties with Alternative Data Sources.</p>
<p>When you hear about the power of alternative data to boost the bottom line in real estate, you might ask your IT team to work on it. However, implementing advanced algorithms, scaling a digital transformation, and capitalizing on all the available alternative data may not be within your team’s capability nor within your budget to experiment with. That means that an in-house solution is unlikely to work. Reach out to a top-ranked software development agency, like <a href=""https://blueorange.digital/"">Blue Orange Digital</a>, to discuss how they can deliver your real estate solution in 90 days or less.</p>
<p>Do you have any related questions? From real estate to health care and energy, the Blue Orange Digital team has extensive experience developing machine learning algorithms, analytic models, and custom big data solutions.</p>
<p>Tell us about your project today, schedule 15 minutes below to discover the power in your data.</p>
<figure class=""wp-block-image""><a href=""https://blueorange.digital/diversify-your-data-identify-undervalued-properties-with-alternative-data-sources/"" target=""_blank"" rel=""noreferrer noopener""><img class=""wp-image-5492"" src=""https://blueorange.digital/wp-content/uploads/2020/07/Diversify-you-data1-1024x536.gif"" alt=""Diversify your data1"" /></a>
<p>&nbsp;</p>
<figcaption>Diversified Data: Identify Undervalued Properties With Alternative Data Sources.</figcaption>
</figure>
<h2>About the Author</h2>
<p>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for Supply Chain, Healthcare Document Automation, and <a href=""/cptcasestudies/"">more</a>.</p>
<hr class=""wp-block-separator"" />
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img class=""wp-image-5323"" src=""https://blueorange.digital/wp-content/uploads/2020/05/Josh-Miramant-CEOpng-1024x1024.png"" alt=""Josh Miramant CEO Blue Orange Digital"" width=""181"" height=""181"" />
<p>&nbsp;</p>
<figcaption>Josh Miramant<br />CEO Blue Orange Digital</figcaption>
</figure>
</div>
<p>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He is a serial entrepreneur and software engineer that has built and scaled 3 startups. He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things.</p>
<p><em>Follow me on </em><a href=""https://twitter.com/BlueOrangeData""><em>Twitter</em></a><em> or </em><a href=""https://www.linkedin.com/in/joshmiramant/""><em>LinkedIn</em></a><em>. Check out my </em><a href=""https://blueorange.digital/""><em>website</em></a><em>.</em></p>
<p>All images sourced from: Canva</p>
<div class=""calendly-inline-widget"" data-url=""https://calendly.com/blue-orange-bd/discovery-call"" data-processed=""true"">
<div class=""calendly-spinner"">
<div class=""calendly-bounce1""> </div>
<div class=""calendly-bounce2""> </div>
<div class=""calendly-bounce3""> </div>
</div>
<p><iframe src=""https://calendly.com/blue-orange-bd/discovery-call?embed_domain=blueorange.digital&amp;embed_type=Inline"" width=""100%"" height=""800"" frameborder=""0"" data-mce-fragment=""1""></iframe></p>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/3rd-party-data-increasing-CRE-ROI.gif,3rd-party-data-increasing-CRE-ROI.gif,/www/blueorangem_500/public/wp-content/uploads/2022/05/3rd-party-data-increasing-CRE-ROI.gif,3355,3rd-party-data-increasing-CRE-ROI,,,,https://blueorange.digital/wp-content/uploads/2022/05/3rd-party-data-increasing-CRE-ROI.gif,,,,,,,,
3372,"7 Tips for a Strong Data Infrastructure","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.22.0"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" hover_enabled=""0"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}"" sticky_enabled=""0""]<p>Everything you want to do when it comes to analytics – from the advanced stuff, like data science and machine learning, to the basics – hinges on a solid data infrastructure.</p>
<p>In this blog, we provide 7 tips from our experience that will help ensure your data infrastructure supports all of your current and future analytics needs.  This is not an exhaustive or sequential list, but rather ideas that we have seen have help our clients.</p>
<h2><strong>1. START FROM THE BEGINNING – Define Your Data and Analytics Strategy</strong></h2>
<p>Before you tackle any kind of BI project, consider questions like:  Do you have a data and analytics strategy?  What is your company’s overall corporate strategy?  What is the business reason behind the need for analytics? You need to define what technology, processes, and people to put in place so you can meet your analytics goals.</p>
<p>Our approach to helping our clients define their data and analytics strategy consists of 4 main steps:</p>
<ol>
<li>Understand Your Vision – what is the long-term analytics vision, and how does it fit into your overall business strategy?</li>
<li>Capture Your Current State – this includes interviewing stakeholders, evaluating data sources, and reviewing technologies</li>
<li>Develop an Analytics Plan – this is a detailed plan that maps out where you want to go and provides a plan to fill in the gaps.</li>
<li>Deliver Results – at Analytics8, we deliver in a phased approach with short 6-8 cycles so that our clients can provide feedback throughout the process and see results along the way.</li>
</ol>
<h2>How to Get Started:</h2>
<p>If you don’t have a well-defined strategy, start making one. A couple of approachable things that anyone could start now include:</p>
<ul>
<li>Talk to the business and gather requirements: Instead of asking what they need, ask them to “show you”, then document findings.</li>
<li>Start making list of sources systems. Interview business to understand source systems and which departments use them.</li>
</ul>
<p>Learn more about our data strategy services.</p>
<h2><strong>2. PRIORITIZE YOUR PROJECTS</strong></h2>
<p>This is a given, but without prioritization, your projects may take turns you never intended. Well-communicated priorities help align projects and programs to its strategies.</p>
<p>Why Prioritize?</p>
<ul>
<li>Increases the success rates of strategic projects</li>
<li>Increases the alignment and focus of management around strategic goals</li>
<li>Clears doubts for the operational teams when faced with decisions</li>
<li><strong>Builds an execution mindset and culture</strong></li>
</ul>
<h2>How to Get Started:</h2>
<p><strong>Use the Prioritization Matrix</strong></p>
<p>Align each of your analytics activities with your overall corporate goals, then determine the technical feasibility of each.</p>
<ul>
<li>Talk to the business and gather requirements and identify KPIs</li>
<li>Work with users to assign business value and technical feasibility for each use case</li>
<li>Plot on chart and determine what projects you should start on first</li>
</ul>
<div class=""wp-block-image"">
<figure class=""aligncenter""><a href=""https://www.analytics8.com/wp-content/uploads/2018/11/7-tips-1.png"" target=""_blank"" rel=""noreferrer noopener""><img class=""wp-image-8870"" src=""https://www.analytics8.com/wp-content/uploads/2018/11/7-tips-1.png"" alt="""" /></a></figure>
</div>
<p><strong>Prioritization Matrix</strong></p>
<h2><strong>3. EVALUATE ENVIRONMENTS</strong></h2>
<p>Where within your technology stack do you need the setup of the environment?  Consider how you move data through the stack.  The whole system will run smoother if this is set up well.  Some things you should start documenting when evaluating your environments include:</p>
<ul>
<li>Security setup considerations</li>
<li>Data load/storage strategy</li>
<li>Architecture diagram</li>
<li>Change management strategy</li>
</ul>
<h2>How to Get Started:</h2>
<p>Ensure your environment is set up thoughtfully.</p>
<ul>
<li>Look for redundancies: Make sure your system is efficient</li>
<li>Evaluate your environment: Consider what’s best for your organization (on premises versus the cloud, etc)</li>
<li>Do you need multiple environments? Do you have Dev, QA, and Prod environments, or is that overkill?</li>
<li>Refresh data: If you have dev source systems, need to ensure the data is refreshed so you have good data to work with</li>
</ul>
<p>Read more about our <a href=""https://blueorange.digital/services/data-architecture/"">data architecture</a> services.</p>
<h2><strong>4. BUILD A FLEXIBLE DATA MODEL</strong></h2>
<p>A data model creates the structure the data lives in, and a thoughtfully created model enables flexibility and ease of use. It also defines how things are labeled and organized which determines how your data can and will be used and ultimately what story that information will tell. Finally, a data model helps define the problem, enabling you to consider different approaches and choose the best one.</p>
<p><strong>Example Data Models</strong></p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><a href=""https://www.analytics8.com/wp-content/uploads/2018/11/7-tips-2.png"" target=""_blank"" rel=""noreferrer noopener""><img class=""wp-image-8871"" src=""https://www.analytics8.com/wp-content/uploads/2018/11/7-tips-2.png"" alt="""" /></a></figure>
</div>
<p>Tools like Qlik, Tableau, PowerBI can help you get better access to your data so you can make better decisions. HOWEVER, if you don’t build a relational data model the solution is not built for the future.</p>
<h2><em>Relational Data Models and Why You Need One</em></h2>
<p>Tools like Qlik, Tableau, PowerBI can help you get better access to your data to better make decisions, but if you don’t build a relational data model, the solution isn’t sustainable.</p>
<p>Why you need a data warehouse:</p>
<ul>
<li>No need to access data sources separately and cuts down on data prep</li>
<li>Automatically integrates disparate data sources along with common attributes</li>
<li>A [good] data warehouse is designed to be understood by a human, not a computer program</li>
<li>Reduces the time to analyze data, gives you confidence in your data, invokes higher quality insights, and provides better data security</li>
<li>Allows for data governance and prevents “wild west” data analysis</li>
</ul>
<h2>How to Get Started:</h2>
<p>Use the Bus Matrix. The Bus Matrix contains all of the different core business processes that you’re trying to model along with the common dimensions which is how you will slice the data. It will provide a top-down strategic perspective to ensure data in the data warehouse environment can be integrated across the enterprise, while agile bottom-up delivery occurs by focusing on a single business process at a time.</p>
<p><strong>Bus Matrix Example</strong></p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><a href=""https://www.analytics8.com/wp-content/uploads/2018/11/7-tips-3.png"" target=""_blank"" rel=""noreferrer noopener""><img class=""wp-image-8872"" src=""https://www.analytics8.com/wp-content/uploads/2018/11/7-tips-3.png"" alt="""" /></a></figure>
</div>
<h2><strong>5. DOCUMENT DATA LINEAGE</strong></h2>
<p>This one is boring, but necessary. Without the knowledge of how your data goes from origination to its destination, you could end up rebuilding things later. When you document your data lineage, you’ll be able to:</p>
<ul>
<li>Get knowledge about what data is available, its quality, and correctness</li>
<li>Get knowledge from the head of the ETL developer</li>
<li>Have more transparency about what’s going on with your data</li>
<li>Give business users more detail about what they’re using in their reports</li>
<li>Understand the impact of changes made on a source system</li>
</ul>
<h2>How to Get Started:</h2>
<p>Build an ETL mapping document. This is a visual of your existing data flow and lineage, including sources and data dependencies, such as revenue. Doing this step during development will save you so much time later on – trust us on this one!</p>
<p><strong>ETL Mapping Document Example</strong></p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><a href=""https://www.analytics8.com/wp-content/uploads/2018/11/7-tips-4.png"" target=""_blank"" rel=""noreferrer noopener""><img class=""wp-image-8873"" src=""https://www.analytics8.com/wp-content/uploads/2018/11/7-tips-4.png"" alt="""" /></a></figure>
</div>
<h2><strong>6. STEP BACK AND ASSESS PERFORMANCE</strong></h2>
<p>You’ll want to consider performance needs for both front-end user experience and backend infrastructure. Taking time to do this doing the development process will help ensure optimal performance.</p>
<p>Here are some questions you can ask when assessing performance.</p>
<p><strong>User Experience:</strong></p>
<ul>
<li>How long does it take to run reports?</li>
<li>What factors are affecting performance?</li>
<li>Are those services really too expensive?</li>
</ul>
<p><strong>Backend Performance:</strong></p>
<ul>
<li>How often does the data need to be refreshed?</li>
<li>Are you using incremental loads?</li>
<li>Are you uploading data that nobody uses?</li>
<li>How is ETL performance?</li>
</ul>
<h2>How to Get Started:</h2>
<p>Again, start <em>documenting</em> the current state, both the front-end user experience and the backend infrastructure performance. Capture performance benchmarks, assess factors impacting performance, establish SLAs, and identify areas for improvement.</p>
<h2><strong>7. IMPLEMENT A DATA GOVERNANCE PROGRAM</strong></h2>
<p>With a properly implemented data governance program, you can gain consistency, get faster time to delivery, lower your maintenance needs, get more quality data, increase user adoption, and a whole lot more. It’s a critical piece to your data and analytics solution, but one that is often overlooked.</p>
<h2>How to Get Started:</h2>
<p>We’ve identified 8 steps to implement a Data Governance Program. Read more about these 8 steps.</p>
<p><strong>How to Implement a Data Governance Program</strong></p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><a href=""https://www.analytics8.com/wp-content/uploads/2018/11/7-tips-5.png"" target=""_blank"" rel=""noreferrer noopener""><img class=""wp-image-8874"" src=""https://www.analytics8.com/wp-content/uploads/2018/11/7-tips-5.png"" alt="""" /></a></figure>
</div>
<p>A key point we’d like to highlight: a grass-roots data governance movement will not work. For your data governance program to be successful, you’ll need buy-in from the top and it needs to be championed across the organization. If your team isn’t motivated by the follow the processes laid out, your plan won’t provide its potential benefits.</p>
<p>Starting with the first step, figure out who will be leading the way. You want a leader who looks at data as an asset.</p>
<div class=""calendly-inline-widget"" data-url=""https://calendly.com/blue-orange-bd/discovery-call"" data-processed=""true""> </div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/10-1.jpg,10-1.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/10-1.jpg,3375,10-1,,,,https://blueorange.digital/wp-content/uploads/2022/05/10-1.jpg,,,,,,,,
3387,"What is Advanced Analytics?","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>Advanced analytics tools are changing the business world. It’s more than data, tables, and spreadsheets. It’s a way to predict your next move, win more customers and reduce risk. Here’s how we think about advanced analytics.</p>
<h2><strong>What Is Advanced Analytics?</strong></h2>
<p>Every company will define it differently. Some choose to emphasize the inputs – all the data you can analyze. Others want to emphasize the brand new insights you can pull from your data. At Blue Orange, here is how we define advanced analytics.</p>
<p>Advanced analytics is a combination of software and practices that transforms your data into problem-solving business insights.</p>
<p>Each part of the definition is significant, so let’s take a moment to unpack each piece.</p>
<ul>
<li>Software. For advanced analytics projects to succeed, you need to select the right software. Relying on Excel or outdated business intelligence (BI) applications is not going to cut it.</li>
<li>Practices. You need an analytical skillset to draw value from analytics. Specifically, you need to know the right questions to ask, critical thinking skills to evaluate your data, and the knowledge to present advanced analytics effectively to your stakeholders. </li>
<li>Data. Advanced analytics requires significant amounts of data. This could be your internal company data (e.g., marketing analytics, customer data, etc.) or data from the marketplace. We can help you with data evaluation so you can focus your analytics efforts in the right areas.</li>
<li>Problem Solving Insights. Processing data does not move the needle forward on your business. You need insights that solve your problems and the determination to act on those insights.</li>
</ul>
<p>Now let’s explore how advanced analytics can benefit your organization.</p>
<h2><strong>How Advanced Analytics Benefits Your Company</strong></h2>
<p>For advanced analytics to produce value, you need to connect it to your business problems and goals. To illustrate how advanced analytics can help your company, let’s focus on one of the most common business goals: acquire more customers.</p>
<p>By implementing advanced analytics, you can acquire more customers in several ways. Let’s assume you already have a website with 10,0000 visitors per month, and you have an active customer base. With advanced analytics, you can get more customers in the following ways.</p>
<ul>
<li>Experiment with lead generation. Use analytics to determine which offers (e.g., 10% discount vs offering a bonus product) generate the orders. Likewise, Blue Orange can also help you identify your most valuable customer segments so you can make the most of your marketing dollars.</li>
<li>Clarify your most profitable customers. Some customers are more profitable to work with than others. Use analytics tools to identify common characteristics of your most valuable customers (e.g., you might find that customers with more than 100 employees are the most profitable). Based on that insight, you can adjust your marketing accordingly.</li>
</ul>
<h2><strong>What Keeps Advanced Analytics Projects From Succeeding?</strong></h2>
<p>If you have tried advanced analytics before without results, you’re not to blame. Implementing this type of advanced technology is not easy. To make this type of project succeed, there are three barriers you need to overcome.</p>
<p>Barrier to Advanced Analytics Success: <strong>Choosing the wrong business problem</strong></p>
<p>Advanced analytics has its limitations, like any methodology. Put, it is better at solving some problems. There are proven analytics strategies to improve sales and marketing problems with analytics. Likewise, you can improve operational efficiency and supply chain problems. However, if your problem relates to leadership, company culture, and other qualitative issues, it may not be the right solution.</p>
<p>Barrier to Advanced Analytics Success: <strong>Focusing on poorly developed analytics questions</strong></p>
<p>The questions you ask shape the answers you have with analytics. For example, if you focus on trying to find tiny improvements, you are unlikely to generate significant wins. For the best results, we recommend basing your analytics questions on business goals and analytics best practices. Let’s illustrate how to overcome this barrier with an example.</p>
<p>Ineffective question: How do we make more money?</p>
<p>Effective question: How can we increase the percentage of customers who purchase a 1-year product warranty?</p>
<p>Barrier to Advanced Analytics Success: <strong>Failing to act on analytics insights</strong></p>
<p>When you receive a data insight that goes against your habits or the traditional way of doing business, what will you do? If you are like most companies, you will ignore the data. Sadly, this is a common problem. In 2019, the<a href=""https://hbr.org/2019/02/companies-are-failing-in-their-efforts-to-become-data-driven""> Harvard Business Review</a> reported the following findings based on a survey of C-level executives: </p>
<ul>
<li>52% admit that they are not competing on data and analytics.</li>
<li>69% report that they have not created a data-driven organization</li>
</ul>
<p>If your technology team builds an advanced analytics capability and executives ignore the results, you cannot be surprised by the results. Solving this barrier does not require different technology. Instead, it requires a champion – a senior executive willing to take chances on advanced analytics.</p>
<h2><strong>The Path To Advanced Analytics Success Starts With Blue Orange</strong></h2>
<p>You don’t have to solve these barriers to advanced analytics success on your own. Reach out to Blue Orange today to discuss how we can address these challenges for you. </p>
<div class=""calendly-inline-widget"" data-url=""https://calendly.com/blue-orange-bd/discovery-call"" data-processed=""true""> </div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/advanced-analytics-scaled.jpg,advanced-analytics-scaled.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/advanced-analytics-scaled.jpg,3388,advanced-analytics,,,,https://blueorange.digital/wp-content/uploads/2022/05/advanced-analytics-scaled.jpg,,,,,,,,
3393,"The 4 Data Questions Every CU Leader Needs to Answer","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>Increased consolidation and competition require that credit unions today adopt a new strategy. The winners in this emerging landscape will be institutions that leverage data and prediction across their organization. Data-driven decision making, made possible by the decreased cost of prediction, allows adopting credit unions to highlight their advantages to customers and run more profitably and efficiently.  But to get to this promised land, all CU leaders first need to answer 4 key questions:</p>
<h2><b>1) What is my data strategy?</b></h2>
<p>Does your institution have a 3-year roadmap for how to take advantage of modern analytics? This seems like a tall order. Most CUs don’t have internal knowledge, resources, analysts, and data structures in place. It is hard to find vendors with the data science expertise to solve these problems holistically and offer simple tools to meet specific, ongoing credit union needs. But without a coherent plan to gain insight into your business, the shift won’t happen.  Food for thought: <a href=""https://www.jpmorganchase.com/corporate/news/stories/tech-investment-could-disrupt-banking.htm"">JP Morgan spends 11B on tech in a single year</a>.</p>
<h2><b>2) Do my systems talk?</b></h2>
<p>Legacy systems weren’t designed for predictive analytics. Core, marketing, loan origination, credit card, and operational data usually live in parallel worlds. Just pulling out the data to build a report or send an email marketing blast can require waiting on the one IT guy who knows commands in an arcane programming language. Ouch. A centralized data warehouse can serve as a single source of truth across the organization, eliminate redundant information systems, and simplify access to analytics that increases revenue. The vision for effective data infrastructure is that all data systems from call center to core talk seamlessly and securely. Cloud storage and computing providers like Amazon Web Services have made this accessible even to the smallest institutions.</p>
<h2><b>3) Where can I apply Business Intelligence?</b></h2>
<p>Machine learning. Optimization. Decision support. There are a lot of names, so what does prediction actually solve? Here are some examples of BI in action:</p>
<ul>
<li>Sales and Marketing Optimization: Run a more effective email campaign by targeting specific members with the cross-selling offers that they are likely to purchase.</li>
<li>Financial Products: Dynamically price loans and interest rates to maximize long term revenue by accounting for member acquisition and retention effects.</li>
</ul>
<ul class=""listing-blogie"">
<li>Operational BI: Use teller and hold/wait time analytics to anticipate interactions that could undermine member loyalty.</li>
<li>Balance Sheet Assessments: Go beyond core deposit studies with decision support and automation tools that allow for real-time what-if scenarios and guidance on institutional finance decisions.</li>
</ul>
<h2><b>4) How does our leadership team use data?</b></h2>
<p>The reason you are in the C-suite is your ability to make tough decisions. But everything doesn’t need to be a gut call. Simple and effective executive reporting is a key step to transforming into a data-driven organization. Automated reporting and easy exploration of the data surrounding a decision help you identify key variables in less time to make better decisions. Visualization tools, custom dashboards, and self-service BI create an environment where complex questions can be answered in hours not weeks. Layering in prediction can automate routine decisions. Multiplying this speed and accuracy across the credit union is the backbone of offering services that make members feel valued in an increasingly complex world.</p>
<h2><b>Pulling it all together</b></h2>
<p>So what would this approach look like in practice? Let’s take an auto loan. Your credit union applies predictive member segmentation and lead scoring to determine promotion and outreach timing for members likely to purchase a car in the next 3 months. A personalized email campaign is coordinated with onsite member service conversations. Loan pricing is optimized for profitability over the lifetime of the member relationship in order to drive loyalty and increase the deposit base, as well as maximize current revenue. At the end of the campaign, reporting metrics and visualization tools allow easy assessment of how the campaign contributed to the CUs annual goals and improvement for the next campaign. Need help navigating a modern data strategy? <a href=""https://blueorange.digital/"">Blue Orange</a> is a data science agency focused on helping credit unions make better business decisions with their data. Reach out for a complimentary call about custom solutions to the data challenges that your institution needs to solve.</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/four-data-questions-.jpg,four-data-questions-.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/four-data-questions-.jpg,3397,four-data-questions-,,,,https://blueorange.digital/wp-content/uploads/2022/05/four-data-questions-.jpg,,,,,,,,
3589,"Blue Orange Digital in NYC’s Top AI Companies, again.","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>At Blue Orange Digital, we simplify how businesses interact and make decisions with their data using machine visions, natural language processing, and robotic process automation. We work with businesses to implement <a href=""https://www.forbes.com/sites/forbestechcouncil/2021/05/07/five-trends-that-will-dominate-data-analytics-for-the-rest-of-2021/"">data-driven analytic techniques</a> derived from statistical modeling and data science. We are a team of passionate data engineers, PhDs, data scientists, and visualization experts. It is our mission to help our clients identify and apply advanced analytics to improve the quality of decision-making.</p>
<p>&nbsp;</p>
</div>
<p><img class=""wp-image-3673 alignnone size-full"" src=""https://blueorange.digital/wp-content/uploads/2022/05/Capture.png"" alt="""" width=""743"" height=""395"" /></p>
<div class=""content"">
<p>We recently received news that our company was highlighted in the <a href=""https://clutch.co/developers/artificial-intelligence/new-york"">2021 Clutch leader</a> awards as one of the <a href=""https://blueorange.digital/blue-orange-named-a-top-ai-development-partner-2020/"">top Artificial Intelligence Companies in New York City.</a>If you haven’t heard of Clutch before, it’s a B2B ratings and reviews platform based in Washington, DC helping firms across the globe connect with the best-fit solution providers that they need to tackle their next business challenge.</p>
<p>Why us? Blue Orange CEO Josh Miramant answers “<a href=""https://blueorange.digital/blue-orange-digitals-ceo-discusses-what-sets-us-apart-with-clutch/"">What sets us apart</a>,” in his interview with Clutch.</p>
<p>Each year, Clutch highlights the top B2B companies in different industries. Receiving this award is no small feat, and we’re extremely appreciative of this recognition.</p>
<blockquote class=""wp-block-quote""><p><em>""It is an honor for our team to receive these awards year after year from Clutch. I am humbled by our client’s recognition of our team’s outstanding dedication to being trusted partners in the cloud data transformation and predictive analytics space. We are most proud of our success in helping to bring confidence and clarity to cloud data strategies.</em></p>
<p><em>I’d like to extend an enormous salute to our esteemed colleagues here at Blue Orange Digital, each of whom is dedicated to putting our clients first on every project. We will continue to strive to do our best to bring life to new innovations and solutions that drive our success. Thank you!</em>""</p>
<p><cite>- <strong>Josh Miramant, CEO Blue Orange Digital</strong></cite></p>
</blockquote>
<p>We’re extremely thankful to our clients for their trust and support and especially to those who left us a review on our <a href=""https://clutch.co/profile/blue-orange-digital#summary"">Clutch profile</a>. Here’s what they had to say about working with us.</p>
<div class=""wp-block-image"">
<figure class=""alignright is-resized""><img class=""wp-image-6070"" src=""https://blueorange.digital/wp-content/uploads/2020/10/Clutch-Badge-White.png"" alt="""" width=""89"" height=""89"" />
<p>&nbsp;</p>
<figcaption>5-Star Review</figcaption>
</figure>
</div>
<p><em>“They are truly committed to technical excellence and doing everything they can to make your project successful.” – CEO, Staff Augmentation for AI Company</em></p>
<p><a href=""https://blueorange.digital/contact-us/"">Connect</a> with a Blue Orange expert to see how we can help.</p>
<p>Interested in learning more about how Blue Orange can help your business exceed its own benchmarks for success? <a href=""https://blueorange.digital/contact-us/"">Drop us a line</a> today!</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Blue-Orange-Digital-Recognized-by-Clutch-Among-New-York-Citys-Top-Artificial-Intelligence-Developers-for-2021-1-1.png|https://blueorange.digital/wp-content/uploads/2022/05/Clutch-Badge-White.png|https://blueorange.digital/wp-content/uploads/2022/05/Artificial_Intelligence_Companies_2021-1-947x1024-1.png|https://blueorange.digital/wp-content/uploads/2022/05/B2B_Companies_NewYork_2021-1-947x1024-1.png|https://blueorange.digital/wp-content/uploads/2022/05/B2B_Companies_NewYork_2021-1-947x1024-1-277x300-1.png|https://blueorange.digital/wp-content/uploads/2022/05/Capture.png,Blue-Orange-Digital-Recognized-by-Clutch-Among-New-York-Citys-Top-Artificial-Intelligence-Developers-for-2021-1-1.png|Clutch-Badge-White.png|Artificial_Intelligence_Companies_2021-1-947x1024-1.png|B2B_Companies_NewYork_2021-1-947x1024-1.png|B2B_Companies_NewYork_2021-1-947x1024-1-277x300-1.png|Capture.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Blue-Orange-Digital-Recognized-by-Clutch-Among-New-York-Citys-Top-Artificial-Intelligence-Developers-for-2021-1-1.png|/www/blueorangem_500/public/wp-content/uploads/2022/05/Clutch-Badge-White.png|/www/blueorangem_500/public/wp-content/uploads/2022/05/Artificial_Intelligence_Companies_2021-1-947x1024-1.png|/www/blueorangem_500/public/wp-content/uploads/2022/05/B2B_Companies_NewYork_2021-1-947x1024-1.png|/www/blueorangem_500/public/wp-content/uploads/2022/05/B2B_Companies_NewYork_2021-1-947x1024-1-277x300-1.png|/www/blueorangem_500/public/wp-content/uploads/2022/05/Capture.png,3665|3662|3663|3664|3671|3673,Blue-Orange-Digital-Recognized-by-Clutch-Among-New-York-City’s-Top-Artificial-Intelligence-Developers-for-2021-1-1|Clutch-Badge-White|Artificial_Intelligence_Companies_2021-1-947x1024|B2B_Companies_NewYork_2021-1-947x1024|B2B_Companies_NewYork_2021-1-947x1024-1-277x300|Capture,|||||,|||||,|||||,https://blueorange.digital/wp-content/uploads/2022/05/Blue-Orange-Digital-Recognized-by-Clutch-Among-New-York-Citys-Top-Artificial-Intelligence-Developers-for-2021-1-1.png,,,,,,,,
3590,"A Guide to Everything You Need to Know About AIOps","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Computers have advanced in many ways since their inception and arguably the most important dimension is in the computational power they provide. It is this increase that ultimately enables machine learning solutions. Machine Learning is an application of artificial intelligence that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. ML brings new techniques across various aspects of business and across many different industries. It brings the ability to automate manual and repetitive tasks and improve the process behind decision making.</p>
<h2>ML vs AI</h2>
<p>You’ve heard the buzz, but you may be asking yourself, what exactly is machine learning? And how does it differ from AI?</p>
<p>ML is a type of computer program or algorithm with the ability to teach itself by analyzing data (inputs) and coming up with a solution (output). What makes machine learning algorithms valuable are the feedback loops--a well-designed algorithm continues to learn from new input data to increase the accuracy of the solution it comes up with. For example, machine learning algorithms in recruiting are used to assess candidates’ personalities, job fit, and resume. ML is essentially statistics and correlations used to make predictions. These predictions become more accurate as more inputs are fed into the system.</p>
<h2>3 Types of ML</h2>
<h4>1. Supervised Learning</h4>
<p>In supervised learning, the algorithm is given a set of correctly labeled input/output example pairs in order to train. The two major types of supervised learning are <strong>regression</strong> and <strong>classification</strong>. Regression involves predicting a quantity by figuring out which features are important for the outcome. Classification involves assigning observations to different categories. </p>
<p>This allows for questions in three formats. Two-class classification (A or B?), multi-class classification (A, B, or C?), and anomaly detection (is this abnormal?). Using these classifications you can ask and answer questions such as; Is this an image of a cat or dog? What is the mood of this tweet? Or, Is this pressure reading atypical?</p>
<h4>2. Unsupervised Learning</h4>
<p>While supervised learning finds patterns in data sets where we know the correct answers, unsupervised learning finds patterns in data sets where we don’t. Unsupervised learning allows us to ask questions about how data is organized and how to compress it. This is achieved through techniques such as <strong>clustering</strong> and <strong>dimensionality reduction</strong>.  For example real estate websites can group their housing listings into neighborhoods so that users can navigate listings easier.</p>
<p>Unsupervised learning allows us to answer two types of questions:</p>
<p>How is this data organized? </p>
<p>How can we represent this data in a compressed format?</p>
<h4>3. Reinforcement Learning</h4>
<p>In reinforcement learning, we do not provide the machine with examples of correct input-output pairs, but we do provide a method for the machine to quantify its performance in the form of a reward signal. The machine tries a bunch of different things and is rewarded when it does something well. Reinforcement learning is useful in cases where the solution space is enormous or infinite, and typically applies in cases where the machine can be thought of as an agent interacting with its environment. An algorithm that can <a href=""https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii"">play video games </a>is an example of reinforcement learning.</p>
<p>Reinforcement Learning is all about the actions the machine can take. The RL algorithm chooses an action based on the factors it has learned to make high reward actions. This process was inspired by how humans and rats respond to rewards and punishment. This makes RL terrific for automated systems. For example an air system can learn to pre-refrigerate the upper floors of an office building before the day gets too hot and takes longer to cool down. This saves money in the long run by having the system use less electricity because it is running and working less.</p>
<p>Here at Blue Orange we have used ML to automate resume screening and shortlist and grade candidates by learning from existing employees’ resumes. First we used a natural language processing ML algorithm to turn the unstructured resume text into relational data. Then we built another ML algorithm that trained itself on prior employees to learn which resume data points (inputs) are correlated with successful employees to produce a shortlist of qualified candidates for the position (output). Instead of just scanning for keywords, we are able to make predictive hiring suggestions to HR. In addition, for firms who use digitized interviews, we can use machine learning technology to assess candidates’ personality and job fit by learning from successful candidates’ facial expressions and word choices. </p>
<p>As technology further integrates into our everyday life, the need for collecting, storing, and analyzing the data we have will only grow in importance. This may seem daunting now, but with foresight ML can be utilized by businesses of all sizes across all industries. So let us tame your business’s data and make it start working for you.</p>
<p><strong> <a href=""/contact-us/"">Contact us today to see how we can help!</a></strong></p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/AIOps-Blog-Cover.png,AIOps-Blog-Cover.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/AIOps-Blog-Cover.png,3652,AIOps-Blog-Cover,,,,https://blueorange.digital/wp-content/uploads/2022/05/AIOps-Blog-Cover.png,,,,,,,,
3591,"The Advantages of Natural Language Processing for Businesses","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>With machine learning developing at lightning speed, communication is an area that can’t be left untouched. Natural language processing (NLP) stands for the utilization of Artificial Intelligence to comprehend language in context and communicate responses based on trained algorithms. NLP assists organizations with basic processes such as the extraction of information and data from text-based documents to more advanced ones, like sentiment analysis. </p>
<p>All internet users have utilized at least one application that was based on NLP. Even the act of performing a search on Google or Bing makes you an active user of NLP-based systems. These search engines employ natural language processing to suggest suitable <a href=""https://blueorange.digital/recommendation-engines/"">recommendations</a> and respond to search requests. </p>
<p>However, natural language processing finds use in other software besides search engines. Alexa or Siri, which are both two well-known voice-activated virtual assistants, depend on natural language processing to recognize the human voice and respond to your questions. Also, chatbots base their answers on NLP. </p>
<p>Businesses and organizations can utilize this technology to retrieve information from unstructured data to build enhanced data sets. Before discussing the benefits that NLP has in comprehending and answering queries of written or spoken words, let us talk about its origin and how it came into use. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>What is NLP (Natural Language Processing)?</strong></h2>
<p>Natural language processing (NLP) is treated as a specific branch of the realm of computer science closely related to artificial intelligence. It deals with the capability of computers to understand spoken and written words as a normal human. </p>
<p>Computational linguistics, which is rule-based modeling of human language, together with machine learning, statistical, and deep learning models work together to decipher sounds from voice data and process human language while taking into consideration the purpose and background of the writer or speaker.  </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/VbKOTleTZUOcEtEKiIacM6xHGK66VzcAMJ5qzbGy0Hx9iBb8SfA_K_WSKfmOSEp2TM3wT76ZZr8j20MaPQExatDWlldL6CmXvWFHrjqg4eNczYQBWrBEC54qSxXl0bmp-lhcGrmF"" alt="""" /><br />
<figcaption><strong><a href=""https://algorithmxlab.com/blog/natural-language-processing/"">Source</a></strong></figcaption>
</figure>
<p>NLP is the heart of translation software programs that adapt content into other languages and summarize large volumes of text in an instant and respond to voice requests in a matter of seconds. </p>
<p>You’d be surprised at the number of running systems that we use on a daily basis powered by <a href=""https://blueorange.digital/how-language-processing-is-being-enhanced-through-googles-open-source-bert-model/"">NLP algorithms</a>. These could be digital assistants, chatbots, GPS systems, or speech-to-text dictation software programs. NLP is not limited to the use of our everyday devices though. It finds use in large companies to simplify business processes, boost employee productivity, and guarantee smooth daily operations.  </p>
<h2><strong>Advantages of NLP for Businesses</strong></h2>
<p>Human language has as many rules as it has exceptions, which makes it incredibly challenging to build software that comprehends voice and text data accurately. Programmers deal with these intricacies daily(metaphors, grammar rules, idiomatic expressions, etc.) but the product of their work is totally worth it. </p>
<p>Especially for businesses seeking to enhance their customer service experience, reduce the response time with context-based automated answers, or analyze customer conversations and produce insights. Some key points of using NLP are:</p>
<h2><strong>In-depth Data Analysis</strong></h2>
<p>Computers find it challenging and time-consuming to analyze and process unstructured data such as emails, documents, or research results. Using NLP technology, vast amounts of textual data are processed with much more ease. </p>
<p>Also, NLP helps recruiters reduce the time spent to hire new employees. NLP applications remove the need for manual screening of thousands of resumes by filtering based on keywords that define specific characteristics. Companies can easily rank candidates by analyzing their resumes with minimal mistakes and then qualifying for them for the next phrase in seconds. </p>
<h2><strong>Streamlines Sophisticated Processes</strong></h2>
<p>Businesses and organizations such as accounting firms and law offices have extensive amounts of contractual and legal documents that need reviewing before proceeding with a partnership or solving a legal case. </p>
<p>Searching manually through these documents for specific decisive phrases is not only tiresome but risky since the human eye is prone to loss of focus. A trained chatbot tailored for accounting or legal professionals powered by NLP can identify such phrases in under a few minutes. Thus, streamlining the contracts review and creation process while staff members work on tasks that can’t be automated. </p>
<figure class=""wp-block-image""><img src=""https://lh5.googleusercontent.com/OCP6On2DgYPm4pqj4C9nFv40XE_X38kWfoAkr3dT0JrEciRviQr_DaKRTa60Wd8v1ArXeGcN8xTKt5yolJNA9Ucyhc3TQNDXMoDDxlH9mCBKRSbJIymBxX2ec8MDmYX2BVK8Ne7M"" alt="""" /><br />
<figcaption><strong><a href=""https://monkeylearn.com/natural-language-processing/"">Source</a></strong></figcaption>
</figure>
<h2><strong>Enhances Customer Experience</strong></h2>
<p>Large artificial intelligence systems are capable of retrieving data fast which helps in providing customers with answers on time. Trained chatbots answer predictable questions from customers regarding shipping costs, business hours, or other service details, eliminating the need to wait in a chat line or communicate through email.  </p>
<p>Nevertheless, natural language processing accomplishes more than replying to queries with automated responses. It also has the capability to analyze customer responses and notice the sentiment in them, especially when analyzing reviews. </p>
<p>The hospitality sector, which relies on reviews and surveys for enhancing customer experience, can identify users' emotions using trained algorithms. NLP solutions analyze patterns found in these reviews to find the conveyed emotions. Negative words such as “I’m tired”, ”I hate” could be the start of negative feedback, and so on. </p>
<h2><strong>Empowers Employees in Their Work</strong></h2>
<p>Numerous repetitive tasks can be eliminated by making use of NLP. Employees could automate most of their tedious processes and work on engaging and productive high-level tasks, increasing efficiency dramatically. </p>
<p><a href=""https://blueorange.digital/automate-customer-service-with-chatbots/"">Chatbots</a> could check several sources at once and elicit the essential data sets required for employees to answer queries or solve tasks. This makes the work process autonomous and independent and employees are more satisfied and deliver impeccable results, which elevates your company's reputation.</p>
<h2><strong>Lowers Expenses</strong></h2>
<p>Increased efficiency means fewer manual processes, and less employees needed. An NLP solution reduces the need for more people to deal with manual work, together with potential mistakes. Whether tasked with data analysis or responding to clients’ queries, an NLP solution automates many costly operations. </p>
<p>Reducing repetitive tasks and streamlining processes frees time for employees to work on other tasks which gets more work done. Productive employees are prompt to stay longer in their workplace, lowering the hiring costs for new staff as well.</p>
<h2><strong>Final Thoughts</strong></h2>
<p>Implementing an NLP solution can greatly impact a business for good, but this shouldn’t be an instant decision. An organization needs to ensure that it is equipped with the proper resources and volumes of data required to feed the algorithms, and have employees ready to embrace this change. </p>
<p>Generally, natural language processing could be integrated for both small and large businesses dealing with ample voice or text information analysis. Analyzing data effectively is fundamental for businesses to step ahead of their competitors. If you’re in the search of an NLP solution, our Blue Orange Digital experts are prepared to provide a project roadmap for your business! Schedule your free consultation <a href=""https://blueorange.digital/contact-us/"">here</a>. </p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/NLP-for-Business-Blog-Post-Cover.png,NLP-for-Business-Blog-Post-Cover.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/NLP-for-Business-Blog-Post-Cover.png,3645,NLP-for-Business-Blog-Post-Cover,,,,https://blueorange.digital/wp-content/uploads/2022/05/NLP-for-Business-Blog-Post-Cover.png,,,,,,,,
3592,"6 Benefits of Using Optical Character Recognition (OCR) to Increase Business Efficiency","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Moving files and documents from one format to the other is necessary during business transactions, deals, or project management. Occasionally, we find JPEG, PNG, or PDF formats pretty practical for sending and saving written content, but what about processing this material, editing, and reading it through machine programs?</p>
<p>As the world moves towards a paperless future, digitizing written content for the data to be stored and available for <a href=""https://blueorange.digital/services/#transformation"">analysis </a>is mandatory. Traditionally, this was done through transcription which requires time as a process and it results in increased costs.</p>
<p>Optical Character Recognition (OCR) has facilitated this process immensely for both businesses and individuals. OCR is a software capable of scanning images of printed, handwritten, or typed text and converting it into editable content.</p>
<p>Today, we’re going over six main reasons why this technology can improve the efficiency of your business. The industry makes no difference as long as the essence of the task is <a href=""https://blueorange.digital/information-extraction/"">extracting information</a> from uncopyable formats and working with them.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Streamlined Data Entry with Minimal Mistakes</strong></h2>
<p>Having employees manually do the process of data entry to retrieve important information from documents and files is time-consuming and comes with high probability of error. Considering that as humans we’re constantly led by emotions, our attention shifts could cause us to forget details, make typos, or misfile documents.</p>
<p>By using OCR software, you’re cutting down costs significantly since you’re not paying more employees to revise these tasks manually to fix mistakes but have them work on more important tasks instead. The potential to make mistakes is reduced thanks to intelligent algorithms.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/P4aL_F8DKGOo4su50oo3yQ8ifCGFnXAlaAQtGn5uyBQRf1lj75_hCjULnCxECjlAOrfPqDpEdTEnubI7swYS9gZBI9nPSVY8JK5m3FS6BHQQg-LzO0lvkVj0Pyu890TTmU-9g0Vb"" alt="""" /><br />
<figcaption><strong><a href=""https://assets.laserfiche.com/_images/OCR_blog_explained_web.jpg"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Enhanced Searchability and Editing Capabilities</h2>
<p>Searchability is crucial when working with vast amounts of data. You might have an archived report with hundreds of pages that holds important data for your customers or business performance. Finding this information by scrolling and manually checking each file for specific data may take forever. OCR offers the option to search through content by using keywords.</p>
<p>Simply type the respective keywords on the Document Management System (DMS) and locate what you were searching for. This reduces the time spent conducting successful and accurate analysis and finding information to answer customer service queries. Gone are the days of transcribing printed documents since OCR helps you turn files into Word, HTML, or Excel formats in minutes. Then, you can easily edit typos or copy-paste information.</p>
<h2>Time Efficient and Effortless Management</h2>
<p>OCR is not only valuable for converting documents into editable formats and having them sit on folders passively. Combined with other tools, businesses can <a href=""https://blueorange.digital/bold-nlp-and-ocr-use-cases/"">utilize OCR</a> for automating workflows.</p>
<p>For instance, DMS programs can be instructed to identify types of files, such as invoices, and direct them towards the respective people responsible for processing them (in this case, the accounts payable manager). This minimizes delays in business operations significantly.</p>
<h2><strong>Reduced Employee and Material Costs</strong></h2>
<p>Incorporating OCR technology in your daily processes reduces costs in measurable ways. Initially, you need fewer employees since there will be less paperwork and manual data entry to be done. There will be no more training costs either.</p>
<p>Secondly, scanning documents and turning them into digital file formats means that there won’t be a need for spending on paper materials, and the processes related to working on it, such as copying, printing, and distribution. Also, there’s no more need for spacious and expensive file cabinets to store and organize these files.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh3.googleusercontent.com/8mCujLqXF_gh_qcDjhyCUGINNnmQblySegx-FvfK5E8jiUPVoWtP4FXKdm4RT5yIRuwjyvn1wStQ_at7_U2cXXGAxwZ0qI-RsZjkvnj3unCIaWzTGSfy_5yP8S4g-dBS7t3UHGtz"" alt="""" /><br />
<figcaption><strong><a href=""https://nanonets.com/blog/content/images/2019/11/OCR.jpg"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Increased Assets Protection</strong></h2>
<p>Storing important data into a physical form such as folders and documents makes them endangered from natural disasters, theft, or destruction. Once all these documents are converted into a digital format, you’re protected from these risks. Backing up your data on the cloud or geo-redundant data centers grants you access to them through the DMS software from any device as long as you have an internet connection.</p>
<p>For those concerned with cyber-attacks and different types of malicious attempts to electronically corrupt this data, extra layers of security with advanced encryptions can be applied to protect it. Implement access restrictions that comply with data regulations such as <a href=""https://www.pcisecuritystandards.org/documents/PCI_DSS-QRG-v3_2_1.pdf"">PCI-DSS</a>, or <a href=""https://aspe.hhs.gov/reports/health-insurance-portability-accountability-act-1996"">HIPPA</a>, and your assets will be safe.</p>
<h2><strong>Happier and More Engaged Employees</strong></h2>
<p>Repetitive processes such as transcription and data entry are boring tasks that challenge employees in an unproductive manner. Such tasks not only might result in misfiled data but can also negatively impact the sanity of your employees. OCR helps you replace these tasks and as a result you have more productive and happy employees that can give the maximum of their potential in other projects, which directly affects business efficiency for the better.</p>
<p>OCR clearly brings numerous benefits to businesses dealing with documents and text-based materials on a daily basis. As this technology advances and integrates with other systems, it can serve for automating both primary and secondary business processes.</p>
<h2><strong>Final Thoughts</strong></h2>
<p>For those who want to contribute to a greener future with minimal investment and decrease their business costs, OCR software is a reasonable solution. Besides cost reductions, it is a solution that produces better documents with minimal errors.</p>
<p>Blue Orange employs data scientists dedicated to increasing your business outcome by using advanced machine learning, artificial intelligence, data transformation, and automation tools. Experienced in developing OCR and other information extraction solutions, we’re here to help. <a href=""https://blueorange.digital/contact-us/"">Schedule </a>a 15-minute call for free today.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Blog-Post-Cover-Images-3-1-1.png,Blog-Post-Cover-Images-3-1-1.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Blog-Post-Cover-Images-3-1-1.png,3636,"Blog-Post-Cover-Images-3 (1)",,,,https://blueorange.digital/wp-content/uploads/2022/05/Blog-Post-Cover-Images-3-1-1.png,,,,,,,,
3593,"Using Snowflake for Building Machine Learning Models","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Machine learning has seen constant developments lately, with startups emerging almost daily into the industry. To serve the growing need for computers to learn from data and perform tasks on their own, machine learning (ML) branches out of the big AI technologies. </p>
<p><a href=""https://pureai.com/articles/2019/07/23/nwsdes-machine-learning-market-growth.aspx"">Reports</a> indicate investments in machine learning will grow from $1.58 billion (2017) to $20.8 around 2023. This is inevitable because ML touches almost all essential sectors, from banking and healthcare to life sciences, government, and retail. </p>
<p>What slows the growth of every emerging startup or existing company that decides to implement AI and more specifically ML practices, stands in finding knowledgeable experts in the field. </p>
<p>However, machine learning tools are lowering the learning curve for data scientists, allowing them to cover more ground from their current position without having to master new technologies. The struggle stands in identifying these ML tools and working with them in data warehouses like <a href=""https://blueorange.digital/build-and-deploy-ml-models-through-sql-with-amazon-sagemaker-autopilot-and-snowflake/"">Snowflake</a> and more. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Identifying Vital Machine Learning Tools</h2>
<p>Machine learning tools resemble <a href=""https://blueorange.digital/predictive-analytics/"">predictive modeling</a> and data mining in theory. They are tools running on artificial intelligence algorithms which share the capability of learning to form independent evaluations after being fed data from the real world. </p>
<p>These tools allow the software to make smarter decisions and predict the outcome of certain processes, without having to program each and every possible scenario. Once the machine learning tools are set up and fed the respective data, we start building ML models that can be applied to real-world applications for solving problems. </p>
<p>Machine learning models find use in different situations. For instance, they can be employed to identify security threats, filter spam, build<a href=""https://blueorange.digital/recommendation-engines/""> recommendation engines</a>, or predict search patterns. Knowing the machine learning tools to use remains crucial for building ML models. </p>
<p>Such tools perform similar functionalities to BI tools or warehousing tools, aiding not only in building ML models but also in portraying detailed analytics and accurate reports. Even though you might notice an overlap between Big Data and ML tools, the latter occupy a more specified space by relying on machine learning frameworks. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h3><strong>Basic Tools</strong></h3>
<p>Programming languages are the initial tools that data scientists should master in order to understand and write efficient algorithms. Some of these languages are R, Java, Python, Javascript, Lisp, and C++, which are commonly practiced by data scientists during their daily work processes. Therefore, minimal learning is required when focusing on ML. </p>
<p>However, companies work with different warehouses and platforms, which might require data scientists to execute extra steps for cleansing and converting data. Since the traditional data warehouses lower the speed at which machine learning processes happen, they usually lead to the complication of data wrangling processes. </p>
<p>Rapid data and machine learning tools grant data scientists the time to spend on perfecting and fine-tuning models until they reach the ideal outcome, instead of staying stuck because of the lack of access to this data. Integrating these tools with one another into a framework facilitates the building of ML models or reports. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img class=""wp-image-3629 size-full aligncenter"" src=""https://blueorange.digital/wp-content/uploads/2022/05/IBTdBZ5Za5F4Pr1Nx6S_2AqlZXbTA-Dbzxdxyjqf_hEaLBXRfckde-uvmxVRPU7NCvieds02K-T1xjIrZFqXIu2vtnDB7MnkPtWUreQES4hYbaAkadD8yUK_IxyjqYTniRJ70z48.png"" alt="""" width=""847"" height=""330"" /><br />
<figcaption><strong>Integrating Snowflake with <a href=""https://ride.citibikenyc.com/system-data"">Citi Bike</a>. <a href=""https://medium.com/snowflake/building-better-machine-learning-models-using-snowflake-data-cloud-25460b7ae85b"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h3><strong>Breaking Down a Machine Learning Framework</strong></h3>
<p>Machine learning frameworks are more or less, interfaces or platforms where data scientists can bring together machine learning tools and develop ML models. Even though they’re used by data scientists, they are optimized for easy use and increased productivity. </p>
<p>The main factor in selecting a suitable machine learning framework for your business revolves around the type of applications you’re developing and the type of data available. The proper machine learning framework intends to free users from sophisticated infrastructure management, while there are others that focus on flexibility and scalability. </p>
<p>When selecting a machine learning framework, know that you’re prompted to find machine learning tools bundled with it. It is crucial to question the use of the framework: will it be for executing classical machine learning or deep learning algorithms? </p>
<p>The advancement of AI has brought the creation of different by-products in ML frameworks. For instance, deep learning frameworks are branching out of the traditional machine learning frameworks because as the name indicates they focus on deep learning models. </p>
<p>Different from machine learning, deep learning focuses on processing unstructured sets of data. As a subfield of machine learning, it goes deeper into <a href=""https://blueorange.digital/cptcasestudies/advanced-sensor-analytics-platform/"">creating models</a> that are based on the actual thought patterns of the human brain. For instance, it builds models that recognize sounds, images, videos, and human faces. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img class=""wp-image-3630 size-full aligncenter"" src=""https://blueorange.digital/wp-content/uploads/2022/05/fyVa-N7UsaVyVmV6YVLPLeboA9PLDYHYhjaEoyNr34KMl65OulmBNSFBU_u75o0FcyijQGbNaAarmjmDDjZRDZuKv9X5lPp0funuJdsFoc-H1kYjk7_wqxXmy338IMDkgvunudSo.png"" alt="""" width=""768"" height=""527"" /><br /><br />
<figcaption><strong>Integrating Snowflake with <a href=""https://ride.citibikenyc.com/system-data"">Citi Bike</a>. <a href=""https://www.ericfrayer.com/2019/11/07/citibike-dataset/""><em>Source</em></a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h3><strong>Snowflake And Machine Learning ToolsReduced Employee and Material Costs</strong> </h3>
<p>As a cloud-computing based data warehousing company, Snowflake is built with artificial intelligence and machine learning applications in mind. At Blue Orange, we have a <a href=""https://blueorange.digital/cptcasestudies/machine-learning-data-transformation-for-performance-management-enterprise-okrs/"">fresh example</a> of integrating Snowflake as a database to support machine learning models for a startup focused on boosting employee engagement. </p>
<p>Besides supporting integrations like Qubole, Spark, Python, and R, Snowflake offers many other features in developing data science solutions. Here are some capabilities of Snowflake that make it ideal for machine learning: </p>
<ul>
<li>High-performance speed (scales up and down seamlessly)</li>
<li>Facilitates the completion of data preparation tasks</li>
<li>Reduces data-related complications from ML tools (e.g the need for retooling data constantly)</li>
<li>Simplification of data for evaluation from non-technical users. </li>
</ul>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h3><strong>Final Thoughts</strong></h3>
<p>Snowflake is a great option for developing machine learning models or producing more accurate business reports and analytics. It works well with most machine learning platforms and provides access to statistical reporting in a simple way by integrating with other ecosystems specialized in this process such as ThoughtSpot or Tableau. </p>
<p>Blue Orange focuses on producing machine learning solutions for companies of different sizes, from startups to enterprises. This leads to a massive increase in performance and cost reductions. Book a 15-minute <a href=""https://blueorange.digital/contact-us/"">free consultation call</a> with our team to learn more. </p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Blog-Post-Cover-Images-3-1.png|https://blueorange.digital/wp-content/uploads/2022/05/IBTdBZ5Za5F4Pr1Nx6S_2AqlZXbTA-Dbzxdxyjqf_hEaLBXRfckde-uvmxVRPU7NCvieds02K-T1xjIrZFqXIu2vtnDB7MnkPtWUreQES4hYbaAkadD8yUK_IxyjqYTniRJ70z48.png|https://blueorange.digital/wp-content/uploads/2022/05/fyVa-N7UsaVyVmV6YVLPLeboA9PLDYHYhjaEoyNr34KMl65OulmBNSFBU_u75o0FcyijQGbNaAarmjmDDjZRDZuKv9X5lPp0funuJdsFoc-H1kYjk7_wqxXmy338IMDkgvunudSo.png,Blog-Post-Cover-Images-3-1.png|IBTdBZ5Za5F4Pr1Nx6S_2AqlZXbTA-Dbzxdxyjqf_hEaLBXRfckde-uvmxVRPU7NCvieds02K-T1xjIrZFqXIu2vtnDB7MnkPtWUreQES4hYbaAkadD8yUK_IxyjqYTniRJ70z48.png|fyVa-N7UsaVyVmV6YVLPLeboA9PLDYHYhjaEoyNr34KMl65OulmBNSFBU_u75o0FcyijQGbNaAarmjmDDjZRDZuKv9X5lPp0funuJdsFoc-H1kYjk7_wqxXmy338IMDkgvunudSo.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Blog-Post-Cover-Images-3-1.png|/www/blueorangem_500/public/wp-content/uploads/2022/05/IBTdBZ5Za5F4Pr1Nx6S_2AqlZXbTA-Dbzxdxyjqf_hEaLBXRfckde-uvmxVRPU7NCvieds02K-T1xjIrZFqXIu2vtnDB7MnkPtWUreQES4hYbaAkadD8yUK_IxyjqYTniRJ70z48.png|/www/blueorangem_500/public/wp-content/uploads/2022/05/fyVa-N7UsaVyVmV6YVLPLeboA9PLDYHYhjaEoyNr34KMl65OulmBNSFBU_u75o0FcyijQGbNaAarmjmDDjZRDZuKv9X5lPp0funuJdsFoc-H1kYjk7_wqxXmy338IMDkgvunudSo.png,3628|3629|3630,Blog-Post-Cover-Images-3-1|IBTdBZ5Za5F4Pr1Nx6S_2AqlZXbTA-Dbzxdxyjqf_hEaLBXRfckde-uvmxVRPU7NCvieds02K-T1xjIrZFqXIu2vtnDB7MnkPtWUreQES4hYbaAkadD8yUK_IxyjqYTniRJ70z48|fyVa-N7UsaVyVmV6YVLPLeboA9PLDYHYhjaEoyNr34KMl65OulmBNSFBU_u75o0FcyijQGbNaAarmjmDDjZRDZuKv9X5lPp0funuJdsFoc-H1kYjk7_wqxXmy338IMDkgvunudSo,||,||,||,https://blueorange.digital/wp-content/uploads/2022/05/Blog-Post-Cover-Images-3-1.png,,,,,,,,
3594,"Blue Orange named a Top AI Development Partner 2020","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Blue Orange Proud to be Named a Top AI Development Partner in New York by Clutch!</p>
<p>Here at Blue Orange, we know it can be taxing and strenuous for any new business to balance <a href=""https://blueorange.digital/is-machine-learning-the-right-solution/"">high impact AI development</a> while bouncing back from a weak financial quarter. That’s why we’re here to help! We’re a data science and machine learning consulting agency with a wealth of experience in finance, marketing automation, and sales enablement. Whether you need a cloud-based solution or robotic process automation, we’re here to deliver! </p>
<p>In light of our impact and dedication, we’ve been named a top artificial intelligence development partner in New York by Clutch, <a href=""https://clutch.co/developers/artificial-intelligence/new-york"">a B2B services marketplace</a>! Clutch uses a one of a kind reviews-based research methodology to compare and contrast leaders in a number of service sectors. </p>
<blockquote class=""wp-block-quote is-style-large""><p><em>""We are honored that our focus and ability to deliver consistently designates us as a leading Artificial Intelligence Consulting and Development Firm."" </em></p>
<p><cite>–Josh Miramant, CEO Blue Orange Digital</cite></p></blockquote>
<p>Our clients were instrumental in helping us earn this award. They took time to get on the phone with Clutch for 15 minutes and review our work. We were graded in areas like quality, attention to project timelines, and overall project management ability. Take a look at what one of our clients had to say in their five-star review below:</p>
<div class=""wp-block-image"">
<figure class=""alignright is-resized""><img class=""wp-image-6070"" src=""https://blueorange.digital/wp-content/uploads/2020/10/Clutch-Badge-White.png"" alt="""" width=""134"" height=""134"" /><br />
<figcaption>5-Star Review</figcaption>
</figure>
</div>
<blockquote class=""wp-block-quote""><p><em>“We had really good communication with their CEO and CTO throughout the project via phone and email. They were both very personally committed to making sure that we were successful and made sure that we were constantly staffed with the most qualified resources that we possibly could be to stay on top of all of our milestones for the development. They are truly committed to technical excellence and, beyond simply providing what is required of them, doing everything they can to make your project successful.” </em></p>
<p><cite>– CEO, AI Company </cite></p></blockquote>
<p>Interested in learning more about how Blue Orange can help your business exceed its own benchmarks for success? <a href=""https://blueorange.digital/contact-us/"">Drop us a line</a> today! </p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Top-AI-Development-Partner-2020-announcement-1.png,Top-AI-Development-Partner-2020-announcement-1.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Top-AI-Development-Partner-2020-announcement-1.png,3619,Top-AI-Development-Partner-2020-announcement-1,,,,https://blueorange.digital/wp-content/uploads/2022/05/Top-AI-Development-Partner-2020-announcement-1.png,,,,,,,,
3595,"AI In The Shipping Industry","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Artificial Intelligence has been re-shaping the world as we know it. Not in the way that we saw in the famous movie the Terminator (SkyNet is not going to take over your phone) but it has transformed our everyday lives by improving processes that we perform regularly. The same holds true for the shipping industry. AI has enabled the implementation of IoT devices that gather information that the AI can learn from, improve upon, and make automated decisions. Automation may be the biggest and most beneficial way AI is used in shipping because it enables anomaly detection, reduction in waste, improved quality control, and decreased shipping times. The combination of IoT devices and AI has brought unparalleled improvements to quality control, fuel consumption, and safety. </p>
<p>One example of how AI is aiding the shipping industry is how it improves quality control. With the installation of cameras and IoT devices in cargo containers shipping companies can monitor the environment of goods to prevent damage and spoiling. This is very prevalent in the food transport industry. AI monitors data received from cameras and IoT devices about data points such as temperature, humidity, shock(fall), light exposure, and even vibration. This provides a richer bank of information on the quality of goods not only at the beginning and end of transport but during. Through automated alerts and solution suggestions shipping companies can adjust containers to remedy problems in real-time and prevent the waste or degradation of goods.</p>
<p>Artificial Intelligence is also allowing shipping companies to manage their fuel consumption and utilize the most efficient shipping routes. The accurate monitoring of how fuel is being used leads to a reduction in fuel spend and brings environmental benefits by decreasing emissions. AI is also being used to improve the physical routes that shipping companies take. Based on historical data on weather patterns like water and wind currents, traffic through certain areas and ports; shipping companies can plan routes that leverage all of this information to reduce fuel consumption and reduce trip times. </p>
<p>Lastly, AI can be used to improve safety by monitoring ship systems and the environment around the ship. An example is a ship image recognition system being developed by tech company SenseTime and Japanese shipping firm Mitsui OSK Lines (MOL). They are developing an image recognition system to identify ships in the surrounding area and monitor shipping lanes. This makes transport within bays, from entering to departing ports, much safer, not only for your ship but the surrounding ships as well. </p>
<p>The advent of cheaper and faster computing power, combined with the improvements in the accuracy and efficiency of AI models has brought about a lot of improvements to the shipping industry. Reduction in waste, efficient fuel consumption, and improved safety features are just a few of the ways the shipping industry is becoming faster, safer, and more efficient in the present and future. </p>
<p>About the Author: Josh Miramant, CEO Blue Orange Digital, <a href=""https://blueorange.digital/josh-miramant-presskit/"">Presskit and Bio</a></p>
<p>Image Credit: Intel</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/intel-digital-container.jpg,intel-digital-container.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/intel-digital-container.jpg,3623,intel-digital-container,,,,https://blueorange.digital/wp-content/uploads/2022/05/intel-digital-container.jpg,,,,,,,,
3596,"3 Reasons Why Your Company Needs a Recommendation Engine","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<blockquote class=""wp-block-quote"">
<p>We are willing victims to the power of recommendation engines, but harnessing one is not an instant download, yet. Here's why you need one and how to get it.</p>
</blockquote>
<p>Without fail, we can't talk about recommendation engines without acknowledging the brilliance of Youtube and Netflix– their recommendation engines are a renowned technique to keep customers engaged and subscribing month after month. Now mimics everywhere make the hot claim to associative-fame saying, ""like Youtube for {insert industry x}."" They started a revolution, but despite the number of years we've all been willing victims to their power, the advanced algorithms are not quite an instant download that you can apply to your own company yet.</p>
<p>In this article, we'll lay out some interesting ways recommendation engines are being used and how you can get your hands around the reigns of your own. Beyond the widely used applications of recommendation engines to convert more sales and improve customer retention, we'll show you even more ways you can make money. We've deduced the benefits and recommend these 3 reasons why your company needs a recommendation engine now.</p>
<h2>1. Highly personalized product recommendations</h2>
<p>This is the best-known use case for product recommendations. If you have a large number of products or an e-commerce website, make product recommendations your focus. You’ve seen it on Amazon, Netflix, and other consumer websites. In B2B sales, a product recommendation engine is also useful because it can provide upsell suggestions for your sales representatives.</p>
<h2>2. Optimized Customer Loyalty Programs</h2>
<p>According to the 80/20 principle, a minority of your customers will account for a large amount of your sales. These highly engaged customers deserve special treatment, so they keep buying and referring more customers to you. Use a recommendation engine to identify your highly engaged customers and give them special offers and rewards. For instance, instead of offering every customer a 10% off coupon for Black Friday, offer something personalized (e.g., “get a 2 for one offer on all the products you’ve purchased in the past six months”) to your loyal customers.</p>
<h2>3. Tailored advertising</h2>
<p>In digital advertising, you have the chance to test many different advertising messages. When you have hundreds or thousands of online ads running, identifying winners becomes difficult. That’s where a recommendation engine can help you. For example, Google Ads includes a recommendation engine that provides suggestions on ways to get more traffic by increasing bids.</p>
<h2>Case Studies: </h2>
<h3>On-screen Retail Product Detection and Recommendations</h3>
<p><a href=""https://aibuy.io/"">AiBUY</a> is an onscreen shopping tool that utilizes computer vision to recognize products within images and videos, in real-time. Currently, they are focusing on the onscreen detection of fashion items and embedding the shopping tool to enable immediate purchase without being redirected or leaving the screen. A user would simply be watching their favorite content when the AiBUY shopping tool would prompt the viewer with purchasing the items in view.</p>
<p>During an interview with AiBUY’s CTO, Ryan C. Scott, he explained how it works, saying, “Firstly the focus was on detecting a person and their gender. Secondarily adding various other classes e.g. if a woman, then dresses, blouses, etc,” similar to nested categories on most fashion sites. The detected images are then searched within a given retailer’s integrated catalog and the most relevant products are recommended. Scott explains, “By integrating directly with the retailer’s eCommerce platform, we import and synchronize the product information and ensure data like inventory levels and product variance selections are maintained.” Noting one of the latest improvements was “the use of the Annoy library(by Spotify) to improve the performance functionality in searches of nearest neighbors for product classification.” Nonetheless, as Scott humbly remarks “we are always reviewing our codebase to find potential bottlenecks so we can continuously evolve and adapt to the ever-changing outer world.”</p>
<p>Scott continues with more exclusive behind the scenes on how they built it, saying, “The AiBUY system is based on a TensorFlow framework and uses Python as the main language. The <a href=""https://datafloq.com/learn/#utm=internal"">training</a> dataset holds about 400,000 images with excellent categorical markup, aggregated and prepared with the help of scripts, supplemented by 1,200,000 images of mixed or poor categorical markup quality from external Affiliate Network companies.” From this rigorous model training, their system is able to recognize clothing worn in your favorite shows, but instead of recommending the next show, it'll show you where you can buy that swimsuit or other recommended options instantly. </p>
<p><img class=""wp-image-3613 alignnone size-full"" src=""https://blueorange.digital/wp-content/uploads/2022/05/Screen-Shot-2020-07-07-at-8.44.39-PM-1024x638-1.png"" alt="""" width=""1024"" height=""638"" /></p>
<figure class=""wp-block-image"">
<figcaption>AiBUY: Powering Shoppable Video Everywhere</figcaption>
</figure>
<h2>Digital Transformation of Government Documents</h2>
<p><a href=""https://govzilla.com/"">Govzilla</a> is a leading data processing company using <a href=""https://datafloq.com/read/?q=Big%20data#utm=internal"">Big Data</a> and AI to make government data accessible, usable, and valuable to top pharma companies, food manufacturers, medical device companies, and service firms from around the globe. Their system ingests regulatory documents, automatically tags the content to make it accessible, and adds recommended content for researchers as they look for side-effects to drugs, track compliance to FDA regulations, or simply want to look for trends in data.</p>
<p>Govzilla partnered with <a href=""https://blueorange.digital/cptcasestudies/digital-transformation-of-government-documents/"">Blue Orange Digital</a>, a top-ranked AI development agency, to accomplish this goal. They started by replacing manual, outsourced data scrapers with advanced automated ingestion <a href=""https://datafloq.com/work/#utm=internal"">jobs</a> to improve accuracy, scalability, and efficiency.</p>
<p>Then evolved the traditional rule-based text extraction system by incorporating leading <a href=""https://blueorange.digital/bold-nlp-and-ocr-use-cases/"">Natural Language Processing (NLP) and Optical Character Recognition(OCR) tools</a>. Once the system had the ability to 'read' and 'understand' the documents, next it needed to file them, and yes, they trained it to do that too. They were able to determine the topics, context, industry, +millions of other categorical tags, and automated the classification of each document along with a range of post-data parsing jobs. Parsing ranged from simple string matching to complex NLP applications including topic modeling, keyword extraction, and semantic understanding. <a href=""https://blueorange.digital/robotic-process-automation/"">Robotic Process Automation(RPA)</a> was then used to route, store, and index data files throughout advanced ETL jobs. This incredible process managed to move and create a file system while indexing data for quick searches and retrieval automatically.</p>
<p>The result was an expertly trained <a href=""https://datafloq.com/read/?q=Machine%20learning#utm=internal"">machine learning</a> model that attempts to replicate, accelerate, and improve the regulatory review process. The model's inputs and outputs were trained, edited, and audited by industry experts, with years of experience, mimicking their own expertise and critical eye. These automated models are able to correctly parse and identify key terms in documents within a few minutes.</p>
<p>Using this technology, Govzilla will be able ""to quantify risk signals about their suppliers, identify market opportunities, benchmark against their peers, and to prepare for the latest inspection trends."" They will be the first to create an objective method for keyword analysis within regulatory deficiency documents. The NLP-driven expert tagging system resulted in the ability to accurately evaluate documents in a few minutes that used to take the human experts multiple hours. The re-engineered data pipeline increased the model accuracy improving the classification and recommended content. Now researchers can spend their time more effectively on finding answers, holding industries accountable, and keeping our society safe and healthy.</p>
<figure class=""wp-block-image""><img class=""wp-image-3614 alignnone size-full"" src=""https://blueorange.digital/wp-content/uploads/2022/05/Screen-Shot-2020-07-07-at-8.37.47-PM-1024x622-1.png"" alt="""" width=""1024"" height=""622"" /><br /><br />
<figcaption>Govzilla: Less Searching, Know More</figcaption>
</figure>
<h1>Other Uses Cases:</h1>
<ul>
<li><strong>Insurance:</strong> Recommends associated products/services, like insurance, with recent purchases of new homes and cars.</li>
<li><strong>Private Equity:</strong> Recommends the best investments after ranking all leads.</li>
<li><strong>Real Estate:</strong> Recommends other houses for sale based on search criteria and viewing history.</li>
<li><strong>Marketing:</strong> Recommends personalized offers based on search history(can also suggest the best follow-up method to convert the sale).</li>
<li><strong>Customer Service:</strong> Recommends the correct department for processing reviews, calls, and issues, based on the detected sentiment.
<ul>
<li>more advanced: use this model in a chatbot to cut down on expenses.</li>
</ul>
</li>
<li><strong>Food Delivery:</strong> Recommends other restaurants or food items and sends timely offers.
<ul>
<li>more advanced: predicts the acceptance rate of offers and balances the delivery demand with customer satisfaction.</li>
</ul>
</li>
<li><strong>Retail: </strong>Recommends products, predicts campaign success and reports supply chain demands.</li>
<li><strong>Entertainment:</strong> Recommends related articles on a popular magazine’s website.</li>
<li><strong>User-generated content:</strong> Recommends categories to organize the topics properly via keyword matching.
<ul>
<li>more advanced: automates this process.</li>
<li>more advanced: beyond keywords, understand phrases, and context with NLP.</li>
</ul>
</li>
<li><strong>Pharma-Forum Monitoring:</strong> Recommends content based on their searches, statements, and questions posed.
<ul>
<li>more advanced: Tag critical information to inform drug companies of noticed correlations of side effects.</li>
</ul>
</li>
<li><strong>Finance: </strong>Recommends the best loan provider for a homeowner's or broker's location and situation.</li>
<li><strong>Cooking:</strong> Recommends recipes based on ingredients, best reviews, and previous recipe viewing history.</li>
<li><strong>Automotive:</strong> Recommends the best car for a given user. Could also recommend service/parts for described issues through a chatbot.</li>
<li><strong>E-learning: </strong>Recommends courses and content based on the user's viewing history, level, and goal.</li>
<li><strong>Business Intelligence:</strong> Recommends visuals for given data inputs through Smart Dashboards.</li>
<li><strong>Health and Wellness:</strong> Recommends personalized exercise videos, recipes, and content.</li>
<li>See more <a href=""https://blueorange.digital/cptcasestudies/"">Case Studies</a></li>
</ul>
<h2>The Fast Way To Bring Recommendation Engines To Your Company</h2>
<p>Developing a recommendation engine takes data expertise. Your internal IT team may not have the capacity to build this out. If you want to get the customer retention and efficiency benefits of recommendation engines, you don’t have to wait for IT to become less busy. You can partner with a co-development firm, like <a href=""https://blueorange.digital/"">Blue Orange Digital</a>, a top-rank AI consulting and development agency, to bring results faster and with less investment.</p>
<p>Article originally published on<a href=""https://datafloq.com/read/3-reasons-why-your-company-needs-recommendation-engines/8689""> Datafloq.com</a></p>
<h2>About the Author</h2>
<p><img class=""wp-image-5323 alignleft"" src=""https://blueorange.digital/wp-content/uploads/2020/05/Josh-Miramant-CEOpng-1024x1024.png"" alt=""Josh Miramant- CEO Blue Orange Digital"" width=""285"" height=""285"" data-id=""5323"" data-link=""https://blueorange.digital/josh-miramant-presskit/josh-miramant-ceopng/"" />
<p>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for <a href=""/cptcasestudies/supply-chain-revenue-predictions-for-pharmaceuticals/"">Supply Chain</a>, <a href=""/cptcasestudies/digital-transformation-of-government-documents/"">Healthcare Document Automation</a>, and <a href=""https://blueorange.digital/cptcasestudies/"">more</a>.</p>
<p>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He is a serial entrepreneur and software engineer that has built and scaled 3 startups.</p>
<p>He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things. </p>
<p>Featured on IBM ThinkLeaders, Dell Technologies, and NYC’s Top 10 AI Development and Custom Software Development Agencies as reviewed on Clutch and YahooFinance for his contributions to NLP, AI, and Machine Learning. Specializing in predictive maintenance, unified data lakes, supply chain/grid/marketing/sales optimization, anomaly detection, recommendation systems, among other ML solutions for a multitude of industries.  </p>
<p>Visit <a href=""https://blueorange.digital/"">blueorange.digital</a> for more information and <a href=""/case-studies/"">Case Studies</a>.</p>
<p><em>Follow me on </em><a href=""https://twitter.com/BlueOrangeData""><em>Twitter</em></a><em> or </em><a href=""https://www.linkedin.com/in/joshmiramant/""><em>LinkedIn</em></a><em>. Check out my </em><a href=""https://blueorange.digital/""><em>website</em></a><em>. </em></p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Case-Study-Bulk-Cover-Photos-2.gif|https://blueorange.digital/wp-content/uploads/2022/05/Screen-Shot-2020-07-07-at-8.44.39-PM-1024x638-1.png|https://blueorange.digital/wp-content/uploads/2022/05/Screen-Shot-2020-07-07-at-8.37.47-PM-1024x622-1.png,Case-Study-Bulk-Cover-Photos-2.gif|Screen-Shot-2020-07-07-at-8.44.39-PM-1024x638-1.png|Screen-Shot-2020-07-07-at-8.37.47-PM-1024x622-1.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Case-Study-Bulk-Cover-Photos-2.gif|/www/blueorangem_500/public/wp-content/uploads/2022/05/Screen-Shot-2020-07-07-at-8.44.39-PM-1024x638-1.png|/www/blueorangem_500/public/wp-content/uploads/2022/05/Screen-Shot-2020-07-07-at-8.37.47-PM-1024x622-1.png,3612|3613|3614,Case-Study-Bulk-Cover-Photos-2|Screen-Shot-2020-07-07-at-8.44.39-PM-1024x638|Screen-Shot-2020-07-07-at-8.37.47-PM-1024x622,||,||,||,https://blueorange.digital/wp-content/uploads/2022/05/Case-Study-Bulk-Cover-Photos-2.gif,,,,,,,,
3597,"IBM thinkLeaders podcast Features Blue Orange Digital CEO Josh Miramant on AI to Improve Employee Experiences","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<h2>Having AI &amp; humans work in tandem to improve employee experiences feat. Josh Miramant &amp; Joe Ciuffo</h2>
<figure class=""wp-block-image""><img class=""wp-image-3607  aligncenter"" src=""https://blueorange.digital/wp-content/uploads/2022/05/Screen-Shot-2020-02-14-at-5.04.20-PM-1024x413-1.png"" alt="""" /><br />
<figcaption>IBM thinkLeaders with Josh Miramant</figcaption>
</figure>
<p>How can AI better serve as a companion for employees to improve efficiency and quality? Are companies applying AI to the right problems? How has the narrative around AI changed in recent years?</p>
<p>In this episode of IBM thinkLeaders podcast, we are joined by guests Josh Miramant (CEO of Blue Orange Digital) &amp; Joe Ciuffo (Product Marketing Director for Genesys). We talk to Josh and Joe about using AI to improve the employee experience, focusing on core problems with AI, getting employee buy-in by better explaining its benefits, and also how society's impression of AI has gone from the threatening Terminator to the helpful Pokemon.</p>
<p>Hosted by Amanda Thurston &amp; Emily Winchurch.</p>
<blockquote class=""wp-block-quote""><p>""The actual adoption of successful artificial intelligence is directly related to how people understand it and use it.""</p>
<p><cite>-Josh Miramant, CEO of Blue Orange Digital</cite></p>
</blockquote>
<blockquote class=""wp-block-quote""><p>""I think we first saw it [AI] maybe as Terminator, everyone was afraid it was going to take over the world. And now it's more like a cute Pokemon. It's there to help you. So it's been a good transition, but I think our expectations are getting more realistic and grounded too.""</p>
<p><cite>-Joe Ciuffo, Product Marketing Director for Genesys</cite></p>
</blockquote>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/IBM-thinkLeaders-podcast-Features-Blue-Orange-Digital-CEO-Josh-Miramant-on-AI-to-Improve-Employee-Experiences.png|https://blueorange.digital/wp-content/uploads/2022/05/Screen-Shot-2020-02-14-at-5.04.20-PM-1024x413-1.png,IBM-thinkLeaders-podcast-Features-Blue-Orange-Digital-CEO-Josh-Miramant-on-AI-to-Improve-Employee-Experiences.png|Screen-Shot-2020-02-14-at-5.04.20-PM-1024x413-1.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/IBM-thinkLeaders-podcast-Features-Blue-Orange-Digital-CEO-Josh-Miramant-on-AI-to-Improve-Employee-Experiences.png|/www/blueorangem_500/public/wp-content/uploads/2022/05/Screen-Shot-2020-02-14-at-5.04.20-PM-1024x413-1.png,3606|3607,IBM-thinkLeaders-podcast-Features-Blue-Orange-Digital-CEO-Josh-Miramant-on-AI-to-Improve-Employee-Experiences|Screen-Shot-2020-02-14-at-5.04.20-PM-1024x413,|,|,|,https://blueorange.digital/wp-content/uploads/2022/05/IBM-thinkLeaders-podcast-Features-Blue-Orange-Digital-CEO-Josh-Miramant-on-AI-to-Improve-Employee-Experiences.png,,,,,,,,
3598,"How can AI be harnessed to help us with Covid?","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2><strong>Can AI help spot infections before they become epidemics? </strong></h2>
AI-based solutions are being used to detect outbreaks of infectious diseases around the world. To illustrate, <a href=""https://healthmap.org/en/"">HealthMap</a> and <a href=""https://bluedot.global/"">BlueDot</a> are two platforms that were early reporters of the unusually high number of pneumonia cases in Wuhan, at the end of December 2019. Such tools rely on advanced analytics and Natural Language Processing techniques to process real-time information spreading in the online world. By mining various sources of information such as online news sources, official medical reports, tweets, google queries, and even blogs and chat rooms, they can detect significant disease events.

Being able to label such events as signs of emerging epidemics is an effort for which both algorithms and human expertise are needed. The AI tools give medical experts a head start in the right direction. This is a powerful way to leverage real-time data and enable early prevention measures. And early prevention saves lives!
<h2><strong>Can AI be used to track epidemics before they become pandemics?</strong></h2>
Let us continue with the example of the coronavirus epidemic. With confirmed cases first centered around a specific country, tools are needed to be able to track and monitor the spread of the disease across the world. But since humans are unpredictable beings that like to roam freely, forecasting where the virus will hit next is not an easy task. AI-based solutions (such as<a href=""http://metabiota.com/epidemic-tracker""> Metabiota</a>) deal with air-travel data, real-time diagnosis information from across the world and hospital admission reports. Analyzing data coming from such a variety of sources is something that advanced predictive tools are designed for. This makes it possible to obtain accurate real-time insights (such as prediction of cities on the virus trajectory).

But again, expert knowledge is needed to augment the information provided by the AI systems. Having the capacity to exploit epidemic data and to extract insights is just the first step. Thanks to AI tools, health and government officials have accurate insights available for better decision making.
<h2><strong>Can AI help aid workers get supplies to where they’re most needed?</strong></h2>
The real-time capacities of AI models gained them some attention in crisis response and management solutions. For example, the Qatar Computing Research Institute has an entire<a href=""https://crisiscomputing.qcri.org/""> Crisis Computing</a> team tasked with finding modern solutions to humanitarian emergencies. By combining Natural Language Processing and Computer Vision techniques, they analyze social media in order to develop situational awareness models. The integration of multiple analysis methods is needed in order to account for the variety of data sources and formats available. This provides relief organizations with 24/7 support and the opportunity to better target their response efforts.

<a href=""https://www.microsoft.com/en-us/ai/ai-for-humanitarian-action"">Microsoft’s AI for Humanitarian Action</a> program is another example of how technology and human expertise can come together to solve pressing issues around the world. When data modeling tools and AI algorithms are widely available, preventing devastating consequences becomes possible.
<h2><strong>How can AI be harnessed to help us with Covid (or future catastrophic events)?</strong></h2>
AI tools have a proven track record in medical use cases. There are two main directions in which AI superpowers have been historically leveraged against diseases: diagnosis and treatment.

Deep learning solutions are commonly used in medical imaging since they can identify radiographic changes in X-ray scans and CT images. When enough training data is available, they can identify specific radiographic features and correlate them with signs of disease. Such tools can assist medical staff on the time-consuming and error-prone task of patient screening.

For the purpose of developing treatment, AI tools have been successfully used for drug discovery. They are able to generate large numbers of molecular structures and search for the one best fitting for a potential vaccine. By leveraging existing molecular structures from similar viral diseases, the expensive process of creating vaccines could be drastically improved.

As of today, a number of research works are using AI tools for tackling diagnosis (<a href=""https://www.medrxiv.org/content/10.1101/2020.02.14.20023028v3"">here</a>,<a href=""https://www.medrxiv.org/content/10.1101/2020.02.25.20021568v2""> here</a>, <a href=""https://arxiv.org/abs/2003.05037"">here</a> and<a href=""https://www.alizila.com/how-damo-academys-ai-system-detects-coronavirus-cases/""> here</a>) and vaccine development (<a href=""https://deepmind.com/research/open-source/computational-predictions-of-protein-structures-associated-with-COVID-19"">here</a>) against the novel coronavirus. While most of the works still need to be peer-reviewed and prove their usability, such interest from the research community shows the great potential of using AI for tackling epidemics.
<h4>Case Study:</h4>
For more ways data science can optimize supply chain see our Case Study:

<a href=""https://blueorange.digital/cptcasestudies/supply-chain-revenue-predictions-for-pharmaceuticals/""><img class=""wp-image-2726 size-medium aligncenter"" src=""https://blueorange.digital/wp-content/uploads/2022/05/Supply-Chain-Revenue-Predictions-for-Pharmaceuticals.png"" alt="""" /></a>
<div class=""wp-block-image"">
<figure class=""aligncenter is-resized"">
<figcaption>Supply Chain &amp; Revenue Predictions for Pharmaceuticals</figcaption>
</figure></div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/how-can-AI-be-used-to-help-with-Covid.png,how-can-AI-be-used-to-help-with-Covid.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/how-can-AI-be-used-to-help-with-Covid.png,3599,how-can-AI-be-used-to-help-with-Covid,,,,https://blueorange.digital/wp-content/uploads/2022/05/how-can-AI-be-used-to-help-with-Covid.png,,,,,,,,
3642,"Partnership Announcement: Oliver Wyman Announces Equity Investment in Blue Orange Digital","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p><a href=""https://www.oliverwyman.com/index.html"">Oliver Wyman</a>, a global management consulting firm, and <a href=""http://Home"" data-wplink-url-error=""true"">Blue Orange Digital</a>, a data science, machine learning, and data visualization firm, have completed a Series A round to bring new levels of data transformation and <a href=""/services/"">modern data stack capabilities</a> to clients.</p>
<p>Blue Orange Digital expertise will be integrated directly into Oliver Wyman projects providing enhanced <a href=""/services/"">data transformation</a> for clients.  By working together, Oliver Wyman and Blue Orange Digital will help clients advance their data governance, update legacy systems, improve backend performance, and provide advanced analytics and insights.</p>
<p><a href=""https://www.linkedin.com/in/joshmiramant/"">Josh Miramant</a>, CEO and founder of Blue Orange Digital, said “Oliver Wyman is a leader in the consulting world and we are proud to partner with them and help deliver data science solutions to their clients.”  To read more about this partnership, you can download the full press release <a href=""/wp-content/uploads/2022/05/Oliver-Wyman-Announces-Strategic-Investment-in-Blue-Orange-Digital.pdf"">here.</a></p>
<p>If you are interested in learning more about how Blue Orange Digital can leverage your data to generate business insights that drive profits, please contact our team to <a href=""/contact-us/"">schedule a free consulting call</a>.  Also, stay up to date with the latest developments in advanced analytics by following us on <a href=""https://www.linkedin.com/company/7972587/admin/"">LinkedIn</a> and <a href=""https://twitter.com/BlueOrangeData"">Twitter</a>.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Partnership-Announcement-Oliver-Wyman-and-Blue-Orange-Digital-3.png,Partnership-Announcement-Oliver-Wyman-and-Blue-Orange-Digital-3.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Partnership-Announcement-Oliver-Wyman-and-Blue-Orange-Digital-3.png,3644,Partnership-Announcement-Oliver-Wyman-and-Blue-Orange-Digital-3,,,,https://blueorange.digital/wp-content/uploads/2022/05/Partnership-Announcement-Oliver-Wyman-and-Blue-Orange-Digital-3.png,,,,,,,,
3659,"Blue Orange Digital Named as One of the Most Reviewed Cloud Consulting Companies in Baltimore","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p><strong>Thank you to our partners and our team for helping us reach this milestone!</strong></p>
<p>In light of our efforts to enable our clients through data analytics solutions, we’re proud to be acknowledged for our work. This year, we’re <a href=""https://themanifest.com/cloud-consulting/companies/baltimore#most-reviewed"">listed as</a> one of the most reviewed cloud consulting companies in Baltimore on <a href=""https://themanifest.com/"">The Manifest</a>!</p>
<p>As a data science and machine learning consulting firm, we always aim to deliver results-oriented solutions that empower businesses in the modern digital world. We were founded on the belief that data has revolutionized how businesses make decisions. To remain competitive, leveraging data is a requisite but not always simple. </p>
<p>We specialize in helping businesses to implement data-driven analytic techniques.  Our team members are passionate Data Engineers, Data Scientists, PhDs, and Visualization experts who put client goals first to provide industry-leading solutions. We always remain focused on implementing cutting-edge technologies to create transformational data solutions for our clients, while prioritizing the development of a caring and dedicated team to make client goals a reality.</p>
<p>For inquiries about our work, don’t hesitate to <a href=""/contact-us/"">contact us</a>!  If you are interested in reading more about our client success stories, head over to our <a href=""/cptcasestudies/"">Case Studies</a> page and for the latest news in the data science industry be sure to check out our <a href=""/blog/"">Blog</a>.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/The-Manifest-Blog-Final.png,The-Manifest-Blog-Final.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/The-Manifest-Blog-Final.png,3666,The-Manifest-Blog-Final,,,,https://blueorange.digital/wp-content/uploads/2022/05/The-Manifest-Blog-Final.png,,,,,,,,
3672,"Itamar Gal, the Director of Engineering, and Will Thomas, Business Development Director, announce Partnership with Blue Orange Digital","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Blue Orange Digital is excited to welcome two of our own, Will Thomas and Itamar Gal, as our agency’s newest partners! Will has been with Blue Orange since 2018 and is an experienced Business and Sales leader working within Data/BI, Cloud QA/QE, Digital Strategy, and Digital Experience. Itamar has been with Blue Orange since 2019 and is a Digital Transformation leader, with expertise in Solution Architecting, Machine Learning, and Robotic Process Automation. </p>
<p>Will started as the first business-side employee during his MBA internship and then became an Account Executive for two years before moving into this new leadership role. He is excited for the opportunity to build out the sales team to meet the growing demand for digital transformation, work with exceptional clients, and establish an awesome company culture!  Will said his favorite part about working for Blue Orange is, “The people. I love my coworkers and have a blast most days. Everyone we work with is brilliant and has a low ego. The challenges of both building a business and solving high-level technical problems drive collaboration and creativity, which attracts high-caliber colleagues and keeps them here.”</p>
<p>Itamar started as a Senior Data Engineer and then spent a year as a Solution Architect before recently working as our Director of Engineering.  He is looking forward to helping to grow our delivery team, discover interesting projects, collaborate with innovative technology companies, and assist our engineers in developing their careers.  Itamar said that what he most enjoys about working at Blue Orange is, “...the culture because we all work together, support each other, and learn from each other. It's a very collaborative environment, which is especially important when working remotely.”</p>
<p>Thank you, Will and Itamar for your contributions to the Blue Orange Team that make us successful in all the work that we do!  </p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Will-and-Itamar-Press-Release-3.png,Will-and-Itamar-Press-Release-3.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Will-and-Itamar-Press-Release-3.png,3674,Will-and-Itamar-Press-Release-3,,,,https://blueorange.digital/wp-content/uploads/2022/05/Will-and-Itamar-Press-Release-3.png,,,,,,,,
3682,"3Pillar Global Partners With AI Solutions Provider Blue Orange Digital","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<h3><em>Leading software development firm and data analytics innovator partner to expand data analytics offerings and deepen client services.</em></h3>
<p>FAIRFAX, VA. –  3Pillar Global, a leading developer of innovative digital products, today announced a new partnership with data science, machine learning, and data visualization firm Blue Orange Digital. Together, they plan to build data and algorithmic-based software products that create new revenue opportunities for Blue Orange and 3Pillar clients.</p>
<p>“This partnership allows 3Pillar Global to combine our award-winning expertise in building data-rich, revenue-generating digital products with Blue Orange Digital's globally-respected experience in data science and machine learning to guide our clients and drive even greater success throughout their digital transformation journey,” said Jennifer Ives, Senior Vice President of Global Partnerships.  </p>
<p>Blue Orange Digital was created to help business leaders make better, data-driven decisions for their companies and their customers. Their team of data scientists and product engineers have created successful enterprise solutions for industry-leading firms. 3Pillar’s partnership will provide new digital product applications for Blue Orange’s data analytics solutions and provide 3Pillar clients access to machine learning capabilities to expand their product development opportunities.</p>
<p>“At Blue Orange Digital, successful AI solutions are the result of broad and complex integrations into well-designed products that improve performance, quality, and safety—ultimately delivering greater business value. This is how 3Pillar’s industry-leading approach to digital solutions enables Blue Orange to integrate intelligent automation, machine learning enhanced products, and advanced predictive analytics,” says <a href=""https://www.linkedin.com/in/joshmiramant/"">Josh Miramant</a>, CEO of Blue Orange Digital.</p>
<p>For more information on 3Pillar Global and their work building software products for digitally-transforming businesses, visit <a href=""https://c212.net/c/link/?t=0&amp;l=en&amp;o=2745045-1&amp;h=963535119&amp;u=https%3A%2F%2Flinkprotect.cudasvc.com%2Furl%3Fa%3Dhttp%253a%252f%252fwww.3pillarglobal.com%26c%3DE%2C1%2ClH5ih5br6Pbc46JbNBNHR1YULQxr4ampBXi_WACyw7euH4u4kL8BrGZvOu97R6H6KncIyAxt03Pd-zu8aIKjF6vQVlwhxQOvV2e3Mrcjgy9-X8A%2C%26typo%3D1&amp;a=www.3pillarglobal.com"">www.3pillarglobal.com</a>.</p>
<h2><strong>About 3Pillar Global</strong></h2>
<p>3Pillar Global builds breakthrough software products that power digital businesses. 3Pillar is an innovative product development partner whose solutions drive rapid revenue, market share, and customer growth for industry leaders like CARFAX, Fortune, and PBS. Leveraging a lean and agile approach, 3Pillar delivers value-generating, digital solutions with specialized product strategy and management, user experience design, as well as software and data engineering expertise across mobile, cloud, and disruptive technologies. Visit <a href=""https://linkprotect.cudasvc.com/url?a=http%3a%2f%2fwww.3pillarglobal.com&amp;c=E,1,YC4LgYYHBjEJ--JooQG1puDUJe5JQVvKuwQj5R4IMzV41XNtnKlmn0llvTKhOAOs8VcH-m7ZxBhCoNCph_ZKqSDSwnx536lS0tI9C7Kwg2BfWQ,,&amp;typo=1"">www.3pillarglobal.com</a> for more information and career opportunities. To learn more about the Product Mindset, visit <a href=""https://linkprotect.cudasvc.com/url?a=http%3a%2f%2fwww.productmindset.com&amp;c=E,1,_zqkHmXo6tAqVVRir1gr1hbSG2cXI0R7j_XBUH2kcTqsnqsrTCHA2tkohqU2yVBlBVQn0w5iCFKTJnL-DdyZFo3wCqJLpZhtp45HbKtYgA,,&amp;typo=1"">www.productmindset.com</a> and pick up a copy of “The Product Mindset: Succeed in the Digital Economy by Changing the Way Your Organization Thinks,” by 3Pillar CEO David DeWolf and VP of UX/UI for CoStar Group Jessica Hall.</p>
<h2><strong>About Blue Orange Digital</strong></h2>
<p>Blue Orange Digital helps leading organizations design, engineer, and deploy end-to-end AI products and solutions. Using industry-leading cloud technologies, Blue Orange helps manage and scale AI solutions that enable companies to take full advantage of their data. Blue Orange has been recognized as a “Top AI Development and Consultant Agency,” for innovations in predictive analytics, automation, and optimization with machine learning in NYC. Please visit <a href=""https://blueorange.digital/"">blueorange.digital</a> to learn more.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/3pillar-press-release-1.png,3pillar-press-release-1.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/3pillar-press-release-1.png,3690,3pillar-press-release-1,,,,https://blueorange.digital/wp-content/uploads/2022/05/3pillar-press-release-1.png,,,,,,,,
3688,"Blue Orange Digital’s CEO Discusses “What Sets Us Apart” with Clutch","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p><em>“Blue Orange Digital was launched with the simple initiative to make it easier and cheaper for companies to utilize, own, and unlock the profit potential hidden in their data.” — CEO, Blue Orange Digital</em></p>
<p>Five years ago, Blue Orange Digital set out to shake up the data management game. “Blue Orange Digital was founded with the goal of simplifying how companies took advantage of their data,” our CEO says. “Our aim was to build a team that could guide our clients on how to improve decision-making using integrated predictive analytics and <a href=""/rpa/"">process automation</a>.”</p>
<p>Our focus has always been on using our <a href=""/services/#analytics"">analytics and machine learning</a> skills to make a positive impact on organizations around the world. “It's incredible what can be done when we combine predictive modeling, large data sets, and robust computing power.”</p>
<p>“These predictive models are no crystal ball, but when organizations are making important decisions at scale, a 10-30% improvement in accuracy has a major impact on their long-term success. We are proud to make these solutions possible for our clients.”</p>
<p>Since 2015, we’ve had several opportunities to apply these solutions to our clients’ businesses. “From Fortune 100s to scaling startups, we look for clients where we can have the greatest impact.” </p>
<figure class=""wp-block-image is-resized""><a href=""https://blueorange.digital/blue-orange-digitals-ceo-discusses-what-sets-us-apart-with-clutch/clutch.co/profile/blue-orange-digital(opens%20in%20a%20new%20tab)"" target=""_blank"" rel=""noreferrer noopener""><img class=""wp-image-5331"" src=""https://blueorange.digital/wp-content/uploads/2020/05/Screen-Shot-2020-05-27-at-1.51.19-AM.png"" alt="""" width=""564"" height=""465"" /></a></figure>
<p>Several of those customers have left reviews for us on <a href=""https://clutch.co/profile/blue-orange-digital"">Clutch</a>, a B2B ratings and reviews platform. In one recent project, we supplied staff augmentation services for an AI company. </p>
<p>Our engineers helped deliver a range of services that left our client extremely satisfied. </p>
<p><em>“They are truly committed to technical excellence and, beyond simply providing what is required of them, doing everything they can to make your project successful.” — CEO, ArthurAI</em></p>
<p>So, what makes our team so effective? “Blue Orange Digital has a particular knack for unpacking complex and messy <a href=""https://searchdatamanagement.techtarget.com/definition/data-management"">data</a> architecture and upgrading them to more modern cloud-based solutions.” </p>
<p>Our CEO continues, “We apply a big-picture approach from the bottom up, that targets business growth as the ultimate measure of our success and clarifies priorities for all involved, making Blue Orange a reliable co-development partner.” </p>
<p>As for advice to other entrepreneurs looking for success similar to Blue Orange Digital’s, he has a few words. “I believe perseverance is one of the most underrated components of a successful company. As a founder, this means deferring profit in order to invest in long-term success. As a team, this mandates a do-what-it-takes attitude in every circumstance.”</p>
<p>“There are many factors that contributed to the success of Blue Orange Digital: luck, timing, hard work, strategy, and teamwork. But perseverance and persistence have been foundational underlying factors.”</p>
<p>Head on over to our profile on Clutch to see why we were recognized among the <a href=""https://clutch.co/developers/artificial-intelligence/new-york"">Top 10 AI Developers</a> in New York. You can also find us on their sister site, The Manifest, another useful platform that helps businesses stand out from the crowd.</p>
<p>As always, if you’re looking to learn more about our service line and get help maximizing your data, we here at Blue Orange Digital are available to help you achieve your goals. <a href=""/contact-us/"">Contact us</a> today!</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Clutch-Blog-1.png,Clutch-Blog-1.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Clutch-Blog-1.png,3689,Clutch-Blog-1,,,,https://blueorange.digital/wp-content/uploads/2022/05/Clutch-Blog-1.png,,,,,,,,
3697,"Matthew Paris named Vice President of Data Science at Blue Orange Digital","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Matthew will be joining Blue Orange Digital as the Vice President of Data Science. He brings over 12 years of experience in automation, process optimization, machine learning, and management consulting. At Blue Orange Digital he will be focusing on developing digital transformation for our clients through the use of Machine Learning, Artificial Intelligence, and Robotic Process Automation.  </p>
<p>Prior to joining Blue Orange Digital, he spent 5 years at Booz Allen Hamilton as a Chief Data Scientist. He led the design, development, and implementation of general management consulting, machine intelligence, robotic process automation (RPA) and advanced analytics services at the Department of Veteran Affairs, Defense Health Agency, Federal Drug Administration, Health and Human Services and Department of Homeland Security. Before his tenure at Booz Allen, Matthew spent 6 years at the Department of Veteran Affairs focused on process optimization, business intelligence, and automation. </p>
<p>Matthew is excited to be joining the team and working with our diverse set of clients, “when I first met with Colin and Josh, I was instantly engaged by their approach and passion for problem-solving. As I got to know more people at Blue Orange, I could see they were setting the tone for the entire company. Add in all the interesting projects and sophisticated work that Blue Orange has accomplished, it was a no brainer.”</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/VP-of-Data-Science-announcement-Matt-Paris.png,VP-of-Data-Science-announcement-Matt-Paris.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/VP-of-Data-Science-announcement-Matt-Paris.png,3698,VP-of-Data-Science-announcement-Matt-Paris,,,,https://blueorange.digital/wp-content/uploads/2022/05/VP-of-Data-Science-announcement-Matt-Paris.png,,,,,,,,
3723,"From Cron to Modern Data Stack (MDS): Dataflow Automation and Its Current State","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>The concept that makes the technological miracles of today possible are defined by data. Enormous amounts of data are collected and processed on a daily basis for businesses and organizations to provide services to their customers; and without large scale of automation regulating and speeding up the calculation of data, we wouldn’t be where we are.</p>
<p>The tools and technologies used to interpret and manage the data over the years have been changed, updated, and renamed, but their function remains the same. Concepts that sound old-fashioned now, such as “scheduler”, “workflow” or “job” are still part of dataflow automation technology but in newly expressed terms. </p>
<p>But where did it all start? What were the very first steps that pointed towards the Dataflow automation path and where we are today? In this article, we’ll go back in time, tracing the early days of cron and fast forward to its progression towards the Modern Data Stack (MDS). </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>The Early Days of Cron </strong></h2>
<p><em>Cron executes commands at specified dates and times.</em></p>
<p>This was the description of the cron’s functionality back in 1974 in one of the manual pages of that time. Cron functions as a scheduler and it was introduced as a command line in Version 6 Unix, which stands as one of the earliest versions of the operating system that is used in several computers today. </p>
<p>Through a set of short commands, which are not always easy to remember (even engineers have to make use of cheat sheets to use them), you can instruct your computer to execute a specific repeating command at a particular time. The commands you can give are pretty limited since the input shouldn’t exceed five numbers separated by spaces and followed by the respective command.  </p>
<p>Cron has you covered if you’re searching to automate a single action to repeat over a regular interval with a short single script. For instance, using this command you can tell your computer to wish you a happy new year every first day of January at the midnight: </p>
<p><em>0 0 1 1 * echo happy new year </em></p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img class=""wp-image-7469"" src=""https://blueorange.digital/wp-content/uploads/2022/05/Cron-Job-Command.png"" alt="""" /><br />
<figcaption><strong><a href=""https://nil.pro.np/set-up-cron-job-linux/""><em>Source</em></a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>The Relational Databases Mark Their Start</strong></h2>
<p>While engineers were enjoying using cron, another invention was yet to be released. Oracle is the most prominent example of what is known as relational databases, which started as a complex system for scheduling or automating work computing. It followed several updates, but one of the major ones was the introduction of job queues (1995) which were described as:  </p>
<p><a href=""https://docs.oracle.com/cd/A57673_01/DOC/server/doc/MIG73/apc.htm""><em>Release 7.2</em></a><em> provides a new feature, job queues, that enables you to schedule periodic execution of PL/SQL code.</em></p>
<p>Relational databases included the simple functions of cron for scheduling and more. If cron helped you set single reminders, using job queues gave you the option to manage an entire to-do list with the possibility of changing reminders and their order. </p>
<ul>
<li>DBMS_JOB allowed users to keep a record of jobs to be executed, their order, and the possibility to monitor or set them as “broken” if they failed to execute. </li>
<li>DBMS_SCHEDULER was used to replace DBMS_JOB with more advanced capabilities.</li>
</ul>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Data Warehouses and Data Integration Soar in Use</strong></h2>
<p>Oracle and other database-based providers were solving numerous problems for businesses through their systems but they were also creating room for a new problem: different applications had separate databases. There was the need to bring all these databases together into a single data warehouse and this was done through <a href=""/services/""><em>data integration</em></a>. </p>
<p>What this process actually entailed was the extraction, transformation, and loading of data (ETL) from the source system to the data warehouse. This was necessary because both the application database and the data warehouse structured data in different <a href=""https://en.wikipedia.org/wiki/Database_schema"">schemas</a>. This required the transformation process to take place in the integration tools. </p>
<p>One of the earliest integrations tools is Informatica which was founded in 1993, and it became prominent with the release of the PowerCenter product five years later. PowerCenter, which is still used today, is capable of managing jobs, their running order, metadata, and other details. From Informatica to Microsoft and Oracle, there’s a range of data integration tools that operate similarly today. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Data Grew into…Big Data</strong></h2>
<p>With the open sourcing of Hadoop from Google, a new way of storing and processing data was introduced to the market. This new way, which became known as data lake in 2011, was based on storing data in more than one computer, and into separate files. Even though this posed more complexities for processing, storing data became cheaper and more simple.  </p>
<p>But again, engineers were working on the next big thing, and this was the launch of workflow orchestrators. These workflow orchestrators were created to work with tools like Hadoop, and solved the adoption problems that were surfacing in the industry. Previous tools like Informatica were too expensive and often led to vendor lock-in. Meanwhile, the developed workflow orchestrators were open-source and free, and users could easily modify and enhance their capabilities.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img class=""wp-image-7470"" src=""https://blueorange.digital/wp-content/uploads/2022/05/Architectural-Shifts-in-Data-Infrastructure.png"" alt="""" /><br />
<figcaption><strong><a href=""https://images.ctfassets.net/gm98wzqotmnx/5DKRQSzalWVZUyr57oX0ev/92469ea793f8dc1ac71771410b9e32a7/Architecture_Shifts_in_Data_Infrastructure.png"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Marching Towards the Modern Data Stack</strong></h2>
<p>But did it all stop there? Not at all. Things are about to get more exciting now with the development of cloud data warehouses in early 2012. Companies like Amazon and Google made their contributions to the industry and we had: </p>
<ul>
<li>The announcement of Amazon Redshift from Amazon Web Services</li>
<li>BigQuery gets released by the Google Cloud Platform</li>
<li>Snowflake, the data warehouse and cloud computing company, was founded</li>
</ul>
<p>Cloud data warehouses made the storing and processing of data much easier. There was no longer data to be processed by a third-party tool before loading it into the data warehouse since they could transform the data in their systems. This marked a shift because extract, transform, and load (ETL) was changed to extract, load, and transform (ELT). </p>
<p>Later on, between 2013 and 2014, we witnessed the emergence of new technologies to process distributed data, such as <a href=""https://en.wikipedia.org/wiki/Apache_Spark"">Spark 1.0</a> by Databricks, and <a href=""https://kafka.apache.org/"">Kafka 0.80</a> by Confluent. These tools increased the processing time so much that they made possible real-time processing, which is also known as <a href=""https://kafka.apache.org/"">streaming</a>. </p>
<p>Together, these tools began to be known as technologies for Modern Data Stack, which Andreessen Horowitz’s Emerging Architectures for Modern Data Infrastructure would define as: </p>
<p><em>a collection of tools and technologies that primarily deliver value over an API, and that are often cloud-based.</em></p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Final Thoughts</strong></h2>
<p>Just because a novel technology enters the market, it doesn’t mean that the previous ones are completely left off. In most cases, this development is made possible alongside other existing technologies. In an average company, it’s not surprising to find scripts scheduled by cron, the use of data integration workflows, and stream processing in one place. </p>
<p>The modern dataflows are inclusive and versatile, and they need to work with more than one technology. The modern data stack is constantly expanding as it adds new tools to analyze and process data. At Blue Orange Digital, we have worked with clients of all industries and helped them integrate tools like dbt, Snowflake, and AWS Sagemaker among others, to boost their revenue and by optimizing their use of data. Schedule a free 15-minutes consultation with us <a href=""/contact-us/"">here </a>to learn how we can help your business too. </p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/From-Cron-to-Modern-Data-Stack-Dataflow-Automation-and-its-Current-State.png,From-Cron-to-Modern-Data-Stack-Dataflow-Automation-and-its-Current-State.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/From-Cron-to-Modern-Data-Stack-Dataflow-Automation-and-its-Current-State.png,3724,From-Cron-to-Modern-Data-Stack-Dataflow-Automation-and-its-Current-State,,,,https://blueorange.digital/wp-content/uploads/2022/05/From-Cron-to-Modern-Data-Stack-Dataflow-Automation-and-its-Current-State.png,,,,,,,,
3738,"Making Your Business Data-Driven the Right Way","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Data is scaling so rapidly that the workload it produces can’t even be compared to what data teams were dealing with in the past 3 or 4 years. If there was a time when the lifecycle of software consisted of its development, shipping, and then automatic use of it, now the process has become more sophisticated. </p>
<p>Things changed as the amount of accumulated data changed. It first began with single monthly reports to portray the data flow, and suddenly teams of data scientists and engineers were needed to monitor and track data. </p>
<p>Egor Gryaznov, co-founder and CTO of Bigeye, emphasized that the pace at which companies release updates has moved from yearly or twice a year to monthly, and at times even more frequently. </p>
<p>“[Years ago] a data warehouse was a piece of software you installed on your server. That was a node, and you created more nodes that you had to manually manage. Because there was so much complexity in this, the software had to move slower.”</p>
<p>Infrastructure changes make it possible for information to be processed faster than ever. Egor continues to explain that “because the infrastructure can move faster, everything else can move faster.” Our challenge is to turn this data into business benefits.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/Y2aaZRaJv7FJ3a-a5WC8BVnMCBi-5CR5IUAGpF2CWiDpK8pCCbAS85DDQh-nCu26ejXpW5YzYTRMpgjNTFH9YdCJJbFwMyMe1KcqlOAQxrz8poFj7ONJOABTFdy8i_HNz3_wkMX3"" alt="""" /><br />
<figcaption><strong><a href=""https://www.business2community.com/marketing/25-mind-blowing-statistics-on-the-state-of-data-driven-marketing-02418119""><em>Source</em></a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>What Does It Mean to Have a Data-Driven Business?</h2>
<p>A <a href=""https://assets.ey.com/content/dam/ey-sites/ey-com/en_gl/topics/digital/ey-global-becoming-an-analytics-driven-organization.pdf"">survey </a>conducted by EY concludes that nearly 81% of businesses consider data to play an important role in decision-making. Moreover, around 31% of the businesses surveyed in this report had changed their infrastructure and operations to achieve this. </p>
<p>But what steps should you take to implement a data-driven infrastructure and what traits characterize a data-driven business? </p>
<p>Data minimizes the risks of failing by taking decisions that aren’t based solely on gut feelings but on the numbers and actions of their customers. Analytics stay at the core of working with data. Here are some other features of data-driven businesses: </p>
<ul>
<li>Facts and trends are the bedrock of the executive strategy.</li>
<li>Data-democratization is established throughout the whole organization.</li>
<li>Business leaders don't take decisions without evaluating the available data.</li>
<li>All employees have achieved some kind of data literacy.</li>
<li>Organizations function on a testing mindset. No product is released without proving assumptions and hypotheses with market data.</li>
<li>Continuous development is the heart of the business for both staff and software.</li>
</ul>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Is Data Overload a Problem?</h2>
<p>An issue that is resurfacing when it comes to data relates to the capability of companies to collect data. The fact that companies can now easily collect data has overloaded them with an enormous amount of data sets that are constantly updating. </p>
<p>Curation and cleansing of data have become challenging and require proper attention. Businesses need to come to grips with the fact that not all of the collected data is useful. Data observability has become mandatory for organizations to filter their data and focus on what helps them make informed decisions.</p>
<p>We can identify cases when data teams spend time and computing power to produce reports not because they’re required but simply because they can produce them. Are those reports on short timelines really needed? “You have all this data updating 24 times a day for a nightly report that’s never looked at again,” Egor said. </p>
<figure class=""wp-block-image""><img src=""https://lh5.googleusercontent.com/qrWWHMJ9MmogK4k9lYVw-NqIvBL8q8m1Ko4kBY7ytnCD9XbDC8MbC7vGOnSwJl65BvjjusnbmAxgp-JI9FdsPiYMrnxsOHmfQllGhXPXj1pjkhnIVHGa4Rwmo2GaS0KXa5Kq0YVZ"" alt="""" /><br />
<figcaption><strong><em>Common obstacles to buildings data-driven business. </em><a href=""https://www.oreilly.com/library/view/creating-a-data-driven/9781491916902/ch01.html""><em>Source</em></a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>What Should Be Measured?</strong></h2>
<p>Relying on the truth when it comes to data is important. Data is continuously expanding and evolving but asking a few fundamental questions can help you differentiate between the data that is worth measuring versus the data that is less important. </p>
<ul>
<li>What data is this? </li>
<li>What does it look like? </li>
<li>What are its use cases? </li>
<li>What people are aware of it?</li>
<li>What state is it currently in? </li>
</ul>
<p>Change is essential for useful implementations. Companies should be willing to change their practices and the data collection they prioritize. These data collection decisions are strongly related to the outcome of <a href=""/services/"">business intelligence </a>teams and lastly to the business decisions. Tracking down the issues properly will help you make the right decisions. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Conclusion</strong></h2>
<p>Using macro measures is useful when you are looking to measure change but it’s not an efficient way to identify the underlying issues you should tackle. Instead, focus on smaller processes or individual projects. However, all these would be useless if you aren’t exchanging your findings and results with business leaders for them to be coherently on track with the trends and changes. </p>
<p>Blue Orange Digital specializes in building data-based affordable solutions for businesses of different sizes. We’ve effectively helped organizations to adopt a data-driven approach (including a<a href=""/cptcasestudies/marketing-optimization-for-fortune-500-bank/""> Fortune 500 bank</a>), and we can help yours too. Schedule a free 15-minutes consultation for us to discuss further <a href=""/contact-us/"">here</a>. </p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Blue-Orange-Digital-Data-Driven-Business-Josh-Miramant.png,Blue-Orange-Digital-Data-Driven-Business-Josh-Miramant.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Blue-Orange-Digital-Data-Driven-Business-Josh-Miramant.png,3741,Blue-Orange-Digital-Data-Driven-Business-Josh-Miramant,,,,https://blueorange.digital/wp-content/uploads/2022/05/Blue-Orange-Digital-Data-Driven-Business-Josh-Miramant.png,,,,,,,,
3745,"What Are Modern Data Stack (MDS) Technologies?","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>The software industry has seen immense changes in recent years thanks to the implementation of open-source, cloud, and SaaS business models. <a href=""/services/"">Data integration</a> is done much more efficiently and effectively, supplying analysts and engineers with more time to spend on other important activities.</p>
<p>Setting a technology stack can be done in half the costs and time it took a few years ago, and businesses can continue running quickly. A “technology stack”, from which the term Modern Data Stack originates, stands for the set of technologies used to store, manage, and analyze data. These technologies are commonly based on cloud-based services and are available on low-code tools for broader access.</p>
<p>The Modern Data stack is focused on solving data challenges throughout its lifecycle in the cloud. This involves its journey throughout the cloud from the moment data is collected to its application in solving users’ problems. Data-based organizations have completely shifted how they position themselves in the industry.</p>
<p>For example, Airbnb is far from being a traditional hotelier and Stitch Fix can’t be compared with normal clothing retailers. <a href=""https://towardsdatascience.com/the-future-of-the-modern-data-stack-in-2022-4f4c91bb778f"">These changes</a> have also heavily impacted the careers of professionals working in the data industry, leading to the creation of new roles and increasing the demand for what were less-important roles.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/CSEhPBmpC0Nzfiln4hvM4bsMnGvUNznMFWCnVGzTqnelG3kBFzOiDP1ySzIfk71Xv5DeUg7aEIwABqL3AgW4aZL_ozfgd0GxXuQ3grRbLSNlKuCsNverT38dJFcGaSKHfdJ770uf"" alt="""" />
<p>&nbsp;</p>
<figcaption><strong><a href=""https://blog.dataiku.com/demystifying-the-modern-data-stack"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>What is Modern Data Stack (MDS)?</strong></h2>
<p>Traditional data platforms are ineffective in successfully managing large amounts of data due to their processing speed and complexities. Technologies that make up a Modern Data Stack rely on a cloud-native data platform. New technologies emerge but their categorization is made based on the same phrase of the data lifecycles.</p>
<ul>
<li>Data Ingestion (Fivetran, Stitch)</li>
<li>A Cloud Data Warehouse (Redshift, BigQuery, Snowflake, or Databricks Delta Lake)</li>
<li>Data Integration (Segment, Airbyte, <a href=""https://www.fivetran.com/"">Fivetran</a>)</li>
<li>ETL Data Transformation Tools (dbt)</li>
<li>BI Layer (Mode, Looker, Periscope, Metabase)</li>
<li>Reverse ETL (Hightouch, Census)</li>
<li>Event Tracking (Segment, Snowplow)</li>
</ul>
<p>The main purpose of a Modern Data Stack is to make data available for use as efficiently as possible and in minimal time. And there has been tremendous progress because data which took months to be available is now usable in a matter of weeks or even hours. Businesses may not need all components depending on their data processing needs to acquire this speed.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>What’s The Difference Between a Legacy Data Stack and a Modern Data Stack?</strong></h2>
<p>The most prominent difference between the two stands in the configuration technicalities. A Modern Data Stack, unlike a Legacy Data Stack, is hosted<a href=""https://blueorange.digital/cloud-architecture-build-vs-buy/""> on the cloud</a> which means a lot less struggle for the users to configure and utilize the tools. This translates to facilitated access for end-users and accelerated scalability.</p>
<p>Achieving the same efficiency and meeting the data needs would require longer and more expensive processes needed to scale the local server instances. As a result, the technical barrier to the implementation of the Modern Data Stack is lowered, allowing a seamless data integration.</p>
<p>Modern Data Stacks are more inclusive since they are built with business users and analysts in mind. This allows users without a technical background to not only use these tools with a minimal learning curve but also administer them.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>What Are The Benefits Of A Modern Data Stack?</strong></h2>
<p>The benefits of a Modern Data Stack are quite straightforward. It saves money, time, effort, and a lengthy learning curve, as well as removing the restrictions that exist for data teams. Compared to on-premise solutions, cloud computing and storage solutions used by Modern Data Stacks are much more affordable.</p>
<p>Using off-the-shelf connectors can save time and costs associated with the designing, building, and maintenance of data connectors. This means that your teams of analysts and data scientists will have more budget and time to spend on higher-value activities.</p>
<figure class=""wp-block-image""><img src=""https://lh4.googleusercontent.com/zw9FIJTIsvf5ocWwRn5Ude4t_Ufst_ANAyEEVgS8Gj94hw6iUep6AAaDO7xouD6g8gp9uG9iAAhufEytfseiMH-Fh-xPhSHoF3k3U24b4EWWNWnMCXID2rm9hrvxE0ES9oDwZbB0"" alt="""" />
<p>&nbsp;</p>
<figcaption><strong><a href=""https://www.moderndatastackconference.com/"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>What Should Each Component of the Modern Data Stack Have?</strong></h2>
<p>The Modern Data Stack comprises four main stages through which data is processed: a data pipeline, destination, transformation layers, and a business intelligence/<a href=""/services/"">data visualization</a> platform. Some features each component should have are:</p>
<h4>Data Pipeline</h4>
<p>In this stage make sure to choose a tool with prebuilt connectors that match your data sources. It will save time in the long term. Also, make sure the tool can be implemented easily for simplified data integration, scaling, and can be fully managed to allow a modification of schema and API changes.</p>
<h4>Data Destination</h4>
<p>Scalability is the main concern when it comes to choosing a data destination. The component should allow scalability in terms of storage and computing in a short downtime to support your analytics and storage requirements. Other things to be considered include the ease of setting up, running, and provisioning models.</p>
<h4>Transformation Tools</h4>
<p>The transformation tool you choose should be suitable for the chosen destination. It should also be equipped with the functionality of tracking your data lineage, and controlling its journey. The features could include the documentation and version control that are useful to track transformation results on your tables.</p>
<h4>BI/Data Visualization</h4>
<p>In this aspect the technical implementation which may involve variable defining for users, user accessibility, and visualization flexibility are important. Other considerations of the tool, such as the ease of self-serving it from a user perspective depends on the internal data structure.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Final Thoughts</strong></h2>
<p>The Modern Data Stack is evolving as new tools emerge and updated functionalities give more flexibility of use to data team members. Rapid growth equals more possibilities but companies still need expertise and time to make use of these developments.</p>
<p>At Blue Orange Digital, we work with dbt, Snowflake, and AWS Sagemaker among other Modern Data Stack technologies to implement data integration and visualization solutions for our clients. You can schedule a free 15 consultation with our data team experts <a href=""/contact-us/"">here </a>to learn more about our services.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Modern-Data-Stack-Technologies-Blue-Orange-Digital.png,Modern-Data-Stack-Technologies-Blue-Orange-Digital.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Modern-Data-Stack-Technologies-Blue-Orange-Digital.png,3746,Modern-Data-Stack-Technologies-Blue-Orange-Digital,,,,https://blueorange.digital/wp-content/uploads/2022/05/Modern-Data-Stack-Technologies-Blue-Orange-Digital.png,,,,,,,,
3753,"5 Steps to Increase Commercial Real Estate (CRE) Revenue with Data Analytics","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>The Commercial Real Estate (CRE) market is intricate and operates on a lot of data. This makes data-driven solutions a must as this means less time spent collecting certain data about properties according to specific characteristics, and more time for making the right decisions before the market changes.</p>
<p>The means of communication between sellers and buyers has changed enormously with companies being more tech-enabled, but this is expected to revolutionize even more CRE companies and how they can reduce costs and drive more profits. We’ve seen how with the help of data, the process of matching and buying is facilitated but is this all data science has to offer? </p>
<p>Experts believe there’s an untapped potential in the use of analytics to invest money more wisely and make better decisions. This also includes the seamless exchange of accurate data about the CRE market, properties, and their qualities in order to drive beneficial decisions and predictions. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Data Science and Commercial Real Estate (CRE)</strong></h2>
<p>When speaking of purchasing or selling properties in the CRE market, numbers play a major decisive role. Sellers use numbers to point out and persuade buyers about the value of a specific property. However, not all companies are convinced about the use of analytics in this market, and this translates to more opportunities for those who do. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh5.googleusercontent.com/_TojPju8cbPmhrrbOj2jYAuawchgqaMANSKk9XZHnRfCCBXoxUJgQFanEGs7WOGw0rnPFbbYv76WTNgo0c4SQPkvhBLkduaTYUzhn79i5FfpOeVsO1vLZ9WK63XsiTCb22Ir6BDf"" alt="""" /><br />
<figcaption><strong><a href=""https://ascendix.com/wp-content/uploads/2021/10/The-Proportion-of-Data-Driven-CRE-Organizations.png"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<p>This happens because not everyone understands the power that stands behind the term “data science”, and how it can impact the CRE market. All we see are numbers and statistics, but behind them lies an architecture of algorithms, machine learning, data mining, deep learning, and predictive and descriptive analysis. </p>
<p>These numbers help in building effective marketing campaigns and sales strategies that target ideal customers. From 2017 to 2021, the number of companies that made use of data science increased by 56%. Implementing <a href=""https://link.springer.com/article/10.1007/s43681-021-00053-4"">data science in the real estate market</a> provides CRE experts with much more data than normal, including risk level, area description, expected CAP rate, available funds, etc. </p>
<p>Moreover, it also answers some of the most important issues in the industry, regarding the ideal time to invest, ROI predictions, and estimating the worth of properties and portfolios. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>The Uses of Data Analytics (DA) in CRE</h2>
<p>Brokers can make use of data analytics to build a CRE strategy that takes into account emerging market trends based on the information about demographics, location, and segmentation. Therefore, they’ll make more calculated decisions with minimal mistakes. For example, data analytics can be applied in: </p>
<ul>
<li>Portraying benefits for tenants</li>
<li>Traffic and customer information (for retail centers)</li>
<li>Detailed revenue charts</li>
<li>Heatmap analysis </li>
<li>Calculators for property renting </li>
</ul>
<p>Not only is this information for making decisions in the present but it also helps brokers and agents for predicting the future outcome of a property and its possible revenue. Different types of CRE Analytics are applied to reveal certain aspects. </p>
<ul>
<li><strong>Descriptive Analytics.</strong> Brings data from past transactions and actions (LTV, DCR, ROI) for a certain timespan. </li>
<li><strong>Diagnostic Analytics.</strong> Collects and presents data from the past, indicating the causes of certain events, and serves as a basis for prescriptive and <a href=""/predictive-analytics/"">predictive analytics</a>.</li>
<li><strong>Predictive Analytics.</strong> As the term suggests, it focuses on forecasting the potential outcome and possible risks, helping brokers outline the proper strategies to manage the results. </li>
</ul>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/3XrQwjoC-rKIEYDk3NvRZVpyS3Mu-usDGB9zeFDJt9a0l81LA8K3gch-uLNCSvRoyofV0puzJ9vr_dz6AP5T1gvT4xYqseSs8a1DwqNSmoFTvOKYgNqZJUEwSXOhNityBTU3t9TL"" alt="""" /><br />
<figcaption><strong><a href=""https://www.cbre.com/insights/viewpoints/managing-corporate-real-estate-leading-and-emerging-practices"">Survey </a>on the Use of Data in CRE</strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Collection of CRE Data</strong></h2>
<p>When working with data, most of the work includes gathering the information, before drawing useable statistics that can help with decision-making. This data can be found in different sources such as APIs, social media, reviews, etc. Data Analysts have to take this data through five main stages: </p>
<ul>
<li><strong>1st step.</strong> CRE data gathering from different sources. </li>
<li><strong>2nd step.</strong> Cleaning of data from incomplete or unusable data and transformation for further use. </li>
<li><strong>3rd step. </strong>The visualization of data and conversion into statistics, and variables used to build effective models. </li>
<li><strong>4th step. </strong>Use of machine learning and deep learning to determine what algorithms and models fit the business needs.</li>
<li><strong>5th step.</strong> The presentation of results and their practical implementation to stakeholders. </li>
</ul>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Final Thoughts</h2>
<p>As the real estate market gets more and more competitive, companies should consider a deeper implementation of new technologies and especially data science practices in order to thrive. However, implementing advanced analytics and interpreting their results is challenging and requires expertise in this field.</p>
<p>At Blue Orange Digital, as an NYC-based data science company, we’ve helped businesses from real estate and healthcare to the financial and commerce sectors build solutions based on machine learning, data science, data transformation, and data visualization. Schedule a short 15-minute meeting <a href=""/contact-us/"">here </a>to see if we can help your business too.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Blog-Post-Cover-Images-3-2.png,Blog-Post-Cover-Images-3-2.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Blog-Post-Cover-Images-3-2.png,3754,Blog-Post-Cover-Images-3,,,,https://blueorange.digital/wp-content/uploads/2022/05/Blog-Post-Cover-Images-3-2.png,,,,,,,,
3760,"Streamlit and Snowflake for Data-Driven Web Apps","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Python is great for building web applications but the conventional way of building such apps by using Flask or Django web frameworks involves time-consuming learning for both their development and implementation. Streamlit has simplified web app development using Python and their latest partnership with Snowflake creates more advantages!</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>What is Streamlit?</h2>
<p>Streamlit is a data science and development software that assists data professionals working with data science models or developing applications. Streamlit works as a Python library that you can utilize for building web apps with ease. Almost anyone who can write scripts on Python, and has knowledge of Python fundamentals can use Streamlit.</p>
<p>Building web apps with Django and Flask doesn’t only involve quite a bit of learning but also limits their access to the eyes of data scientists or other members of the data community. Using Streamlit, data analysts, scientists, or hobbyists can build web apps from their machine learning models with a minimal low-code platform like <a href=""https://streamlit.io/"">Streamlit</a>.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh4.googleusercontent.com/DtoHD1c-SsTAV63dnG7NrsWPZNWOmEWN9u_VxXwqqVT9N-2roUVy8bCDkbe1MjiGFVWkFm5TS_XtzvDN9fmbnD_pnzele_d-Nss8BCQxIU_UNt7y-0yc5AGIcIhPCJVR658FjErF"" alt="""" />
<p>&nbsp;</p>
<figcaption><strong><a href=""https://aws.amazon.com/financial-services/partner-solutions/snowflake/"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>What is Snowflake?</strong></h2>
<p>Snowflake has made a name for the data science industry for its data warehousing capabilities and an array of different analytics stacks. We can say that it is a <a href=""https://docs.snowflake.com/en/user-guide/intro-key-concepts.html"">database software</a> for the cloud which helps companies move from traditional on-premises to seamlessly transition their data architecture into the cloud.</p>
<p>If we look deeper into the system of Snowflake we will notice that from an architectural perspective, what keeps the platform functioning smoothly is the capability to keep computational workloads separated from the storage. One single source of truth brings together two major kinds of data, structured and semi-structured.</p>
<p>Being that Snowflake can be deployed into different cloud providers from AWS to Google Cloud and Microsoft Azure, the vendor lock-in is reduced, opening more ways to work with data.  However, there’s an array of other providers that offer an ecosystem of cloud-native data warehouse offerings on these cloud providers which allow you to build and test applications. Something that Snowflake misses but can add to its tool belt is the <a href=""https://www.snowflake.com/blog/snowflake-to-acquire-streamlit/"">acquisition of Streamlit </a>framework.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh5.googleusercontent.com/NN9yrbxrLdOHCZRrVq7oNCRO2mSL7tS9hNjb6yW40Vjkzojg93MuT0c6TVMC-pVoOex1vIMBP9IB-zVHJkKm0wrVXhq-pAveXGP5Yt3UaR8MaiXlhKk0u17KDiiX4nfrX_lKt__Y"" alt="""" />
<p>&nbsp;</p>
<figcaption><strong><a href=""https://149695847.v2.pressablecdn.com/wp-content/uploads/2022/03/FM376wWUYAIstFq-2048x986.jpg"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Streamlit and Snowflake Come Together</strong></h2>
<p>Streamlit CEO and Co-Founder, Adrien Treuille <a href=""https://www.snowflake.com/news/snowflake-announces-intent-to-acquire-streamlit-to-empower-developers-and-data-scientists-to-mobilize-the-worlds-data/#:~:text=%E2%80%9CBy%20joining%20forces%20with%20Snowflake%2C%20both%20the%20Streamlit%20and%20Snowflake%20developer%20communities%20will%20be%20able%20to%20tap%20into%20cutting%20edge%20technologies%20for%20unlocking%20data%E2%80%99s%20true%20potential.%E2%80%9D"">said </a>that “by joining forces with Snowflake, both the Streamlit and Snowflake developer communities will be able to tap into cutting edge technologies for unlocking data’s true potential.”</p>
<p>Snowflake has served as a data platform for many useful data-based applications, such as Lacework or Instacart. But the truth is that not all teams have full-stack engineering teams specialized in building data apps the old way. Therefore, Snowflake envisions the integration with Streamlit will directly empower data scientists and machine learning engineers to create web apps on their own.</p>
<p>Here are four points on which they promise to keep delivering:</p>
<ol>
<li>Both Snowflake and Streamit will continue to support the development of new features and the open-source project by Streamlit.</li>
<li>Stream lit promises to focus even more on engaging with its community. Especially after Snowflake is added to the partner’s list with its features.</li>
<li>All new features, ideas, paradigms, and work will be distributed actively via Streamlit Cloud for everyone in the machine learning and data science communities.</li>
<li>This partnership is expected to lead to the opening of many new use cases.</li>
</ol>
<p>It seemed like a no-brainer for the two companies to partner up since they’ve had joint customers who relied on them for their apps. This helps developers and data scientists build these advanced web applications for their needs while working with high-quality standards data that requires little provision and maintenance.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Final Thoughts</h2>
<p>We understand that developing applications for your data insights or analytics needs is challenging. Blue Orange Digital has worked with many organizations to help them build apps or move from on-premises towards cloud environments.</p>
<p>This involves working closely with data platforms like Snowflake (something that’s time-consuming and requires expertise from your staff) and we can assist with the process. Whether you want to build web applications or have other data-related issues, we can help. Simply schedule a free 15-minute call with us <a href=""/contact-us/"">here</a>.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Streamlit-and-Snowflake-for-Data-Driven-Web-Apps-Blue-Orange-Digital-CEO-Josh-Miramant.png,Streamlit-and-Snowflake-for-Data-Driven-Web-Apps-Blue-Orange-Digital-CEO-Josh-Miramant.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Streamlit-and-Snowflake-for-Data-Driven-Web-Apps-Blue-Orange-Digital-CEO-Josh-Miramant.png,3761,Streamlit-and-Snowflake-for-Data-Driven-Web-Apps-Blue-Orange-Digital-CEO-Josh-Miramant,,,,https://blueorange.digital/wp-content/uploads/2022/05/Streamlit-and-Snowflake-for-Data-Driven-Web-Apps-Blue-Orange-Digital-CEO-Josh-Miramant.png,,,,,,,,
3767,"Amazon Elastic Kubernetes Service (EKS) for On-premises and Cloud Kubernetes","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Containerized applications are fantastic for accelerating development, lowering overhead, and building solutions that run on more than one platform (even the cloud) without having to rewrite them. Moreover, they guarantee excellent security thanks to their isolation capacities. </p>
<p>However, managing containerized applications presents a challenge. They need to be built and managed efficiently. Otherwise, the efforts wouldn’t be worth it. Kubernetes (K8s) does exactly this: assists in the management of containerized applications. As an open-source system, it allows a seamless scaling, management, and deployment of applications. </p>
<p>The costs of maintaining the service yourself can outweigh the savings. Therefore it makes sense to find a platform that provides Kubernetes as a managed service. Amazon, Google, and Microsoft offer their distinct platforms, but today we are discussing the former. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>What Is Amazon Elastic Kubernetes Service (EKS)?</h2>
<p>Amazon Elastic Kubernetes Service (EKS) functions as a completely managed container service (no need for the self-maintenance of your infrastructure) where you can run, deploy, and scale applications in both the on-premises and the cloud. </p>
<p>Launched in June 2018, Amazon EKS was made available by relying on the open-source Kubernetes version. It was prepared with the shared responsibility principle in mind: </p>
<p><strong><em>""AWS provides a Kubernetes control plane while AWS customers control their worker Nodes.""</em></strong></p>
<p>It started off by offering a managed control plane for its EKS cluster which allowed the EC2 instances management for the application containers. Users were prompted to make use of the cluster orchestration platform. Later on, the service was developed to further assist with the deployment of auto-scaled EC2 nodes.</p>
<p>As a self-managed service, it doesn't require you to deal with the development of scalability and availability for master nodes. This gives administrators more time to deal with workloads and the cluster. EKS automates not only the parallel processing and load distribution on the application workloads you're running but in others too (including databases). </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>How to Use Amazon EKS? </h2>
<p>Amazon EKS allows single points of failure that occur from running Kubernetes in other ways, utilizing the applications on various availability zones. Even if you are running Kubernetes applications elsewhere, they can be migrated into Amazon EKS with ease. </p>
<p>Since the project is open-source, numerous tools and plugins are built by developers who spotted issues in the process. However, when considering migrating an application, talking to AWS Certified Engineers is necessary. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh5.googleusercontent.com/mWIheoDKaH6N3wZUj0-50rbD3c8LCRqmJbjNigzsvWKERxm49Kp2FnOmdZp8507fi7QMooYK12N2zIfa2xHQONILX5gkQaVgdNmXmo4kZyqTAbZ5gLUAS3VxhNN_lfpyHc50OMiQ"" alt="""" /><br />
<figcaption><strong><a href=""https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html""><em>Source</em></a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<p>Moving from-self managed Kubernetes to fully managed Amazon EKS can be done in four steps:</p>
<ol>
<li>Onboard on AWS Management Console and build an Amazon EKS cluster. (You can also use an AWS SDK or AWS CLI).</li>
</ol>
<ol>
<li>Finish the deployment if workloads on AWS Fargate or launch Amazon EC2 nodes (either managed or self-managed)</li>
</ol>
<ol>
<li>After the cluster is set up, start configuring K8s tools such as <a href=""https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html"">kubectl </a>to interact with it. </li>
</ol>
<ol>
<li>Keep managing and deploying workloads on the Amazon EKS cluster similarly to other Kubernetes environments, while monitoring the workloads through the Amazon Management Console. </li>
</ol>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>The Benefits of EKS</h2>
<p>Amazon EKS saves you the time and resources needed to install and maintain a Kubernetes control plane all on your own. All the applications can be managed through the Kubernetes Dashboard which allows changes to certain single resources as well. </p>
<p>Securing, scaling or managing, and learning to optimize Kubernetes on their own come with complications that have quite steep learning curve. Amazon EKS builds a cloud-native architecture in AWS with ease. </p>
<p>EKS works with internal/public classic and NLB annotations. This means that a number of tools such<a href=""https://kubernetes-sigs.github.io/aws-load-balancer-controller/v1.1/""> as ALB Ingress Controller</a> and KIAM will advance the features of EKS by allowing pods to predict the IAM roles, and have the Kubernetes Load Balancer involve ALB as well. <br />Security and scalability remain two main features for your applications and EKS integrates seamlessly with other EKS services to help develop into these areas. Some of these services include: IAM for authentication, improved load balancing using the Elastic Load Balancing, and strengthened isolation with Amazon VPC (<a href=""https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html"">Virtual Private Cloud</a>).</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>What Are Some Use Cases of Amazon EKS? </h2>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh5.googleusercontent.com/FS7dIF9Q0vcVyXf6MoQKqMuJZo5csQWx2ENrwy6KkT9ZDcHReUKjFwic_gx0yLn3dH6xc28VkW_wI9YnbfKlYMY_qTFGq__8RAvzj7rd2nFP8ILHuoktSDoHlNmQjr_aNTaonVmv"" alt="""" /><br />
<figcaption><strong><em>Deploying applications on the cloud with Amazon EKS. </em><a href=""https://aws.amazon.com/eks/""><em>Source</em></a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h4>Deploy Across Hybrid Environments</h4>
<p>Companies do keep a good part of their Kubernetes clusters in on-premises data centers and hybrid environments. Amazon EKS offers a unified toolset through Amazon EKS Anywhere which standardizes and operationalizes Kubernetes functionalities across environments. </p>
<h4>Model Machine Learning (Ml) Workflows</h4>
<p>Optimize Machine Learning Operations and workflows by integrating Amazon EKS with <a href=""https://blueorange.digital/build-and-deploy-ml-models-through-sql-with-amazon-sagemaker-autopilot-and-snowflake/"">Sagemaker </a>or by using it on its own. It allows you to quickly run training jobs with the recent EC2 (Elastic Compute Cloud) and accelerates the deployment of inferences and training with the support of Kubeflow.  </p>
<h4>Build And Run Web Applications</h4>
<p>Building scalable and secure applications is attainable with the use of multiple security and networking integrations and the diversity of Availability Zones (AZ) that prevent points of failure. Moreover, applications are available seamlessly in both the cloud and on-premises and under highly available configurations. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Final Thoughts </h2>
<p>Kubernetes is fantastic for running secure and efficient containerized applications for your business. However, the stress and costs that come with the traditional path of self-managing the Kubernetes are exhausting. Therefore, Amazon EKS is the ideal solution to manage these applications and streamline their workflows. </p>
<p>At Blue Orange Digital, we have developed multiple data solutions for <a href=""https://blueorange.digital/cptcasestudies/"">clients of different industries</a>, from healthcare and marketing to real estate and supply chains. If you would prefer to have a virtual chat with our team, book a 15-minute call <a href=""https://blueorange.digital/contact-us/"">here</a> for free.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Amazon-EKS-for-On-Premises-and-Cloud-Kubernetes-Blue-Orange-Digital-CEO-Josh-Miramant.png,Amazon-EKS-for-On-Premises-and-Cloud-Kubernetes-Blue-Orange-Digital-CEO-Josh-Miramant.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Amazon-EKS-for-On-Premises-and-Cloud-Kubernetes-Blue-Orange-Digital-CEO-Josh-Miramant.png,3768,Amazon-EKS-for-On-Premises-and-Cloud-Kubernetes-Blue-Orange-Digital-CEO-Josh-Miramant,,,,https://blueorange.digital/wp-content/uploads/2022/05/Amazon-EKS-for-On-Premises-and-Cloud-Kubernetes-Blue-Orange-Digital-CEO-Josh-Miramant.png,,,,,,,,
3769,"IoT Aiding Supply Chain Improvements","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<h2>Can You Save Millions In Supply Chain Costs With The Internet of Things?</h2>
<p>Getting everything you can out of your technology and processes has never been more critical. In supply chain management and logistics, there is a new way to streamline your operations. It's easy because you don't need to purchase any new hardware. You just need a new perspective on the data you already have.</p>
<h2>Do You Need Special Hardware For Internet of Things Supply Chain Optimization?</h2>
<p>Hardware manufacturers will tell you that you need to buy additional hardware to leverage the Internet of Things (IoT). Indeed, specialized hardware brings more value and options to the table. It isn't required, though. If you have mobile devices like smartphones and GPS, you have everything you need to achieve supply chain improvements in terms of hardware. The next step is to look at those resources with a new perspective.</p>
<h2>Get Your IoT Project Started With Three Powerful Data Questions</h2>
<p>To illustrate the power of using what you already have, let's look at fleet logistics. You may have ten, twenty or a hundred vehicles in your fleet. There's no need for more equipment. Your company is already collecting plenty of useful data. You simply need the perspective to analyze it. Get started by using these strategic questions.</p>
<h2>1) What assets and devices do you already have in place to collect data?</h2>
<p>Your company probably already has smartphones in the hands of your employees. You might also have GPS devices installed on your vehicles. Ideally, you will have apps in place to collect data. However, if you lack this capability right now, you can work with a data management partner like Blue Orange to develop this capability.</p>
<h2>2) What are your operational bottlenecks?</h2>
<p>Identify the most costly restraints in your business. For example, a delivery company could face high costs by having drivers take inefficient routes. Inadequate monitoring of cargo could lead to waste in the form of perishable deliveries (e.g., food and pharmaceuticals).</p>
<h2>3) What data are you already collecting about your business?</h2>
<p>You might be collecting valuable data and hiding it away in spreadsheets and databases. With the right data management processes, you can pull cost and time-saving ideas from the data you already have.</p>
<h2>Implementing Data-Driven Supply Chain Improvement Without Special Hardware</h2>
<p>When you first start, you may have limited resources to improve your supply chain. Fortunately, you can achieve some wins using assets you already have. You don't always need to purchase and install specialized hardware. Courier companies like UPS have shown the way. As<a href=""https://www.cnn.com/2017/02/16/world/ups-trucks-no-left-turns/index.html""> CNN</a> reported:</p>
<p>UPS, which makes 18 million deliveries a day in the US, says that Orion analyzes 250 million address points a day and performs 30,000 route optimizations per minute. This saves the company $300 to $400 million annually in fuel, wages, and vehicle running costs: ""Our basic routines were already good, and allowed us to save about 85 million miles a year. When we put Orion on top of those, it shaved off an extra 100 million miles, and the savings got up to 185 million miles a year.""</p>
<p> If you have a smaller fleet with fewer routes, the dollar savings you can expect from route optimization will be lower. However, you can keep earning those savings year after year, so remember to keep the long term view for these projects.</p>
<h2>Next-Generation IoT Supply Chain Improvements</h2>
<p>At a certain point, you will exhaust the improvements you can make with your current hardware. In those situations, you may need to install some specialized equipment into your supply chain. To illustrate what's possible, consider these two use cases.</p>
<h2>1) Track individual items through your supply chain</h2>
<p>Imagine you are tracking a shipment of medical supplies such as vaccines, drugs, and personal protective equipment. Traditional tracking methods make it difficult to track each item in a container. That's a problem because each item may have a different destination, and customers may expect detailed tracking. You can use simple solutions like printed QR codes or 5G trackers to track an individual item’s location, temperature, shock, and other environmental factors to detect tampering, damage, or delays.</p>
<h2>2) Reduce waste and supply chain losses</h2>
<p>Shipping food is a classic supply chain problem. Customer demand for fresh food is constant, even as the seasons change. However, some food items like produce have a short shelf life. For example, a green banana purchased from a grocery store generally takes 3-4 days to ripen fully. A week after that, the item starts to go stale. Therefore, distributors have a strong incentive to get the timing right in bringing this kind of product to stores.</p>
<p>Wal-Mart, a retailer with a significant grocery business, has used technology to improve its banana distribution process directly. Using a new machine learning-based software program, Wal-Mart is on track to reduce $2 billion in produce waste. As indicated in an<a href=""https://community.arm.com/iot/b/internet-of-things/posts/5-ways-iot-is-revolutionizing-the-supply-chain""> industry report</a>, Wal-Mart ""can monitor the temperature of shipping containers and the ripeness of bananas they're carrying. If necessary, [the system] can reroute the containers to a closer store, so the bananas don't arrive too ripe.""</p>
<h2>3) Use Case </h2>
<p>A great example of IoT devices saving money and increasing efficiency came from RedLore. RedLore specializes in optimization solutions for supply chain companies. With a focus on high visibility and transparency into the supply chain through IoT sensors. RedLore has increased the quality control around environment sensitive products by utilizing their sensors in a different way. </p>
<blockquote class=""wp-block-quote""><p><em>“RedLore sensor devices are designed to be installed on the pallet or box. As the sensor is linked to the unit of transport rather than the transport container, the measurements are not interrupted during a lay-over between transport modes and full continuous monitoring from the producer’s warehouse to the retailer and even into the final warehouse can take place.”</em></p>
<p>&nbsp;</p>
<p><cite><em>-Niek Van Dierdonck</em></cite></p></blockquote>
<p>This continuous monitoring of the specific products compared to the container as a whole allows RedLore to detect changes in temperature, humidity, light exposure throughout the whole transport journey(ship to truck, truck to warehouse, warehouse to retailers). Coupled with automation to detect changes and send out alerts, RedLore’s sensors can help predict problems before spoilage occurs. This decreases damaged goods and increases customer satisfaction. An example provided by the CEO of RedLore Niek Van Dierdonck shows how the sensors were able to detect a change in temperature due to an inefficient arrangement of pallets inside a trailer. By rearranging the pallets to provide for better airflow in the trailer this reduces the temperature of all the goods in the trailer. </p>
<blockquote class=""wp-block-quote""><p><em>“RedLore's sensor devices process the sensor information on the device itself rather than relying on a (cloud) server to detect a problem. As a result, the device will detect anomalies also when there is no connectivity. Moreover, it will be able to predict anomalies preemptively such that the problem can be remedied before the spoilage occurs.”</em></p>
<p>&nbsp;</p>
<p><cite><em>-Niek Van Dierdonck</em></cite></p></blockquote>
<h2>Accelerating Results With A Data Management Partner</h2>
<p>Even without new hardware, there is a lot of work involved in applying the Internet of Things (IoT) to your supply chain. You need a high level of data literacy. You need to know the right software tools to use. You need to understand the capabilities of <a href=""https://blueorange.digital/data-lakes-vs-data-warehousing-choosing-the-right-option-for-your-data-strategy/"">data lakes vs. data warehouses</a>. There's no need to go out and hire a team of data experts. After all, you want to deliver products on time. You make more deliveries on time without errors and waste by getting insights from your data. Contact Blue Orange Digital today to discuss your data options.</p>
<p>In conclusion, the advent of advanced technologies such as AI, ML, and analytics combined with the IoT technology has made the collection, process, and analysis of data easier and more accurate than ever. These major advancements have transformed the supply chain industry by making it more efficient, safer, and improving ROI.</p>
<hr class=""wp-block-separator"" />
<p><strong>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for </strong><a href=""https://blueorange.digital/cptcasestudies/supply-chain-revenue-predictions-for-pharmaceuticals/""><strong>Supply Chain</strong></a><strong>, </strong><a href=""https://blueorange.digital/cptcasestudies/digital-transformation-of-government-documents/""><strong>Healthcare Document Automation</strong></a><strong>, and </strong><a href=""https://blueorange.digital/cptcasestudies/""><strong>more</strong></a><strong>.</strong></p>
<hr class=""wp-block-separator"" />
<p><em>Follow me on </em><a href=""https://twitter.com/BlueOrangeData""><em>Twitter</em></a><em> or </em><a href=""https://www.linkedin.com/in/joshmiramant/""><em>LinkedIn</em></a><em>. Check out my </em><a href=""https://blueorange.digital/""><em>website</em></a><em>. </em></p>
<div class=""wp-block-image"">
<figure class=""alignleft""><img class=""wp-image-4644"" src=""https://blueorange.digital/wp-content/uploads/2020/03/Josh-Miramant.png"" alt=""CEO Josh Miramant"" /><br />
<figcaption>            CEO Josh Miramant</figcaption>
</figure>
</div>
<p>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He is a serial entrepreneur and software engineer that has built and scaled 3 startups. He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things. </p>
<p>Featured on IBM ThinkLeaders, Dell Technologies, and NYC’s Top 10 AI Development and Custom Software Development Agencies as reviewed on Clutch and YahooFinance for his contributions to NLP, AI, and Machine Learning. Specializing in predictive maintenance, unified data lakes, supply chain/grid/marketing/sales optimization, anomaly detection, recommendation systems, among other ML solutions for a multitude of industries.  </p>
<p>Visit <a href=""https://blueorange.digital/"">blueorange.digital</a> for more information and <a href=""https://blueorange.digital/cptcasestudies/"">Case Studies</a>.</p>
<p>Article originally published here on <a href=""https://www.manufacturingtomorrow.com/article/2020/08/iot-aiding-supply-chain-improvements/15729"">Manufacturing Tomorrow.</a></p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/iot-aiding-supply-chain-.jpg,iot-aiding-supply-chain-.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/iot-aiding-supply-chain-.jpg,3789,iot-aiding-supply-chain-,,,,https://blueorange.digital/wp-content/uploads/2022/05/iot-aiding-supply-chain-.jpg,,,,,,,,
3770,"Optimization Modeling Intro","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<h2><b><strong style=""font-style: inherit;"">Intro</strong></b></h2>
<p style=""font-weight: 400;"">The hardest engineering, scientific and statistical problems of our times are being tackled by means of mathematical optimization. Operating at the core of most statistical techniques and machine learning methods, optimization is what allows algorithms to transform large numbers of random variables into understandable and actionable observations. </p>
<p style=""font-weight: 400;"">However, the optimization concept is by no means only limited to computer scientists, engineers, and statisticians. On the contrary, we are all exposed on a daily basis to different kinds of optimization. Search engines trying to figure out the best responses to search queries? Heavily relying on optimization. Location-based driving assistants trying to find the best route across town? You guessed it, all powered by optimization. </p>
<p style=""font-weight: 400;"">In the business world, optimization models also play a crucial role: they are a proven way to improve strategic, tactical, and operational processes. They give human decision-makers the opportunity to tackle complex problems and answer questions that are impacted by a large number of factors. Building mathematical models based on historical and real-time data provides an objective and scientific foundation for day-to-day plans, predictions, and decisions.</p>
<h2>Recognizing an Optimization Problem</h2>
<p style=""font-weight: 400;"">A large variety of business problems can be formulated as optimization problems. However, this requires an appropriate problem formulation, that identifies the sources of uncertainty (known as random variables), appropriate modeling methods, and deployment solutions. In order to get started, it is necessary to identify the following elements, common to all optimization problems:</p>
<h2><b><strong style=""font-style: inherit;"">Objective Function</strong></b></h2>
<p style=""font-weight: 400;"">The objective function specifies what needs to be accomplished after solving the optimization problem. What are the quantitative goals and how are the success measures calculated? In the case of simple problems, only a single objective function is specified, whereas more complex problems require identifying multiple objective functions. </p>
<h2><b><strong style=""font-style: inherit;"">Decision Variables</strong></b></h2>
<p style=""font-weight: 400;"">The decision variables specify what data points are available for tackling the problem. These can be of various types (categorical, continuous, binary) and they have a direct impact on the result of the objective function. The number of decision variables has a direct impact on the complexity of the problem. </p>
<h2><b><strong style=""font-style: inherit;"">Constraints</strong></b></h2>
<p style=""font-weight: 400;"">The constraints correspond to conditions that must be satisfied when solving the problem. They represent business restrictions and can take many shapes (legal, economic, physical), according to the nature of the problem. Naturally, optimization models are successful when they reach the objective function and also satisfy all constraints.</p>
<p style=""font-weight: 400;"">All these elements are necessary for optimization models. They can be seen as the translation into mathematical formulas of the key characteristics of a business problem. There are many use cases for optimization models since they can be employed to improve multiple aspects <a href=""https://simplicable.com/new/business-optimization"">of a business</a>: improving processes, increasing automation, enabling efficient resource management.</p>
<p style=""font-weight: 400;"">Let us take a closer look at an optimization use case in an industry that does not run short of optimization problems.</p>
<h2>Optimization Model Use Case - A Lean and Green Supply Chain</h2>
<p style=""font-weight: 400;"">Supply chain management is built entirely around the concept of optimization.<b><strong style=""font-style: inherit;""> </strong></b>From fleet management to distribution networks and production management, many operational problems in the supply chain can be seen as an optimization challenge.<b><strong style=""font-style: inherit;""> </strong></b></p>
<p style=""font-weight: 400;"">One modern challenge for the supply chain is the implementation of the Lean and Green paradigm. With corporations seeing increased benefits (economic, environmental, and social) when accounting for their environmental impact, lean and green practices have become an indispensable part of modern supply chain strategies. </p>
<h2><b><strong style=""font-style: inherit;"">The Problem Definition</strong></b></h2>
<p style=""font-weight: 400;"">As part of an automotive corporate group, a complex supply chain network includes a variety of companies. There are raw material suppliers, plants, assemblers, collection, and disassembly centers. Each is responsible for specific kinds of processing all throughout the transformation from raw materials to finished products. Similarly, each of the different entities has a different capacity, processing, and delivery constraints. Ensuring that such a complex ecosystem stays functional requires the synchronization of all parties involved. </p>
<p style=""font-weight: 400;"">The common objective is to identify and eliminate activities that do not add value to the ecosystem and to remove those that result in unnecessary spending and waste. Also known as non-value activities, they consist of <i><em style=""font-weight: inherit;"">“overproduction, waiting, transportation, inappropriate processing, unnecessary inventory, unnecessary motion and defects in manufacturing”.</em></i></p>
<p style=""font-weight: 400;"">Understanding the intricate relations in such a complex ecosystem and achieving the lean and green objective would be impossible without a way to mathematically formulate and tackle the problem. This is where optimization modeling comes into play.</p>
<p><img class=""wp-image-3772 size-full aligncenter"" src=""https://blueorange.digital/wp-content/uploads/2022/05/Captura-de-ecrã-2020-11-25-às-12.06.13.png"" alt="""" width=""542"" height=""362"" /></p>
<p><i><em style=""font-weight: inherit;"">The structure of the optimization model. Trying to bring order into a complex world. </em></i><a href=""https://www.springer.com/de/book/9783319975108""><i><em style=""font-weight: inherit;"">Source</em></i></a></p>
<h2><b><strong style=""font-style: inherit;"">The Optimization Model</strong></b></h2>
<p style=""font-weight: 400;"">Without going into too much mathematical detail, let us take a look at the main optimization components discussed above. The model chosen to represent the network above is a linear programming model, in which the requirements are represented by linear relationships. Similarly, the model also uses a linear objective function, which is subject to linear equality and inequality constraints.</p>
<p style=""font-weight: 400;""><b><strong style=""font-style: inherit;"">The objective function</strong></b> is a weighted sum of six other functions, which need to be minimized by the optimization model. The list includes:</p>
<ul style=""font-weight: 400;"">
<li style=""font-style: inherit; font-weight: inherit;"">the transportation costs between facilities;</li>
<li style=""font-style: inherit; font-weight: inherit;"">the purchasing and operational costs;</li>
<li style=""font-style: inherit; font-weight: inherit;"">The late delivery percentages of raw material suppliers;</li>
<li style=""font-style: inherit; font-weight: inherit;"">The generated CO2 emission costs (caused by construction, transportation, manufacturing, and handling)</li>
</ul>
<p style=""font-weight: 400;"">Each function is in turn specified as a linear function of a variety of factors. Here is the formula for the CO2 emission costs, just to feed your curiosity:</p>
<p><img class=""wp-image-3774 alignnone size-full"" src=""https://blueorange.digital/wp-content/uploads/2022/05/Captura-de-ecrã-2020-11-25-às-12.09.32.png"" alt="""" width=""427"" height=""237"" /></p>
<p style=""font-weight: 400;""><i><em style=""font-weight: inherit;"">We know, we promised not to go into detail. But this looks amazing, doesn’t it? That’s why our team is here for you: so you don’t have to deal with it.</em></i></p>
<p style=""font-weight: 400;""><b><strong style=""font-style: inherit;"">The decision variables and model parameters </strong></b>include a few hundred factors, specifying anything from distances, prices, transportation duration &amp; costs to opening hours. The following are a few examples:</p>
<ul style=""font-weight: 400;"">
<li style=""font-style: inherit; font-weight: inherit;"">Amount of raw materials (in tons) shipped from the supplier to plant, using a specific vehicle</li>
<li style=""font-style: inherit; font-weight: inherit;"">Distance from the raw material supplier to plant</li>
<li style=""font-style: inherit; font-weight: inherit;"">Collection center opening hours</li>
<li style=""font-style: inherit; font-weight: inherit;"">Number of tours from the raw material supplier to the assembler </li>
<li style=""font-style: inherit; font-weight: inherit;"">Unit transportation cost of vehicle ($/ton.km)</li>
<li style=""font-style: inherit; font-weight: inherit;"">...</li>
</ul>
<p style=""font-weight: 400;""><b><strong style=""font-style: inherit;"">The constraints </strong></b>can refer to one of the following categories: capacity, demand, transportation. More complex constraints are known as balance constraints (Kirchoff Law), which ensure that the sum of flows coming into a node is equal to the sum of flows going out of that node. Once more, a few hundred formulas represent these constraints. Listing them all here is beyond the scope of this article.</p>
<h2>Conclusion</h2>
<p style=""font-weight: 400;"">The use case presented above is by no means purely theoretical. A multitude of industry players is implementing an adapted version of the Lean and Green optimization model. While the big players in the automotive industry are leading research efforts to better optimize their supply chains, companies of all sizes engage in optimization modeling across a variety of business areas. From capacity planning to network design, human resource management, inventory, and transportation management, mathematical optimization provides a way to better understand complex, intricate ecosystems.</p>
<p style=""font-weight: 400;"">Optimization is by no means restricted to specific industries. Real-world examples can be found in a variety of sectors: from internet search to telecommunications, <a href=""https://link.springer.com/chapter/10.1007/0-387-23392-X_15"">chemical processing</a>, and even <a href=""https://link.springer.com/chapter/10.1007/978-3-319-44234-1_4"">water resource management.</a> Optimization-based solutions help model uncertainty and bring a competitive advantage to decision-makers. They also offer a solid foundation for an objective, scientifically-proven decision-making process.</p>
<p style=""font-weight: 400;"">Getting started with mathematical optimization is possible for businesses of all sizes. Get in touch with our team of engineers and PhDs to better understand your business problems. We’ll pin down those that can be tackled by means of optimization and we’ll assist you on every step of the journey.</p>
<p style=""font-weight: 400;""><a href=""https://blueorange.digital/contact-us/""><i><em style=""font-weight: inherit;""><b><strong style=""font-style: inherit;"">Schedule 15-min</strong></b></em></i></a><i><em style=""font-weight: inherit;""><b><strong style=""font-style: inherit;""> with a Blue Orange Digital Solution Architect to discuss which option is right for your data sources and future goals.</strong></b></em></i></p>
<p style=""font-weight: 400;"">Josh Miramant- CEO<br />Blue Orange Digital</p>
<p style=""font-weight: 400;"">Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC.</p>
<p style=""font-weight: 400;"">Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. As an example of thought leadership, Miramant has been featured in IBM ThinkLeaders, Dell Technologies, Global Banking &amp; Finance Review, the IoT Council of Europe, among others. He can be reached at contact@blueorange.digital.</p>
<p style=""font-weight: 400;"">Blue Orange Digital is recognized as a “<b><strong style=""font-style: inherit;"">Top AI Development and Consultant Agency</strong></b>,” by Clutch and YahooFinance, for innovations in predictive analytics, automation, and optimization with machine learning in NYC. </p>
<p style=""font-weight: 400;"">They help organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things.</p>
<h2 style=""font-weight: 400;"">For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for <a href=""https://blueorange.digital/cptcasestudies/supply-chain-revenue-predictions-for-pharmaceuticals/"">Supply Chain</a>, <a href=""https://blueorange.digital/cptcasestudies/digital-transformation-of-government-documents/"">Healthcare Document Automation</a>, and <a href=""https://blueorange.digital/cptcasestudies/"">more.</a></h2>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Optimization-Modeling-1.png|https://blueorange.digital/wp-content/uploads/2022/05/Captura-de-ecrã-2020-11-25-às-12.06.13.png|https://blueorange.digital/wp-content/uploads/2022/05/Captura-de-ecrã-2020-11-25-às-12.06.13-1.png|https://blueorange.digital/wp-content/uploads/2022/05/Captura-de-ecrã-2020-11-25-às-12.09.32.png|https://blueorange.digital/wp-content/uploads/2022/05/Captura-de-ecrã-2020-11-25-às-12.09.32-1.png,Optimization-Modeling-1.png|Captura-de-ecrã-2020-11-25-às-12.06.13.png|Captura-de-ecrã-2020-11-25-às-12.06.13-1.png|Captura-de-ecrã-2020-11-25-às-12.09.32.png|Captura-de-ecrã-2020-11-25-às-12.09.32-1.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Optimization-Modeling-1.png|/www/blueorangem_500/public/wp-content/uploads/2022/05/Captura-de-ecrã-2020-11-25-às-12.06.13.png|/www/blueorangem_500/public/wp-content/uploads/2022/05/Captura-de-ecrã-2020-11-25-às-12.06.13-1.png|/www/blueorangem_500/public/wp-content/uploads/2022/05/Captura-de-ecrã-2020-11-25-às-12.09.32.png|/www/blueorangem_500/public/wp-content/uploads/2022/05/Captura-de-ecrã-2020-11-25-às-12.09.32-1.png,3771|3772|3773|3774|3775,"Optimization-Modeling-1|Captura-de-ecrã-2020-11-25-às-12.06.13|Captura-de-ecrã-2020-11-25-às-12.06.13 (1)|Captura-de-ecrã-2020-11-25-às-12.09.32|Captura-de-ecrã-2020-11-25-às-12.09.32 (1)",||||,||||,||||,https://blueorange.digital/wp-content/uploads/2022/05/Optimization-Modeling-1.png,,,,,,,,
3786,"What is Privacy by Design and its 7 Foundational Principles?","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Security remains an issue with advanced technologies. Attempts for broader user protection have led to the invention of new approaches like PbD. Privacy by Design focuses on privacy during the development of IT systems, network infrastructure, product development, internal projects, and even company policies. </p>
<p>The whole idea was initially verbalized by Dr. Ann Cavoukian. Concerned by the prevalent need for a regulatory framework that prioritized privacy,<a href=""https://en.wikipedia.org/wiki/Ann_Cavoukian""> Ann, a former Information and Privacy Commissioner of Ontario</a>, invented the concept of Privacy by Design. Since 1995, when it was formalized and to the present day, the concept has become widespread.  </p>
<p>It is essential for departments handling personal sensitive data, to have privacy design applied in their daily working processes. Addressing privacy-related issues during the early phases of a project means avoiding issues appearing in the future and impacting a large number of users. </p>
<p>The GDPR (General Data Protection Regulation) <a href=""https://gdpr-info.eu/issues/privacy-by-design/"">adopted Privacy by Design</a> in its regulations in 2010, obliging the data controllers to implement Privacy by Design in their products and infrastructure. Implementing Privacy by Design correctly, means respecting the seven Privacy by Design principles discussed below. </p>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/TKl5fyHSwtFGmuWB8hMCggWSH9r1GHuJP8lbvF4FH8Cu1u2uRAYFTTER_XCKwJpAEcTqlz_gKHNcdaK8mi2kN1hZmilz7vJnRwEVmMmewOOOydLol53epKf7j6J2f-t08T0MSI1n"" alt="""" /></figure>
<p><a href=""https://www.termsfeed.com/public/uploads/2016/10/privacy-by-design.jpg"">Source</a></p>
<h2><strong>1. Proactive and Preventative Approach, not Remedial</strong></h2>
<p>When we talk about PbD privacy regulations, the goal is to build structures that prevent breaches and invasive events from happening. Identification and anticipation are two essential strategies that emphasize taking action before any invasive event occurs. </p>
<p>This is a proactive rather than reactive approach to data privacy, as it evaluates data exposure and possible threats continuously in order to prevent them. Privacy by Design is an approach that does not provide remedies for invasive events after happening. It focuses on prevention and continuous monitoring for poor privacy design points that should be enhanced.</p>
<h2>2. Lead with Privacy as the Default Setting</h2>
<p>Individuals entering their data on a system should receive instant protection of their details without having to take any further action by themselves. Privacy should be a default rule that is followed without a second thought. To assist in achieving maximum protection, this approach suggests the limitation of data stored per individual, and stating its collection purpose beforehand. </p>
<p>Disclosure, linking, or retention of data provided by users should be limited as much as possible. Even if the individual has consented to allow the disclosure of their data in specific cases, limitation of such disclosure means stronger prevention measures. </p>
<h2>3. Embedding Privacy into the Design Process</h2>
<p>Privacy is never additional when it comes to implementation. It should be treated as an integral element that develops with the business practice, operations, information architectures, and IT systems. However, this should be done without affecting the design's full functionality. </p>
<p>Nevertheless, you should not set unchangeable standards or frameworks. The best practice is to perform audits and collect external reviews for privacy improvements but create space for upgrades and adjustments initially. Regardless of the heavy reliance on technology on a daily basis, these practices lower the impact of potential breaches in technological systems.</p>
<h2>4. Retain Full Functionality (positive-sum, not zero-sum)</h2>
<p>Having to choose between privacy and security should not be a discussion when you implement this approach. Privacy by Design states that there should be no compromise of privacy to attain better security and vice-versa. </p>
<p>A<a href=""https://www.investopedia.com/terms/z/zero-sumgame.asp""> zero-sum</a> result or impairing functionality and rejecting legitimate interests is not acceptable in Privacy by Design. Systems should retain full functionality, and even non-privacy-related regulations should be balanced in a positive-sum manner.  </p>
<h2>5. Ensure End-to-end Security Throughout Data Lifecycle</h2>
<p>Data reaches a point in its lifecycle where it needs to be permanently destroyed, and this is as important as the secured retention of data until that phase. Privacy by Design practices should be applied from the first extraction of data, accompanying it until the final process. </p>
<p>The data controllers should leave no gaps in security or accountability. Users should be granted full access throughout the data lifecycle, to access, delete and control the actions affecting their data. Integrity and confidentiality should be maintained with security in mind.</p>
<h2>6. Maintain Visibility and Transparency </h2>
<p>Privacy by Design emphasizes transparency as one of its features. Partners or stakeholders should be reassured that the practices being followed are compliant with the main objectives and agreed stipulations, and can be verified independently by them. </p>
<p>Providers and users should receive equal rights to verify and check with transparency the processes and operations they are part of. FIP (<a href=""https://iapp.org/resources/article/fair-information-practices/"">Fair Information Practices</a>) rules which focus on openness, compliance, accountability, and transparency must receive proper attention.  </p>
<h2><strong>7. Respecting User Privacy</strong></h2>
<p>Most practices on which you base the privacy protection designs should not be done independently without the involvement of the users. These implementations should be presented to users through user-friendly approaches and clear notices.</p>
<p>Respecting users’ privacy remains one of Privacy by Design’s main components. It means that users are notified of the practices their data is subjected to, as well as the option to reject or accept them. Users should be aware of breaches happening and of the available options to file complaints if needed. </p>
<h2><strong>Final Thoughts</strong></h2>
<p>Privacy by Design holds important for organizations that want to provide business partners as well as data regulators with assurance regarding an impeccable and safe user experience. It is important that the Privacy by Design checklist of seven principles is followed from the start of a project, testing phase, and until the collected data remains no longer useful.</p>
<p>Prediction and prevention are the key elements of sailing safely through the vast ocean of digital information. We believe that keeping these principles in mind is important when implementing Privacy by Design. Using Machine Learning tools and advanced analytics, Blue Orange Digital reduces operational costs, while lowering the risks and keeping privacy at an optimal state. <a href=""/services/"">Discover how.</a> </p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Privacy-by-Design-2.png,Privacy-by-Design-2.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Privacy-by-Design-2.png,3791,Privacy-by-Design-2,,,,https://blueorange.digital/wp-content/uploads/2022/05/Privacy-by-Design-2.png,,,,,,,,
3798,"Quick Wins In Real Estate With Automation","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>The real estate industry is changing rapidly. In 2019, more than 5.5 million existing homes were sold in the United States, and more activity is moving online. According to the<a href=""https://www.nar.realtor/sites/default/files/documents/2019-home-buyers-and-sellers-generational-trends-report-08-16-2019.pdf""> National Association of Realtors</a> (NAR), 50% of all buyers found the home they purchased on the Internet. While the Internet has changed some aspects of the process, it remains slow and inefficient.</p>
<p>Despite the value of the real estate market, it remains stubbornly manual. Many processes haven’t changed in decades – in-person meetings, signed documents, and paperwork define the industry. 20% of all buyers consider paperwork to be the most challenging step of the home buying process, according to the<a href=""https://www.nar.realtor/sites/default/files/documents/2019-home-buyers-and-sellers-generational-trends-report-08-16-2019.pdf""> National Association of Realtor research</a>. Automation can ease this paperwork step so you can close more deals.</p>
<p>Automation technologies are finally changing the industry. Unlike other emerging technologies, you don’t have to wait for innovations to arrive. These are wins you can achieve right now. Let’s start with improving top-line revenue with real estate automation.</p>
<h2>Robotic Process Automation For Real Estate Sales: Two Processes To Automate This Year</h2>
<p>The pain of closing a real estate transaction prevents some deals from happening. It also increases the chances of poor customer experience for the buyer or seller. If a client has a poor experience in a transaction, they are less likely to provide referrals and do repeat business. Fortunately, robotic process automation(RPA) for real estate can help in several ways.</p>
<ul>
<li><strong>Closing Process. </strong>In the final days and hours of a real estate transaction, emotions tend to run high. The seller wants the money so they can move on. The agent wants the commission they have worked hard for, and the buyer wants to start a new chapter in their life. With all these concerns, automation can expedite the filing, analysis, and verification of new forms which will reduce closing times for all parties.</li>
<li><strong>New Client Onboarding.</strong> Some companies use checklists to gather information from new clients. However, it is sometimes difficult to gather all the required information consistently every time. Robotic process automation can reach out to new prospects to collect all the needed data you need to start the relationship right. That means you can walk into your first face to face meeting with a deep understanding of what the client wants.</li>
</ul>
<p>Finding the right real estate task to automate is easy when you use a few guidelines. First, identify tasks that are done repeatedly (e.g., monthly reports or new client process). Second, determine how much of that task can be reduced to rules such as entering or processing data in an Excel spreadsheet. Each task you find that meets these two rules are candidates for automation.</p>
<p>By automating these tasks, real estate professionals will gain more time for sales, networking, and other high-value activities.</p>
<h2>How Property Managers Save Time With Robotic Process Automation</h2>
<p>As a property manager, you need to manage three factors to achieve success: the property owner, the property, and the tenants. Neglect any one of these factors, and the business suffers. From an automation standpoint, there are significant opportunities to improve tenant management. Take new tenant screening. It can take several days simply to gather the necessary baseline data like verifying past addresses, credit cards, and criminal background checks. Once that information is received, your staff have to assess the data.</p>
<p>To streamline your processes, apply robotic process automation to these property management activities.</p>
<h2>Cut Your Vacancy Rate By Bringing In Quality Tenants More Quickly.</h2>
<p>Effective tenant selection is an art and science. Get it wrong, and you end up with tenants who damage the property, fail to pay the rent and worse. Use robotic process automation to screen tenants upfront. Specifically, you can process a potential tenant’s application into your database and run analytics on that <a href=""https://www.softwaredevelopmentcompany.co/real-estate-software-developers/"">data</a>. This can save you hours of administrative effort. That means you can focus on effective conversations with your tenants. If you take too long to respond to the potential tenant, they will go elsewhere, and you will lose revenue.</p>
<h2>Optimize Back Office Operations.</h2>
<p>It may not be sexy, but reporting is critical to keeping the property owner satisfied. They want to know about costs, tenant turnover, and issues that impact the property’s value. RPA helps by gathering data, cleaning it, and getting it ready for presentation. That’s important. For example, you may have ten vendors that provide services to your properties like cleaning, repairs, and landscaping. Instead of manually reviewing each invoice before payment, use automation rules to evaluate the invoice. In seconds, an automation pool can recommend the invoice for payment based on rules you set (e.g., the price on the invoice matches the price in the contract). That means less time spent on administrative tasks each month.</p>
<h2>How To Get Quick Wins In Real Estate Automation Without Stretching Your Tech Team</h2>
<p>When you hear about automation’s power to boost the bottom line in real estate, you might ask your IT team to work on it. However, the real estate sector tends to have limited technology resources. That means that an in-house solution is unlikely to work. Reach out to a <a href=""https://www.softwaredevelopmentcompany.co/software-development-companies-new-york/"">top-ranked software</a> development agency, like <a href=""https://blueorange.digital/"">Blue Orange Digital</a>, to discuss how they can deliver real estate automation in 90 days or less.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Case-Study-Bulk-Cover-Photos.gif,Case-Study-Bulk-Cover-Photos.gif,/www/blueorangem_500/public/wp-content/uploads/2022/05/Case-Study-Bulk-Cover-Photos.gif,3826,Case-Study-Bulk-Cover-Photos,,,,https://blueorange.digital/wp-content/uploads/2022/05/Case-Study-Bulk-Cover-Photos.gif,,,,,,,,
3799,"Diversify Your Data: Identify Undervalued Properties With Alternative Data Sources","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<h2>Find diamonds in the rough and increase ROI.</h2>
A popular question among property managers and private investors is: “Is there a way to reliably identify undervalued properties?”

While this question may have found some (partial) answers in the past, today’s technological environment allows us to find answers in predictive technology. The volatile real estate market is impacted by many economic and social factors alike, whose effect is either unknown or hard to measure. The limitations of traditional real estate data are reached when trying to figure out the evolution of the real estate market. Simple historical data is not enough anymore.

<em>See also: <a href=""https://blueorange.digital/gain-a-competitive-advantage-third-party-data-is-increasing-commercial-real-estate-roi/"">Third-Party Data is Increasing Commercial Real Estate ROI</a></em>

Instead, <a href=""https://blueorange.digital/"">Blue Orange Digital</a>, a top-ranked AI development agency in New York explains how alternative data sources offer a way to accurately identify real estate market trends and identify undervalued properties.
<h2><strong>Modeling the impact of local-scale effects</strong></h2>
Since the real estate market is not only impacted by global factors, but by local factors alike, undervalued properties can be identified by modeling local dynamics.<strong> </strong>A variety of alternative data sources provide information about the behavior of markets at a local scale.

When investigating the areas surrounding a property, location data gives an accurate model of nearby activity. Tracking makes it possible to determine the usage and status of public spaces (such as parking spots), to identify the most commonly used pathways, as well as traffic patterns in a neighborhood. At the same time, IoT and sensor data can give insights with respect to both indoor and outdoor activities (shopping centers, commercial areas, drug stores, etc.). Such data can be leveraged by predictive technology to understand the impact on real estate prices.

Research has <a href=""https://www.aresjournals.org/doi/abs/10.5555/jsre.3.1.033722n763487886"">repeatedly</a> <a href=""https://onlinelibrary.wiley.com/doi/full/10.1111/ssqu.12065?casa_token=p-xV6sp8HE4AAAAA%3AeceK_9XNOUWIyvXx2KFaSrt7ioLsRH40vFk8TUZbmRA37dcrbtHupccbMQn8bgcVodZEGjQQORCsRg"">identified</a> local activity as a factor impacting real estate prices, in both commercial and residential areas. The walkability score, for example, is a popular measure that has an impact on property value. Apart from its social and environmental benefits, it has been <a href=""https://onlinelibrary.wiley.com/doi/full/10.1111/j.1540-6229.2010.00296.x?casa_token=KFAE-G6q55EAAAAA%3AVb8Ht6AJeUNnYef38gekuQeogsX-_7egwG3kVkrS1CVv-2Zplg0WmBzBXbUSpuHoYBmukG8wx_FwXA"">found</a> that “<em>All walkable property types generated higher income and therefore have the potential to generate returns as good as or better than less walkable properties, as long as they are priced correctly</em>.”

Another score that represents local activity is the so-called proximity effect. It accounts for travel times, distances to specific locations, and different modes of transportation that are available in the area. By utilizing alternative data sources, research has reached some interesting conclusions with regards to house pricing, such as the “<em>negative relation between residential values and proximity to commercial and industrial zones.</em>” With the plethora of alternative data sources available to the CRE sector, modeling different scores of local activity is now easily available.
<h2><strong>Digital transformation of real estate processes</strong></h2>
Increasing numbers of real estate transactions are happening online, producing a digital track record of investments and their value in real-time. Automated processing and tracking tools of online listings give an opportunity to identify undervalued properties that fall outside the typical market pricing range. Data scraped from real estate listing websites plays a crucial role in the estimation of both buying and selling prices.

Alternative data collected from the web can complement the traditional features used to evaluate real estate properties. For example, sociodemographic data and geographic features of an area can also be extracted from public online listings. Modern pricing models can handle heterogeneous data sources and this gives them increased accuracy for determining price-impacting factors. Once underpriced properties are identified (those with a price estimation well above their current listing value), price prediction systems can be automated to send custom alerts, helping real-estate players stay ahead of the market.
<h2><strong>Using Data Science to get more information from your data</strong></h2>
Predicting the price of commercial real estate is a difficult process. You may have a lot of data but not know what to do with it or you may want to know what data can be used to gain an advantage. First, let’s look at how you can use some of your existing data to better inform your decisions.

In the following case study, Blue Orange Digital models the effects of adding diversified data sources into advanced prediction models to more easily identify undervalued properties. For this basic demonstration, to show the value of integrating third-party data, they began with about 2,500 observations of commercial real estate sales from 2017 in New York City. The key features of this data are neighborhood, build class category (e.g. office, retail, hotel, garage), unit type(residential, commercial, and total units), year built, and gross square feet.

Using this data set they wanted to build a model that predicts the price per square foot starting with a basic model and gradually increasing the complexity to compare the accuracy rates. Finally, they added different alternative data sources to witness how that would again impact the effectiveness of the models. Noting of course, that more data, is always the first approach to increase accuracy, but even with this limited amount of data, the point is clear.

Firstly, they cleaned the data and removed any outliers to get a data set that would give the most accurate predictions. They focused their data set on properties that were selling from $100 to $1,000 per square foot since this was the price range for the majority of our observations.

Next, they wanted to mimic the current basic standard of analysis, a linear regression model, to get a baseline measure of accuracy to build upon. Using this method they found a mean square error (MSE) of $186.93. What this represents is by applying just a standard linear regression, our model predicts a value that was within +/- $186.93 of the real price. The closer your MSE is to 0, the better your model. Since we are looking only at values between $100 and $1,000 per square foot, the first prediction isn’t very good.

<em>Phase 1: Basic linear regression model: Gives a baseline comparison for improved accuracy.</em>
<table class=""wp-block-table is-style-stripes"">
<tbody>
<tr>
<td><strong>Linear Regression</strong></td>
</tr>
<tr>
<td>$186.93</td>
</tr>
</tbody>
</table>
Let’s see how the model improves with the use of more advanced algorithms and data science. Instead of using a standard linear regression model, they sampled results across three different regression models: Decision Tree, Random Forest, and a Gradient Boosting Regressor. To save you the boring details, these models are versions of regression models that each apply a different statistical methodology. Here are the MSE results for our models:

<em>Phase 2 increase accuracy: Apply complex models</em>
<table class=""wp-block-table is-style-stripes"">
<tbody>
<tr>
<td><strong>Random Forest Regressor</strong></td>
<td><strong>Decision Tree Regressor</strong></td>
<td><strong>Gradient Boosting Regressor</strong></td>
</tr>
<tr>
<td>$167.93</td>
<td>$186.92</td>
<td>$162.92</td>
</tr>
</tbody>
</table>
As you can see, the Decision Tree model performed just as poorly as our linear regression model, but our Random Forest and Gradient Boosting Model provide a significantly more accurate prediction than a standard linear regression model. You can use this model now to predict which commercial real estate listings are currently overpriced or underpriced.

Now, let’s see what happened when they added alternative data to the model. For this example, they chose to use the WalkScore API (Application Program Interface) and GoogleMaps API to help get some additional features about the data. By adding this external data they were hoping to reduce the MSE to help make a better prediction. Here are the results:

<em>Phase 3 to increase accuracy: Apply WalkScore API</em>
<table class=""wp-block-table is-style-stripes"">
<tbody>
<tr>
<td><strong>RandomForestRegressor</strong></td>
<td><strong>DecisionTreeRegressor</strong></td>
<td><strong>GradientBoostingRegressor</strong></td>
</tr>
<tr>
<td>$151.92</td>
<td>$178.60</td>
<td>$152.95</td>
</tr>
</tbody>
</table>
You can see by adding this one piece of data they were able to gain a 6% increase in accuracy in predicting price. While the mean standard error was drastically reduced from our baseline model, it is still relatively high. In order to drive down the MSE closer to 0, you would need to add more observations or more variables. Picking the right alternative data sources will depend on your market and your access to data. This is why it is important to team your commercial real estate expertise with a company like Blue Orange Digital that has the technical expertise to enrich, organize, and analyze your data to gain more analytic insight into the commercial real estate market.
<h2>Monitoring the real estate market in real-time</h2>
The volatility of the real estate market can present both a challenge and an opportunity for real-estate players. Keeping a close eye on the market fluctuations is a way to quickly identify undervalued properties, but this is hard to achieve with traditional data sets and tools. Alternative data sources allow the capturing of market patterns and the modeling of market fluctuations. Web scraped data, social media posts, and news articles are commonly integrated with traditional real-estate data for market monitoring and forecasting applications.

Traditional market forecasts rely merely on statistics provide in annual reports, financial statements, government data, which are published with a delay and only serve as descriptions for historical events. Alternative and real-time data are more suitable for market monitoring: orthogonal data sources capture a 360-degree view of the market and predictive tools can process data events as they happen. This leads to better-performing models and more reliable insights, enabling real-estate players to be proactive instead of reactive.

Additional insights have been gained by integrating <a href=""https://www.nber.org/chapters/c12994"">search indices</a> from Google Trends with the more traditional housing index price data. Beyond that, natural language processing has allowed companies to <a href=""https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1104&amp;context=pajais"">integrate online news articles</a>, based on the assumption that “<em>emotions or sentiment of words in online opinions or articles could serve as an effective indicator of the real-world,</em>” which makes such sentiment data relevant for prediction applications. Since the internet nowadays is used by most buyers and sellers engaging in real estate transactions, there is a lot of potential and economic value in alternative data.
<h2>Conclusion: Diversified data-driven investments strategies are more accurate and have a better rate of return on investment</h2>
We have seen how data science, real-time data, and sentiment analysis can bring insights that were previously hidden. This is all made possible via third-party and alternate data that provides an opportunity to understand local-scale effects and derive property value from seemingly unrelated data events. Similarly, web scraped data provides an opportunity to evaluate properties, build automated tools, and stay up-to-date with market events. Lastly, external data such as news articles, search indices, and more web-scraped data can help investors keep track of market fluctuations and establish proactive behavior, instead of reacting to data events in the past.

All in all, we can conclude that alternative data is a true compass that can help identify undervalued opportunities. When leveraged by predictive technology, there’s the potential to increase ROI and answer the sector’s most pressing questions.
<h2>What’s Next?</h2>
When you hear about the power of alternative data to boost the bottom line in real estate, you might ask your IT team to work on it. However, implementing advanced algorithms, scaling a digital transformation, and capitalizing on all the available alternative data may not be within your team’s capability nor within your budget to experiment with. That means that an in-house solution is unlikely to work. Reach out to a top-ranked software development agency, like <a href=""https://blueorange.digital/"">Blue Orange Digital</a>, to discuss how they can deliver your real estate solution in 90 days or less.

Do you have any related questions? From real estate to <a href=""https://blueorange.digital/cptcasestudies/digital-transformation-of-government-documents/"">health care</a> and <a href=""https://blueorange.digital/energy/"">energy</a>, the Blue Orange Digital team has extensive experience developing machine learning algorithms, analytic models, and custom big data solutions.

Tell us about your project today, schedule 15 minutes below to discover the power in your data.

Read More.... about alternative data sources and how they are being used to increase ROI in <em><a href=""https://blueorange.digital/gain-a-competitive-advantage-third-party-data-is-increasing-commercial-real-estate-roi/"">Third-Party Data is Increasing Commercial Real Estate ROI.</a></em>

<img class=""wp-image-3355 size-medium aligncenter"" src=""https://blueorange.digital/wp-content/uploads/2022/05/3rd-party-data-increasing-CRE-ROI.gif"" alt=""""  />

<figure class=""wp-block-image"">
<figcaption>3rd Party data increasing commercial real estate ROI</figcaption>
</figure>
<h2>About the Author</h2>
For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for <a href=""https://blueorange.digital/cptcasestudies/supply-chain-revenue-predictions-for-pharmaceuticals/"">Supply Chain</a>, <a href=""https://blueorange.digital/cptcasestudies/digital-transformation-of-government-documents/"">Healthcare Document Automation</a>, and <a href=""https://blueorange.digital/cptcasestudies/"">more</a>.

<hr class=""wp-block-separator"" />

<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img class=""wp-image-5323"" src=""https://blueorange.digital/wp-content/uploads/2020/05/Josh-Miramant-CEOpng-1024x1024.png"" alt=""Josh Miramant- CEO Blue Orange Digital"" width=""149"" height=""149"" />
<figcaption>Josh Miramant- CEO Blue Orange Digital</figcaption>
</figure></div>
Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He is a serial entrepreneur and software engineer that has built and scaled 3 startups. He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things.

Featured on IBM ThinkLeaders, Dell Technologies, and NYC’s Top 10 AI Development and Custom Software Development Agencies as reviewed on Clutch and YahooFinance for his contributions to NLP, AI, and Machine Learning. Specializing in predictive maintenance, unified data lakes, supply chain/grid/marketing/sales optimization, anomaly detection, recommendation systems, among other ML solutions for a multitude of industries.
Visit <a href=""https://blueorange.digital/"">blueorange.digital</a> for more information and <a href=""https://blueorange.digital/cptcasestudies/"">Case Studies</a>.

<em>Follow me on </em><a href=""https://twitter.com/BlueOrangeData""><em>Twitter</em></a><em> or </em><a href=""https://www.linkedin.com/in/joshmiramant/""><em>LinkedIn</em></a><em>. Check out my </em><a href=""https://blueorange.digital/""><em>website</em></a><em>. </em>

</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Diversify-you-data1.gif,Diversify-you-data1.gif,/www/blueorangem_500/public/wp-content/uploads/2022/05/Diversify-you-data1.gif,3822,Diversify-you-data1,,,,https://blueorange.digital/wp-content/uploads/2022/05/Diversify-you-data1.gif,,,,,,,,
3800,"Bold NLP and OCR: Use Cases","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Last time we’ve covered some <a href=""https://blueorange.digital/boring-machine-learning-everyone-should-get-excited-about/"">boring machine learning use cases</a>, showing how algorithms can leverage data and solve tasks in an automated manner. Today we take a closer look at two machine learning disciplines that enable advanced automation: Natural Language Processing and Optical Character Recognition. </p>
<h2><strong>Natural Language Processing</strong></h2>
<p><strong>NLP </strong>is an umbrella term defining all (machine learning) tasks aiming to understand and process human-generated text or speech. Among all machine learning disciplines, NLP faces a particularly challenging aspect: the data originating in human language and communication is highly unstructured. Online reviews, internal communication emails, newsletters and customer service logs are all examples of such unstructured data. When businesses need to handle it on a daily basis, they are not only interested in solving simple tasks (e.g. keyword extraction), but in understanding the actual meaning of the content. NLP algorithms can decipher that meaning and provide valuable interpretations of human language.</p>
<p>NLP-based applications are deployed by businesses in a variety of scenarios. Take the example of the real-estate agency that wishes to <a href=""https://medium.com/@_orcaman/gaining-insights-about-real-estate-properties-from-online-reviews-using-nlp-211c7754d1c"">evaluate tenants’ sentiments</a> towards property management. NLP models trained on reviews written in natural language can help identify the property quality, ongoing issues, and overall investment potential. A <a href=""https://dspace.mit.edu/bitstream/handle/1721.1/120609/1088413444-MIT.pdf"">study</a> covering the use of AI and ML in the real-estate sector has also identified another popular NLP-powered solution: 24/7 customer service via chatbots and virtual assistants. Having natural, personalized conversations with humans is made possible by advanced Natural Language Generation models. This gives agencies an opportunity to improve the interaction experience of their potential customers (or tenants). Last but not least, NLP tools are ideal information extraction tools. They can process, analyze and extract meaning from human-generated text and speech content. Such applications are nowadays as ubiquitous as spam filters.</p>
<p>NLP models are extremely powerful due to their capacity of handling highly unstructured data (such as natural language) and turning it into structured, analyzable data. This means that large volumes of text information can become a valuable source of business insights.</p>
<h2><strong>Optical Character Recognition</strong></h2>
<p><strong>OCR </strong>technology has developed with the business need for capturing data from physical documents. Letters, invoices, printed contracts or even images are examples of documents that need to be managed as part of daily business operations. However, high document volumes turn the most basic tasks (such as searching) into extremely time-consuming and costly endeavors. OCR tools create digital copies of said documents and can extract data into structured formats (i.e. databases). This makes the data readily available for further processing and enables quick sorting, searching and editing of the stored information.</p>
<p>OCR applications are encountered across industries. An example coming from the banking sector is the handling and processing of cheques. OCR tools perform automated cheque clearance (i.e. scanning, text conversion, and signature matching) and save time for all parties involved - the bank, the payer, the payee. In the legal sector, an example is the possibility to search across a large number of documents. OCR solutions can handle large volumes of documents and enable fast access to information, right at the moment when it’s needed. Accounts payable is another <a href=""https://softco.com/blog/power-of-ocr-software-in-ap/"">example</a> that is relevant for companies serving a large number of customers, such as the ones in the energy sector. Scanning invoice contents and storing them as key-value pairs into a database is a well-known approach to make invoice data ready for further electronic processing.</p>
<p>Examples, can, of course, be found across all industry sectors. The bottom point is: OCR technology redefines the way businesses operate with and handle documents. When digitized document information is available in a database, it becomes ready for all kinds of further processing: searching, editing, and even translating.</p>
<h2><strong>Business Benefits</strong></h2>
<p>Gartner <a href=""https://www.gartner.com/smarterwithgartner/gartner-top-10-data-analytics-trends/"">identifies</a> the disruptive potential of NLP technologies since they enable text analysis and speech recognition applications. Powered by NLP, businesses can develop solutions that:</p>
<ul>
<li>replace time-consuming manual processing with automated solutions</li>
<li>transform unstructured data into structured, analyzable data formats</li>
<li>turn text &amp; speech data into valuable assets</li>
</ul>
<p>Similarly, OCR tools have become a top priority for businesses looking to streamline their document processing workflows. The use of OCR technology brings the following advantages:</p>
<ul>
<li>Saves costs on storage space</li>
<li>Makes information easily available </li>
<li>Reduces the costs associated with manual processing</li>
</ul>
<p>The key takeaway is clear<strong>: </strong>NLP and OCR make it possible to streamline processes and improve operational efficiency. They assist businesses in their data transformation journey while helping them cut down on operational costs. This turns them into important strategic capabilities for any company that wishes to leverage their data assets.</p>
<p>Can NLP and OCR solutions be developed for your business use case? How to get started with an NLP solution? What processes can be automated via OCR?</p>
<p>Do you have any related questions? From <a href=""https://blueorange.digital/cptcasestudies/removing-bias-from-hiring-with-natural-language-processing/"">HR</a> to <a href=""https://blueorange.digital/cptcasestudies/digital-transformation-of-government-documents/"">health care</a>, the Blue Orange Digital team has extensive experience with OCR and NLP based solutions.<br /><a href=""mailto:contactus@blueorange.digital"">Get in touch</a> and we are happy to provide you with answers!</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/NLP-OCR.png,NLP-OCR.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/NLP-OCR.png,3801,NLP-OCR,,,,https://blueorange.digital/wp-content/uploads/2022/05/NLP-OCR.png,,,,,,,,
3806,"Why Consider Data Fabric Solutions?","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Data fabric is being used more often in the data science industry and specifically in analytics and data management processes. Gartner Inc, a reputable advisory and research company, ranked data fabric among the top<a href=""https://www.gartner.com/en/newsroom/press-releases/2021-03-16-gartner-identifies-top-10-data-and-analytics-technologies-trends-for-2021""> ten technological trends for 2021</a>. Therefore, it’s worth spending a few paragraphs to delve into what a data fabric is. </p>
<p>To demystify the term, we can say that data fabric is an architecture that unifies technologies and services used on that architecture into a single environment. By using continuous analytics over traditional data management methods, it intends to simplify the deployment, extraction, and design of data in multi-cloud as well as hybrid platforms. </p>
<p>Data fabrics make use of machine learning for a faster extraction and understanding of metadata so that businesses can waste less time performing these processes manually and focus on high-priority tasks instead. It immediately maximizes the value of your data and creates room for rapid technological transformation. </p>
<p>Such solid and powerful architecture simplifies the communication and flow of data throughout the cloud, edge devices, and on-premises software. With security, data access and control, insights, and visibility, data fabric is ranked among the best ways to work with data. </p>
<figure class=""wp-block-image""><img src=""https://lh4.googleusercontent.com/4TiEtgTkNZT32rXKTaww5DOe7AaTNRAJBTaC_zLyC6BtkFfWw8XNhDW1YWlIKzCH67htID7RDT4B6WeM6bU-SFPTjbDnvfhuuN7XhmsR1Gm4lo7BC6emDfIj7Vb6jGdEYKNngWPX"" alt="""" /><br />
<figcaption><strong><a href=""https://www.irion-edm.com/data-management-insights/gartner-data-summit-irion-representative-vendor-for-data-fabric-technology/"">Source</a></strong></figcaption>
</figure>
<h2>Reasons for Using Data Fabric</h2>
<p>Several advantages turn data fabric into an optimal strategy that serves not only enterprises but also small businesses to maximize their data value across edge, cloud, and core. It allows central governance while permitting communication through private and public clouds, on-premises, IoT, and edge devices. </p>
<p>Data fabrics bring an end to frighteningly large data silos spanned across unconnected and disparate infrastructures. Utilizing a versatile set of data management practices and competencies, data fabrics enable consistent communication among your unified environments. That said, let’s analyze three key points for why data fabric is advantageous.</p>
<h2><strong>1. Data Prompts Competitive Growth</strong></h2>
<p>Innovative technologies are developing at a fast pace, seeking architectures of data that provide data flow at a lighting speed. Customers asking for solutions care less about how you plan to achieve them, rather they want results otherwise they’ll switch to your competitors. </p>
<p>Acknowledging the value of data, organizations are adopting various methods to profit out of data by serving it in multiple formats and decreasing the operational costs in the process. If before data was bound by on-premises data centers due to the expensive and restricted processing capabilities, this has changed. IoT and cloud technologies give more options to work with data that accelerate growth. <strong>B</strong></p>
<h2><strong>2. More Efficient Transitions</strong></h2>
<p>Considering that enterprises need to work with data from multiple locations, such as <a href=""https://docs.google.com/document/d/1mfhsRw1KMeNKAKC09WuRPuxvIT-bbTE3TPdTfA41wME/edit?usp=sharing"">data lakes</a>, transactional data stores, application storage, cloud storage, data warehouses, machine logs, and social media storage, the entire process requires ease in data transitions.  </p>
<p>Implementing data fabrics allows seamless communication and switching when working with data between computing resources and cloud vendors. Therefore, users deal with fewer disruptions than usual, and lower the time it takes to retrieve certain insights and identify data patterns. Consequently, a reduction in processing time allows your business to make decisions faster. </p>
<h2>3. Flexible Adaptation and Evolving Potential </h2>
<p>Organizations that use data fabrics are guaranteed a smooth adaptation with new, emerging technologies and infrastructures. Best of all, connecting multiple infrastructure endpoints with a unified data management system is done with ease and without misinterpretation risks. </p>
<p>It is common for startups in their early stages to settle for low-cost storage solutions, until they can afford higher and advanced storage alternatives. Data fabrics allow an uncomplicated adaptation of infrastructures so that organizations protect their data during interventions or infrastructure upgrades.</p>
<h2><strong>Final Thoughts</strong></h2>
<p>Data fabrics provide organizations with the architecture needed to thrive in their industry by providing businesses and customers with quick answers even when these answers seek an iteration through different types of data storage. Not only does this help you fully utilize the potential of the hybrid cloud, but also gives you competitive advantages in the market. </p>
<p>Dealing with sophisticated heaps of data gets overwhelming at times. At Blue Orange Digital, we have helped multiple companies implement novel solutions that incorporate advanced analytics with machine learning.<a href=""/contact-us/""> Reach out</a> to us if you want to facilitate <a href=""/services/"">data transformation</a> while reducing time and financial costs in your daily work processes.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Data-Fabric-Blog-Cover.png,Data-Fabric-Blog-Cover.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Data-Fabric-Blog-Cover.png,3809,Data-Fabric-Blog-Cover,,,,https://blueorange.digital/wp-content/uploads/2022/05/Data-Fabric-Blog-Cover.png,,,,,,,,
3814,"Say Goodbye to Costly SQL Server Licences with AWS Babelfish","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>The rate at which we are seeing technological developments that were once thought of as fiction come to life is frightening as much as it is exciting. With the Metaverse to soon become a reality, we can expect the service we will discuss today (that’s named after a fictional fish) to be no less extraordinary. Figuratively speaking, the <a href=""https://hitchhikers.fandom.com/wiki/Babel_Fish"">Babel Fish </a>was invented by Douglas Adams in 1978 as part of his novel the <a href=""https://en.wikipedia.org/wiki/The_Hitchhiker%27s_Guide_to_the_Galaxy""> Hitchhiker’s Guide to the Galaxy</a>, only to be recreated in 2021 as a digital service. The author describes the fish as a small, odd creature that feeds on brainwave energy emitted from others around. If you were to put it into your ear all languages would become understandable to you. </p>
<p>So, in 2021 does this mean that Babelfish is a translation service? Its concept goes beyond spoken languages, and since we mentioned it is a digital service, we’ve given the most important clue. Babelfish, as AWS CEO Andy Jassy explained, “aims to reduce the need for purchasing expensive SQL server licenses.” How is the concept of translation involved in the process and what are the advantages and disadvantages of utilizing Babelfish in your infrastructure? </p>
<h2>Process faster migrations with fewer hazards</h2>
<p>It’s common for businesses to build applications based on Oracle or Microsoft SQL Servers as these have been the standards for most organizations. Settling into a new database requires an immense amount of work, which entails not only moving all the data into a new database but also rewriting SQL statements one by one. </p>
<p>The utmost benefit of using Babelfish remains the reduction of licensing fees. By using Babelfish you can migrate applications built for SQL server into PostgreSQL with ease. Only a few changes to the code are required, while database drivers can remain the same. This allows the migration process to happen seamlessly in less time. </p>
<p>This doesn’t eliminate the need for using other separate tools such as <a href=""https://aws.amazon.com/dms/"">Amazon’s Database Migration Service</a>. You have to use it to move your schema and all of your data, but it’s all done in less time because you are not required to rewrite the application code. </p>
<figure class=""wp-block-image""><img src=""https://lh4.googleusercontent.com/L-2srlrL8KZO8hI2mIHTLmVSRD1uEbX7PNJyrQKvGfoVo-5F7F-oMgwGKpmDwplq8tMbVpK4FPyemqFOxDHqqjJ7_i9zqgullLMag-212oYooDHNxMNyaN6qlsjm-T777oyYoIhy"" alt="""" /><br />
<figcaption><a href=""https://aws.amazon.com/rds/aurora/babelfish/""><em>Source</em></a></figcaption>
</figure>
<h2><strong>Build new functionalities with AWS Babelfish </strong></h2>
<p>Babelfish executes query translations in real-time to allow the use of applications built for Microsoft SQL Server to run through Amazon Aurora PostgreSQL. During the process, it also implements the requisite protocols that allow the use of SQL Server tools against PostgreSQL while migrating. Does this imply you must use only T-SQL queries forever? </p>
<p>After activation, Babelfish supports your old queries but at the same time, it allows you to build new functionality with native Postgres. While this removes the need for replacing database drivers and rewriting the application it’s a plain sailing transition to Postgres.</p>
<h2>Providing ideal data and query correctness </h2>
<p>Considering the unique ways in which both languages store data it leaves room for thinking that there could be mistakes during code translation. Matt Asay<a href=""https://aws.amazon.com/blogs/opensource/want-more-postgresql-you-just-might-like-babelfish/""> states an example</a> of these possible scenarios. In his example, the difference between databases affects how the information is stored depending on the data type and this can be a source of great confusion. </p>
<p>We can illustrate this using the Money data type. In SQL Server, the Money data type takes four digits of the decimal, while in PostgreSQL, the same data type counts only two digits to the right of the decimal. Storing a number such as $12.2343 would give us two alarmingly different results ($12.23 in PostgreSQL and $12.2343 in SQL Server). </p>
<p>With the unveiling of AWS Babelfish, Andy Jassy addressed such data risks and assured that they are receiving maximum attention from engineers to assure data and query correctness across servers and code. Developers can also contribute to the Babelfish source code <a href=""https://github.com/bblfsh"">found on Github</a> as well to further mitigate risks and identify solutions. Through these efforts, the goal is for applications not to simply execute queries correctly but also behave as if running in a SQL Server. </p>
<h2>Why managing data matters </h2>
<p>A fundamental element of working with data is its organization in a manageable and accurate way. This enables your teams to have access to in-depth insights from your business data so your organization can scale. Building these flexible data architectures is our specialty at Blue Orange Digital and we are proud to be <a href=""https://partners.amazonaws.com/partners/0010h00001cABiwAAG/"">certified AWS Partners</a>. We work with businesses of different sizes to assist in transitioning towards advanced solutions using machine learning and data science. </p>
<p>For a full list of digital transformation processes that we can assist with <a href=""/services/"">click here</a>.  To read more on Data Science and Data Transformation trends, check out our <a href=""/blog/"">related blog posts</a>.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/AWS-Babelfish-revised.png,AWS-Babelfish-revised.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/AWS-Babelfish-revised.png,3817,AWS-Babelfish-revised,,,,https://blueorange.digital/wp-content/uploads/2022/05/AWS-Babelfish-revised.png,,,,,,,,
3825,"How Players and Developers Benefit From Gamer Data","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" hover_enabled=""0"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}"" sticky_enabled=""0""]<div class=""post-blog"">
<div class=""content"">
<p>Data science tools are nowadays at the core of the most popular gaming engines on the market. We can even say that data science has become indispensable for the gaming industry, given the value it brings to a variety of stakeholders.</p>
<p>Game designers can improve features based on usage data collected in almost real-time. Developers have access to unlimited algorithmic power, only made possible by the increased availability of gaming data. Players enjoy increasingly personalized experiences, while marketing teams and business analysts can understand their behavior better than ever.</p>
<p>But what lies as the common foundation that has turned data science into such a powerful tool? We know it, you know it, everybody knows it: it’s the datasets on which the algorithms are built. None of the challenges above could be solved without advanced algorithms. These algorithms, in turn, could not be implemented without access to high-quality datasets.</p>
<h2><strong>So what makes a gaming dataset?</strong></h2>
<p>What types of data are contained in it, how are they relevant, and what kind of processing does that data need?</p>
<p>We roughly isolate the following categories: player data, activity data, and environment data.</p>
<h2><strong>Player Data</strong></h2>
<p>Player data is the kind of data that describes a player’s behavior and usage patterns: daily logins, the number of sessions, the average playtime, and maybe even their absence (tracked as the last login date). While these are all common measures found across most games, many gaming datasets contain more fine-grained data, corresponding to specific game features: progress, role, current character level, and character race.</p>
<p>From such basic features, more complex features are usually computed and added to the gaming dataset. These are usually built using common mathematical operations (such as sum, mean, max, min, etc.), which allow building features that summarize different intervals of interest. </p>
<p>Research on the topic <a href=""https://arxiv.org/pdf/1710.02262.pdf"">reports</a> using different means built over such basic data, in order to build more features: <em>“the mean is calculated over several different time periods, namely over the player’s first nine days, last nine days and full lifetime. Finally, to get the current state of the player, the total purchases, total playtime, total logins, and current level are also added. </em>”</p>
<p>A <a href=""https://arxiv.org/abs/1802.02301"">game data mining</a> competition organized in 2018 reports up to 600 features describing an individual player. However, manually crafting features also comes with a caveat: having too many features characterizing each player (and not a big enough dataset) can lead to the well-known curse of dimensionality. An appropriately large dataset needs to be available, in order for machine learning and statistical models to perform well on such multidimensional data.</p>
<p>Together with past spending habits on in-game acquisitions, you can already see how this kind of data is important: it can be used to model (and anticipate) players’ behaviors. But let’s not get ahead of ourselves here. Let us look at some more data types commonly found in gaming datasets. </p>
<h2><strong>Activity Data</strong></h2>
<p>Game Activity Data is known in the scientific literature under the name of Game Telemetry Data. If you thought Player Data can get complex, you need to see Game Activity Data in action. This kind of data refers to different game events, initiated either by the player or by the game engine. It can refer either to interactions among participants or to interactions with objects. To make things even more complex, this data is usually collected over time, which means it needs to be stored and handled as time-series data.</p>
<p>Basic activity features usually refer to all possible actions that players can take. Whether the player ducks jump or crawl if he shoots and the exact timestamp when he does it. If the player is moving an object, making an in-game purchase, or using his superpowers. This list can go on and on</p>
<p>Since these features are usually represented as timestamps, most of the data-preprocessing on activity data is dealing with transformations of time-series data points. For example, it is common to transform time-series data into the frequency domain and use that as a feature for learning. </p>
<p>The potential for manual feature engineering is once again unlimited. But modeling and gaining insights from time-series data such as game activity data requires specific algorithms and neural models. Such is the case of LSTM networks, which are known to perform well on time-series data. Another popular approach in dealing with such complex data is the use of ensemble learning when outputs from multiple networks are stacked together before being fed to other algorithms. </p>
<h2><strong>Environment Data - Game States and Objects</strong></h2>
<p>There are players, the interactions among them, and the actions they take. That must be all of it, right? Well, not really.</p>
<p>There’s plenty of other data sources in gaming environments, referring to objects, the states of the game, and the overall system parameters. On a higher abstraction level, this is data describing game progress parameters, such as the current game level, the number of interactions in each stage, or available system resources. More fine-grained information comes from the different objects in the game: their position in 3D space, their state, their motions, and even their physical characteristics (such as texture, shape, and size).</p>
<p>The data about the players’ environment and the objects that they are interacting with can be thought of as contextual information. It completes the information created by the Player Data and by the Activity Data, since analyzing the particular behavior of a player is only complete when we understand the context in which he is manifesting that behavior.</p>
<p>The particularly interesting aspect of Environment Data is the fact that such data is already at the core of the gaming engine itself. Just as object information is required for rendering, so are game parameters known, logged, and tracked by the gaming engine itself at every point in time. This turns gaming engines into an infinite source of data ready for learning. Many gaming engines even provide APIs for accessing their environments, and these can be extremely valuable for building custom data sets.</p>
<h4>Players and developers benefit from gamer data to an extent*</h4>
<p>While the gaming data categorizations above are meant to illustrate the variety and challenges of different types of gaming data, it also shows a tendency that exists in the industry: that of collecting every single event and action that happen throughout a game.</p>
<p>When it all comes together, we feel compelled to raise a warning sign about the unhealthy habit of collecting unnecessary data. Not only can this result in unnecessary processing costs, but it may actually hinder any productive analysis. Instead, observations and data collection strategies should correspond to well-defined requirements that serve very specific goals. It is only when meaningful data is collected that all stakeholders get to truly benefit from it. </p>
<hr class=""wp-block-separator"" />
<p><a href=""/contact-us/""><em>Schedule 15-min</em></a><em> with a Blue Orange Digital Solution Architect to discuss which option is right for your data sources and future goals.</em></p>
<hr class=""wp-block-separator"" />
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img class=""wp-image-5323"" src=""https://blueorange.digital/wp-content/uploads/2020/05/Josh-Miramant-CEOpng-1024x1024.png"" alt=""Josh Miramant- CEO Blue Orange Digital"" width=""216"" height=""216"" /><br />
<figcaption>Josh Miramant- CEO<br />Blue Orange Digital</figcaption>
</figure>
</div>
<p>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC.</p>
<p>Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. As an example of thought leadership, Miramant has been featured in IBM ThinkLeaders, Dell Technologies, Global Banking &amp; Finance Review, the IoT Council of Europe, among others. He can be reached at contact@blueorange.digital.</p>
<p>Blue Orange Digital is recognized as a “<strong>Top AI Development and Consultant Agency</strong>,” by Clutch and YahooFinance, for innovations in predictive analytics, automation, and optimization with machine learning in NYC. </p>
<p>They help organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things.</p>
<hr class=""wp-block-separator"" />
<p>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for <a href=""https://blueorange.digital/functions/supply-chain/"">Supply Chain</a>, <a href=""https://blueorange.digital/industries/healthcare/"">Healthcare Document Automation</a>, and <a href=""/cptcasestudies/"">more.</a></p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Gamer-Aquisition-and-Value.png,Gamer-Aquisition-and-Value.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Gamer-Aquisition-and-Value.png,2718,Gamer-Aquisition-and-Value,,,,https://blueorange.digital/wp-content/uploads/2022/05/Gamer-Aquisition-and-Value.png,,,,,,,,
3835,"Boring Machine Learning Everyone Should Get Excited About","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Machine Learning has become a strategic focal point for businesses that wish to find innovative solutions to their most complex problems. Examples of successful applications can be found in every industry and AI solutions are causing ongoing disruption to business models.</p>
<p>But there is a very simple reason why the predictive power of machine learning algorithms is so valuable for businesses: it helps them cut down on costs and resources associated with the most tedious and unrewarding tasks. Let us take a closer look at a few examples of “boring” tasks that can be delegated to machine learning tools.</p>
<h2><strong>Automated Document Processing &amp; Analysis</strong></h2>
<p>Businesses deal with large amounts of documents and written content (emails/correspondence) originating in their daily operations. Both internal and external channels are sources of information that can be collected, analyzed and turned into valuable business insights.</p>
<p>Document understanding tasks can be simple (e.g. search and match) or complex (topic modeling, keyword extraction, semantic understanding), depending on individual business use cases. However, the unstructured nature of document data makes it challenging to understand and process manually. Such tasks are tedious and overwhelming without an automated analysis and parsing approach. Some may even be unsolvable due to the large data volumes and large processing times involved.</p>
<p>Computer vision methods (such as OCR) and NLP tools are known solutions for various document understanding tasks. They have evolved from traditional rule-based approaches and can be trained on large amounts of data. Automated parsing results in faster document processing times and increased accuracy. Also, they make it straightforward to scale when more processing power is needed.</p>
<h2><strong>Intelligent Conversational Interfaces</strong></h2>
<p>Businesses in all sectors face a constant need to offer high-quality customer service. Be it assisting online shoppers, providing answers to technical questions, or suggesting products, it is all about serving customers with the information they need when they need it.</p>
<p>Traditional customer and <a href=""https://www.designrush.com/agency/software-development"">technical support</a> teams need to deal with large volumes of routine inquiries while having limited availability. This usually results in long interaction times, decreased customer engagement, and wasted resources. Also, outdated communication channels may not satisfy customers’ needs for an immediate response, which may negatively impact sales and marketing results.</p>
<p>Intelligent conversational agents can deal with both voice and text inputs and can infer responses to natural language queries. They learn from the customers’ past preferences and can provide personalized support in real-time, with permanent availability. When chatbots deal with the basic queries, they free up time for the expert human operators to tackle more complex issues.</p>
<p>The advantages for businesses are clear: an intelligent conversational solution ensures that customers can be assisted at any time, on any channel. Personalization and interaction are known to improve customer engagement. Also, there are no limits to the volume of queries that can be handled. When more chatbots are needed, more can be deployed. </p>
<h2><strong>Data Extraction and Information Retrieval</strong></h2>
<p>Apart from leveraging their own data for valuable insights, many businesses also rely on online information for their B2B or B2C processes. Information published via the internet is available in different formats (HTML, XML, PDF, CSV) and can originate in a wide variety of sources. Ecommerce transactions, news articles, RSS feeds, marketing &amp; sales reports or customer feedback forms are only a few examples.</p>
<p>But handling such a variety is impossible by manual processing. Especially when also considering the huge data volumes and its velocity. Manual data extraction is an inherently error-prone and inefficient process. Searching for the data of interest in a source web page, copying and pasting it into a structured format (usually spreadsheets) for further analysis is not only cumbersome but also time-consuming.</p>
<p>Automated extraction frameworks were built to prevent such waste of time and resources. They can handle heterogeneous data sources and multiple formats and can be configured to stay up to date with ever-changing API specifications. The value for businesses is again clear: by removing time-consuming, error-prone, and inefficient processes they enable human staff to focus on more important business aspects. The predictive superpowers of ML tools have changed the way businesses think about, rely on, and implement artificial intelligence solutions. Achieving more with fewer resources is now possible and data assets can be turned into tangible operational improvements.</p>
<p>Blue Orange Digital has vast experience using predictive technology for otherwise boring and wasteful tasks. You can read more about our document processing solution and about our revenue prediction case study.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Boring-ML-everyone-should-get-excited-about.png,Boring-ML-everyone-should-get-excited-about.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Boring-ML-everyone-should-get-excited-about.png,3842,Boring-ML-everyone-should-get-excited-about,,,,https://blueorange.digital/wp-content/uploads/2022/05/Boring-ML-everyone-should-get-excited-about.png,,,,,,,,
3836,"Reduce Time-to-Market with AWS SageMaker No-Code ML Interface","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>Are you involved in ML training and development but non-proficiency in coding gives you headaches when testing new models and making predictions? AWS SageMaker assists data scientists, business analysts, and engineers in deploying and training efficient models with minimal ML or coding skills! </p>
<p>Organizations can implement <a href=""https://blueorange.digital/services/#analytics"">machine learning (ML) solutions</a> to decrease costs and promote business growth in challenging verticals such as predicting customer churn, credit scoring, late shipment predictions, best offers identification, pricing, manufacturing quality improvement, and demand forecasting.</p>
<p>Developing ML through the traditional cycles requires data science skills and reliable engineering knowledge, and it can take months to finish. Analysts who have bright ideas have to rely on data science teams since they lack these skills while data scientists are constantly working on more sophisticated projects which fundamentally increases the time-to-market (TTM) for a certain product, and slows down growth. </p>
<p><a href=""https://aws.amazon.com/sagemaker/"">AWS SageMaker</a> helps accelerate this process with the use of tools like Amazon SageMaker Canvas, which assists analysts in working with data from data warehouses, building ML models, and performing predictions and batch scoring for large datasets, all while writing almost no line of code. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh3.googleusercontent.com/T-0cPLQHaJ8tDi88_5ZJFgJKc8UgavTT-_qe1EmAb4bZyxC9UfO7cPjQsMSxgQ7Ap5kKLzWQ8MQC4KMAxwNZutHNNEW3eS0-bRrYtEHYaZH3gkI2NNn6mMeZ9nMi4ESkF6HiMYRG"" alt="""" /><br />
<figcaption><strong><a href=""https://aws.amazon.com/sagemaker/canvas/"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>How Does It Work?</strong></h2>
<p>Data scientists and analysts can utilize AWS SageMaker to cooperate with each other efficiently and exchange datasets, and models and build them from the ground up through a simplified point-and-click interface. The integration of the  <a href=""https://aws.amazon.com/blogs/machine-learning/add-automl-functionality-with-amazon-sagemaker-autopilot-across-accounts/"">AutoML functionality</a> into tools like Amazon Redshift, Domo, and <a href=""https://blueorange.digital/why-people-are-excited-about-snowflake/"">Snowflake</a>, is especially helpful while building these ML models, especially for non-experts. </p>
<p>The process is quite straightforward and it can be put into these steps: </p>
<ul>
<li><strong>Browsing, importing, and joining data. </strong>Garner and import data located in different sources for creating novel datasets all unified and ready to be used for training prediction models. </li>
<li><strong>Target selection. </strong>Decide on the values you’re interested to predict. </li>
<li><strong>Data preparation and analysis. </strong>Use Amazon SageMaker Canvas capabilities to sort through data, identify mistakes, cleanse them and perform deep analysis to make sure data is properly prepared for ML. </li>
<li><strong>Creating models.</strong> Seamlessly build models in minimal steps by sending them to data scientists through the Amazon SageMaker Studio and exchanging feedback. </li>
<li><strong>Generating predictions.</strong> Based on your choice and needs you can generate bulk or single predictions and understand them. </li>
</ul>
<p>Analysts aren’t required to master ML in order to produce ML models thanks to the no-code ML workspace offered in <a href=""https://aws.amazon.com/blogs/aws/announcing-amazon-sagemaker-canvas-a-visual-no-code-machine-learning-capability-for-business-analysts/"">SageMaker Canvas</a>. The IDE (Integrated Development Environment) known as Amazon SageMaker Studio allows cooperation between the parties to help them combine their expertise. This way data analysis can contribute with their experimentation results, and domain knowledge and data scientists can build pipelines while streamlining the process.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh3.googleusercontent.com/d2YoCUuK0oyXTDImmM4bEZowWpO1bwGnyHtRmpXzuiW4XmntXKdO5-Xh0DyUlGTlHAtoRyJLsUJmguTla4SXp-QQDW7m2IlU8XFWOP7yh1vduXl-Jgz_YoGzzIokwer9QHgS4DhO"" alt="""" /><br />
<figcaption><strong><a href=""https://aws.amazon.com/blogs/aws/announcing-amazon-sagemaker-canvas-a-visual-no-code-machine-learning-capability-for-business-analysts/"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>The Benefits of Using Amazon SageMaker</strong></h2>
<p>Coding knowledge, which restricts analysts from having a more active role in the production of models remains a constraint no longer. Analysts can make use of the visual interface and make ML predictions without coding skills. Does this mean that only analysts can benefit from it? </p>
<p>No. Actually, engineers can successfully deploy and manage multiple models by using SageMaker MLOps, and data scientists can prepare and build models through the SageMaker Studio. How does this reflect in benefits for the business? </p>
<h2>Diverse Contributors to ML </h2>
<p>If ML is made accessible to more people who can provide solutions and help build efficient models, this shortens the time for each model to be built. The simplification of ML into point-and-click interfaces facilitates this immensely.</p>
<h2>Scalable Data Processing</h2>
<p>Oftentimes, the presence of a large amount of data stands in the way of efficient solutions. SageMaker allows the processing, access, and labeling of considerable amounts of unstructured data (video, photos, and audio) as well as structured or tabular data with ease. </p>
<h2>Faster ML Development </h2>
<p>An optimized infrastructure aids in reducing the time it takes to train your time in working with ML-related issues. Results have brought a 10X increase in team production thanks to the use of tools that cater to different team members based on their expertise and skillsets. </p>
<h2>Standardized ML Processes</h2>
<p>You can streamline and <a href=""https://blueorange.digital/aws-sagemaker-automagically/"">automate </a>MLOps processes and practices across your organization to build, prepare, deploy and manage multiple models of large sizes, save manhours, and reduce time-to-market.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>In a Nutshell</strong></h2>
<p>Business analysts and data scientists can reduce time-to-market by implementing AWS SageMaker into their practices. Integrating it with other tools, such as Snowflake, <a href=""https://blueorange.digital/forget-about-managing-data-warehouse-infrastructure-use-amazon-redshift-serverless/"">Amazon Redshift</a>, or Amazon Simple Storage Service (Amazon S3), to allow analysts to work with data stored in these cloud-based systems as well as local datasets. </p>
<p>They can seek feedback from data scientists or decide to perform batch or single predictions to complete their models by themselves. This produces more solutions and gives data scientists time to work on complex problems that require their knowledge. </p>
<p>At Blue Orange Digital, we have <a href=""https://blueorange.digital/cptcasestudies/"">extensive experience</a> working with data for medium and large-scale organizations. As partners with Snowflake and <a href=""https://partners.amazonaws.com/partners/0010h00001cABiwAAG/"">certified AWS partners</a>, we can efficiently help you solve your data problems. <a href=""https://blueorange.digital/contact-us/"">Schedule </a>a free 30 minute discovery call with us to learn more.</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Reduce-Time-to-Market-with-AWS-Sagemaker-No-Code-ML-Interface.png,Reduce-Time-to-Market-with-AWS-Sagemaker-No-Code-ML-Interface.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Reduce-Time-to-Market-with-AWS-Sagemaker-No-Code-ML-Interface.png,3850,Reduce-Time-to-Market-with-AWS-Sagemaker-No-Code-ML-Interface,,,,https://blueorange.digital/wp-content/uploads/2022/05/Reduce-Time-to-Market-with-AWS-Sagemaker-No-Code-ML-Interface.png,,,,,,,,
3839,"Green Initiatives of Gartner’s 2020 Top Chainnovators","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2>Go Organic or Go Broke?</h2>
<p class=""has-medium-font-size""><em>The latest </em><a href=""https://www.gartner.com/en/supply-chain/research/supply-chain-innovators""><em>Gartner Chainnovators Awards</em></a><em> revealed that there was a “major methodology [shift towards] increased corporate social responsibility.” Featuring interviews with Elemica, Enevo, and VANTIQ on their green initiatives.</em></p>
<p>The <a href=""https://emtemp.gcom.cloud/ngw/globalassets/en/supply-chain/documents/trends-top-25/gartner-supply-chain-top-25-2020-white-paper.pdf"">Gartner Supply Chain Top 25 for 2020</a> lists supply chain leaders and their operational models, ranking their management practices and innovation capabilities. This year’s pandemic crisis has brought a certain degree of novelty to the ranking. In the fast-changing environment, companies needed to stay agile and make use of their transformation capabilities, to sometimes pursue goals outside of their main focus areas.</p>
<p>Despite the challenging times, the report finds that leading companies give increased attention to Environmental, Social, and Government (ESG) measures. Organizations are actively researching ways to make their supply chains more ethical and sustainable. We take a closer look at this trend and list the top initiatives that ESG-focused companies have been pursuing in the first half of 2020.</p>
<h2><strong>1. Ethical Sourcing</strong></h2>
<p>Ethical sourcing is a top priority for organizations that are aiming to run sustainable supply chains. They partner up with suppliers and encourage them to respect environmental and social standards. They also emphasize visibility well beyond the first-tier suppliers and across the entire supply network.</p>
<p>The Swedish <a href=""https://www2.hm.com/pt_pt/index.html"">H&amp;M</a> has opened up its global supply network to other players in the industry. They offer expertise as a service and enable smaller brands to pursue sustainability and share their long-term supplier partnerships. Like this, they share the keys to their own ethical practices, which have become a top priority in the past years.</p>
<p>This shows how achieving true sustainability is not an endeavor that a single company can tackle, but rather a collective effort, that includes players all around the global supply network.</p>
<p><a href=""https://elemica.com/"">Elemica</a>, digitally transform providers in supply chain logistics, Global Director of Marketing, David Cahn, mentions that they are “helping companies make green vendor choices by using electronic certificates of analysis during transit, which tell the source, quality, and all the details you need to know to make a sourcing decision.” Also noting that preferential treatment is given to green vendors, saying, “it is imperative in certain industries that ingredients are sustainable and green or they lose out on contracts.” Elemica offers a way to ensure those sourcing initiatives are enforced.</p>
<h2><strong>2. Focus on Recycling </strong></h2>
<p>Global supply chain leaders give recycling extreme importance. Not only is their production process optimized to reuse as many components as possible, but they also give their customers the possibility to engage in recycling behavior. Such is the example of <a href=""https://www.alibabagroup.com/en/global/home"">Alibaba</a>, which has deployed 75,000 recycling depots, where buyers could dispose of packaging and shipping boxes.</p>
<p>At the same time, <a href=""https://www.colgatepalmolive.com/en-us"">Colgate-Palmolive</a> has certified the first recyclable tube and aim to make all their products recyclable by 2025. They also make their research and technology open source. By sharing their findings with other companies, they help turn recycling into normal behavior and enable less resourceful companies to raise the bar on their sustainability practices. </p>
<p><em>“As government incentives and attraction to companies with green initiatives grows, so does the need to verify and track recycling and collection rates,” </em>says Geoffrey Aardsma of<strong> </strong>Enevo.<strong> </strong></p>
<p>Installing <a href=""https://www.enevo.com/blog/how-we-saved-a-multimillion-dollar-doughnut-franchise-28-161"">Enevo</a> trash sensors is one way that companies can quantify changes in recycling habits in their stores, restaurants, factories, and more. In one use case for +100 locations of a popular donut chain in the U.S., these trash sensors decreased waste costs by 28% and proved an effective way to measure and optimize recycling efforts and collection. In another case, applied to city trash collection, by tracking fill rates and setting notifications for as-needed pickups, this Enevo backed solution “optimized routes for trash collection which reduced carbon emissions by 49%.” </p>
<h2><strong>3. Conservation of Natural Resources</strong></h2>
<p>Leadership companies are aware of pressing climate issues and act accordingly. They make conservation a top priority since they recognize the crucial role that natural resources play on a global scale. They also keep an eye on the interaction between their business choices and natural environments and engage in responsible behavior for mitigating their impact.</p>
<p><a href=""https://www.unileverusa.com/"">Unilever</a> is utilizing digital tools and geospatial tracking technology, in their attempt to certify the origins of palm oil. Since this resource is crucial for the development of their personal care products, they aim to keep an eye on local issues such as deforestation and the disenfranchisement of smallholders.</p>
<p><a href=""https://vantiq.com/"">VANTIQ</a> works with companies around the world to take real-time data from IoT devices and use it to improve sustainability and operational efficiency in smart cities, supply chains, and in the supply of water:<em> </em></p>
<p><em>“WaterBit is using VANTIQ technology to help large-scale farms improve their water usage. WaterBit has hundreds of IoT-enabled sensors in place at these farms. Farmers can take action based on the data collected - and it’s working. For instance, water use has dropped by as much as 40% while water use efficiency has climbed 20% to 30%.”   </em>- David Sprinzen, VANTIQ</p>
<h2><strong>4. Commitment to Reduced Carbon Emissions </strong></h2>
<p>Awareness of their carbon footprint is a common characteristic of almost all companies in Gartner’s list of Chainnovators. While some have announced their intentions to actively try &amp; reduce carbon emissions, some are planning to reach net-zero within the next decades.</p>
<p><a href=""https://www.amazon.com/"">Amazon</a> is doing efforts in this direction and aims to reach net-zero carbon by 2040, 10 years ahead of the Paris Agreement. With their large number of physical assets and logistics infrastructure, they have already taken a series of steps towards this goal. For once, they have announced the acquisition of 100 000 electric vehicles that should start delivering in 2021. This shows commitment to the use of electric vehicles and is likely to set a global trend that more companies will follow.</p>
<h2><strong>5. Decreasing Packaging Waste</strong></h2>
<p>Top Chainnovators give extreme attention to how their product packages are designed, recycled, and repurposed. Some focus on the elimination of non-recyclable plastics, while others take an active role in dealing with post-consumer waste. Their ultimate goal is to reduce the environmental impact of their packaging and come up with innovative and sustainable solutions.</p>
<p>To illustrate, <a href=""https://www.colgatepalmolive.com/en-us"">Colgate-Palmolive</a> has invested efforts into becoming TRUE Zero Waste and into gaining that certification for a large number of its manufacturing sites. Supported by the Green Business Certification Inc. (GBCI), the TRUE Zero Waste certification program enables organizations to identify, plan, and achieve their zero waste goals. This is not an isolated case since more and more companies are defining similar initiatives (such as <a href=""https://www.coca-cola.com/"">Coca-Cola</a>’s “World Without Waste”).</p>
<h2><strong>6. Renewable Energy</strong></h2>
<p>Another ESG objective common to most Chainnovators is the transition towards renewable energy. This is a global transition, that happens across all continents, independent of national regulations and policies. Private companies have a leading role in the global transition towards clean energy.</p>
<p><a href=""https://www.apple.com/"">Apple</a>, for example, is already running all its offices, data centers, and retail locations on renewable energy. Its commitment to solving ESG issues across its global supply network has secured it a Top 5 in Gartner’s evaluation.</p>
<p>Other multinational corporations that scored particularly well on their renewable efforts are <a href=""https://www.pepsico.com/"">PepsiCo</a>, <a href=""https://us.pg.com/"">P&amp;G</a>, and <a href=""https://www.generalmills.com/"">General Mills</a>. Given the large scale at which these companies operate, it is expected that their efforts will have a long-lasting, positive impact on the global supply network.</p>
<h2><strong>7. Circular Economy</strong></h2>
<p>Particular focus on the Circular Economy is another trend observed across companies operating top global supply chains. This regenerative model enables economic development that benefits not only businesses but also the society and environment. As such, it is more and more important for global players to balance the consumption of finite resources with their economic growth.</p>
<p><a href=""https://www8.hp.com/us/en/hp-information/index.html"">HP Inc.</a> and <a href=""https://www.lenovo.com/us/en/"">Lenovo’s</a> CE practices brought the two technologies companies in the list of global Chainnovators. Their ESG strategies are centered around circularity across multiple business layers: from hardware and product development to packaging and repair/reuse policies. </p>
<p><a href=""https://www.cisco.com/"">Cisco</a> and <a href=""https://www.se.com/ww/en/"">Schneider Electric</a> have also been praised for their Circular Economy practices:</p>
<p>“<em>Leaders such as </em><a href=""https://www.cisco.com/""><em>Cisco</em></a><em> and </em><a href=""https://www.se.com/ww/en/""><em>Schneider Electric</em></a><em> are focused on recycling components from old equipment back into new offerings or, at a minimum, recapturing some value from them before safely disposing the remainder.</em>”</p>
<h2>Conclusion</h2>
<p>With all the examples above, the outcome of <a href=""https://www.gartner.com/en"">Gartner’s</a> research is clear: purpose-driven organizations take the lead in the supply chain. On their quest to develop ethical and sustainable supply networks, they constantly improve their operational models and keep awareness of their impact on the world. These changes are amplified when companies partner with machine learning capable firms like <a href=""https://blueorange.digital/"">Blue Orange Digital</a>. As <a href=""https://www.americanexpress.com/us/foreign-exchange/articles/using-AI-in-supply-chain-management/""> American Express</a> notes that, “market-research firm IDC predicts that by 2020, 50 percent of mature supply chains will use AI and advanced analytics for planning.” This leads to transformational capabilities and sustainable goals that inspire customers and employees alike. </p>
<p>In the process, supply chain practices are improved, transparency is increased and all involved parties develop for a greener, sustainable future. </p>
<hr class=""wp-block-separator"" />
<p>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for <a href=""https://blueorange.digital/cptcasestudies/supply-chain-revenue-predictions-for-pharmaceuticals/"">Supply Chain</a>, <a href=""https://blueorange.digital/cptcasestudies/digital-transformation-of-government-documents/"">Healthcare Document Automation</a>, and <a href=""https://blueorange.digital/cptcasestudies/"">more</a>.</p>
<hr class=""wp-block-separator"" />
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img src=""https://lh4.googleusercontent.com/ca-SLeC7uKAS9oBXZWi5nxK5twxVvkT_-U5sI3NVikKKPqu9psFoTLEhjvgA4fg_N75djyjpZOS_jAHYkxk0nuqiFkxHfBTIBBeonXeJjw49sdzll0vCGGFjodej7rlqBP57Atc2"" alt="""" width=""180"" height=""180"" /></figure>
</div>
<p><em>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things. </em></p>
<p><em>Featured on IBM ThinkLeaders, Dell Technologies, and CU Insight. Recognized among NYC's Top 10 AI Development and Custom Software Development Agencies by Clutch and YahooFinance for his contributions to NLP, AI, and Machine Learning. Specializing in predictive maintenance, supply chain/grid/marketing/sales optimization, unified data lakes, anomaly detection, recommendation systems, among other ML solutions for a multitude of industries. </em></p>
<p>Originally Published: <a href=""https://medium.com/datadriveninvestor/green-initiatives-of-gartners-2020-top-chainnovators-222ecae5c770"">https://medium.com/datadriveninvestor/green-initiatives-of-gartners-2020-top-chainnovators-222ecae5c770</a></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Green-Initiatives-trending-in-Supply-Chain-Innovation-with-IoT-1.jpg,Green-Initiatives-trending-in-Supply-Chain-Innovation-with-IoT-1.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/Green-Initiatives-trending-in-Supply-Chain-Innovation-with-IoT-1.jpg,3895,Green-Initiatives-trending-in-Supply-Chain-Innovation-with-IoT-1,,,,https://blueorange.digital/wp-content/uploads/2022/05/Green-Initiatives-trending-in-Supply-Chain-Innovation-with-IoT-1.jpg,,,,,,,,
3840,"4 IoT Devices in Healthcare Making An Impact Now","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>IoT technologies increase the accessibility to patient data, enable real-time decision making, and offer ease and efficiency through automation. </p>
<p>IoT-powered software solutions for the healthcare sector are shifting the focus from digitalization to intelligence. IoT technologies increase the accessibility to patient data, enable real-time decision making, and offer huge potential for automation. Combined with predictive modeling and advanced software/hardware capabilities, IoT devices are helping healthcare facilities address some of their most pressing pain points.</p>
<p>Here are four examples of innovative, IoT-powered solutions that are demonstrating the impact of technological progress upon the entire healthcare sector.</p>
<h2>1. Real-time asset management</h2>
<p>Asset management is a common challenge encountered by healthcare facilities. It requires keeping track of a variety of medical devices and being aware of their status as they move from one location to another. For all medical and management staff involved, manually keeping track of asset location &amp; condition is a time-consuming and inefficient task. Modern solutions for improving the clinical workflow are relying on automation-enabling technologies, such as IoT.</p>
<p>IoT sensors can be connected to anything and anyone. When wearable devices are used by medical staff and sensors are attached to pieces of equipment, an interconnected environment is created. Modern communication protocols (such as Bluetooth LE, Wi-Fi, Z-wave, ZigBee) enable these devices to communicate their location and real-time condition. Like this, tracking applications and solutions become possible, minimizing manual efforts and improving clinical workflows.</p>
<p><a href=""https://centrak.com/solutions/asset-tracking-management/"">Centrak</a> offers an asset tracking solution that enables medical staff to know at all times where medical equipment is located. They employ a variety of RFID technologies and provide room-level accuracy. They make it possible to use sensor-collected data for custom alerts and security measures. On top of that, they provide a way to integrate asset tracking with in-building security features, such as door locks, elevators, or security cameras. </p>
<h2>2. Improved patient compliance</h2>
<p>Patient compliance is another aspect that healthcare systems need to deal with on a regular basis. That is, making sure that patients undergoing treatment are sticking to their prescriptions. Correctly taking the medication, not missing out on the refill dates, and respecting individual routines are all behavioral challenges that have a direct impact on the treatment outcome. Dealing with the challenges of the treatment process can be achieved by leveraging modern technologies, such as IoT.</p>
<p>IoT devices are commonly used for remote monitoring. They can integrate with commonly available gadgets, such as smartphones, tablets, and wearable devices. This makes it possible to easily communicate real-time events, as they happen. Outside of the hospital, IoT technologies can provide great treatment solutions for both patients and medical staff.</p>
<p><a href=""https://www.adheretech.com/"">Adhere Tech</a> is offering an IoT-based solution for remote treatment monitoring. Their Smart Pill Bottle provides a simple yet powerful solution, that requires no setup. </p>
<p>Did the patient forget to take a pill? </p>
<p>The bottle will send them an SMS with a reminder. </p>
<p>Does the bottle need a refill? </p>
<p>You guessed it! The bottle will let them know via an SMS.</p>
<p>Is further assistance required from a pharmacist? <br />All the data collected by the Smart Pill Bottle is synced and available to the pharmacists. Like this, personalized and accurate patient support can be offered.</p>
<p>On top of this, <a href=""https://www.adheretech.com/"">Adhere Tech</a> integrates a variety of data sources, such as patient feedback and pharmacy reports. This is a fine example of how integrating contextual information can improve patient treatment and support. Such a solution only becomes possible with the use of IoT sensor frameworks.</p>
<h2>3. Automation of clinical workflows</h2>
<p>Clinical workflow automation is seeing increased attention from healthcare facilities. Throughout diagnosis, treatment and intervention, non-primary tasks still need to be carried on in order to ensure the quality of health care services. Cleaning, disinfecting, and even the simple task of bringing food to patients are tasks that are consuming valuable human resources. Solutions to some of these tasks come in the shape of autonomous, intelligent robots.</p>
<p>When sensing capabilities are combined with reasoning and freedom of movement, intelligent robots can be coworkers in real-world environments. They can navigate in indoor spaces, self-localize &amp; map entire buildings, and even do facial recognition. Not to mention that they can easily keep track and alert humans of environmental conditions, such as humidity and temperature. By integrating a variety of software and hardware technologies, these robots gain autonomy: they can assess the conditions in their environment and act accordingly, just as humans would. </p>
<p><a href=""https://www.corvus-robotics.com/delivery-robot"">Corvus Robotics</a> offers two such intelligent robots, that can tackle food delivery and disinfection. They can either be scheduled to cover specifically predefined areas, or they can be “<em>allowed to roam freely</em>” in autonomous mode. They avoid all collisions with objects and humans in their environment, make an internal map of the building, and automatically keep track of their past destinations.</p>
<blockquote class=""wp-block-quote""><p><em>“We're using IoT / healthcare robots to help disinfect areas including hospitals, and also provide deliveries autonomously (food, medicine to patients) while lowering the risk of cross-infection.</em><br /><em>By reducing healthcare professional workload in already overcrowded and understaffed areas, doctors and nurses are freed up to do higher-value tasks, leaving deliveries and disinfections to robots.”</em></p>
<p><cite>Corvus Robotics</cite></p></blockquote>
<p>Especially during the current global health crisis, such autonomous robots prove their potential. By helping ensure high hygiene standards, they keep both medical staff and patients protected, minimizing the risks of cross-infection.</p>
<h2>4. Reliable organ transplantation</h2>
<p>Organ transplantation is the medical area where real-time decisions can literally make the difference between life and death. Identifying logistic flaws in the system, removing uncertainty, and minimizing the risk for errors are imperative for the wellbeing of patients. Since transplantation networks carry out critical missions, they require state-of-the-art performance and reliability. The technological advances brought by software, hardware, and IoT platforms can support medical healthcare workers all throughout this vital undertaking.</p>
<p>IoT sensors communicate environment data from a variety of data sources. This data comes in huge volumes and varieties, and making sense of it requires modern software and hardware tools. Cloud technologies enable the collection, integration, and analysis of sensor data in real-time. These platforms make it possible to collect real-time data from an environment and take reliable decisions. Modern transplantation solutions for alerting, monitoring, and tracking are all integrating such modern technologies.</p>
<p><a href=""https://gomedigo.io/"">MediGO</a> offers an IoT and cloud-powered solution for the extremely complex transplantation system. First of all, they enable tracking the vital signs of in-transit organs. The exact location and conditions of the organ (such as humidity, temperature, pressure, and light exposure) are tracked and communicated in real-time. Additionally, the data is collected and analyzed for further operational improvements across the transplantation network.</p>
<blockquote class=""wp-block-quote""><p><em>“Transplantation requires coordinating an abundance of moving parts and communicating with Organ Procurement Organizations (OPO), transplant centers, surgeons, hospitals, couriers, patients, and other stakeholders. Right now communication between these groups is done manually -- organ arrival time is estimated based on last known location and recipients are called in to prepare for surgery without any certainty that the organ will arrive close to its estimated time.”</em></p>
<p><cite><em>- </em>Chetan Paydenkar, General Manager of MediGO</cite></p></blockquote>
<p>Such a solution shows how integrating sensing technologies with modern data processing frameworks creates opportunities for more reliable health care services.</p>
<h2>What’s next?</h2>
<p>Healthcare software innovation is standing on the shoulders of giants. IoT platforms, predictive analytics, modern cloud frameworks, software &amp; hardware tools. They all power innovative healthcare solutions and create new business models and opportunities.</p>
<p>These four IoT-powered healthcare applications showed that the healthcare system is going from digital to intelligent. The autonomy, the real-time decision making, and the increased accuracy that these solutions provide make them stand out from the crowd.</p>
<p>Adopting and integrating one of these advanced technologies doesn’t need to burden your IT staff that isn’t trained on the specific implementation of these technologies. Instead partner with Blue Orange Digital, to facilitate the seamless migration of databases to cloud systems, integration with existing systems (while avoiding crashing the previous), and to explore more AI and automation options. Consult the experts in digital transformations, <a href=""https://blueorange.digital/"">Blue Orange Digital</a>, a top-ranked AI co-development firm remotely available from NYC and Washington DC.</p>
<p>We are more than excited to see what comes next in healthcare innovation. With each new and exciting innovation, hot IoT device, or artificial intelligence enhancement, we’ll be there to help you connect, update, and upgrade your business processes or co-develop a custom solution to specifically address your challenges. <a href=""https://blueorange.digital/contact-us/"">Tell us</a> about a challenge your business is facing and we’ll see how we can help.</p>
<hr class=""wp-block-separator"" />
<p>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for <a href=""https://blueorange.digital/cptcasestudies/supply-chain-revenue-predictions-for-pharmaceuticals/"">Supply Chain</a>, <a href=""https://blueorange.digital/cptcasestudies/digital-transformation-of-government-documents/"">Healthcare Document Automation</a>, and <a href=""https://blueorange.digital/cptcasestudies/"">more</a>.</p>
<hr class=""wp-block-separator"" />
<figure class=""wp-block-image""><img src=""https://lh5.googleusercontent.com/Seir2wv5bDadxdPCb2EeZbuivw8ZHNnYfL30n0wu6ET8G5QJNpKfwvhjl59v45_57IZBiVbpLq0WnqPbItUS4Fu7HF4JwWJCirU-ekjxEvHyzj5WFqyct2MV9673-0mvS9E7DLc8"" alt="""" /></figure>
<p><em>Follow me on</em><em> </em><a href=""https://twitter.com/BlueOrangeData""><em>Twitter</em></a><em> </em><em>or </em><a href=""https://www.linkedin.com/in/joshmiramant/""><em>LinkedIn</em></a><em>. </em><em>Check out my</em><em> </em><a href=""https://blueorange.digital/""><em>website</em></a><em>. </em></p>
<p>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He is a serial entrepreneur and software engineer that has built and scaled 3 startups. He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things. </p>
<p>Featured on IBM ThinkLeaders, Dell Technologies, and NYC’s Top 10 AI Development and Custom Software Development Agencies as reviewed on Clutch and YahooFinance for his contributions to NLP, AI, and Machine Learning. Specializing in predictive maintenance, unified data lakes, supply chain/grid/marketing/sales optimization, anomaly detection, recommendation systems, among other ML solutions for a multitude of industries.  <br />Visit <a href=""https://blueorange.digital/"">blueorange.digital</a> for more information and <a href=""https://blueorange.digital/cptcasestudies/"">Case Studies</a>.</p>
<p>Originally published here on <a href=""https://www.predictiveanalyticsworld.com/machinelearningtimes/4-iot-devices-in-healthcare-making-an-impact-now/11636/"">Machine Learning Times.</a></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/IoT-in-healthcare.jpg,IoT-in-healthcare.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/IoT-in-healthcare.jpg,3874,IoT-in-healthcare,,,,https://blueorange.digital/wp-content/uploads/2022/05/IoT-in-healthcare.jpg,,,,,,,,
3841,"Guesstimated Time of Arrival","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2>How IoT is delivering more accuracy in Supply Chains</h2>
<p>Traditionally, it has only been possible to look backward at the information collected from something in transit and guess the reason for delayed shipments, asserting blame to convenient scapegoats like “traffic,” when really the truck driver took a nap at a nearby gas station. Now modern tracking systems are bringing truth and clarity to the supply chain with real-time location updates, in-transit product monitoring, as well as delays and damage reports throughout the journey. Maybe the truck driver really needed that nap and that was the safest thing for her to do, now with IoT smart sensors, that can be tracked too. </p>
<p>Managing the supply chain pipeline means keeping a close eye on a multitude of processes. Reporting, dispatching, and tracking tools and staff, all need to work together to allow seamless production and delivery of products and assets. </p>
<p>The internet of things(IoT) or smart sensors are taking this challenge head-on. Offering new ways to measure and track previously un-quantifiable metrics. Combining these new data sources with advanced analytics is a strikingly affordable solution to solve a very expensive problem. By integrating multiple data sources, it is possible to gain a real-time understanding of the entire supply chain and to streamline the whole process.</p>
<p>From some context, a tech analyst company, IDC, predicts that in total there will be 41.6 billion connected IoT devices by 2025.  While IHS, a global data and information services business, reports that by 2030, 125 billion connected devices will be part of daily life.</p>
<p>That’s why Krenar Komoni, CEO, of Tive, a leading IoT tracking device owner gives this advice: </p>
<blockquote class=""wp-block-quote""><p>“Trusted brands have to have a trusted logistics partner to give the end consumer the experience they expect. Top brands want to make sure that their product arrives on time, in good condition, and are available to their devoted customers.”</p>
<p><cite>-<strong>Tive</strong></cite></p></blockquote>
<p>Ultimately, the ability to fulfill adapting consumer demands is the best metric for any successful supply chain and that be actualized through the adoption of IoT.</p>
<h2>What IoT Can Do For You</h2>
<p>Leading supply chain companies have shown an interest in IoT solutions since they have <a href=""https://www.gartner.com/en/documents/3964470"">repeatedly</a> <a href=""https://www.gartner.com/en/documents/3971188"">proven</a> to have a direct impact on cost and productivity optimization strategies. Below are some of the most popular directions in which IoT solutions can impact the supply chain sector:</p>
<ul>
<li><strong>Magnify productivity </strong>by allocating resources and equipment where they are needed</li>
<li><strong>Increase visibility </strong>by tracking and localizing assets and products all throughout the supply chain flow</li>
<li><strong>Increase the safety</strong> of workers and goods by deploying sensing hardware and intelligent software to ensure compliance</li>
<li><strong>Facilitate futuristic decision making </strong>by analyzing and visualizing real-time operational data </li>
<li><strong>Reduce waste </strong>by taking data-driven, proactive measures instead of reactive measures</li>
<li><strong>Automation </strong>for delegating repeatable, boilerplate tasks to software and algorithms</li>
</ul>
<p>Quantifying these benefits depends on the use case and the industry segment. Let us take a closer look at some real IoT applications, backed up by companies who offer IoT solutions for the supply chain.</p>
<h2>Use Case Interview Series</h2>
<h2>Equipment Monitoring and Maintenance </h2>
<p>A variety of devices, vehicles, and expensive tools need to be maintained by supply chain managers. Their functional reliability ensures the stability of the entire pipeline and has a direct impact on operational costs. </p>
<p>Remote IoT sensors collect data from different pieces of equipment and enable preventative maintenance measures. Analytics performed on such data gives accurate predictions about equipment behavior and triggers notifications to maintenance staff before it causes delays in the supply chain.</p>
<p><a href=""https://www.clearblade.com/"">ClearBlade</a>’s CEO, Eric Simone, discusses a smart monitoring use case for an aircraft manufacturing company using IoT data to get real-time visibility into operational maintenance of their assets. ClearBlade’s software “ingests information about each assets’ location, elevation history, hours of use, etc. allowing optimization of maintenance schedules and compliance.” </p>
<h2>Real-Time Remote Inspection of Product Condition</h2>
<p>Beyond knowing products are on their way via basic geolocation information, multi-sensory 5G trackers, like those from <a href=""https://tive.co/"">Tive</a>, sense shock, moisture, and temperature for a comprehensive supply chain awareness, which are relevant for the most sensitive assets. Such is the case for medical supplies, fresh food, and other perishable products that are highly dependent on a maintained environment during transit. </p>
<p><a href=""https://tive.co/"">Tive</a>’s 5G ready sensors make it possible to constantly keep an eye on these products across an ocean transit or on the other side of the globe. From damage monitoring to proper handling supervision, they provide enhanced visibility for in-transit products. This, in turn, enables a better logistics experience for all parties involved and the minimization of associated risks.</p>
<blockquote class=""wp-block-quote""><p><strong><em>“</em></strong><em>The system was able to alert a beer manufacturer that their shipment mistakenly went to 80 degrees Fahrenheit during shipment. The data from that incident allowed them to file an insurance claim to be compensated for their loss of product. The system was also able to tell a pharma distributor that their shipment went above 32 degrees Celsius when it was supposed to be between 2 and 8 C. In that case, they were able to alert the truck driver to correct the issue in real-time and save a few hundred thousand dollars on that load.""</em></p>
<p><cite><strong><em>- </em></strong><a href=""https://tive.co/""><strong><em>Tive</em></strong></a><strong><em> CEO, Krenar Komoni</em></strong></cite></p></blockquote>
<h2>Improved Efficiency with Less Waste</h2>
<p>Awareness of carbon footprinting is a common characteristic of almost all companies in Gartner’s list of <a href=""https://emtemp.gcom.cloud/ngw/globalassets/en/doc/documents/720332-high-tech-supply-chainnovator-finalists-2020-automated-contracts-planning-and-fulfillment.pdf"">Chainnovators</a>. While some have announced their intentions to actively try and reduce carbon emissions, some are planning to reach net-zero within the next decades.</p>
<p><a href=""https://aws.amazon.com/redshift/"">Amazon</a> is doing efforts in this direction and aims to reach net-zero carbon by 2040, 10 years ahead of the Paris Agreement. With their large number of physical assets and logistics infrastructure, they have already taken a series of steps towards this goal. Firstly, they have announced the acquisition of 100 000 electric vehicles that should start delivering in 2021. This shows commitment to the use of electric vehicles and is likely to set a global trend that more companies will follow.</p>
<p>An impactful example was presented by Garter as they recognized Western Digital for the ways their supply chain innovation was able to improve efficiency and reduce waste: </p>
<blockquote class=""wp-block-quote""><p>“<a href=""https://www.westerndigital.com/"">Western Digital</a> enabled cost savings as products are not in transit for as many days. Additionally, increased shipment consolidation means fewer shipments out of its facilities, leading to lower costs and fewer shipments on carbon-intensive planes, trucks, and ships, ultimately reducing its carbon footprint.”</p>
<p><cite>- <a href=""https://emtemp.gcom.cloud/ngw/globalassets/en/doc/documents/720332-high-tech-supply-chainnovator-finalists-2020-automated-contracts-planning-and-fulfillment.pdf"">Gartner</a></cite></p></blockquote>
<p><a href=""https://elemica.com/"">Elemica</a>, Global Director of Marketing, David Cahn, mentions that they are “helping companies make green vendor choices by using electronic certificates of analysis during transit, which tell the source, quality, and all the details you need to know to make a sourcing decision.” Also noting that preferential treatment is given to green vendors, saying, “it is almost an imperative in certain industries that ingredients are sustainable and green.” Elemica offers a way to ensure those sourcing initiatives are enforced.</p>
<p>These examples show the trend of society to prioritize eco-friendly options to gain market share and the way IoT is used to aid green initiatives.</p>
<h2>Safety and Compliance </h2>
<p>An IoT use case that spans well beyond the supply chain sector is that of safety and compliance. Safety measures concern all types of organizations that must ensure that they abide by the rules and regulations governing each phase of the product journey. From filing Chinese exportation documentation and ensuring expiration dates haven’t lapsed, to properly maintaining equipment to regulation standards. </p>
<p>IoT sensors can be embedded into machines but also attached to most any part of a system. A use case from ClearBlade utilizes data from a North American railroad company to ensure safety at railroad crossings.</p>
<blockquote class=""wp-block-quote""><p><em>“IoT sensor data informs railroad crossing systems of potential failures of safety measures like the lights, gates, and track switches. The system has the ability to see the amperage increase on a gate motor, and use edge-computing to know if this increase is enough to warrant a notification to be sent to alert maintenance staff about a potential malfunction.”</em></p>
<p><cite>- <a href=""https://www.clearblade.com/""><strong>ClearBlade</strong></a></cite></p></blockquote>
<p>Like this, they provide a real-time preview of their systems, which helps prevent hazardous situations before they occur.</p>
<p>Similarly, the value of asset tracking to avoid issues with regulatory compliance is evident in the following use case: </p>
<p><em> “</em><em>An airplane customer had a critical asset go missing last week. This is a common occurrence that prior to deploying ClearBlade would have taken 2 people about 2-3 days to track the asset down. Typically when a new asset goes missing, a new one needs to be purchased to carry out critical aircraft maintenance in a timely fashion to avoid FAA violations and fines. In this case, it was a $20,000 asset and they found it in 30 minutes because of the ClearBlade system.”</em></p>
<p>Another example of compliance enforcement through IoT is from <a href=""https://www.samsara.com/"">Samsara</a>, whose AI-powered Dash Cam analyzes the road and generates real-time driver report cards for fleet managers if alerted to unsafe driver behavior. This enhances driver safety while reducing accident-related costs. </p>
<h2>From Guesstimation To Predictive Modeling</h2>
<p>Today’s world is increasingly more connected through IoT-enabled machines big and small, which help humans to work smarter, not harder. By equipping machines with sensors, factory managers, logistics planners, energy grid optimizers, industrial farmers - you get the picture, can more accurately map machine workloads, inputs, and outputs. Ultimately leading to optimization and automation. </p>
<p>This input data continuously expands as technology is able to <a href=""https://blueorange.digital/cptcasestudies/digital-transformation-of-government-documents/"">convert text(OCR)</a>, speech(<a href=""https://blueorange.digital/case-study-old/nlp/"">NLP</a>), photos, reviews, customer phone calls, and more, into measurable and quantifiable information. Machine learning is used to connect the dots and find previously hidden or misunderstood causal relationships and trends. </p>
<p>That’s where <a href=""https://blueorange.digital/data-architecture-legacy-edition/"">unified data lakes</a> come in. They provide ONE singular place to put all this information and let the machine do its work at finding the hidden connections in the data. Fortunately, automation helps to ingest all these sources, by writing scripts and scrapers to go retrieve all this information from devices, social media, an old-school CRM, and while we’re at it, those old hard-drives from the ’90s. Dump that in there too. </p>
<p>As more data is available to apply to AI and ML algorithms the need increases for versatile <a href=""https://blueorange.digital/rpa/"">integration and automation experts</a> to garner real-time actionable insights. </p>
<p>Integration and Automation with Advanced Analytics</p>
<p><a href=""https://blueorange.digital/"">Blue Orange Digital</a>, a top-ranked AI co-development partner, speeds up enterprise IoT and Supply Chain companies’ innovation cycles, by assisting with the deployment of large scale custom analytics solutions. Using a data lake model, they can manipulate heterogeneous data types and gain data-insights in real-time. With the data available in a single repository, customized advanced analytics and visuals are made possible, such as anomaly detection and predictive forecasting. </p>
<blockquote class=""wp-block-quote""><p><em>“Blue Orange simplifies the process for IoT companies to make their data actionable. By building performant, advanced, secure infrastructure to enable teams to leverage real-time data for process automation, advanced optimization, and predictive analytics.”</em></p>
<p><cite><em>- </em><a href=""https://blueorange.digital/""><strong><em>Blue Orange Digital</em></strong></a></cite></p></blockquote>
<h2>What’s Next?</h2>
<p>“Firstly, we’ll feed these AI engines lots of data from IoT devices so they can create more advanced prediction models. Then you'll start to see a push of those models down to the edge, running them close to the machinery,” says <a href=""https://www.clearblade.com/"">ClearBlade</a> CEO, Eric Simone. </p>
<p>Clearly edge computing at the device level will speed up the supply chain as it will ease some of the strain on the main data source and infrastructure. Instead, each IoT device will have the capability to run machine learning algorithms right in place, filter the noise, and only send critical information back to the data store. </p>
<p>Finally,<a href=""https://elemica.com/""> Elemica</a> had this to add, “IoT has taken us from descriptive to predictive, next is prescriptive. Meaning, devices will run logic algorithms and be able to react and adapt on their own in real-time. Like the sensor that sends an alert when a truck has exceeded its temperature tolerance but instead self-adjusts the thermostat itself. That’s what’s next.”</p>
<p>All these IoT solutions and the large amounts of data they collect have laid the perfect groundwork for continued advancements in predictive intelligence and advanced data analytics. Data aggregation and collection were the foremost obstacles that supply chain organizations faced but IoT devices have bridged that gap by digitizing most of the variables in the chain. These large scale real-time machine learning algorithms finally provide companies with the speed and accuracy necessary to implement proactive measures. <a href=""https://blueorange.digital/contact-us/"">Experienced teams</a> have already had incredible success in implementing data infrastructures for a variety of supply chain solutions. </p>
<p>Special thanks to the following guest interviewees for sharing their perspectives on this ever-changing technology: </p>
<ul>
<li>Eric Simone of <a href=""https://www.clearblade.com/"">ClearBlade</a></li>
<li>Krenar Komoni of <a href=""https://tive.co/"">Tive</a></li>
<li>David Cahn of <a href=""https://elemica.com/"">Elemica</a></li>
<li>Josh Miramant of <a href=""https://blueorange.digital/"">Blue Orange Digital</a></li>
</ul>
<p>Know of an interesting Supply Chain innovation? Please mention it in the comments or get in touch, it could get featured in the next interview series.</p>
<p>Subscribe to get the latest on Machine Learning applications from Blue Orange Digital.</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Copy-of-Quesstimated-time-of-arrival-3.gif,Copy-of-Quesstimated-time-of-arrival-3.gif,/www/blueorangem_500/public/wp-content/uploads/2022/05/Copy-of-Quesstimated-time-of-arrival-3.gif,3904,Copy-of-Quesstimated-time-of-arrival-3,,,,https://blueorange.digital/wp-content/uploads/2022/05/Copy-of-Quesstimated-time-of-arrival-3.gif,,,,,,,,
3855,"Automate Customer Service with Chatbots","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>You want to improve your customer service without hiring a small army of employees. That’s when you turn to the power of machine learning. After all, you see a lot of companies out there promising to deliver 24/7 customer service with chatbots and other AI-supported tools. To make smart choices, you need to sort fact from fiction.</p>
<p> Before we explore how to harness the power of machine learning for customer service, you might be wondering if this is worth it.<a href=""https://www.computerweekly.com/news/450401505/Case-study-How-Ocado-is-using-machine-learning-to-help-customer-services-avoid-email-overload""> Ocado</a>, a UK company, used machine learning to organize a high volume of inbound customer service emails. In their case, the company started their project with 3 million customer emails. After that was loaded, the machine learning system was better able to classify incoming customer service requests and route them to the right place. That means fewer customers waiting for help.</p>
<h2>1) Inventory Your Customer Service Tasks</h2>
<p>Asking “can machine learning perform customer service?” is fundamentally the wrong question to ask. Customer service is the name of a department or a whole category of job roles. Instead, let’s get down into the details.</p>
<p>It is far more useful to examine specific customer service tasks. To do that, we need to create an inventory of the most common tasks. As a rule of thumb, only include functions that occur at least twice per month and make sure you develop a list of 10 tasks.</p>
<p>For a home appliance retailer, here are some of the customer service tasks you might expect.</p>
<ul>
<li>When will my order be delivered?</li>
<li>My machine is broken. Does the warranty cover repairs?</li>
<li>Do you have machine 123 in stock at the downtown location?</li>
<li>Is machine 123 compatible with accessory 789?</li>
<li>The repair technician was rude to my family. I want an apology</li>
<li>I want a refund for a product.</li>
</ul>
<blockquote class=""wp-block-quote""><p><em>Tip: Validate the customer service tasks you come up with by speaking with your front line customer service representatives.</em></p>
</blockquote>
<h2>2) Categorize Customer Service Tasks </h2>
<p>Using the inventory of tasks you developed in the step above, categorize each task. If the task can be effectively completed with rules and standard operating procedures, classify it as “Rule-Based.” If the task requires significant judgment, empathy or management involvement, categorize it as “non-rule based.”</p>
<p> Here are some examples:</p>
<ul>
<li>When will my order be delivered? - Rule-Based (assuming you have an order number)</li>
<li>My machine is broken. Does the warranty cover it? (Rule-Based)</li>
<li>Do you have machine 123 in stock at the downtown location? (Rule-Based)</li>
<li>Is machine 123 compatible with accessory 789? (Rule-Based - assuming you have detailed information on compatible accessories)</li>
<li>The repair technician was rude to my family. I want an apology (Non-Rule Based)</li>
<li>I want a refund for a product. (Depends on Company Policy. You might automatically approve refund requests up to a certain dollar value for instance.)</li>
</ul>
<h2> 3) Define The Key Rules Governing Rule-Based Customer Service Tasks</h2>
<p> Most machine learning projects tend to be most successful when they have a significant amount of data and rules available. Take the example of checking whether a given product is in stock. That is an entirely rule-based task - execute a query against your database. If the inventory is low (i.e., less than three units), you might add a rule to phone the location to confirm it is in stock.</p>
<p>As you define the critical rules used to complete a given customer service task, you will run into some unusual situations. For example, how do you handle a customer who has submitted multiple refund requests in a month? In that situation, you may want to question the customer further before agreeing to their request. Fortunately, there is no need to have predefined answers to every possible customer service task or question. Instead, focus on the most common questions.</p>
<h2>4) Develop A Pilot Test Project</h2>
<p>It is best to start small when you first get involved in machine learning. Therefore, we recommend that you choose one to three customer service tasks for your pilot test project. We recommend selecting tasks that tend to occur in high volume and provide value to customers — for example, giving order or delivery status information at a retailer.</p>
<p>You’re probably wondering how all of the thinking and analysis you’ve done so far connects with machine learning. That’s where the final step comes into play.</p>
<h2>5) Leverage The Expertise of A Software Company</h2>
<p>While machine learning for customer service has come a long way, using an off the shelf solution is still not good enough. You need to use the services of a<a href=""https://www.softwaredevelopmentcompany.co/software-development-companies-new-york/""> professional software development company</a> that knows machine learning and Big Data like Blue Orange. If you complete the first three steps outlined in this post before reaching out, you will have a much more productive conversation. We can set up automation for repetitive customer service tasks so your employees can spend more time on high touch customer needs.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Automate-Customer-Service-with-Chatbots.png,Automate-Customer-Service-with-Chatbots.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Automate-Customer-Service-with-Chatbots.png,3858,Automate-Customer-Service-with-Chatbots,,,,https://blueorange.digital/wp-content/uploads/2022/05/Automate-Customer-Service-with-Chatbots.png,,,,,,,,
3865,"Robotic Process Automation","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Robotic Process Automation, sometimes called Intelligent Process Automation, is the deployment of software tools with the goal of automating recurring business processes. While traditional automation means programming and integrating tools to achieve specific tasks (i.e. <em>make a machine to do task X</em>), RPA works at the User Interface level by <em>mimicking human user actions</em>. Software tools (also referred to as “robots”) are deployed on top of existing IT infrastructure and solve tasks in the same way that a human would.</p>
<h2><strong><em>Wait, so there are no actual robots involved at all?</em></strong></h2>
<p>That’s right! If anything, <a href=""https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/the-next-acronym-you-need-to-know-about-rpa"">RPA takes the robot out of the human</a>. Copying data, logging into applications, extracting information from documents, moving files and folders, filling in forms. Such repetitive tasks qualify for Robotic Process Automation since they are usually part of standardized business processes. As a result, human workers are freed from time-consuming, high-volume activities and can focus on strategic business tasks. </p>
<p>The integration of RPA is straightforward with existing IT systems and has a significant impact on operational costs while offering the possibility to scale according to business needs. It is therefore no wonder that it’s been gaining increased attention from organizations seeking to automate back- and middle-office digital processes.</p>
<p>But let us take a closer look at some global surveys covering RPA adoption in 2019. The Gartner <a href=""https://www.gartner.com/en/documents/3939733/2019-rpa-adoption-snapshot"">2019 RPA Adoption Snapshot</a> (focusing on the finance sector) has found that 80% of respondents are already implementing or planning to start employing RPA as part of their business operations. Another <a href=""https://econsultsolutions.com/2019-global-rpa-survey/"">global survey</a> covering 450 companies has classified 32% of respondents as <em>leaders (</em>i.e. having extensive experience with mature RPA applications<em>) </em>and 41% as <em>intermediates </em>(i.e. in the course of testing and planning RPA adoption). Also, they report that while RPA maturity stage varies by industry, all respondents plan to expand RPA usage within the next two years. Moreover, the <a href=""https://www2.deloitte.com/ro/en/pages/technology-media-and-telecommunications/articles/deloitte-global-rpa-survey.html""><em>Deloitte Global RPA Survey</em></a><em> </em>carried across 26 countries asked 523 executives about their RPA adoption strategy. 58% of the respondents reported they have already started their automation efforts. Additionally, 78% of those already implementing RPA solutions expect to increase RPA investments over the next three years. </p>
<p>It seems like organizations already implementing RPA <a href=""https://hbr.org/sponsored/2019/12/how-companies-are-using-intelligent-automation-to-be-more-innovative"">solutions</a> have it figured out: <em>finding the right distribution of tasks between humans and machines enables organizations to become more efficient, cut down on costs and improve the quality of their services</em>.</p>
<p>Let us take a closer look at the multifaceted value of RPA business process transformation:</p>
<h2><strong>Improved Accuracy of Data Processing </strong></h2>
<p>Reducing human intervention and relying on rule-based software bots instead is a way to completely remove any chance of errors. Since RPA also involves tracking and activity logging, it is also easier to identify, repair and avoid common processing failures. </p>
<h2><strong>Scalability and Ease of Integration</strong></h2>
<p>When additional processing resources are required, it is not necessary to train and employ new workers. Instead, it is enough to deploy a new bot, on an environment of choice (locally, or in the cloud), without performing any changes to the underlying IT infrastructure.</p>
<h2><strong>Improved Employee Morale and Customer Satisfaction</strong></h2>
<p>Assigning the repetitive tasks to robots means freeing up time and resources for employees to tackle high-value, rewarding tasks. Also, increased data processing capabilities can reduce the processing time of customer interactions, resulting in superior customer experience.</p>
<h2><strong>Increased Productivity Gains</strong></h2>
<p>Since software bots can work and process data 24/7, they can ensure permanent operations. Also, they can achieve greater speeds than their human counterpart when dealing with both structured and unstructured data inputs.</p>
<h2><strong>Reduced Operational Costs</strong></h2>
<p>Manual, repetitive, time-consuming tasks can be carried out by RPA at a fraction of the regular cost. As such, automation becomes a strategic tool for cost optimizations. Current adoption reports show how successful RPA implementations ensure a <a href=""https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/the-next-acronym-you-need-to-know-about-rpa"">positive ROI</a> within <a href=""https://www.uipath.com/solutions/whitepapers/capgemini-next-revolution"">the first year</a> of adoption.</p>
<h2><strong>Enhanced Compliance</strong></h2>
<p>RPA tasks can be recorded at each step of the process. Logs and system information are therefore easily available for audit regulation and other bureaucratic purposes. Additionally, RPA makes it straightforward to keep up with and operate in accordance with industry-specific regulations and standards.</p>
<p>The benefits of RPA are not by any means limited to a specific industry sector. On the contrary, we can wholeheartedly admit that RPA is already transforming businesses <em>in every sector</em>. From banking and health care, to customer service, insurance, retail, and manufacturing. There are countless success stories that show how RPA is the quickest way to improve performance and reduce costs. </p>
<p>There are also <a href=""https://www.clariontech.com/hubfs/Whitepaper/What-Every-Business-Need-To-Know-about-RPA-Bots.pdf"">no restrictions</a> when it comes to the scale of RPA deployment. Indeed, different synchronization and configuration efforts may be required when dealing with thousands of complex processes specific to a global corporation, as opposed to the (relatively limited) needs of a startup. But there are repetitive, rule-based processes in every business, regardless of its size. And these processes are consuming resources (time &amp; money), killing the human workforce creativity and limiting the potential of business services. Unless, of course, a carefully planned RPA strategy is defined.</p>
<p>RPA is the modern driver for business performance and efficiency. Automation investment brings benefits far beyond time and cost savings but also fosters innovation. Businesses across industries have discovered the added value of automation and <a href=""https://www.softwaredevelopmentcompany.co/custom-software-development-companies/https://www.softwaredevelopmentcompany.co/custom-software-development-companies/"">some</a> are already taking it to the next level. Blue Orange Digital, ranked among the Best Custom Software Developers of 2020, is qualified in new solutions that combine RPA with AI tools and advanced analytics (i.e. <em>Intelligent Automation) </em>and are well on their way to further reshaping tomorrow’s business operations. Take your business to the next level, whether that means recession-proof, market foresight, optimization, or automation to you, we can do it. Can you afford not to call? Free <a href=""/contact-us/"">discovery call</a> today.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Robotic-Process-Automation.png,Robotic-Process-Automation.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Robotic-Process-Automation.png,3867,Robotic-Process-Automation,,,,https://blueorange.digital/wp-content/uploads/2022/05/Robotic-Process-Automation.png,,,,,,,,
3873,"Data Lakes vs. Data Warehousing: Choosing The Right Option For Your Data Strategy","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>There’s much buzz about data lakes vs. data warehouses today. They are sophisticated tools. So, it pays to be thoughtful before putting time and energy into a business case. Let’s start with definitions.</p>
<h2>What Is A Data Warehouse?</h2>
<p>A data warehouse is an organized system that enforces high-quality standards. For instance, customer records can only be added if they meet data rules (e.g., all US states must follow two-character abbreviations). Due to these restrictions, data contained in data warehouses tend to be of high quality. There are trade-offs to consider, as well. A data warehouse requires substantial ongoing maintenance effort and it tends to be best for managing structured data.</p>
<p>Data warehouses are the right solution for cases where data integrity and accuracy are top priorities. For example, you might have financial data in a data warehouse so that your auditors have access to high-quality data. For routine activities like “produce a standard report each month,” a data warehouse is an excellent solution.</p>
<h2>What Are Data Lakes?</h2>
<p>Data lakes are much more flexible than data warehouses.</p>
<p>Conceptually, any data can be poured into a data lake: nothing is turned away. Likewise, no user is turned away – anyone may use the data. You’re no longer dependent on a small group of overworked data analysts to get insights. To illustrate why data lakes are becoming more popular, take a look at how EMC uses data lakes to improve its marketing.</p>
<p>EMC, a technology company that produces digital storage products, uses data lakes to improve marketing productivity. According to a<a href=""https://www.intel.com/content/dam/www/public/us/en/documents/case-studies/data-lake-analytics-emc-case-study.pdf""> case study published by Intel</a>, EMC reduced its marketing data query time from 4 hours to less than a minute. That means EMC can investigate many more ideas than ever before. As a result, the company can correctly predict “what and when a customer is going to purchase 80% of the time.” That level of accuracy means faster customer service because you know what customers want.</p>
<h2>Two Reasons Why Your Company Needs A Data Lake Right Now</h2>
<p>Most large companies already have data warehouses in place. Those systems serve a function. However, they require significant upfront effort in data management. They are also limited in the kinds of data they can manage – unstructured data is usually not welcome.</p>
<p>If you want to break new ground, setting up a data lake is your next step. A data lake is so much more than a standard-issue database.</p>
<h2>1) Save Time On Data Administration And Gain New Data Flexibility</h2>
<p>With a data lake, the sky is the limit for your data. Anything you want, you can put it into a data lake. It could be text, structured data sets, customer comments, invoice data and more. Unlike a data warehouse, you don’t have to do complex configurations for every type of new data you add. Eliminating time-consuming data administration and cleansing work means you have more time to extract useful insights from your data. The free form nature of data lakes means your imagination no longer limits you. Data you put into the data lake today could become helpful next year or five years from then. We’ll see an example of that next with natural disasters.</p>
<h2>2) Discover Insights With Machine Learning That Would Have Taken Years To Find With Traditional Methods</h2>
<p>With a data warehouse, you need to know the end goal of your data analysis before you start. A data lake is different! By adding a wide variety of data, you can use the power of machine learning to discover new correlations. For example,<a href=""https://www.predictiveanalyticsworld.com/machinelearningtimes/nine-bizarre-surprising-predictive-insights-data-science/8183/""> Walmart discovered</a> that hurricanes and snack purchases are correlated! Before a hurricane, the company found that Pop-Tart sales increased seven-fold! This correlation is an excellent example because few people would imagine that hurricanes could predict a specific type of sale.</p>
<p>At this point, you might be wondering which technologies to use. For insights on specific cloud technologies like Amazon Web Services, Google Cloud Platform, and Microsoft Azure, check out our post on “<a href=""https://blueorange.digital/the-cloud-war/"">The Cloud War</a>.”</p>
<h2>Making Smart Choices About Your Data Strategy Before Deciding On Data Lakes vs. Data Warehouses</h2>
<p>Before you choose a data lake or a data warehouse, take a step back. These are data tools that need to operate in the service of your strategy. For instance, you might have a marketing optimization objective that requires an in-depth understanding of your customers. Your first step will involve developing a few questions like what characteristics do our best customers have in common? Once you have that question in mind, you can start to build a data infrastructure to produce answers.</p>
<p>In our experience, most large companies will have a combination of data warehouses and data lakes. The data warehouse is needed for cases where data accuracy and integrity are non-negotiable, like financial reporting. A data lake is an excellent choice for situations where you want to encourage innovation, experimentation, and new ideas. In practice, data lakes tend to be most popular with sales, marketing, and customer service departments first. Once you become comfortable using data lakes in those areas, you can expand them to other areas.</p>
<h4>Are you feeling overwhelmed with the data lakes vs. data warehouse debate?</h4>
<p>You’re not alone. Many companies we speak with are still developing their strategies. The good news: you still have great opportunities to build an advantage with the data. The bad news: your staff may not have the skills and capacity to execute a modern data strategy. <a href=""/contact-us/"">Contact</a> Blue Orange today to discuss your data opportunities.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Case-Study-Bulk-Cover-Photos-2.png,Case-Study-Bulk-Cover-Photos-2.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Case-Study-Bulk-Cover-Photos-2.png,3880,Case-Study-Bulk-Cover-Photos-2,,,,https://blueorange.digital/wp-content/uploads/2022/05/Case-Study-Bulk-Cover-Photos-2.png,,,,,,,,
3885,"Marketing Optimization with Unified Data","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>Modern marketing tools are getting increased attention from organizations that wish to maximize the potential of their customer data. While automation efforts focus mostly on predictive analytics and modern algorithms, the magic happens one layer below, at the data layer. Today we look at the data storage model that makes it all possible: unified data. </p>
<p>As opposed to siloed data, unified data means storing all of an organization’s data in its raw form, regardless of the data source. Both structured and unstructured data are stored in a single location and become available for predictive analytics.</p>
<p>The implications for sales and marketing teams are non-negligible: unified data provides a single access point to ever-increasing amounts of customer information. Marketing automation tools, CRM systems, and campaign monitoring platforms all become connected at the data layer. When user-generated information (web &amp; mobile activity, sensor data, etc.) is added to the mix, we can say that <strong>unified data provides the full 360-degree customer view</strong>.</p>
<p>Below are some actual examples of how unified data supports advanced marketing processes. And how that enables your organization to cut down on costs and increase revenue.</p>
<p>Let’s start with <strong>customer segmentation. </strong>Figuring out <em>who </em>your customers are is one of the main prerequisites of a successful marketing strategy. In this sense, it is mandatory to analyze <strong>data from all customer touchpoints</strong>. Isolated demographic and location data used in traditional segmentation models are simply not enough anymore since they do not lead to actionable insights. Instead, all customer data must be included in the segmentation process. Emails, call center interactions, webchats, transaction logs, and other available sources. </p>
<p>A unified data architecture handles heterogeneous data sources and makes the data readily available for modern predictive tools. Automated, ML-based segmentation is <a href=""https://www.gartner.com/imagesrv/media-products/pdf/Criteo/Criteo-1-43VKFYC.pdf"">a proven way</a> to <strong>cut down manual processing costs</strong> and remove the need for labor-intensive tasks. </p>
<p>Other benefits of ML segmentation include the potential to scale on-demand, removing the human bias and dealing with an unlimited number and size of segments. Such capabilities would be unimaginable in a traditional approach, based on siloed data warehouses and human processing. But when the data is unified and predictive technology is employed, there are no limits to how you can let your customer data do the work for you. </p>
<p>Knowing about the main customer groups and their characteristics, it is then relevant to <strong>understand their behavior</strong>. Is it possible to predict <em>how</em><strong><em> </em></strong>they will interact with your business in the future? Customer LifeTime Value (CLTV) is one of the metrics indicating how much revenue will be derived from a customer and helps <a href=""https://www.ecommercecompanies.com/ecommerce-development-companies/"">marketers</a> identify the most valuable prospects. </p>
<h2>Traditional Model vs. Machine Learning Model</h2>
<p><strong>Unified data enables accurate predictions</strong> of CLTV. Unlike <a href=""https://s3.amazonaws.com/academia.edu.documents/33530722/495_serv_20090518_10_journal_of_service_research_-_lifetime_value.pdf?response-content-disposition=inline%3B%20filename%3DModeling_Customer_Lifetime_Value.pdf&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWOWYYGZ2Y53UL3A%2F20200112%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20200112T102807Z&amp;X-Amz-Expires=3600&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=1fcf0aefdbf86674cde8c75a138600be019241e7a4079c103ba59c82f6ebeb7a"">traditional RFM</a> models (that have been used in <a href=""https://www.ecommercecompanies.com/new-york-ecommerce-development-companies/"">marketing</a> for more than 3 decades) that only model CLTV based on historical transactional data, machine learning approaches extract predictive insights from customer data itself. Website analytics of your customer’s online behavior, data originating from social media interactions or sensor data of how your products are being used are all data sources that can be aggregated together in a unified architecture. When data is unified and analyzed together with the transactional data, more reliable CLTV estimates are obtained. </p>
<figure class=""wp-block-image""><img src=""https://lh4.googleusercontent.com/4zWlgIgP4H2QrtZTTr2PxJmjCa0vvYR3iGKkMsy6J4ddIP1ugO5kJ4XbmHiVNql9AXiCZ-lsfoip77wV6TaYAqSxotJJUyo3O8R39QEtbPsmtbJTxr85uuL975PivLWjpG_M51yc"" alt=""Graph shows basic historical data of how customers have spent their money."" /><br />
<figcaption><a href=""https://cloud.google.com/solutions/machine-learning/clv-prediction-with-offline-training-intro%EF%BB%BF"">Traditional</a>, are limited to probabilistic models that look at RFM values, representing Recency, Frequency &amp; Monetary values of only past transactional data.<strong> </strong></figcaption>
</figure>
<p>A Machine Learning Model enables your marketing team to plan a precise marketing strategy and only target the most valuable customers. The accuracy of the prediction becomes a guarantee for <strong>well-invested resources</strong> and <strong>reduces the time potentially wasted</strong> with unsuccessful leads.</p>
<figure class=""wp-block-image""><img src=""https://lh3.googleusercontent.com/WMKas1npya0UWgTfszmEiZ7uOPU16Wp59btQahDF_8i26RCuFoekMtxFdZxM0a-k5NZyrkB0UByMdd4qjnwoPkTChk5oDl3v4KH7J2RPt-ry_scScDZSKOD71m-GUXLhm4gJRbDC"" alt=""Machine Learning CLTV estimation models can integrate heterogeneous data sources. This chart shows how when you use a Machine Learning Model you have much more information on each customer, not just what they previously bought, but who they are, what people like them typically want. With this information, you can predict how much you can earn from them, not just right now but over a lifetime of engagement. Heterogeneous customer data originates from, you guessed it, from a unified data storage! "" /><br />
<figcaption><a href=""https://cloud.google.com/solutions/machine-learning/clv-prediction-with-offline-training-intro%EF%BB%BF"">Machine Learning</a> CLTV estimation models can integrate heterogeneous data sources. Unifying website analytics, social media, sensor data and much more.</figcaption>
</figure>
<p>The above chart shows that when you use a Machine Learning Model with heterogeneous data you have much more information on each customer from multiple sources like website analytics, social media, sensor data, and it's all integrated. This system knows not just what the customers previously bought, but who they are, what people like them typically want, how likely they are to buy, what they will buy next, etc. With this information, you can predict how much you can earn from them, not just right now but over a lifetime of engagement. Heterogeneous customer data originates from, you guessed it, unified data storage! </p>
<p>In both <a href=""https://www.intechopen.com/books/data-mining/estimating-customer-lifetime-value-using-machine-learning-techniques"">academia</a> and <a href=""https://cloud.google.com/solutions/machine-learning/clv-prediction-with-offline-training-intro"">industry</a>, machine learning CLTV models are overtaking the traditional, probabilistic models. This is yet another example of how unified data architectures play a crucial role in the development of modern predictive tools.</p>
<p>With the understanding of customer types and accurate models of their behavior in the future, you are now ready to set up a <strong>targeted marketing campaign</strong>.<strong> </strong>But <em>what </em>is the right content for each of your customers? And <em>which</em> of the plethora of channels (web/social/mobile/email/SMS) is more suitable for engaging with them? And <em>when</em> is the most suitable time to get in touch?</p>
<p>Once again, unified data to the rescue!</p>
<p>The same big data used for segmentation and behavior modeling can be repurposed to create personalized messages that customers are more likely to react to. Moreover, <strong>quick access and real-time inference</strong> are now possible and that opens a whole world of possibilities since timing is a crucial aspect in customer interaction all throughout the purchase consideration cycle.</p>
<p>The possibility to extract relevant ads and provide speed responses to customer interactions can <strong>shorten lead-to-cash cycles</strong>. Employing unified data and predictive technology also translates to <strong>less time and fewer resources</strong> for building personalized interactions with your customers. Such a strategic advantage is crucial for a successful <a href=""https://www.ecommercecompanies.com/ecommerce-consulting-agencies/"">marketing</a> strategy.</p>
<p>We have seen how unified data and predictive technology enable cheaper segmentation efforts, more accurate behavior modeling, and quicker inference for targeted marketing campaigns. </p>
<p>However, these are only a few examples of marketing and sales processes that can be optimized as part of a modern, data-focused strategy. Customer retention, lead generation &amp; scoring, demand forecasting, and many others are also susceptible to improvement by modern predictive technologies.</p>
<p>It all starts with a unified data solution and making sure your customer data is properly aggregated.</p>
<h2><a href=""https://blueorange.digital/contact-us/"">Contact us</a> today to unify your data.</h2>
<p>&nbsp;</p>
<p>See our Case Study on Marketing Optimization for a fortune 100 Energy company:</p>
<div class=""wp-block-image"">
<figure class=""aligncenter is-resized""><a href=""https://blueorange.digital/cptcasestudies/marketing-optimization-for-energy-company/""><img class=""wp-image-4303"" src=""https://blueorange.digital/wp-content/uploads/2020/02/2-1024x536.png"" alt=""Blue Orange Digital showcases its Marketing Optimization platform built for a Fortune 100 Energy Company."" width=""512"" height=""268"" /></a><br />
<figcaption>Blue Orange Digital showcases its Marketing Optimization platform built for a Fortune 100 Energy Company.<br />Social Media and Brand Management made easy.</figcaption>
</figure>
</div>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Case-Study-Bulk-Cover-Photos-3.png,Case-Study-Bulk-Cover-Photos-3.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Case-Study-Bulk-Cover-Photos-3.png,3887,Case-Study-Bulk-Cover-Photos,,,,https://blueorange.digital/wp-content/uploads/2022/05/Case-Study-Bulk-Cover-Photos-3.png,,,,,,,,
3897,"Blue Orange Digital Joins Amazon Web Services Partner Network","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<h2><em>New York-Based Cloud Engineering and Predictive Analytics Agency Solidifies Industry Expertise with AWS Partnership</em></h2>
<p>Blue Orange Digital, a boutique data science agency that provides custom data architecture and analytics services is happy to announce that they have recently achieved Select Consulting Partner status within the Amazon Web Services Partner Network (APN). This new certification solidifies Blue Orange’s expertise in providing cost-effective data architecture, analytics, and integration services. </p>
<p>Gaining the Select Consulting Partner status shows tremendous initiative by the company and its employees toward continued growth and education. Blue Orange is elated about this major step and the opportunities it will unlock for expanding, improving, and maintaining all the services they have to offer. </p>
<p>These are very exciting times for Blue Orange as they are gearing up for large growth this year. Becoming an APN partner supports our growing staff with opportunities to learn and stay on the cutting-edge of technology while bringing our clients proven solutions. As Blue Orange expands so do the industries that benefit from all the immense potential of AWS. </p>
<h2>About Blue Orange Digital</h2>
<p>Blue Orange is an emerging player in providing custom data science architecture and solutions. They offer secure big data infrastructure that unifies data for simplified access, analytics capabilities, and the use of advanced BI tools. This enables predictive analytics and data visualization for solving pressing business problems and answering the most pertinent business questions, not just in the now but in the future. All of this is done <strong>custom</strong>, for each company, for secure, high-performing, and scalable infrastructure that the client will own without vendor lock-in. Blue Orange is headquartered in New York City, with a second office in Washington DC.</p>
<h4>Follow Blue Orange Digital:  </h4>
<ul>
<li><a href=""https://www.linkedin.com/company/blue-orange-digital/"">LinkedIn</a></li>
<li><a href=""https://twitter.com/BlueOrangeData"">Twitter</a></li>
<li><a href=""https://medium.com/@BlueOrangeDigital"">Medium</a></li>
</ul>
<div class=""wp-block-image""> </div>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Copy-of-Josh-AWS.png,Copy-of-Josh-AWS.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Copy-of-Josh-AWS.png,3898,Copy-of-Josh-AWS,,,,https://blueorange.digital/wp-content/uploads/2022/05/Copy-of-Josh-AWS.png,,,,,,,,
3911,"Data Literacy: A Key Skill in The Future Workplace","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<ul>
<li>
<p>In a world driven by data, it is imperative for industry leaders to develop strong Data Literacy within their organization. <a href=""https://www.media.mit.edu/publications/designing-tools-and-activities-for-data-literacy-learners/"">Data Literacy</a> represents the ability of an organization’s personnel to “<em>identify, understand, operate on, and use data</em>”. The benefits of investing in such a skill are two-fold. On the one hand, it enables accurate, data-based communication among the employees of an enterprise. On the other hand, it allows turning data into action and eases the decision-making process. </p>
<p>Early efforts to define the term have related it to existing models, such as information literacy and statistical literacy. We propose a more pragmatic definition, inspired by the realities of the <a href=""https://www.weforum.org/about/the-fourth-industrial-revolution-by-klaus-schwab"">fourth industrial revolution</a>: </p>
<h2>Data Literacy is a fundamental business need</h2>
<p>From the health and public sector, to finance, insurance and manufacturing, the progress of a variety of <a href=""https://link.springer.com/chapter/10.1007/978-3-319-21569-3_9"">industrial sectors</a> has been driven by big data. Moreover, constant technological advances make it increasingly affordable to acquire and store data from a <a href=""https://www.sas.com/en_us/insights/big-data/what-is-big-data.html"">variety of sources</a> (industrial equipment, online platforms, smart IoT devices, etc.). This gives us the certainty that big data is still going to be one of the <a href=""https://www.rieti.go.jp/en/papers/contribution/oguro/data/07.pdf"">key pillars</a> leading the industrial revolution for many years to come.</p>
<p>However, <em>having</em> the data is different from <em>understanding</em> the data. It is crucial for businesses that wish to stay ahead to make use of the big data available to them. Investing in data literacy enables employees to read, understand, analyze and argue based on that data. That is, in our opinion, a key skill to have in the modern workplace.</p>
<p>The positive impacts of data literacy have been identified by <a href=""https://www.qlik.com/us/resource-library/the-data-literacy-index?ga-link=datalit-bp1-datalitindex-us"">The Data Literacy Index</a>, a report that aims to quantify and rank businesses according to their data literacy skills. It turns out that companies already investing in data literacy empower their workers at all hierarchical levels. Below are some common benefits and the practices used to achieve them:</p>
<h2>Impact on the productivity of data-literate employees</h2>
<ul>
<li>Business analysts, data scientists and data engineers all rely on specialized software that enables them to easily manipulate data. Having <strong>access to specialized data tools</strong> is a way to make sure that data-literate employees become productive with their daily tasks (from handling and visualizing data, to preventing data breaches and optimizing deployment pipelines). The report has found a positive correlation between the use of specific data technologies and corporate performance.</li>
</ul>
<h2>Impact on business growth opportunities</h2>
<ul>
<li>Employees directly responsible for business growth rely on storytelling, visualization, and critical thinking when working with data. The report found that <strong>democratizing access to data </strong>and ensuring <strong>training in data and analysis</strong> for such roles is common for organizations at the top of the data literacy ranking. This translates in the long run to more business growth opportunities.</li>
</ul>
<h2>Impact on data-driven decision making</h2>
<ul>
<li>Executives are responsible for maintaining a competitive advantage and for taking the right decisions. In this sense, Data Literacy skills enable them to turn data insights into correct decisions and perform their job at the highest standard. The report shows that creating a <strong>structure that supports data-driven decision making </strong>is the focus of the top data-literate organizations.</li>
</ul>
<p><strong>Getting started </strong>with Data Literacy training for employees is now more accessible than ever. Online data literacy training courses, educational guides to data literacy and proven tools are easily available for all enterprises. The <a href=""https://thedataliteracyproject.org/"">Data Literacy Project</a> is a global community that aims to develop data literacy beyond the workplace and provides everybody with the opportunity to become a data literate citizen.</p>
<p>For the enterprise still deciding whether or not to invest in data literacy skills, we point them at the data: and the data says that the top-performing companies are the most data-literate companies. Cut your financial and time investment in half by beginning your data journey by contracting an expect from <a href=""https://blueorange.digital/"">Blue Orange Digital</a>. Industry-leading data strategies and direct steps to start making your data work for you. No barrier to entry, come join us.</p>
</li>
</ul>
<div class=""wp-block-image""> </div>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/NLP_pic.jpg,NLP_pic.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/NLP_pic.jpg,3912,NLP_pic,,,,https://blueorange.digital/wp-content/uploads/2022/05/NLP_pic.jpg,,,,,,,,
3918,"Visualization Libraries for Machine Learning with Python","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<ul>
<li>
<p>You managed to install all the <strong>Essential Python Libraries</strong> for your Machine Learning project. You’ve also analyzed your data and found some interesting patterns that will definitely have an impact on your business solution.</p>
<p>Since a well-drawn graph speaks a thousand words, you decide to let the data present itself.</p>
<p>However, you are facing again a multitude of Python libraries. Which visualization library to choose for your ML project? Each of them comes with its own superpowers, so let us take a closer look at the most popular options.</p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-3258"" src=""https://blueorange.digital/wp-content/uploads/2019/12/so_trends_visualization.png"" alt=""stackoverflow visualization trends"" /><br />
<figcaption>The Stackoverflow Trends for the most popular Python Visualization Libraries. Matplotlib is the low-level solution and seems to be the default choice for a large portion of projects. In a true Pythonic manner, the other 3 libraries are built on top of it and offer a range of higher-level features.</figcaption>
</figure>
</div>
<h2><strong>Matplotlib</strong></h2>
<div class=""wp-block-image"">
<figure class=""aligncenter is-resized""><img class=""wp-image-3261"" src=""https://blueorange.digital/wp-content/uploads/2019/12/logo_matplotlib-1024x246.jpg"" alt=""Matplotlib: Python plotting"" width=""398"" height=""96"" /><br />
<figcaption>Matplotlib: Python plotting</figcaption>
</figure>
</div>
<p>As a low-level solution, <a href=""https://matplotlib.org/"">Matplotlib</a> is the standard option when it comes to exporting 2D plots and graphs. The library allows the creation of a <a href=""https://matplotlib.org/3.1.0/gallery/index.html"">variety of plots</a> and (surprise!) works out of the box with both Numpy and higher-level Pandas objects.</p>
<p>The selling point of the Matplotlib library is that its plotting environment is highly customizable. This means that the finest details like grids, legends and labels can be controlled independently of each other. </p>
<p>However, such increased flexibility comes with a cost. Be ready for a <em>steep learning curve</em> when learning about the hundreds of knobs and methods available to you. </p>
<h2><strong>Seaborn</strong></h2>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-3262"" src=""https://blueorange.digital/wp-content/uploads/2019/12/Logo_Seaborn.png"" alt=""seaborn: statistical data visualization"" /><br />
<figcaption>Seaborn: statistical data visualization</figcaption>
</figure>
</div>
<p>As a high-level visualization library, <a href=""https://seaborn.pydata.org/"">Seaborn</a> offers good looking, high-quality figures out of the box. The focus of the library is to enable visualization of various statistical models and to help you quickly explore relationships between multiple variables.</p>
<p>Sophisticated graphs can be easily created without having to worry about the underlying Matplotlib backbone, but customization is still possible if you’re feeling adventurous. The main features of this library are a set of <a href=""https://seaborn.pydata.org/tutorial/aesthetics.html#aesthetics-tutorial"">built-in visualization themes</a>, custom <a href=""https://seaborn.pydata.org/tutorial/color_palettes.html#palette-tutorial"">color palettes</a> and out of the box support for <a href=""http://seaborn.pydata.org/examples/faceted_histogram.html#faceted-histogram"">multiplot grids</a>. Really hard to resist!</p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-3263"" src=""https://blueorange.digital/wp-content/uploads/2019/12/matplotlib_vs_seaborn-1.png"" alt=""A violin plot in matplotlib (left) and seaborn (right). The looks of your figures should match the format of your publication. Try it out for yourself: https://www.datacamp.com/community/tutorials/seaborn-python-tutorial"" /><br />
<figcaption>A violin plot in matplotlib (left) and seaborn (right). The looks of your figures should match the format of your publication. Try it out for yourself: https://www.datacamp.com/community/tutorials/seaborn-python-tutorial</figcaption>
</figure>
</div>
<h2><strong>Plotly</strong></h2>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-3264"" src=""https://blueorange.digital/wp-content/uploads/2019/12/Logo_Plotly.png"" alt=""Plotly Python Graphing Library | Python | Plotly"" /><br />
<figcaption>Plotly Python Graphing Library | Python | Plotly</figcaption>
</figure>
</div>
<p>Also a high-level library, <a href=""https://plot.ly/"">Plotly</a> supports interactive visualization of data on the web. It makes it possible to either create plots and graphs from scratch or to import them from existing Matplotlib formats.</p>
<p>Setting up public or private dashboards enables <a href=""https://plot.ly/python/v3/ipython-notebooks/collaboration/"">collaboration</a> among multiple team members. On top of that, the <a href=""https://plot.ly/"">web environment</a> can be plugged into via its API from multiple programming languages (R, Matlab, and others).</p>
<p>As opposed to the previous libraries, Plotly is not open source. The additional tools that it provides via its commercial offer may however still be of interest to you or your team.</p>
<h2><strong>Bokeh</strong></h2>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-3265"" src=""https://blueorange.digital/wp-content/uploads/2019/12/Logo-Bokeh.png"" alt=""Visualization Libraries for Machine Learning with Python"" /></figure>
</div>
<p>Another choice for the fans of interactive visualization, Bokeh is a web tool ideal for sharing and collaborating on data plots. The powerful interface is based on javascript and allows the exploration of a variety of datasets: along with multidimensional tables, geolocation data and network graphs are also supported.</p>
<p>Deploying your own Bokeh server during exploratory data analysis, collaborating on interactive Jupyter notebooks and even embedding interactive plots in HTML documents are some of the most attractive features.</p>
<p>On top of that, web-like interactions (like zooming, hovering, selecting of data points) make the tool particularly suited for presenting data-based reports in modern browsers.<br />These python libraries are the most popular options that allow you to easily visualize your data and your analysis results. Next time we will try to figure out which Python Deep Learning frameworks are suited for your data-driven problem-solving.</p>
</li>
</ul>
<div class=""wp-block-image""> </div>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Python-Library-part-2-twitter.png,Python-Library-part-2-twitter.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Python-Library-part-2-twitter.png,3922,Python-Library-part-2-twitter,,,,https://blueorange.digital/wp-content/uploads/2022/05/Python-Library-part-2-twitter.png,,,,,,,,
3919,"Part 1: Private Equity Firms Maximize Portfolio Value Without Hiring More Analysts","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<p>In private equity, you’re playing a high risk and high reward game. Investors expect significant returns compared to the public markets. As a result, private equity specialists need every advantage. Simply hiring another quantitative investment analyst is not enough. Every PE firm is already doing that. Instead, you need new techniques to increase the value of your portfolio companies.</p>
<p>Leverage Points To Boost Private Equity Investments</p>
<p>Private equity is slow at adopting new technology. According to a report from the<a href=""https://knowledge.wharton.upenn.edu/article/data-analytics-slowly-transforming-private-equity/""> Wharton School</a>:</p>
<blockquote class=""wp-block-quote""><p>“when it comes to the world of private equity it’s a different story, according to Sajjad Jaffer, co-founder of the advisory and investment firm Two Six Capital. He said that when he and Ian Picache started their analytics-based firm in 2013, there had been “no technological innovation in private equity since the invention of the Excel spreadsheet.”</p>
</blockquote>
<p>In private equity, you influence the success and failure of your investments. Unlike investors in the public markets, you may have board seats and the ability to influence management decisions. At the same time, you also need to be thoughtful in how you exercise that influence. If you meddle too much, you may frustrate your portfolio company CEOs and lose credibility in the marketplace.</p>
<p>The solution to this tension? Focus on a few leverage points where your expert judgment will produce the best results. Aside from those cases, step back and let your companies operate.</p>
<ul>
<li>1) Optimize your deal sourcing with data</li>
</ul>
<ul>
<li>2) Improve portfolio company operational efficiency</li>
</ul>
<p>The first technique improves your returns by reducing the likelihood of investment mistakes. The second technique helps you to increase returns by improving operational performance. Let’s take a closer look at how Blue Orange makes both of these wins possible.</p>
<h2>PE Leverage Point: Improve Deal Sourcing</h2>
<p>In private equity, you face a difficult task to find attractive investment deals. First, you have to find companies that fit your financial criteria in terms of profitability, growth, and related criteria. Second, you need to find “blue ocean” investment opportunities where you are not competing with other investors. When you pursue hot companies with many other investors, the investment price you have to pay tends to go up, and that makes it harder to achieve significant returns. In contrast, sourcing a deal where you are the only investor at the table means you will have improved flexibility.</p>
<ul>
<li>Gather Non-Financial Data. Most private equity transactions involve private companies where there is limited public financial data. At the deal sourcing stage, you need other data points to identify promising data. Use data analytics to identify deals based on non-financial data points such as growth and engagement trends in web traffic and social media. While Internet engagement does not equate to revenue, rapid growth in these metrics suggests that a company is successfully attracting attention.</li>
<li>Enable Peer Analysis. When you look at three different companies in the cybersecurity software field, how do you evaluate them? Use data analytics to review how end customers are discussing these products (e.g., using sentiment analysis). Further in the deal process, you can use analytics to compare business model differences (e.g. pricing, customer lifetime value, and expenses).</li>
<li>Refine Investment Models. Modeling future investment returns in private equity is nothing new. Data analytics has a role to play in helping you to improve the reliability of those projections. For instance, a portfolio company projects 50% year over year revenue growth. How do you know if that is a credible forecast? Use data analytics to conduct a bottom-up financial forecast. If the company relies heavily on digital marketing methods to acquire leads and customers, it will be even easier to develop these models.</li>
</ul>
<p>To take advantage of this leverage point, you will need to adjust your methodology to consider new and unusual investment opportunities. Once you have made an investment decision, some investors take a step back. That hands-off approach is no longer good enough</p>
<h2>PE Leverage Point: Improve Portfolio Company Efficiency</h2>
<p>When you invest in middle-market companies, they are unlikely to have sophisticated analytics departments. They might have an analyst who works with marketing data and one that works on financial analysis. However, such relatively immature analytics functions tend to be backward-looking. Reporting on past events is necessary, but it is not enough.</p>
<p>As an investor, you can supplement the analytics capability of portfolio companies. Specifically, we suggest helping companies address problems such as:</p>
<ul>
<li>Quality Improvement. When a company receives a large number of customer support tickets, complaints, and other input, it is tough to know what to improve first. Use analytics to summarize and clarify the best ways to address customer needs. As a result, the company will retain more customers by improving product quality.</li>
<li>Sales and Marketing Analytics. Use analytics methods to drive down the cost of acquiring new customers. What if the company does not yet have a repeatable process to acquire customers. Data analytics can help you design and measure different tactics until you find an approach that resonates with your customers.</li>
</ul>
<p>To deliver those capabilities, you don’t need to build your internal analytics and consulting department. Instead, leverage Blue Orange Digital. We can step in and help your portfolio companies to optimize their operations.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/home_webdeveloper_pic10-1.png|https://blueorange.digital/wp-content/uploads/2022/05/home_webdeveloper_pic10.png,home_webdeveloper_pic10-1.png|home_webdeveloper_pic10.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/home_webdeveloper_pic10-1.png|/www/blueorangem_500/public/wp-content/uploads/2022/05/home_webdeveloper_pic10.png,3939|3938,home_webdeveloper_pic10|home_webdeveloper_pic10,|,|,|,https://blueorange.digital/wp-content/uploads/2022/05/home_webdeveloper_pic10-1.png,,,,,,,,
3920,"Preventing Fraud with Anomaly Detection","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<h2>Anomaly Detection with MIDAS</h2>
<p>Anomaly Detection has become one of the most useful machine learning tools of the past five years. It can be used from fraud to quality control. Is it possible to isolate fraudsters in online review websites? Can fraudulent financial transactions be detected as they occur? Can live sensor data inform about power grid failures before they happen?</p>
<p>Anomaly detection provides answers to questions like these. Identifying anomalies in data is a vital data understanding task. By exposing large datasets to machine learning tools and statistical methods, normal patterns in data can be learned. When inconsistent events occur, anomaly detection algorithms can isolate abnormal behavior and flag any events that do not correspond to the learned patterns. Such functionality is crucial in many business use-cases. Anomaly detection enables applications in a large number of sectors, from security to finance and <a href=""https://arxiv.org/abs/1804.07474"">IoT monitoring</a>. </p>
<p>Web-scale graphs are nowadays ubiquitous and are a common representation of big data structures. They power both online and offline applications. A few online examples are large social networks, product recommendation engines, and financial transaction graphs. In the offline: road networks, IoT platforms, and voltage sensors in electrical power grids are all sources of large amounts of graph-like data. Having data represented as graphs brings both benefits and challenges to the owners of said datasets. On the one hand, it allows representing data points and their relationships in a multi-dimensional space. On the other hand, scalable algorithms for data analysis and interpretation are needed. This has led to an <a href=""https://kilthub.cmu.edu/articles/Anomaly_Detection_in_Graphs_and_Time_Series_Algorithms_and_Applications/8337236"">increased research focus</a> on methods such as <strong>anomaly detection on graph data.</strong></p>
<p>Let us take a closer look at a state-of-the-art algorithm developed for anomaly detection in dynamic graph data.</p>
<h2>MIDAS</h2>
<p><strong>Microcluster-Based Detector of Anomalies in Edge Streams (MIDAS) </strong>is an algorithm that tackles anomaly detection on <em>dynamic</em> graph data. It has been developed by researchers at the National University of Singapore who claim that their method outperforms state-of-the-art approaches. Their method alleviates the most common shortcoming of previous anomaly detection implementations:</p>
<p>Below is the new baseline for anomaly detection developed by Siddarth Bhatia and his team at the University of Singapore</p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img src=""https://www.kdnuggets.com/wp-content/uploads/midas-header-updated.jpg"" alt=""Introducing MIDAS: A New Baseline for Anomaly Detection in Graphs"" /><br />
<figcaption>Introducing MIDAS: A New Baseline for Anomaly Detection in Graphs. Image Source: <a href=""https://www.kdnuggets.com/2020/04/midas-new-baseline-anomaly-detection-graphs.html"">Blog</a></figcaption>
</figure>
</div>
<h2>Representing the data as a <em>static</em> graph</h2>
<p>Static graphs contain only connectivity information and ignore temporal information. They are also known as graph snapshots and can only be used for spotting unusual graph entities (e.g. suspicious nodes, edges, or subgraphs). However, for many practical applications, the temporal aspect is equally important: it is relevant to know <em>when</em> the graph structure has changed. To illustrate, in a static graph representing network traffic stream, an edge only informs that there is a connection between a source IP address and a destination IP address. But the temporal description of the edge is missing and therefore the time when the two addresses connected is unknown. Since static graphs could not model such temporal information, anomaly detection methods built on top of such graphs provide only limited support for real-world applications.</p>
<p>On the other hand, <strong>MIDAS handles data stored in a </strong><strong><em>dynamic </em></strong><strong>graph. </strong>Each of the elements in the graph has an associated timestamp, representing the time when that element was added to the graph. Following up on the example above, a dynamic network traffic graph would also inform about <em>when</em> a connection between two IP addresses occurred. The timestamp changes whenever an existing edge or node is updated, or when new edges are added to the graph. As such, dynamic graphs are a time-evolving structure that better fits many real-world applications, which are dynamic in nature. They make it possible to use both connectivity and time information for the detection of suspicious graph elements. Based on that capability, MIDAS can detect anomalies in real-time and thus offers support for many business use-cases.</p>
<p><strong>MIDAS is optimized to work on dynamic graph data. </strong>As we’ve seen above, dynamic graphs make it possible to represent time-varying data. However, this also means that the graph structure itself also changes over time. This introduces certain challenges for the anomaly detection algorithms that aim to use this data in real-time applications. One example is the <strong>scalability of the method</strong> with regards to changing graph characteristics. Given the large data volumes corresponding to some applications, algorithms need to be linearly scalable to the size of the graph. MIDAS runs in an online fashion and processes each edge in constant time and constant memory. The authors also report that the algorithm runs <em>“162-633 times faster than state-of-the-art approaches”</em>. This makes the algorithm suitable for real-time applications, where the processing of high volume data streams is necessary. </p>
<h2>Which business use-cases need MIDAS?</h2>
<p>To gain a little insight into anomaly detection being utilized in today's business world we interviewed Canada based cryptocurrency provider, <a href=""https://ndax.io/"">NDAX</a>. NDAX uses anomaly detection within three areas of their business: general business operations, the marketing department, and the compliance team. Anomaly detection helps identify bugs, which allows them to improve website performance and client onboarding process. It also allows them to provide guidance to software development and back-office operation teams on how to resolve those issues. Website traffic is another area that can leverage the power of anomaly detection. Understanding the outliers in website traffic gives insight and better understanding to the marking team, which allows them to identify if a marketing campaign is working or not. Thus giving a clearer picture of which area is the most important to concentrate their efforts. Our last example is how client sign up anomaly helps the compliance team to identify potential fraud and reduce client risk.</p>
<p>In our discussion with NDAX Chief Compliance Officer, Julia Baranovskaya highlights how anomaly detection's importance has been emphasized during the current pandemic. There has been a 300% increase in fraud detected in the past few months. Desperate times combined with high online traffic invites scams of all sorts that target the unemployed and elderly. With anomaly detection, we are now able to turn these outliers into indicators of fraud or trends. The following graph shows how fraud has fluctuated during the front half of this year.</p>
<p>NDAX's chart below shows an increase in fraudulent activity in Q2 2020, targeting the elderly and unemployed through job scams.</p>
<div class=""wp-block-image"">
<figure class=""aligncenter""><img class=""wp-image-5774"" src=""https://blueorange.digital/wp-content/uploads/2020/08/Fraud-Trend-NDAX.png"" alt=""Anomaly Detection"" /><br />
<figcaption>NDAX found an increase in Q2, specifically scams involving the elderly and fake job postings.</figcaption>
</figure>
</div>
<h2>What About Your Business?</h2>
<p>Anomaly detection algorithms can help businesses identify and react to unusual data points in multiple scenarios. A bank security system may employ anomaly detection for the identification of fraudulent transactions. Likewise, manufacturing plant owners rely on anomaly detection for dealing with malfunctioning equipment and implementing predictive maintenance measures. In <a href=""https://bosch.io/resources/white-paper/anomaly-detection-with-event-data-in-the-internet-of-things/?ref=ot-inst-de-2016h1-technology-bosch-iot-analytics-white-paper"">IoT sensor networks</a>, anomaly detection is used as part of condition monitoring solutions and for the prevention of undesired malware deployment. The bottom point is clear: businesses that have access to large amounts of data can employ MIDAS (and other anomaly detection algorithms) in order to identify unusual patterns in real-time. </p>
<p>How is your data structured and how could we help you set up a modern anomaly detection solution?</p>
<p>Drop us a line and let us know. The <a href=""https://blueorange.digital/"">Blue Orange Digital</a> data science team is happy to make anomaly detection work for your benefit too!</p>
<p>For more on AI and technology trends, see Josh Miramant, CEO of Blue Orange Digital’s data-driven solutions for <a href=""https://blueorange.digital/cptcasestudies/supply-chain-revenue-predictions-for-pharmaceuticals/"">Supply Chain</a>, <a href=""https://blueorange.digital/cptcasestudies/digital-transformation-of-government-documents/"">Healthcare Document Automation</a>, and <a href=""https://blueorange.digital/cptcasestudies/"">more</a>.</p>
<hr class=""wp-block-separator"" />
<p><em>Follow me on</em><em> </em><a href=""https://twitter.com/BlueOrangeData""><em>Twitter</em></a><em> </em><em>or </em><a href=""https://www.linkedin.com/in/joshmiramant/""><em>LinkedIn</em></a><em>. </em><em>Check out my</em><em> </em><a href=""https://blueorange.digital/""><em>website</em></a><em>. </em></p>
<div class=""wp-block-image"">
<figure class=""alignleft is-resized""><img class=""wp-image-5323"" src=""https://blueorange.digital/wp-content/uploads/2020/05/Josh-Miramant-CEOpng-1024x1024.png"" alt=""Josh Miramant- CEO"" width=""162"" height=""162"" /><br />
<figcaption>Josh Miramant- CEO</figcaption>
</figure>
</div>
<p><em>Josh Miramant is the CEO and founder of Blue Orange Digital, a data science and machine learning agency with offices in New York City and Washington DC. Miramant is a popular speaker, futurist, and a strategic business &amp; technology advisor to enterprise companies and startups. He is a serial entrepreneur and software engineer that has built and scaled 3 startups. He helps organizations optimize and automate their businesses, implement data-driven analytic techniques, and understand the implications of new technologies such as artificial intelligence, big data, and the Internet of Things. </em></p>
<p><em>Featured on IBM ThinkLeaders, Dell Technologies, and NYC’s Top 10 AI Development and Custom Software Development Agencies as reviewed on Clutch and YahooFinance for his contributions to NLP, AI, and Machine Learning. Specializing in predictive maintenance, unified data lakes, supply chain/grid/marketing/sales optimization, anomaly detection, recommendation systems, among other ML solutions for a multitude of industries.  </em></p>
<p><em>Visit </em><a href=""https://blueorange.digital/""><em>blueorange.digital</em></a><em> for more information and </em><a href=""https://blueorange.digital/cptcasestudies/""><em>Case Studies</em></a><em>.</em></p>
<hr class=""wp-block-separator"" />
<p>image source: Canva</p>
<p>Originally published: <a href=""https://www.unite.ai/business-anomalies-protect-your-company-from-fraud-with-anomaly-detection/"">Unite.AI</a></p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Banking-Customer-Acquisition.png,Banking-Customer-Acquisition.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Banking-Customer-Acquisition.png,3085,Banking-Customer-Acquisition,,,,https://blueorange.digital/wp-content/uploads/2022/05/Banking-Customer-Acquisition.png,,,,,,,,
3921,"Part 2: The Top Three Private Equity Problems Firms Need To Solve","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<h2>The Top Three Private Equity Problems Firms Need To Solve</h2>
<p>It’s getting more challenging to win in private equity. Investors come to private equity firms for unique opportunities and higher returns. Companies come to private equity for funding when other funding options are not suitable. To succeed, private equity firms need to land a steady stream of new investment opportunities to meet investor expectations.</p>
<h2>The Key Problems Private Equity Must Face</h2>
<p>The days of small personal networks dominating private equity are over. According to<a href=""https://www.mckinsey.com/~/media/McKinsey/Industries/Private%20Equity%20and%20Principal%20Investors/Our%20Insights/Private%20markets%20come%20of%20age/Private-markets-come-of-age-McKinsey-Global-Private-Markets-Review-2019-vF.ashx""> McKinsey research</a>, there are 8,000 PE-backed companies in the USA in 2017 versus 4,000 in 2006. In terms of private debt fundraising, there were 139 funds in 2018, with an average fund size of $781 million. New firms are hungry for deals to establish themselves. Established firms can no longer assume they will get all of the investment deals they need.</p>
<h2>1) High levels of competition from other private equity firms</h2>
<p>When a growing company seeks funding to grow, they have no shortage of options. At the small end of the spectrum, the rise of angel investor websites like<a href=""https://angel.co/""> AngelList</a> make it easy to obtain small amounts. At the larger end of the deal spectrum, there are hundreds of firms sitting on large amounts of capital. Add up these challenges and it is no surprise that a growing number of PE firms are sitting on their capital.  </p>
<p>Consulting firm<a href=""https://www.ey.com/en_us/private-equity/how-high-levels-of-dry-powder-are-driving-private-equity-competition""> EY</a> recently summarized the state of the PE market in these terms: “many players chasing too few deals.” Private equity firms have more than $600 billion in capital sitting on their books as of early 2019. As more and more capital sits on the sidelines, return on assets and other financial metrics will start to decline.</p>
<h2><strong>2) Difficulty carrying out due diligence processes</strong></h2>
<p>Invest in the wrong company, and you will suffer terrible returns and reputational damage. Imagine if you were an investor in Theranos, the failed health technology company that raised $700 million from investors. In private equity, your judgment in selecting investment deals matters. If you are associated with a CEO who ends up facing criminal charges, your investors will ask you tough questions.</p>
<p>You cannot eliminate investment uncertainty in private equity. However, you can take steps to reduce the most common problems with due diligence. On the other hand, private equity firms are under pressure to complete their due diligence process as quickly as possible to close a deal.</p>
<h2><strong>3) Difficulty in locating suitable investment opportunities</strong></h2>
<p>Information is king in private equity. If you rely on public sources like TechCrunch to find promising companies, you will continuously face deal competition. When your firm competes against other investors, you are going to make hard choices. For example, you might not get the board seats you want. Or you might have to agree to a different valuation. In some hot deals, you might have to accept a smaller allocation than you desire.</p>
<p>What Will Happen If You Ignore These Problems?</p>
<p>Failing to deliver strong returns to your investors means you will face difficult conversations. You may have to take on higher risk deals to meet your returns. Or you may have to pause your plans to raise additional capital while you regroup. Such a move may send unintentional signals to the marketplace that your fund is struggling. Taking on more risk and pressuring portfolio companies for better deal terms are not the only ways to improve returns.</p>
<p>Use Data Strategy To Improve Your Returns</p>
<p>Every private equity firm wants to claim that they are smarter than the competition. If you’re serious about making that claim, you can’t merely point to the number of PhDs you have on staff. Instead, you need to differentiate your PE firm based on data expertise. There are three ways private equity firms can deploy data skills to improve returns.</p>
<p>Identify New Deal Opportunities</p>
<p>Your ability to locate highly promising investment deals before anybody else is a critical way to build your reputation. In addition to relying on your networks, create your database to identify new strategies. Here is a simple illustration to show how to use data to determine investment opportunities:</p>
<ul>
<li>Investment Hypothesis. You start with a tested idea, such as that computer science departments at certain institutions (e.g., Carnegie Mellon and Stanford) tend to produce high potential founders.</li>
<li>Data Source. You use data on company founders from<a href=""https://www.crunchbase.com/""> Crunchbase</a> and other sources to build a database of founders who share the patterns you identify above.</li>
<li>Data Analysis. Use data analytics to identify other patterns behind high growth companies like activity at conferences.</li>
<li>Deal Identification. Generate a list of high potential early-stage companies to approach. If you are the first or second investor in a company, you are more likely to land favorable investment terms.</li>
</ul>
<p>Not sure how data analytics can help you identify deal opportunities? Reach out to <a href=""https://blueorange.digital/"">Blue Orange</a> to discuss the options.</p>
<p>Reduce Investment Mistakes: Optimize The Due Diligence Process</p>
<p>Warren Buffet’s first rule of investment success is: never lose money.</p>
<p>All investment decisions come with risk. However, you can use data insights to avoid mistakes. Consider the example of meeting a charismatic company founder. Their pitch may impress you so much that you want to charge ahead on the deal. Use a data-based balanced scorecard as a counterweight on the deal. Specifically, you can use data tools to effectively challenge a founder’s estimates of their company growth rates and overall market size.</p>
<p>For guidance on optimizing your due diligence processes without compromising on quality, contact Blue Orange for a free data capability assessment.</p>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/photo-1558588942-930faae5a389.jpeg,photo-1558588942-930faae5a389.jpeg,/www/blueorangem_500/public/wp-content/uploads/2022/05/photo-1558588942-930faae5a389.jpeg,3933,photo-1558588942-930faae5a389,,,,https://blueorange.digital/wp-content/uploads/2022/05/photo-1558588942-930faae5a389.jpeg,,,,,,,,
3944,"Comparing Business Intelligence vs. Business Analytics vs. Data Analytics","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<ul>
<li>
<p>Simply reading these three terms together creates confusion. This happens because intelligence and analytics are pretty abstract concepts that give the idea that they could easily overlap each other. However, the distinction between Business Intelligence (BI) and Business Analytics (BA) is not only realistic but also crucial to avoid misunderstandings. Also, this leads us into clarifying the difference between Data and Business Analytics. </p>
<p>Managing ever-growing volumes of data requires efficient algorithms and programs that turn numbers into comprehensible metrics to base decisions on. BA is fantastic at supplying analysts with advanced analytics but these results are achieved in combination or completely based on the principles of BI. Both these data collection systems integrate similarly with one another to increase business revenue but purpose differentiates them. </p>
<p>To build the big picture, we can say that Business Intelligence is branched into other subsets like Business Analytics and Data Analytics. Perhaps you’ve seen these terms used interchangeably. To make the borders clear, we’d want to start with simple definitions. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Understanding Business Intelligence (BI)</strong></h2>
<p>Shortly put, business intelligence includes all the steps of the data collection process, from the process of collecting it from respective business operations to storing and performing analysis on it. BI provides business owners with actionable metrics which can guide them into profitable decisions. </p>
<p>Employing BI solutions into your business assists you with a clearer understanding of the market trends, performance issues, and compliance enhancement. After finishing the analysis of data sets, BI tools visualize it into graphs, dashboards, charts, or reports for an immediate representation of the business situation.  </p>
<p>For instance, an enterprise with a sophisticated supply chain and a vast number of products could utilize the power of BI tools to identify the main shipping issues that arise, top-selling products, or track which shipping methods are used more frequently. Then, shipping delays can easily be tackled if the process is tracked down to their route. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Understanding Business Analytics (BA)</strong></h2>
<p>BA aims to reiterate through the business data using statistical techniques and formulas that will enhance the business both in terms of finance and innovation. Business Analytics digests data over a period of time with the intention of producing solutions and strategies that will guide the internal processes of the business for the long term. </p>
<p>Generally, we have three main types of Business Analytics models: descriptive, prescriptive, and predictive. The option you’d choose depends on the stage your business is in. What matters for all of them is that there exists a considerable amount of data to be processed. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/7awjvMx8SBRWGCrRfdX8hEtt30gJ05Px_CW0ZtEcLrvYP087SPLMFERAnA9wfPiZPKwt0iJiR4WQOKIzUKj-WUROsjJCQCOnHEBNlujCJwOj1CfF8R555QtvL-JMOpl8nCHzL0Ik"" alt="""" /><br />
<figcaption><strong><a href=""https://www.mygreatlearning.com/blog/what-is-the-difference-between-business-intelligence-and-business-analytics/"">Source</a></strong></figcaption>
</figure>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Understanding Data Analytics (DA)</strong></h2>
<p>As the name suggests, Data Analytics stands for the process of collecting large amounts of different data types in the unprocessed form and examining them to attain a certain understanding of a process. This data could be regarding market research, completed transactions, logistics, customer behaviors, etc.</p>
<p>Data Analytics focuses on storing and sorting data accordingly to uncover patterns and trends that emerge among an audience. It heavily relies on big data processing, a combination of statistical techniques, and advanced technologies. You could have encountered the use of Data Analytics solutions in the form of machine learning models. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Comparing Business Analytics, Data Analytics, and Business Intelligence</h2>
<p>The three of these systems deal with data collection, ingestion, and <a href=""/services/"">transformation </a>into insights that can be leveraged for wiser business decisions. However, there exists some slight differences between them that are crucial to know in order to apply the proper solutions for your business problems. </p>
<h4>What Questions Do They Answer To?</h4>
<p><em>Business Intelligence</em> relies on descriptive analytics while Business Analytics focuses mostly on <a href=""/predictive-analytics/"">predictive analytics</a>. The former supplies an ample amount of useful clues when it comes to knowing the historical background of what has happened until this point. If we were to define most questions BI can answer to, we’d say that it answers to “hows” and “whats”. </p>
<p>On the other hand, <em>Business Analytics</em> focuses on predictive analytics to forecast the expected outcomes. It relies on data mining, machine learning, financial analysis tools, and numerous data visualization tools. It answers the “whys”, helping you understand the inner mechanisms and create solutions that serve the forefront of the business. </p>
<p>Lastly, <em>Data Analytics</em> covers a broader aspect of data analysis. Compared to Business Analytics, it deals with the backend processes, studying trends, patterns, locating anomalies, and risks. It involves more technical processes, requiring a good understanding of programming languages like Python and other IT skills. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Practical Use Case of BI, BA, and DA</strong></h2>
<p>For a better understanding of the three of them, let’s take a practical application: <strong>Selling T-shirts online</strong>. </p>
<p>Employing <em>BI solutions</em> you’d be able to produce reports with the ongoing statistics of the sales process from a certain point until now. It shows in what area more T-shirts have been sold in the last five days. Let’s say that T-shirts with the quote “Data Rocks”, have the highest number of sales. </p>
<p>Now, you decide to print more of them to comply with the demand. Here’s where <em>Business Analysts</em> enter the room and seek clues: “Why did sales with this quote skyrocket?” Utilizing data mining on your store traffic tells you that most of it comes from Instagram because your Brand Ambassadors have shared the affiliate content you had prepared for them. </p>
<p>But does it end here? Not at all. Your <em>Data Analysts</em> are analyzing each visitor that comes on the site. They would find out the major traffic trends, identify the demographics, and even build systems to track their behavior on the site, and how they click through pages.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Final Thoughts </h2>
<p>Choosing which direction to invest your resources: Business Intelligence, Business Analytics, or Data Analytics doesn’t quite make sense as a question because to manage data properly and fully reap its benefits, you need to have the three types of technologies implemented for optimized operations. Blue Orange has extensive experience in building technological systems that are easy to use by analysts and business owners. If you’re still confused about the solutions your business needs, we can set up a 15-minute call and chat about it entirely for free. Book <a href=""/contact-us/"">here</a>.</p>
</li>
</ul>
<div class=""wp-block-image""> </div>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/BI-vs-BA-cover-image.png,BI-vs-BA-cover-image.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/BI-vs-BA-cover-image.png,3957,BI-vs-BA-cover-image,,,,https://blueorange.digital/wp-content/uploads/2022/05/BI-vs-BA-cover-image.png,,,,,,,,
3945,"5 Solar Energy Breakthroughs with Machine Learning","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<h2>Intro: Machine learning in the solar energy industry</h2>
<p>The high availability of data in the energy sector makes it a great environment for machine learning and data science solutions. Power grids, energy networks, consumers, smart homes, and appliances are only a few examples of rich data sources. They enable energy providers to better understand their role in the energy ecosystem and to optimize their operational performance.</p>
<p>Moreover, specific sectors are seeing a spike in innovative solutions made possible by the increased data availability. In solar energy, disruptive business models and custom applications are at the forefront of innovation. They make use of Machine Learning and analytics for tackling some of the most pressing challenges of renewable energy.</p>
<p>Below are 5 directions in which Machine Learning is being leveraged to lead progress in the solar energy sector. </p>
<h2>1. Smart infrastructure design of solar energy systems</h2>
<p>The planning and assessment of solar energy systems need to account for a variety of factors: weather conditions, optimal sizing, and correct geographical placement. These factors influence how solar grid systems will be performing for their entire lifespan. Understanding the intricate interactions among these factors is mandatory in order to implement productive and well-behaving solar systems. </p>
<p>A variety of data sources can be integrated into this decision process: historical weather data, power production data collected from other energy grids, and even simulated load demand data. Such data sources make it possible to integrate advanced ML applications when designing the <a href=""https://blueorange.digital/cptcasestudies/advanced-sensor-analytics-platform/"">infrastructure of solar energy grid systems</a>.</p>
<p>ML has already been successfully used to tackle some infrastructure design decisions: from improving solar energy storage to identifying the optimal layout of solar panels. In their comprehensive infographic, <a href=""https://www.ibmbigdatahub.com/infographic/big-data-analytics-adds-power-renewable-energy"">IBM shows</a> how they have leveraged historical satellite data and real-time weather for increasing generated power. That is, without requiring additional panels or turbines. This illustrates how decisions based on machine learning can lead to cost optimization at the very initial stages of infrastructure design.</p>
<h2>2. Intelligent maintenance of solar energy plants</h2>
<p>The maintenance of solar energy plants is particularly challenging given the properties of renewable energy sources: they are fluctuating and are highly influenced by weather conditions. ML solutions enable energy providers to be proactive and to keep a close eye on the performance and availability of their solar energy plants.</p>
<p>Since energy grids are nowadays empowered with <a href=""https://blueorange.digital/iot/"">advanced sensors</a>, vast amounts of data are collected 24/7. This is a way to give expensive machines and equipment a way to communicate their current performance status. Combined with weather data, this allows innovative ML applications to solve the most complex maintenance tasks.</p>
<p>ML applications for <a href=""https://blueorange.digital/energy/"">solar plant maintenance</a> include but are not limited to: anomaly detection, failure prediction, and automated monitoring. By looking at historical and real-time system data, these algorithms can offer insights about the future health parameters of the grid. When having access to such predictive intelligence, grid operators can improve the safety and reliability of their solar plants.</p>
<h2>3. Solar energy production forecasting </h2>
<p>The last decade of research and development in the renewable energy sector has reached a conclusion that impacts both the design and maintenance of energy grid systems. In order to better maintain and design such expensive physical infrastructure, custom software solutions are needed. Such is the capability of forecasting energy production according to both internal and external data sources.</p>
<p>Historical satellite data, environment data, and real-time weather can all be integrated and analyzed by predictive algorithms, in order to inform hardware maintenance decisions. Such is the example of <a href=""https://www.ibm.com/ibm/history/ibm100/us/en/icons/deepthunder/"">Deep Thunder</a>, IBM’s solution for the hyper-local understanding of weather patterns. </p>
<p><em>“For example, to help a utility company prepare for the after-effects of a major storm, the team could mine and model historical data of what kind of damage was caused to power lines or telephone poles, and why. By coupling that with a hyper-local forecast, IBM could help a company plan for how many repair crews would be needed, and where.”</em></p>
<p>This example is not isolated and clearly shows how investing in software and custom machine learning and analytics services can have an impact on the performance and maintenance of expensive hardware (such as solar plants or power networks). By leveraging forecasted energy production information, grid operators can cut down on operational costs and make informed decisions, based on real-time performance data.</p>
<h2>4. Optimized transmission &amp; distribution networks</h2>
<p>The oldest challenge of the energy sector revolves around the maintenance of transmission and distribution networks. With the increasing availability of renewable energy sources, the task becomes increasingly complex: the fluctuations of solar and wind-generated energy bring another layer of complexity to this problem. Integrating them into traditional grids constitutes the modern challenge of the energy sector. </p>
<p>Forecasted production data (covered above), the integration of consumption data, and the proactive monitoring of energy grid systems make it possible to gain fine-grained control over the energy networks.</p>
<p><a href=""https://blueorange.digital/services/#analytics"">ML algorithms</a> integrate consumption patterns and can power applications dealing with the health of distribution networks. They power preventive maintenance solutions and also make it possible to identify anomalous behavior (such as theft). Such capabilities allow energy suppliers to maximize the usage of renewable energy and to act on quality and congestion issues before they happen.</p>
<h2>5. Understanding the solar energy market</h2>
<p>Keeping up with consumption fluctuations and balancing supply and demand is one of the top priorities of established energy providers. At the same time, new business models and services arise from the innovative use of technologies and data. More and more energy startups are joining this competitive market. Keeping up with the innovations and demands of this emerging ecosystem requires access to data and modern learning capabilities.</p>
<p>Once more, a variety of data sources constitute a huge opportunity for all players on the energy market. Price fluctuations, consumption patterns, historical prices, and production metrics can all be integrated into <a href=""https://blueorange.digital/services/#transformation"">unified data structures</a>. Both internal and external data sources can be merged and fed to the data-hungry algorithms, which can handle such heterogeneous data sources out of the box.</p>
<p>The traditional use of ML algorithms is focused on forecasting market-clearing prices. However, innovative solutions for solar energy generators integrate market data into daily operational and maintenance decisions: technical parameters, demand fluctuations, and grid performance can all be balanced by means of machine learning and real-time data analytics. Such capabilities offer huge untapped potential for both established companies, as well as for startups and energy traders.</p>
<h2>What’s next is solar?</h2>
<p>The increased availability of energy data enables advanced ML and analytics services to lead innovation in the solar energy sector. From the design of smart solar grids to automated maintenance and even production forecasting, the renewable sector seems to be gaining intelligent superpowers. Delivery networks are becoming increasingly reliable, consumers’ energy needs are better understood and overall production costs are kept to a minimum.</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/5-Solar-Energy-Breakthroughs-with-Machine-Learning.jpg,5-Solar-Energy-Breakthroughs-with-Machine-Learning.jpg,/www/blueorangem_500/public/wp-content/uploads/2022/05/5-Solar-Energy-Breakthroughs-with-Machine-Learning.jpg,3949,5-Solar-Energy-Breakthroughs-with-Machine-Learning,,,,https://blueorange.digital/wp-content/uploads/2022/05/5-Solar-Energy-Breakthroughs-with-Machine-Learning.jpg,,,,,,,,
3947,"Why The Oil & Gas Industry Needs RPA Right Now","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]Falling energy prices in 2020 are undeniable. In one month, WTI crude prices have fallen over 12%. If the COVID pandemic continues, we may be facing a recession. This means less demand for Energy. This leaves just one critical question. How can companies obtain profitability targets when prices fall through the floor like this?
<h2>The Traditional Response To Falling Energy Prices Isn’t Enough</h2>
The conventional playbook to respond to falling energy prices has some value. You might defer projects into the future. You might cut back on development. Some companies may even look at laying off some of their workforce. Other companies might refocus their energy efforts on jurisdictions that offer high tax incentives to the energy sector. These measures make a difference, however, there is one critical problem with these steps.

All of your competitors know about these moves, and they are all going to take them as well. That means that taking these steps will yield limited returns. To get ahead of your competition quickly, you need to look at alternative options.
<h2>Introducing RPA (Robotic Process Automation)</h2>
An emerging technology, robotic process automation (RPA), is one of the best ways to improve your efficiency in Energy. Unlike staff layoffs, RPA does not generate negative publicity. Further, RPA can pay dividends during hard times and make the boom times even better. In essence, RPA helps to automate repetitive tasks in your company. Instead of having a person work through a requisition form or analyze standardized data in a spreadsheet, use RPA to carry out that task.
<h2>Robotic Process Automation Generates Over $8 Million In Savings: DTE Energy</h2>
Is RPA worth the effort to implement? It’s a fair question to ask before you start a new technology project. DTE Energy, a Detroit based energy company with more than 10,000 employees, achieved these results with RPA according to<a href=""https://www.zdnet.com/article/energy-company-on-a-mission-to-automate-processes/""> ZDNET</a>.:
<blockquote class=""wp-block-quote""><em>By automating these processes with RPA, the company has saved nearly one quarter million annualized man-hours and has 75 automations in the backlog queue. Throughout 2019, DTE plans to implement 35 more automations in 5 additional business units.</em></blockquote>
That’s impressive! We can quantify that further by translating those figures into concrete terms. According to the<a href=""https://www.bls.gov/iag/tgs/iag22.htm#earnings""> U.S. Bureau of Labor Statistics</a>, the average hourly wage rate in the utility industry was $42.22 in February 2020. That means DTE’s efforts have already generated more than $8 million in savings. It is also important to highlight that DTE achieved these savings by automating dozens of business processes. If you want to achieve similar results, plan to analyze and automate multiple processes.
<h2>RPA For Oil Pipelines: Optimize Monitoring and Maintenance</h2>
Pipelines are one of the fastest-growing segments in the modern energy industry. More than 200,000 people are working in the oil and gas pipeline construction industry alone. As pipeline infrastructure continues to expand, managers need a way to monitor and manage thousands of miles of pipelines in a cost-effective and safe manner.

RPA helps improve pipeline management by processing reports from your field crews. For example, you may receive 200 weekly maintenance reports from your staff. Manually summarizing all of those reports takes a long time. Each day you spend summarizing the data means you have less time available to consider your options and make good choices. Use robotic process automation to summarize safety reports in minutes so that you can provide quick feedback to your field crews.
<h2>Use RPA To Improve Customer Service In The Energy Industry</h2>
Consumer behavior and environmental factors are a significant variable in energy demand. Using sources like the short-term energy outlook from the<a href=""https://www.eia.gov/outlooks/steo/report/electricity.php""> U.S. Energy Information Administration</a>, you can make some educated response plans for weather conditions and how they will impact energy demand. However, other factors may be less noticeable. Let’s say your utility supplies a college town like Ann Arbor, Michigan. In that case, you may have a customer service challenge with a large number of new tenants arriving every September. The university has over 40,000 students, while the city of Ann Arbor is only 113,000, so addressing student demand for Energy and other services matters.

Robotic process automation helps to manage customer demand by processing orders and common inquiries. For example, you can use an RPA system to evaluate new customer applications and automatically contact the customer if there are fundamental errors. Following up on these errors through automation gives customers faster service and saves your customer service staff for inquires that require a human touch.
<h2>How To Get Started Even If You Don’t Know Anything About RPA</h2>
Adding robotic process automation to your energy company may feel scary. As the DTE Energy example shows, there are significant benefits available in the form of faster service and cost savings. However, there is some prep work before you can jump right into this project. Before you begin, you will need to analyze your business and prioritize which processes to automate first, get budget and staff allocation approvals, then research how to execute this technology. After that preparation is done, your job is not yet done. You still need to select an RPA technology, configure it, and fine-tune it for your environment. Don’t put the burden solely on your technology department. Contact <a href=""https://blueorange.digital/contact-us/"">Blue Orange Digital</a> to explore the robotic process automation opportunities hidden inside your company.

For more info see our Case Study on Energy Grid Optimization:

<a href=""https://blueorange.digital/cptcasestudies/advanced-sensor-analytics-platform/""><img class=""wp-image-3186 alignnone size-medium"" src=""https://blueorange.digital/wp-content/uploads/2022/05/Advanced-Sensor-Analytics-Platform.png"" alt="""" /></a>
<div class=""wp-block-image"">
<figure class=""aligncenter is-resized"">
<figcaption>Advanced Sensor Analytics Platform, Blue Orange Digital Case Study</figcaption>
</figure></div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Why-The-Oil-Gas-Industry-Needs-RPA-Right-Now.png,Why-The-Oil-Gas-Industry-Needs-RPA-Right-Now.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Why-The-Oil-Gas-Industry-Needs-RPA-Right-Now.png,3962,Why-The-Oil-Gas-Industry-Needs-RPA-Right-Now,,,,https://blueorange.digital/wp-content/uploads/2022/05/Why-The-Oil-Gas-Industry-Needs-RPA-Right-Now.png,,,,,,,,
3967,"OpenLineage and Airflow Simplify Data Lineage","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<ul>
<li>
<p>The <a href=""https://ec.europa.eu/info/law/law-topic/data-protection/eu-data-protection-rules_en"">GDPR</a> (General Data Protection Regulation), asks organizations to implement data lineage for a clear understanding of the data used within the systems. Paying attention to data lineage not only helps organizations comprehend complex issues within their data operations but also helps explain and justify errors which your users might stumble upon. </p>
<p>Primarily, the function of data lineage remains to keep track of data since its extraction from the source, the transformations that follow, and loading into the destination. Staying updated on these phases data goes through allows businesses to make wiser decisions. Not knowing where data originated from and the state of those resources could create a mess.</p>
<p>However, considering the vast amount of data, complexity, and its ever-changing state proves challenging with the implementation of data lineage, and requires tools and platforms that adapt to different industries with ease. Today, we’ll discuss the execution of a data lineage strategy using Airflow and OpenLineage.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh5.googleusercontent.com/XCECNoL0fkf2poj0pzznbxLNNycHaxIjzcni4WMJbaEoGuHkbE1dks3QuqH5ZZevOIpGKTFoBvvTN_g-iTc0k6XNb5uH_5A_wAqdu4pxyRGJ_H3EWXeWgwnIh2eGQaslaV2zMukp"" alt="""" /><br />
<figcaption><strong><a href=""https://www.datacouncil.ai/blog/openlineage"">Source</a></strong></figcaption>
</figure>
<h2>What is Data Lineage and how do you implement it?</h2>
<p>The data within an organization undergoes several processes. Data lineage attempts to portray this journey of data, from the initial collection phase to the final state of deletion. In short, data lineage is concerned with the identification, understanding, tracking, and representation of the data state as it changes and the reasons why.   </p>
<p>Data lineage includes the sophisticated relationship between jobs and datasets being processed in a pipeline. This involves the relationship among consumers and producers in datasets, and the input and output collected during each job. Data lineage is best represented in a visual form that simplifies its complex nature. </p>
<p>Implementing data lineage in your organization early gives you advantages for the long term. Even though it requires time and experts to deal with its intricacies, it is essential for most businesses. We’ll try to explain its implementation in under four steps: </p>
<ul>
<li><strong>Determine the data elements</strong> - Collect information from users to locate the essential elements of your business. </li>
<li><strong>Find the origin</strong> - Gather information about the identified elements from their origin to the current state. </li>
<li><strong>List sources and documents</strong> - Include all the resources to data elements, sources, and related materials into a spreadsheet. </li>
<li><strong>Start mapping</strong> - Turn all the known systems into visual maps, and create a large map to include all of them. </li>
</ul>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>What is OpenLineage?</strong></h2>
<p><a href=""https://openlineage.io/"">OpenLineage</a> is not a single tool. It functions as a platform encompassing multiple libraries for common languages, multi-functional integrations, a metadata reference implementation known as Marquez, and much more. As the name suggests, the purpose of OpenLinage is the gathering and analysis of data lineage, while data is being processed through pipelines.  </p>
<p>As an open-source project <a href=""https://datakin.com/introducing-openlineage/"">initiated by Datakin</a>, it was built with the help of many contributions, as seen in the image below. Among them are also dbt, Apache Spark, and Marquez. </p>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/eo_ikQRa5XD7Rbpp1AOQZsdRidbBin6p1K7Jm0BqQRo4qgxbHvRR2Rr7OBBRaoiQF-kHAmJt9H1_CzDru0wRfAqbGDI7bvrCjunQfISGgKLXzQKx57belvsFAGMDf5l_dWQokFFn"" alt="""" /><br />
<figcaption><strong><a href=""https://www.astronomer.io/events/recaps/data-lineage-with-openlineage-and-airflow?utm_campaign=Marketing&amp;utm_medium=email&amp;_hsmi=196747456&amp;_hsenc=p2ANqtz-_HV1IX0bN7tE5xVsWgd_DqvQYkpSF3MIvO6K9ZA7USobZS5C4Q-uYfGORNzzrUdtaQ2V1jEDy4mAzvulk6LLkiq93Rng&amp;utm_content=196747456&amp;utm_source=hs_email"">Source</a></strong></figcaption>
</figure>
<p>Traditionally, organizations use data fragmentation which offers some kind of assistance in how the data is organized and managed. Answering fundamental questions that surround data management is challenging with a fragmented data infrastructure. </p>
<p>What is the source of data, who owns it, and what has changed? Is there a schema for us to check? How often is this data updated and where does it go? Finding answers is easier with data lineage. </p>
<p>OpenLineage focuses on reducing fragmentation to help create useful and practical solutions regarding data compliance, operations, and governance. </p>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/ioJjsuSkJm5RD8Fp6tPItmcmJ7gEDb2M9ouIMMuXf_FIhj7OKbAx5dG_nXlmXKA4GogZQTPMm_GLg_FqpcSpEaqOxiqYidIgeli8BnKJuDPwtOORet73ajiH8K3gLGyph8ibZfE0"" alt="""" /><br />
<figcaption><strong><a href=""https://images.ctfassets.net/bsbv786nih7n/4g0NLwhv6bBiqLMmI201Ge/26b07a26a62a48458dd699472ac113ed/data-lineage-image16.png?w=1332"">Source</a></strong></figcaption>
</figure>
<p>OpenLineage is architectured with three layers in mind, considering the flow of metadata from producers to consumers. It goes like this: </p>
<ul>
<li>Lineage metadata is captured on tools concerned with data transformation and dataset production. </li>
<li>Lineage information is processed towards the selected backends. </li>
<li>The lineage metadata information is served to users who seek it.</li>
</ul>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Using Apache Airflow and OpenLineage</strong></h2>
<p>Monitoring and scheduling workflows get challenging as data expands. Airflow is an open-source tool that assists with the monitoring, authoring, and visualization of workflows, data pipeline processes, code progress, success status, etc. Airflow <a href=""https://airflow.apache.org/docs/apache-airflow/1.10.12/concepts.html"">turns workflows into DAGs</a> (Directed Acyclic Graph) which display tasks in such a way that makes their dependencies and relationships observable.</p>
<p>These graphs are written in Python, specifying tasks and their details. The data and tasks included in these scripts don’t have to belong to the same systems or uses. Neither do the tasks have to depend on each other. What matters is for tasks to be executed in their order.</p>
<p>However, by using Airflow alone the management of inter-DAG dependencies and a display of the execution processes remains sophisticated. The integration of Airflow with OpenLineage brings metadata lineage DAGs in a manageable and visible graph while keeping track of the historical runs for each of them. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>In a Nutshell</strong></h2>
<p>Large, mid-sized, and small organizations, all need to maintain the quality of their data in order to resolve problems and keep track of their data flow. To achieve this, there are three characteristics data should have: freshness, quality, and availability. Data lineage assists in fulfilling these characteristics by tracking the “footsteps” of data within your systems.  </p>
<p>A combination of business intelligence tools, platforms, and data science integrations makes data and metadata presentable and manageable. At Blue Orange, we strive to create an environment where our clients can get a clear picture of their data as it is running and base their decisions on real numbers. Find more details <a href=""/services/"">here</a>. </p>
</li>
</ul>
<div class=""wp-block-image""> </div>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Data-Lineage-Blog-Cover-Final.png,Data-Lineage-Blog-Cover-Final.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Data-Lineage-Blog-Cover-Final.png,3970,Data-Lineage-Blog-Cover-Final,,,,https://blueorange.digital/wp-content/uploads/2022/05/Data-Lineage-Blog-Cover-Final.png,,,,,,,,
3972,"The Way To Use Dynamic Pricing in eCommerce","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<p>As eCommerce continues to grow, retailers are seeing more competitive pressure. Whether it is keeping up with product quality, delivery expectations, or margins, eCommerce is becoming more challenging. With all of these different problems, you might feel overwhelmed. The solution? Focus on business fundamentals like margins and pricing.</p>
<h2>The Margin Problem In eCommerce</h2>
<p>In eCommerce 1.0, low prices were a key advantage in attracting market share. Consumers assumed that some eCommerce retailers had lower operating costs so those savings should be passed on to them. There is some truth to that. Amazon does not have to pay for expensive retail space in large cities. However, operating a large scale eCommerce operation requires considerable supply chain expenses.</p>
<p>In many cases, eCommerce companies are struggling to maintain acceptable profit margins to achieve their goals. In 2014, Marketing Sherpa found that gross eCommerce margins were 30% and higher based on a survey of 413 companies. In 2018, these higher margins continued but required more effort. Private and manufacturing-based eCommerce models were growing much faster than drop shipping. Overseeing manufacturing processes introduces more complexity. If this complexity is not well managed, customer satisfaction and purchase behavior may fall.</p>
<h2>The Way To Maintain Margins And Sustain Growth</h2>
<p>Implementing dynamic pricing is one of the most potent levers to pull to enhance eCommerce performance. Instead of waiting for the month-end to adjust pricing, use data tools to adjust prices rapidly in response to the market. To support effective dynamic pricing, use these three data strategies.</p>
<h3>1. Unified 360 Customer Profile: The Foundation For Data-Based Decision Making</h3>
<p>Larger eCommerce companies have customer data in multiple systems. One application has marketing insight to help you understand marketing engagement, social media analysis, and beyond. Another system will have data on order volume, order frequency, and shipping. Manually integrating all of these data sets is a huge pain. However, it is critical to understand customer behavior.</p>
<p>To build a comprehensive customer profile, clarify what you are aiming to achieve first. Here are a few guiding principles to inform your 360 customer profile development.</p>
<ul>
<li>Clarify Product Margins. Your accounting systems will provide data on margins at the company level. However, that level of aggregation has limited value for day to day decision making. </li>
<li>Identify Profitable Customer Segments. Some customers are more profitable than others. Organize your customer profile data to find patterns in your most valuable customers.</li>
<li>Define Operational Problems. Instead of tracking the total number of complaints, find patterns in the problems. For example, you may detect that a key logistics supplier fails to deliver large volume orders during holiday rush seasons.</li>
</ul>
<p>Once your customer data profiles are created, there are two ways to implement dynamic pricing.</p>
<h2>2. Machine Learning For Customer Segmentation</h2>
<p>Let’s take a closer look at applying dynamic pricing to your customers. For illustration, let’s assume that you identify two segments. Segment one is high order volume customers (e.g., ten orders over twelve months). Segment two is infrequent customers (e.g., buyers who wait for holiday promotions). By machine learning, you can develop multiple pricing scenarios, such as the following.</p>
<p>Segment 1: Create a one day, offer 10% price discount as a loyalty reward to maintain customer loyalty.</p>
<p>Segment 2: Develop a “reactivation” pricing promotion to encourage customers to buy more frequently.</p>
<p>With machine learning, you can develop pricing change experiments hundreds of times per year. That increases the chances you will find profitable price points without working around the clock.</p>
<h2>3. Using Behavioral Analytics </h2>
<p>Predicting the future, especially for seasonal activities, is crucial to success in eCommerce. For example, many eCommerce companies begin ordering inventory in June for the year-end customer. If inventory can be optimized, your company saves money in terms of warehousing cost and financing. Here are a few ways to introduce the power of behavioral analytics in eCommerce.</p>
<ul>
<li>Website Behavior. Look for behavior patterns that occur before purchase such as customers clicking on different color and size variations. Once these patterns are detected, you optimize your website to present the most popular product variations first.</li>
<li>Volume Pricing. Does offering a special price for ordering three, five, or more units make sense in your eCommerce business? Marketing wisdom generally favors volume discounts. However, the Devil is in the details! Use behavioral analytics techniques to analyze and test which types of offers are the most profitable.</li>
</ul>
<h2>You’re Not Alone To Implement Dynamic Pricing</h2>
<p>You don’t need to start from scratch with dynamic pricing. There is a way to shortcut the process, find the right data, and design pricing experiments. How is all this possible? Contact Blue Orange Digital to improve your pricing strategy. In a matter of weeks, you could improve your margins by 5-10% solely by leveraging dynamic pricing. Find out what’s possible for your company by contacting us now.</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/The-way-to-use-Dynamic-Pricing.png,The-way-to-use-Dynamic-Pricing.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/The-way-to-use-Dynamic-Pricing.png,3979,The-way-to-use-Dynamic-Pricing,,,,https://blueorange.digital/wp-content/uploads/2022/05/The-way-to-use-Dynamic-Pricing.png,,,,,,,,
3984,"Forget About Managing Data Warehouse Infrastructure: Use Amazon Redshift Serverless","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<ul>
<li>
<p>Data analytics use is on the rise and organizations are constantly searching for ways to remove the hurdles that limit access for team members with minimal expertise. Data warehouses are necessary systems used to report and <a href=""/services/"">analyze data</a>, but they require quite a lot of learning. Not everyone has the time and capability to learn how to operate them. </p>
<p>Amazon states that developers, business professionals, and data analysts don’t have to bother learning them. There’s a solution rocking the scene, called Amazon Redshift. Redshift allows its users to work with data across data warehouses, databases, and data lakes by using SQL. However, today we’re taking Redshift one step further. </p>
<p>Meet <a href=""https://aws.amazon.com/redshift/redshift-serverless/"">Amazon Redshift Serverless</a>. As the name suggests, ARS analytics run on the cloud. All it asks for are data and your queries. No more boring cluster setup and management or expensive costs when the data warehouse is inactive. You're charged only for those seconds when the database is actively loading or querying data. </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Features of AWS Redshift Serverless</strong></h2>
<p>Amazon Redshift Serverless utilizes the existing data warehouse capacities to portray business statistics clearly and scale their resources into a more compatible display. Relying on a serverless endpoint, it regulates the system capacities within seconds to maximize performance and simplify even highly complicated operations, regardless of the workload. </p>
<p>The serverless endpoint brings other several features that are quite useful: </p>
<ul>
<li>Users aren't required to deal with the setting up and management of Amazon Redshift provisioned clusters to analyze and access data. </li>
<li>Querying across data lakes, data warehouses, and operational data sources is fairly simple by using the advanced Amazon Redshift SQL functions, and its lake house architecture.</li>
<li>It charges only for the amount of time (in seconds) when the data warehouse is actively processing queries.  </li>
</ul>
<p>The control of data flow and its movement from the serverless data warehouse is done through a console interface. From there you can extract data from the Amazon S3 data lake or Redshift managed storage.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h4>Using AWS Redshift Serverless </h4>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh3.googleusercontent.com/56TE_Rd3fOcr_3VWDUpvxIVW9HJCesj77xTrokmoEsNqUSL8OV2IiIOaYCaD3tlYnBmuA7a-HZtof3JfpOtsFj6o29f2kz3EkawhPDy6Wgq-lSWR2FQCUdUOFUk6Ozdxd_HcVHPq"" alt="""" /><br />
<figcaption><strong><a href=""https://aws.amazon.com/blogs/aws/introducing-amazon-redshift-serverless-run-analytics-at-any-scale-without-having-to-manage-infrastructure/"">Source</a></strong></figcaption>
</figure>
<p>Now, let's get to the part of using the Amazon Redshift console. Using the console requires having the IAM (Identity and Access Management) permission. Then, continue by attaching to your IAM user or role a policy that resembles this one below: </p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/EIhl4-qeiycekbbXCEDfbM9WoCDkEL9lBgq_K68rY3lFWlJ8CgcCxCuqJT_jrS4e-v5eT7xDj1i-kygiqz9DB_WDjVLo7r0mwzaqJN_-b2m0pUDjEAWfuO5QlxtCtalv4mbdwT5e"" alt="""" /><br />
<figcaption><strong><a href=""https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-serverless.html"">Source</a></strong></figcaption>
</figure>
<p>Choose the Amazon Redshift console from the AWS Management Console and then tap on Try Amazon Redshift Serverless. The first time you open the serverless endpoint console if the AWS identity and IAM permissions are correct, you’re going to see the <em>Get Started with Amazon Redshift Serverless</em> page.</p>
<p>You are presented with two options to choose from: Use the default settings or Customize Settings. The second allows you to create a serverless database or endpoint on your own. Selecting the second option displays a number of settings you can customize. </p>
<ul>
<li><strong>Admin User Credentials: </strong>The <a href=""https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-serverless.html#serverless-iam"">login information</a> for the initial database administrator (user name and password). This user is granted ownership permission of the database. </li>
</ul>
<ul>
<li><strong>Database Name: </strong>This initial (default) database resides in the AWS Region and it’s named ‘dev’. You are not allowed to change it but the database is in the ownership of your account. </li>
</ul>
<ul>
<li><strong>Virtual private cloud (VPC):</strong> The details of the VPC which holds the created database. </li>
</ul>
<ul>
<li><strong>VPC Security Groups:</strong> The IP range and subnets accepted by the VPC are defined by these security groups. </li>
</ul>
<ul>
<li><strong>Subnet:</strong> It names the subnets contained in the VPC connected with the selected database. </li>
</ul>
<ul>
<li><strong>Customize Encryption Settings: </strong>By default, the system uses the AWS-owned KMS for data encryption. However, you’re allowed to <a href=""https://docs.aws.amazon.com/kms/latest/developerguide/create-keys.html"">choose a KMS key</a> on your management. </li>
</ul>
<ul>
<li><strong>Audit Logging: </strong>A list of audit log types that you would like to export. Amazon Redshift Serverless allows the movement of the user, user activity, and connection data easily. </li>
</ul>
<ul>
<li><strong>Permissions: </strong>The IAM role linked with the serverless endpoint must involve a secure <a href=""https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-serverless.html#serverless-endpoint-iam-role"">relationship </a>with redshift.amazonaws.com and redshift-serverless.amazonaws.com.</li>
</ul>
<p>Before using the serverless endpoint you have to wait a few minutes for Amazon Redshift Serverless to complete resources initialization for your account. After this process is done and the environment is set, the Amazon Redshift query editor pops up for you to work on.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>Final Thoughts</strong></h2>
<p>The pricing model is one of the features to set Amazon Redshift Serverless apart from other services. Data warehouse compute capacity is counted in Redshift Processing Units (RPUs). The billing doesn’t rely on the computing capacity but only the time of query processing and is done in RPU-hours on a per-second basis of your workload. </p>
<p>Data science holds the key to an organization’s success. Blue Orange Digital assists businesses in multiple industries, from healthcare, real estate, and agriculture to financial services, in extracting and presenting data for better data-based decisions. Read more <a href=""/services/"">here</a>.   </p>
</li>
</ul>
<div class=""wp-block-image""> </div>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/AWS-Redshift.png,AWS-Redshift.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/AWS-Redshift.png,3985,AWS-Redshift,,,,https://blueorange.digital/wp-content/uploads/2022/05/AWS-Redshift.png,,,,,,,,
3992,"Replicate Data and Utilize Change Data Capture (CDC) Easily with Datastream","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<ul>
<li>
<p>As billions of internet users exchange information with each other and as platforms diversify, data grows exponentially together with the complexity to manage, organize, and analyze it. Companies are faced with dull data architectures that require better solutions, and the ideal alternative that exists is called change streaming. </p>
<p><strong>Change streaming relates to the direct display of data changes in real-time from a source (usually a database) to the destination. </strong></p>
<p>Change streaming relies on change data capture (CDC) patterns to replicate and move data so that major disruptions from having too many hands in the data flow can be mitigated. Google Cloud recently released Datastream, their novel replication and data capture service completely serverless and available to anyone interested. </p>
<p>Datastream joins the data science stage with its much-needed features to streamline database replication, provide real-time analytics, and support event-driven architectures. It unifies the data found in separate storage systems, databases, and applications with maximum speed and minimum latency. </p>
<p>Let’s explore how Datastream allows you to deliver change streams from MySQL and Oracle into Cloud Spanner, BigQuery, and other Google Cloud services.</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<figure class=""wp-block-image""><img src=""https://lh5.googleusercontent.com/rIRMa0-SIehChEc3i7g-w0eBBbxRd7y_KKWK8BgQEtjdiDgnamEdq9myWR-OX-hlIpzmBV8KfDVlzWbm0cZilnBsbDhSLoZzIWvdqikgR_YcbuQDIZrdz42gXhJaQ1DWKJIbY0xV"" alt="""" /><br />
<figcaption><strong><a href=""https://cloud.google.com/blog/topics/developers-practitioners/all-you-need-know-about-datastream"">Source</a></strong></figcaption>
</figure>
<h2><strong>What are the Capabilities of Datastream?</strong></h2>
<p>Datastream allows users to synchronize data across their business faster. Applications and heterogeneous databases will keep working efficiently and without disruptions even after the implementation of Datastream to gather data. Your source will remain intact so that you can work with data and accelerate database replication, support event-driven architectures, process rapid cloud migrations, and build analytics by using data streams. </p>
<p>Users shouldn’t be concerned that high volumes of data would cause latency. Datastream is serverless and it can adapt with ease according to the volume of data presented. It means that you have to spend less time dealing with the infrastructure, maintaining optimal performance, or provisioning resources and dedicate more time to studying the insights derived.  </p>
<p>Datastream promises to enhance your experience in working with data on-premises and on the cloud. Here are some of the perks that accompany the implementation of Datastream in your organization:</p>
<ul>
<li><strong>Minimal latency.</strong> Datastream serverless architecture brings maximal performance in processing speed. One stream allows 10 MBs per second to be processed without impacting performance. Data maintains the same flow and quality regardless of its amount.</li>
</ul>
<ul>
<li><strong>Easy implementation.</strong> All processes that may change data replication in real-time should be integrated into one flow. Datastream simplifies the process by putting database preparation documentation, stream validation, and secured connectivity set up right into the flow. </li>
</ul>
<ul>
<li><strong>Security. </strong>Datastream allows the information to pass from the source to the destination through private connectivity, and with information being <a href=""https://cloud.google.com/datastream#:~:text=Datastream%20supports%20multiple%20secure%2C%20private,is%20protected%20as%20it%20streams."">encrypted in transit</a>. This way your migrated data travels securely and is displayed in its original form without loss.</li>
</ul>
<ul>
<li><strong>Holistic solution.</strong> Replication changes into the destination databases and building pipelines shouldn’t take forever. Datastream provides users with templates that cut down the time it takes to move data into Cloud SQL, BigQuery, and Cloud Spanner. </li>
</ul>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>When to Use Datastream?</strong></h2>
<p>Datastream finds use in multiple industries where data insights are required. One of their earliest customers is Schnuck Markets, Inc, the giant supermarket retailer with over 100 stores. <a href=""https://cloud.google.com/blog/products/databases/new-cloud-based-cdc-replication-across-databases#:~:text=Customers%20tell%20us,our%20business%20users.%E2%80%9D"">They used Datastream</a> to replicate and monitor data into BigQuery which proved more effective than using on-premises. </p>
<p>Would Datastream be useful for your business? It depends on whether its capabilities are a match for your current infrastructure. Here are some of its potential implementations: </p>
<ul>
<li>Building tables of replicated data by using BigQuery and Dataflow templates to allow seamless access to data analytics insights.</li>
</ul>
<ul>
<li>Synchronizing and replicating database data for Spanner or PostgreSQL into Cloud SQL by using Datastream with Dataflow templates to ensure safe database replications.</li>
</ul>
<ul>
<li>Ingesting changes into object stores such as Google Cloud Storage from several sources to build event-driven architectures. </li>
</ul>
<ul>
<li>Building data pipelines that allow data streams to pass from legacy relational data stores with the help of Datastream into MongoDB in a continuous manner. </li>
</ul>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2><strong>How to Get Started with Datastream?</strong></h2>
<p>Getting started with Datastream can be done in a straightforward process of six steps. Then, you’re all ready and set to stream real-time changes from MySQL and Oracle databases through Datastream. </p>
<ol>
<li>Click <strong>Create Stream</strong> on your Google Cloud console, found under Big Data in the Datastream section. </li>
<li>Select the source database type and complete the details of setting it up. </li>
<li>Complete your <strong>source connection profile</strong> to simplify use at other times. </li>
<li>Select the <strong>connection method </strong>for the source </li>
<li>Set up and finish configuring your <strong>destination connection</strong> database profile</li>
<li>Finally, <strong>test </strong>your stream and tune details until it’s successful. </li>
</ol>
<p>Now, you’re all set to start data streaming!</p>
<div class=""wp-block-spacer"" aria-hidden=""true""> </div>
<h2>Final Thoughts</h2>
<p>Datastream is appropriate for various applications because it offers both cloud and on-premises support. It makes it possible to capture changes and historical data into Cloud Storage from all MySQL sources and Oracle. Moreover, it integrates with Dataflow and Cloud Data Fusion to deliver replications to multiple Google Cloud destinations. </p>
<p>We believe using data analytics is crucial for every organization, and we have found this by working on over 100 projects with organizations of different sizes. Making use of machine learning, data science, and multiple other tools, we help unify data in one place to portray useful insights that can be used for more accurate business decisions. Read more <a href=""/services/"">here</a>. </p>
</li>
</ul>
<div class=""wp-block-image""> </div>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Blog-Post-Cover-Images-1.png,Blog-Post-Cover-Images-1.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Blog-Post-Cover-Images-1.png,3994,Blog-Post-Cover-Images-1,,,,https://blueorange.digital/wp-content/uploads/2022/05/Blog-Post-Cover-Images-1.png,,,,,,,,
3998,"Deploying dbt on Databricks Simplifies Data Transformation Even More","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}""]<div class=""post-blog"">
<div class=""content"">
<ul>
<li>
<p>Simple is powerful. This is the unofficial motto behind dbt, which stands for Data Build Tool. With the complex problems that arise in the implementation of new technologies, a proper study of data always leads to statistical solutions. </p>
<p>As data analysts and engineers, we seek affordable tools that get the job done without much sophistication. <a href=""https://docs.getdbt.com/docs/introduction"">Dbt </a>is one of those tools that has helped engineers by allowing them to work with data in various warehouses more efficiently. </p>
<p>Databricks, another powerful tool, complements dbt in accomplishing these processes. As an Enterprise AI cloud data platform, the company has its roots back in 2013 when Apache Spark founders decided to expand their activities.</p>
<p>Seeing the massive use of SQL and the practicality it comes with, Databricks developers searched for ways to streamline its use throughout their platform with ease. Therefore, they came up with a native adapter for dbt, which allows clients to build seamless data pipelines on Databricks by writing lines of SQL code. </p>
<h2>What is Databricks? </h2>
<p>Databricks is a data lake that supports AI. After using other products such as Snowflake ,you might be curious about their differences. They both offer similar services but differ in their capabilities and their growth potential. </p>
<p>Snowflake is a data warehouse where you can store, manage, and work with data in a proficient way. However, Databricks offers much more than storing and managing data. It offers artificial intelligence solutions that allow the use of data to produce smart models.</p>
<p>Databricks is mainly focused on advanced large enterprise projects in the field of data science, such as Artificial Intelligence and Machine Learning. It is a cloud-based data platform that handles data transformation securely by making use of in-memory caching for rapid query execution that facilitates the processes even with large amounts of data.   </p>
<p>Located in over 20 offices around the world, Databricks is growth-focused and it has delayed going IPO so that it can channel all the resources into expanding in multiple countries, offering completely localized service.</p>
<figure class=""wp-block-image""><img src=""https://lh6.googleusercontent.com/LqxoaaMGgJaaw3Phq3tOKbpqloBm2p52QlDn8w5YvOO3_RIsL3_uSGm20TpFE86b6YGD5xL3pTKK-kqsiugRmtHxzbvUfJl8aGFOiJoMijK4HHlZEoA81MwwwtB_ckTcCdoObY07"" alt="""" /><br />
<figcaption><strong><a href=""https://blog.getdbt.com/what-exactly-is-dbt/"">Source </a></strong></figcaption>
</figure>
<h2><strong>What is dbt?</strong></h2>
<p>Dbt is an <a href=""https://blog.getdbt.com/what-exactly-is-dbt/"">open source data modeling tool </a>used by analysts and engineers for writing SQL queries. Building data pipelines is done faster since files are organized in folders and directories, just as plain text so deployment, testability, and version control are made simple.</p>
<p>Not only does dbt simplify complex queries, but it also reduces the need for repeatable lines of code. It turns queries into blocks of code that execute data transformation tasks inside your warehouse. Dbt runs code against the database, after compiling it into SQL.</p>
<p>To understand dbt, we must understand <a href=""https://www.ibm.com/cloud/learn/elt"">ELT</a>. ELT stands for Extract, Load, and Transform. This type of architecture focuses on transforming data after loading. Dbt is the T in ELT. It transforms existing data in your warehouse, but it doesn’t deal with its extraction or load.</p>
<h2><strong>How do dbt and Databricks work together?</strong></h2>
<p>As a development environment, dbt users can run transformative commands on their data by writing only SQL select statements. Then, it’s the job of dbt to take these statements and build views and tables. Your code is compiled into raw SQL and runs against a specific Databricks database. There, users have access to version control, modularity, collaborative coding patterns, documentation, and much more. </p>
<p>The dedicated native adapter for Databricks can be installed comfortably by running <a href=""https://github.com/databricks/dbt-databricks"">pip- dbt-databricks</a>. This package was developed by the programmers who founded dbt-spark and it’s open source for you to analyze and modify. Led by dbt Labs, all contributors worked on developing a package that is easy to install and doesn’t depend on ODBC drivers. </p>
<p>Three points worth noting during this adaptation are: </p>
<ul>
<li>Dbt models follow the Delta format primarily .</li>
<li>Photon speeds up the work of expensive queries. </li>
<li>Delta Lake’s MERGE statement is implemented with incremental models.</li>
</ul>
<h2>Final Thoughts</h2>
<p>The dbt Labs team is continuously working on enhancing the functions of dbt and specifically its integrations with Databricks Lakehouse. Considered as an ideal environment for data warehousing activities, it offers optimal performance and understands commands written in standard SQL. Obviously, it accepts data pipelines based on dbt as well. </p>
<p>Blue Orange has a team of data scientists well-versed in analyzing and storing data in data lake environments and more. Our clients benefit from a faster extraction, ingestion, and transformation of data with maximal accuracy. Read further details <a href=""/services/"">here</a>.  </p>
</li>
</ul>
<div class=""wp-block-image""> </div>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/Blog-Post-Cover-Images.png,Blog-Post-Cover-Images.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/Blog-Post-Cover-Images.png,3999,Blog-Post-Cover-Images,,,,https://blueorange.digital/wp-content/uploads/2022/05/Blog-Post-Cover-Images.png,,,,,,,,
4005,"Build and Deploy ML Models Through SQL with Amazon Sagemaker Autopilot and Snowflake","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px||3px|||"" locked=""off"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.17.1"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" width=""100%"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.17.1"" text_font=""Titillium Web||||||||"" text_text_color=""#000000"" text_font_size=""18px"" header_2_font=""Titillium Web|700|||||||"" header_2_text_color=""gcid-23a00398-10e3-44db-a429-8ad12fd4fe90"" header_2_font_size=""35px"" header_2_line_height=""2em"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" hover_enabled=""0"" text_font_size_tablet=""14px"" text_font_size_phone=""12px"" text_font_size_last_edited=""on|phone"" header_2_font_size_tablet=""24px"" header_2_font_size_phone=""20px"" header_2_font_size_last_edited=""on|phone"" global_colors_info=""{%22gcid-23a00398-10e3-44db-a429-8ad12fd4fe90%22:%91%22header_2_text_color%22%93}"" sticky_enabled=""0""]<div class=""post-blog"">
<div class=""content"">
<ul>
<li>
<p>Machine Learning brings unlimited innovative opportunities to work with data. Whether planning to build the next revolutionary virtual assistant or social media network, you'll always work with data in transformative ways. However, the complex environment of ML technology requires a solid infrastructure, multiple software packages, and specialized engineers who can build and maintain it. </p>
<p>For a minute, imagine if this was accessible to a broader range of data professionals with less constraints. Considering the high number of those who have knowledge of SQL, this can now become a reality. Analysts can seamlessly build and deploy ML models by using SQL from end to end. What are the implications? </p>
<ul>
<li>Scoring a large number of datasets and building models without using Python, Scala, or another language.</li>
<li>No need for infrastructure provision and management in a public cloud or on-prem.</li>
<li>Avoiding costs of additional software packages (PyTorch, TensorFlow, MXNet, etc.).</li>
</ul>
<p>The foremost result is a reduction in expenses and inefficiency. Organizations can implement Machine Learning models for predicting and revealing patterns that lead towards more revenue. Gone are the days when ML models were built and deployed solely by data scientists and ML programmers! </p>
<p>Instead, analysts who have a strong background in SQL and business can implement machine learning in more areas of your organization. The recent integration between Snowflake and Amazon SageMaker Autopilot makes this achievable. This integration pairs up the machine learning capabilities of Amazon SageMaker Autopilot with Snowflake’s predictive analytics and processing power. All in just a few lines of SQL code. </p>
<p>SQL is receiving attention lately, and we saw this while uncovering how Babelfish works. Using SQL from inside Snowflake, engineers can create and deploy ML models easily which is an amazing functionality that is available in public preview as an integration from AWS, and known also for being part of the AI for Data Analytics <a href=""https://aws.amazon.com/blogs/apn/ai-for-data-analytics-aida-partner-solutions-will-empower-business-experts-with-predictive-analytics/"">(AIDA) initiative.</a> For a clear understanding of this integration, let’s dive into what Snowflake and Amazon Sagemaker are. </p>
<h2>What is Snowflake &amp; Amazon Sagemaker Autopilot?</h2>
<p>Snowflake is turning into a widely known data warehouse to base data analytics stacks of different industries. It allows a seamless connection with BI and data analytics tools or other types of cloud services. Compared to other data warehouses, Snowflake offers more flexibility and faster processing. It is separated from your computer storage and runs entirely on cloud storage instead of relying on existing technologies or “big data” software platforms. </p>
<p>Snowflake scales in a flexible manner both up and down, while preserving all of its features. Perfect for optimal performance while keeping a low overhead. Through Snowflake, you can build a home for data on the cloud for more efficient access to it while building ML models. Spend time on data strategy rather than being concerned about the maintenance of your cloud architecture. </p>
<p>On the other hand, Amazon Sagemaker assists in the training and deployment of ML models on AWS. It feeds predictions with data by sending HTTP requests with the data that requires prediction. As one of the first MLaaS (Machine Learning as a Service) systems, it supports end-to-end Machine Learning workflows. </p>
<p>Released in 2017, Sagemaker has surpassed basic functionalities, turning into a more complex cloud infrastructure. Data scientists, researchers, and engineers can utilize its fully managed cloud infrastructure for the training and deployment of ML models by benefiting from its time-saving integrated environment.   </p>
<p>Recently, another feature known as Amazon SageMaker Autopilot was added. The feature utilizes tabular data for training your ML model while portraying the process with full transparency. It allows users to specify the target column with data and then leave the process to run automatically. </p>
<figure class=""wp-block-image""><img src=""https://lh5.googleusercontent.com/36WjmUDdKCSltg3cP4eim2-VbPDOI6ZK1qOcRBye5MqMaX1Npzp7rdah5lzF3UzXFvrZ1VVozOB72Q7IR9oaUl-T-Lw7Suq70EwGTPruJbHp7sWiFAWj7gpyQh6uy_MhiEPCCfxQ"" alt="""" /><br />
<figcaption><strong><a href=""https://aws.amazon.com/blogs/apn/how-to-use-amazon-sagemaker-to-improve-machine-learning-models-for-data-analysis/"">Source</a></strong></figcaption>
</figure>
<h2>New Possibilities with Amazon Sagemaker Autopilot and Snowflake</h2>
<p>Torsten Grabs, Director of Product Management at Snowflake, <a href=""https://www.snowflake.com/blog/analysts-can-now-use-sql-to-build-and-deploy-ml-models-with-snowflake-and-amazon-sagemaker-autopilot/?utm_campaign=Oktopost-linkedin-Snowflake&amp;utm_content=Oktopost-Content+-+Blogs&amp;utm_medium=social&amp;utm_source=linkedin#:~:text=%E2%80%9CUsing%20the%20Snowflake,from%20within%20Snowflake.%E2%80%9D"">pointed out</a> the opportunities that this integration between Amazon Sagemaker Autopilot and Snowflake turns data into reliable ML-powered insights that serve not only existing data science teams, but can be utilized for future use as well. </p>
<p>Automation remains critical. If organizations automate the process of deploying and training machine learning models, costs are lowered and models can be produced more efficiently. Subjected to latency constraints and model sizes, data scientists test multiple ML models for IoT or ad-serving applications. Amazon Sagemaker Autopilot requires no knowledge of machine learning to build regression and classification models, which simplifies and shortens the process of finding the ideal solution.  </p>
<p>Snowflake works immaculately to store a rich range of tabular data sets. The integration with Amazon Snowflake Autopilot allows users to make use of its different algorithms and data preprocessors to scour through data columns and find an optimal model.  </p>
<h2><strong>In a Nutshell</strong></h2>
<p>The integration between Snowflake and Amazon Sagemaker Autopilot lays the power of machine learning models in hands of more data professionals, including data analysts and other SQL users. Classification and regression algorithms find use in multiple marketing cases such as: </p>
<ul>
<li>Customer life value prediction </li>
<li>Sales and price prediction</li>
<li>Predictive maintenance</li>
<li>Customer churn prediction, etc. </li>
</ul>
<p>Blue Orange Digital has partnered up with Snowflake, and is also an AWS certified partner capable of helping organizations build and deploy predictive and customized machine models. Experienced in working with data transformation, predictive analytics, and data vizualization, we help implement large-scale solutions. <a href=""/services/"">Reach out </a>to our team and have a chat for more.</p>
</li>
</ul>
<div class=""wp-block-image""> </div>
</div>
</div>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/05/SQL-Snowflake-Blog-Post-Cover.png,SQL-Snowflake-Blog-Post-Cover.png,/www/blueorangem_500/public/wp-content/uploads/2022/05/SQL-Snowflake-Blog-Post-Cover.png,4006,SQL-Snowflake-Blog-Post-Cover,,,,https://blueorange.digital/wp-content/uploads/2022/05/SQL-Snowflake-Blog-Post-Cover.png,,,,,,,,
5003,"Approaching Data as a Product can Unlock Its Hidden Potential","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.16"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text _builder_version=""4.17.6"" _module_preset=""default"" global_colors_info=""{}""]<p><span style=""font-weight: 400;"">The power that data holds to transform business is already acknowledged to be vast, and we’re constantly on a quest to manage this data better in order to achieve more efficiency. Escaping the necessity of data is impossible because it’s a key asset. Therefore, we have to find ways to turn data into a manageable asset instead. One approach is to treat data like a product. </span></p>
<p><span style=""font-weight: 400;"">When companies develop products they do so with a clear picture of the ideal customer in mind and of what they want. The same thing can be done with data as a product: it can be packaged into sets that serve specific sectors in a business. In this article, we’re going through the current approaches taken on data and how businesses can tailor their approach to derive more value out of their </span><a href=""https://blueorange.digital/the-4-data-questions-every-cu-leader-needs-to-answer-2/""><span style=""font-weight: 400;"">data</span></a><span style=""font-weight: 400;"">.</span></p>
<p>&nbsp;</p>
<h2><span style=""font-weight: 400;"">The Current Approaches to Data </span></h2>
<p><span style=""font-weight: 400;"">There are two main approaches to data: the big-bang and grassroots data strategy. Both of them come with major handicaps and limitations that keep the value of data locked. Let’s see how each approach works. </span></p>
<p>&nbsp;</p>
<h3><span style=""font-weight: 400;"">The Grassroots Approach</span></h3>
<p><span style=""font-weight: 400;"">The costs of building, managing, and maintaining </span><a href=""https://blueorange.digital/the-evolution-of-data-architecture-intro/""><span style=""font-weight: 400;"">the architecture</span></a><span style=""font-weight: 400;""> for the grassroots approach are pretty high. Individual teams come together to assemble the technologies and data required to work together. The grassroots approach results in duplication of efforts which requires more time and resources.</span></p>
<p>&nbsp;</p>
<h3><span style=""font-weight: 400;"">Big-bang Strategy</span></h3>
<p><span style=""font-weight: 400;"">As the name implies, the big-bang strategy deals with vast amounts of data. When a team applies this strategy, it extracts, cleanses, and gathers massive amounts of data. The approach reduces the amount of rework needed in the process but it’s rarely aligned with business use cases which makes it less valuable in supporting the users’ needs. </span></p>
<p><span style=""font-weight: 400;"">Both of these strategies provide a clouded prediction for the current and future use cases that reveal actual value for the end users and the business. </span></p>
<p>&nbsp;</p>
<h2><span style=""font-weight: 400;"">The Newest Approach: Data as a Product</span></h2>
<p><span style=""font-weight: 400;"">This approach has benefits for companies that have implemented it for multiple reasons. For companies that treat and manage data as a product, it has been easier to realize the value of their investments and forecast with more value extracted from their data. Three of the key reasons for this are: </span></p>
<p>&nbsp;</p>
<h3><span style=""font-weight: 400;"">1. Data Products Deliver All Data About Specific Entities </span></h3>
<p><span style=""font-weight: 400;"">The beauty of working with data as a product stands in the fact that it can encapsulate all the required information about a specific entity such as employees, branches, customers, or product lines in one space. The set of data can be used by people in the organization to solve </span><a href=""https://blueorange.digital/case-study/""><span style=""font-weight: 400;"">particular problems</span></a><span style=""font-weight: 400;"">. </span></p>
<p>&nbsp;</p>
<h3><span style=""font-weight: 400;"">2. Standard Types of Consumption Are Excellently Delivered with Data Products </span></h3>
<p><span style=""font-weight: 400;"">For companies that provide diverse business systems, data products are wired in a manner that allows these systems to consume and utilize data according to their needs. For example, these can be reporting systems or digital apps, and each of them has its own “consumption archetype”. Data products provide data in its most suitable form for the particular consumption archetype.</span></p>
<p>&nbsp;</p>
<h3><span style=""font-weight: 400;"">3. Data Products Provide Increased Efficiency and Speed</span></h3>
<p><span style=""font-weight: 400;"">The main problems we faced with traditional approaches to data (namely grassroots and big-bang) were concerning efficiency and speed. Data products provide enhancements in this aspect because the work process is different. Teams won’t struggle to search for data, convert it, and then build bespoke data pipelines if they’re working with data products. </span></p>
<p><span style=""font-weight: 400;"">This way they’ll save time on the governance and architectural challenges that arise with it. Furthermore, data products offer other benefits, such as: increasing the use cases delivery speed </span><a href=""https://hbr.org/2022/07/a-better-way-to-put-your-data-to-work#:~:text=Companies%20that%20treat%20data%20like%20a%20product%20can%20reduce%20the%20time%20it%20takes%20to%20implement%20it%20in%20new%20use%20cases%20by%20as%20much%20as%2090%25.""><span style=""font-weight: 400;"">up to 90%</span></a><span style=""font-weight: 400;"">, decreasing total costs by 30%, and reducing the data-governance risks that arise. </span></p>
<p>&nbsp;</p>
<h2><span style=""font-weight: 400;"">How to Get Started with Data Products? </span></h2>
<p><span style=""font-weight: 400;"">The factors that ensure success in product development are similar to those that indicate success in the development of data products as well. These factors include: </span></p>
<ul>
<li style=""font-weight: 400;"" aria-level=""1""><b>Specific funding and management.</b><span style=""font-weight: 400;""> Data products are managed by specific teams which include data platform engineers, data architects, site reliability engineers, and a product manager. These teams should be equipped with proper funding to enhance the product and be informed of the customer’s feedback.  </span></li>
<li style=""font-weight: 400;"" aria-level=""1""><b>Established best practices and standards.</b><span style=""font-weight: 400;""> Companies built successful products when they follow standards and proven practices. These are tasks that are taken care of by the Data Center of Excellence (DCoE) and include processes such as: audit data use, data provenance, data quality measuring, and establishing principles upon which essential technologies should be designed for versatility in usage. </span></li>
<li style=""font-weight: 400;"" aria-level=""1""><b>Performance tracking. </b>The success of data products depends on their performance so it makes sense to keep track of the end-user activity. This includes product use cases, survey statistics, and the ROI achieved.</li>
<li aria-level=""1""><b>Quality assurance.</b><span style=""font-weight: 400;""> After doing the hard work of building data products, it’s important to ensure customer satisfaction by actively monitoring their quality. For this matter, data teams should monitor data definitions, availability, and access control as a few examples.</span></li>
</ul>
<p>&nbsp;</p>
<h2><span style=""font-weight: 400;"">Final Thoughts</span></h2>
<p><span style=""font-weight: 400;"">Unlocking the full potential of data requires expertise and commitment from your data teams. The obstacles seem oftentimes endless and the future loses its brightness unless you leverage data wisely today. At Blue Orange Digital we’ve helped companies reinvent their relationships data for more revenue and efficiency. </span><a href=""https://blueorange.digital/contact/""><span style=""font-weight: 400;"">Schedule a call</span></a><span style=""font-weight: 400;""> with us today to learn more about our services. </span></p>
<p>&nbsp;</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/08/Approaching-Data-as-a-Product-can-Unlock-Its-Hidden-Potential-Blue-Orange-Digital.png|https://blueorange.digital/wp-content/uploads/2022/08/Screen-Shot-2022-08-04-at-9.41.38-AM.png|https://blueorange.digital/wp-content/uploads/2022/08/Screen-Shot-2022-08-04-at-9.43.30-AM.png,Approaching-Data-as-a-Product-can-Unlock-Its-Hidden-Potential-Blue-Orange-Digital.png|Screen-Shot-2022-08-04-at-9.41.38-AM.png|Screen-Shot-2022-08-04-at-9.43.30-AM.png,/www/blueorangem_500/public/wp-content/uploads/2022/08/Approaching-Data-as-a-Product-can-Unlock-Its-Hidden-Potential-Blue-Orange-Digital.png|/www/blueorangem_500/public/wp-content/uploads/2022/08/Screen-Shot-2022-08-04-at-9.41.38-AM.png|/www/blueorangem_500/public/wp-content/uploads/2022/08/Screen-Shot-2022-08-04-at-9.43.30-AM.png,5012|5010|5011,"Approaching Data as a Product can Unlock Its Hidden Potential, Blue Orange Digital|Data as a Product, Harvard Business Review|Data Consumption, McKinsey and Company",||,||,"|Data as a Product, Harvard Business Review|Data Consumption, McKinsey and Company",https://blueorange.digital/wp-content/uploads/2022/08/Approaching-Data-as-a-Product-can-Unlock-Its-Hidden-Potential-Blue-Orange-Digital.png,,,,,,,,
5026,"Unify Transactional and Analytical Data with Snowflake Unistore","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.16"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""]<p><span style=""font-weight: 400;"">A common struggle that had slowed down how organizations work with data, was the separation of transactional and analytical data. This was something that limited the capacity to process queries faster but now it belongs to the past. Snowflake has developed </span><a href=""https://www.snowflake.com/workloads/unistore/""><span style=""font-weight: 400;"">Unistore</span></a><span style=""font-weight: 400;"">–the workload that brings transactional and analytical data together into a single platform. </span></p>
<p><span style=""font-weight: 400;"">Now organizations can leverage a single data set to successfully deploy applications and keep track of their analytical and transactional data as they operate. This seemingly simple change will enable access to new opportunities for business owners and organizations and lead to rapid growth. </span></p>
<p>&nbsp;</p>
<h2><span style=""font-weight: 400;"">Understanding Unistore </span></h2>
<p><span style=""font-weight: 400;"">Unistore is a workload that was developed with one purpose: to eliminate the frustrations that organizations face when moving data across systems. Sometimes they need to maintain redundant data sets across multiple solutions unnecessarily. Making the data available in one place simplifies the work process, and makes results easy to manage and communicate to other team members. </span></p>
<p><span style=""font-weight: 400;"">However, Snowflake offers much more than just the unification of data in one place with Unistore. It gives organizations the capability to build transactional business applications without leaving Snowflake. Well-known companies such as UiPath, Wolt, and Adobe have already adopted Unistore for their services on use cases such as enhancing their online stores and storing application states for pipelines. </span></p>[/et_pb_text][et_pb_image src=""https://blueorange.digital/wp-content/uploads/2022/08/Screen-Shot-2022-08-12-at-9.34.18-AM.png"" alt=""Snowflake"" title_text=""Snowflake"" url=""https://resources.snowflake.com/solution-briefs/snowflake-unistore?utm_cta=website-workload-unistore-resources-solution-brief&_ga=2.223026782.419163312.1659958664-1492692052.1659958664"" _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""][/et_pb_image][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""]<h2><span style=""font-weight: 400;"">The Benefits of Unistore </span></h2>
<p><span style=""font-weight: 400;"">Behind Unistore lies the simple principle of removing data silos which has proven successful in other approaches to data. By creating a space where analytical and transactional data is brought together, Snowflake is providing a workload with four core benefits: </span></p>
<ul>
<li style=""font-weight: 400;"" aria-level=""1""><b>Unifies Data in a Single Dataset for Rapid Development. </b><span style=""font-weight: 400;"">Organizations can integrate analytical and transactional data in a single dataset, which opens ways to improve almost any area of their work. This leads to enhanced customer experiences, faster responses, and new enriched insights on data. </span></li>
</ul>
<p>&nbsp;</p>
<ul>
<li style=""font-weight: 400;"" aria-level=""1""><b>Simplifies the Development of Transactional Apps.</b><span style=""font-weight: 400;""> Organizations can build transactional apps on Snowflake capable of handling enterprise-sized data with maximum performance and simplicity. Those who’ve worked with Snowflake’s Data Cloud can expect an unmatched similar experience with Unistore. </span></li>
</ul>
<p>&nbsp;</p>
<ul>
<li aria-level=""1""><b>Removes Silos Between Analytical and Transactional Data. </b>Building transactional applications and working with both analytical and transactional data is made easier. This means that data workers can directly run analytical queries in real-time to work with transactional data.</li>
</ul>
<p>&nbsp;</p>
<ul>
<li style=""font-weight: 400;"" aria-level=""1""><b>Consolidates Analytical and Transactional Systems. </b><span style=""font-weight: 400;"">There’s no more need to copy or move data from one platform to the other. Moreover, Unistore allows you to standardize governance and security controls and produce simpler architectures. </span></li>
</ul>
<p><span style=""font-weight: 400;"">Data workers and developers will find the development of new technologies easier by working with Unistore and Snowflake. The financial space handles complicated and important data and it seems like companies are paying attention to it. </span><a href=""https://blueorange.digital/databricks-lakehouse-for-financial-services/""><span style=""font-weight: 400;"">Databricks Lakehouse</span></a><span style=""font-weight: 400;""> has also approached this area successfully. </span></p>[/et_pb_text][et_pb_image src=""https://blueorange.digital/wp-content/uploads/2022/08/Screen-Shot-2022-08-12-at-9.38.32-AM.png"" alt=""Snowflake Unistore"" title_text=""Snowflake Unistore"" url=""https://www.snowflake.com/news/snowflake-launches-new-unistore-workload-to-drive-next-phase-of-innovation-with-transactional-and-analytical-data-together-in-the-data-cloud/"" _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""][/et_pb_image][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""]<h2><span style=""font-weight: 400;"">How Does Unistore Enable Analytical and Transactional Use Cases</span></h2>
<p><span style=""font-weight: 400;"">Application developers need fast and compatible platforms that enable them to process transactional data with the proper capabilities. Unistore </span><a href=""https://www.youtube.com/watch?v=kHbXBZhdQbg""><span style=""font-weight: 400;"">introduces Hybrid Tables</span></a><span style=""font-weight: 400;""> to help developers achieve this without lowering the performance. Snowflake has built a row-based storage engine that allows fast single-row operations to happen, which means that the applications can be built directly on Snowflake. </span></p>
<p><span style=""font-weight: 400;"">However, when we talk about leveraging Snowflake in a much smarter way, this doesn’t include only the capability to build applications directly on Snowflake. Transactional data is important for extracting </span><a href=""https://blueorange.digital/making-your-business-data-driven-the-right-way/""><span style=""font-weight: 400;"">business insights</span></a><span style=""font-weight: 400;""> and Unistore allows you to perform analytical computations directly on this analytical data. Done the old way, this meant you had to upload this data into Snowflake from external databases but now the data is in one place and you can even run real-time queries on live data. </span></p>
<p>&nbsp;</p>
<h2><span style=""font-weight: 400;"">Final Thoughts</span></h2>
<p><span style=""font-weight: 400;"">Unistore is an excellent workload powered by Snowflake’s Data Cloud. This means that besides the benefits we mentioned when working with transactional data, you’ll benefit from the security controls and data governance among others. </span></p>
<p><span style=""font-weight: 400;"">If this sounds like something you’d want in your organization, Blue Orange Digital can assist you. We’re </span><a href=""https://blueorange.digital/modern-data-stack-technologies/snowflake/""><span style=""font-weight: 400;"">official partners</span></a><span style=""font-weight: 400;""> of Snowflake Services and can cater to your data needs. </span><a href=""https://blueorange.digital/contact-us/""><span style=""font-weight: 400;"">Schedule </span></a><span style=""font-weight: 400;"">a short call with us today for more information. </span></p>
<p>&nbsp;</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/08/Unify-Transactional-and-Analytical-Data-with-Snowflake-Unistore-Blue-Orange-Digital.png|https://blueorange.digital/wp-content/uploads/2022/08/Screen-Shot-2022-08-12-at-9.34.18-AM.png|https://blueorange.digital/wp-content/uploads/2022/08/Screen-Shot-2022-08-12-at-9.38.32-AM.png,Unify-Transactional-and-Analytical-Data-with-Snowflake-Unistore-Blue-Orange-Digital.png|Screen-Shot-2022-08-12-at-9.34.18-AM.png|Screen-Shot-2022-08-12-at-9.38.32-AM.png,/www/blueorangem_500/public/wp-content/uploads/2022/08/Unify-Transactional-and-Analytical-Data-with-Snowflake-Unistore-Blue-Orange-Digital.png|/www/blueorangem_500/public/wp-content/uploads/2022/08/Screen-Shot-2022-08-12-at-9.34.18-AM.png|/www/blueorangem_500/public/wp-content/uploads/2022/08/Screen-Shot-2022-08-12-at-9.38.32-AM.png,5034|5029|5031,"Unify Transactional and Analytical Data with Snowflake Unistore, Blue Orange Digital|Snowflake|Snowflake Unistore",||,||,"|Snowflake|Snowflake Unistore",https://blueorange.digital/wp-content/uploads/2022/08/Unify-Transactional-and-Analytical-Data-with-Snowflake-Unistore-Blue-Orange-Digital.png,,,,,,,,
5134,"AlloyDB for PostgreSQL","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.16"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""]<p><span style=""font-weight: 400;"">Legacy database systems are far from perfect and that’s why enterprises aim to find different solutions to keep their applications running smoothly. That’s why Google announced on May 11 at their event Google I/O, a preview of </span><a href=""https://cloud.google.com/alloydb/docs/overview#:~:text=AlloyDB%20is%20a%20fully%2Dmanaged,compatibility%20with%20open%2Dsource%20PostgreSQL.""><span style=""font-weight: 400;"">AlloyDB </span></a><span style=""font-weight: 400;"">for PostgreSQL. Organizations can now leverage this PostgreSQL-compatible database service to innovate their most used enterprise database workloads. </span></p>
<p><span style=""font-weight: 400;"">According to the tests that were performed, AlloyDB was four times faster than the standard PostgreSQL when used for transactional workloads and over a hundred times much faster when used for analytical queries. This speed and reliability make AlloyDB a compatible substitute for legacy database engines. </span></p>
<p>&nbsp;</p>
<h2><span style=""font-weight: 400;"">What Makes AlloyDB Special? </span></h2>
<p><span style=""font-weight: 400;"">Switching from </span><a href=""https://blueorange.digital/data-architecture-legacy-edition/""><span style=""font-weight: 400;"">legacy products</span></a><span style=""font-weight: 400;""> to an open-source database poses a lot of challenges in the terms of performance tuning, application availability management, and interruptions caused by vacuuming. AlloyDB intends to address these issues with its security, availability, manageability, and AI/ML-powered management that complies with PostgreSQL compatibilities and reliable storage. </span></p>
<p><span style=""font-weight: 400;"">AlloyDB allows you to scale without sacrificing performance. Thanks to its sophisticated database-optimized storage service tailored for PostgreSQL that uses similar building blocks to worldwide services such as Youtube and Gmail, it can disaggregate storage and compute at multiple layers and provide help with scaling.</span></p>
<p><span style=""font-weight: 400;"">Google teams have equipped AlloyDB with enough power and capabilities including automatic tiering of data and analytical acceleration so that it can handle almost any workload with little management overhead. Even if you have existing applications on PostgreSQL, you can migrate them with nearly no changes since AlloyDB supports the latest version of PostgreSQL. </span></p>[/et_pb_text][et_pb_image src=""https://blueorange.digital/wp-content/uploads/2022/08/Screen-Shot-2022-08-22-at-10.02.25-AM.png"" alt=""AlloyDB for PostgreSQL"" title_text=""AlloyDB for PostgreSQL"" url=""https://cloud.google.com/blog/products/databases/alloydb-for-postgresql-intelligent-scalable-storage"" _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""][/et_pb_image][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""]<h3><span style=""font-weight: 400;"">Increased Scale and Performance</span></h3>
<p><span style=""font-weight: 400;"">AlloyDB is guaranteed to bring a high level of performance with its multiple layers of caching that are automatically tiered according to workload patterns. Since the AlloyDB service is much faster than Amazon’s comparable PostgreSQL-compatible service (2x) and the standard PostgreSQL (4x) it makes sense for it to provide an enhanced experience and facilitated scaling. </span></p>
<p>&nbsp;</p>
<h3><span style=""font-weight: 400;"">Provides Transparent and Predictable Pricing</span></h3>
<p><span style=""font-weight: 400;"">Pricing often becomes a major hurdle in adopting new database services. This is not an issue with AlloyDB as it comes with predictable and transparent </span><a href=""https://cloud.google.com/alloydb/pricing""><span style=""font-weight: 400;"">pricing</span></a><span style=""font-weight: 400;""> based on charging customers only for the services they use. There are no extra costs for read replicas or vague I/O charges. Storage is continuously provisioned on autopilot and the lighting-fast cache aids further in achieving an optimized relationship between price and performance. </span></p>
<p>&nbsp;</p>
<h3><span style=""font-weight: 400;"">Superior Availability in the Industry </span></h3>
<p><span style=""font-weight: 400;"">Ryuzo Yamamoto, a software engineer at Mercari (Souzoh, Inc.) states that “</span><i><span style=""font-weight: 400;"">AlloyDB will bring more scalability and availability with no application changes.</span></i><span style=""font-weight: 400;"">” AlloyDB is able to identify and quickly recover from database failures no matter the load or size of the database. The stellar </span><a href=""https://blueorange.digital/cloud-architecture-build-vs-buy/""><span style=""font-weight: 400;"">architecture </span></a><span style=""font-weight: 400;"">handles perfectly instance resizing and is adapted for non-disruptive database maintenance. Now customers have access to a functional and reliable database that rarely turns unavailable</span><span style=""font-weight: 400;"">. </span></p>
<p>&nbsp;</p>
<h3><span style=""font-weight: 400;"">Delivers Business Insights in Real-Time</span></h3>
<p><span style=""font-weight: 400;"">We’ve already given you a hint about the speed at which AllobyDB operates and this makes it an excellent option for hybrid transactional and analytical workloads (HTAP), reporting, and business intelligence. With the ability to deliver analytical queries 100 times faster than PostgreSQL, thanks to a vectorized columnar accelerator, AlloyDB provides faster aggregations and scans that speed up the delivery time. The data is stored in an optimized columnar format in memory which makes access easier. </span></p>[/et_pb_text][et_pb_image src=""https://blueorange.digital/wp-content/uploads/2022/08/Screen-Shot-2022-08-22-at-10.04.35-AM.png"" alt=""AlloyDB Database"" title_text=""AlloyDB Database"" url=""https://techcrunch.com/2022/05/11/google-cloud-launches-alloydb-a-new-fully-managed-postgresql-database-service/"" _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""][/et_pb_image][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""]<h3><span style=""font-weight: 400;"">Improved Insights and ML Backed Up Management</span></h3>
<p><span style=""font-weight: 400;"">AlloyDB comes with several capabilities that ease the work of developers and DBAs. Surely, it includes all the basic services that are expected from most database services such as scaling, replication, database patching and backups, and much more. </span></p>
<p><span style=""font-weight: 400;"">The advanced adaptive algorithms and </span><a href=""https://blueorange.digital/how-does-machine-learning-help-in-business-transformation/""><span style=""font-weight: 400;"">machine learning</span></a><span style=""font-weight: 400;""> intelligently organize your data and help in analytical acceleration, PostgreSQL vacuum management, and storage management. Let’s also not forget about the built-in integration with Google Cloud’s artificial intelligence platform, </span><a href=""https://cloud.google.com/vertex-ai""><span style=""font-weight: 400;"">Vertex AI</span></a><span style=""font-weight: 400;"">, that guarantees low latency, and high throughput without extra effort in writing additional code.   </span></p>
<p>&nbsp;</p>
<h2><span style=""font-weight: 400;"">Closing Thoughts</span></h2>
<p><span style=""font-weight: 400;"">It’s about time data workers and organizations escape the risks of vendor lock-in that come from legacy databases and embrace the capabilities of AlloyDB. With much more freedom than before, AlloyDB allows you to provide your customers with an enhanced experience. At Blue Orange Digital we specialize in providing data-driven solutions to maximize the revenue you get from your data infrastructure. Learn more about </span><a href=""https://blueorange.digital/services/""><span style=""font-weight: 400;"">our services</span></a><span style=""font-weight: 400;""> by scheduling </span><a href=""https://blueorange.digital/contact-us/""><span style=""font-weight: 400;"">a call</span></a><span style=""font-weight: 400;""> today</span><span style=""font-weight: 400;"">. </span><span style=""font-weight: 400;"">   </span></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/08/AlloyDB-for-PostgreSQL.png|https://blueorange.digital/wp-content/uploads/2022/08/Screen-Shot-2022-08-22-at-10.02.25-AM.png|https://blueorange.digital/wp-content/uploads/2022/08/Screen-Shot-2022-08-22-at-10.04.35-AM.png,AlloyDB-for-PostgreSQL.png|Screen-Shot-2022-08-22-at-10.02.25-AM.png|Screen-Shot-2022-08-22-at-10.04.35-AM.png,/www/blueorangem_500/public/wp-content/uploads/2022/08/AlloyDB-for-PostgreSQL.png|/www/blueorangem_500/public/wp-content/uploads/2022/08/Screen-Shot-2022-08-22-at-10.02.25-AM.png|/www/blueorangem_500/public/wp-content/uploads/2022/08/Screen-Shot-2022-08-22-at-10.04.35-AM.png,5140|5137|5138,"Google Cloud AlloyDB|AlloyDB for PostgreSQL|AlloyDB Database",||,||,"Google Cloud AlloyDB|AlloyDB for PostgreSQL|AlloyDB Database",https://blueorange.digital/wp-content/uploads/2022/08/AlloyDB-for-PostgreSQL.png,,,,,,,,
5152,"Migrate from Stored Procedures to dbt","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.16"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" hover_enabled=""0"" sticky_enabled=""0""]<p><span style=""font-weight: 400;"">We all love shortcuts. That’s why many organizations use stored procedures in their data warehousing processes. They’re an excellent solution for packaging and scheduling complex transformations through logical conditions. Stored procedures have become a core building block of teams’ workflows. But do they have any cons? </span></p>
<p><span style=""font-weight: 400;"">Data workers indicate a noticeable increase in data warehouse costs, frequent data downtime, and a rise in the unavailability of data in production. This immediately translates to confused teams who find it hard to trust their data and even more confused and overworked developers.  </span></p>
<p><span style=""font-weight: 400;"">dbt is a wonderful tool that helps in </span><a href=""https://blueorange.digital/materialize-and-dbt-transform-data-with-ease/""><span style=""font-weight: 400;"">transforming data</span></a><span style=""font-weight: 400;""> in real time by just using SELECT statements. Dbt takes these inputted statements and turns them into views and tables. Based on this principle, dbt solves major problems in the data industry, and it works as an effective alternative to stored procedures. </span></p>
<h2> </h2>
<h2><span style=""font-weight: 400;"">The Drawbacks of Stored Procedures</span></h2>
<p><span style=""font-weight: 400;"">At first, stored procedures make complete sense but their disadvantages become apparent later on when we expect data pipelines to assist in sophisticated but necessary processes such as testability, transparent documentation, and code reusability. Stored procedures aren’t testable since they don’t function well in the documentation </span><a href=""https://blueorange.digital/dataflow-automation-and-its-current-state/""><span style=""font-weight: 400;"">data flow</span></a><span style=""font-weight: 400;"">, which affects documentation negatively as well.</span></p>[/et_pb_text][et_pb_image _builder_version=""4.18.0"" _module_preset=""default"" alt=""Stored Procedures to dbt"" title_text=""Stored Procedures to dbt"" src=""https://blueorange.digital/wp-content/uploads/2022/08/Stored-Procedures-to-dbt.png"" hover_enabled=""0"" sticky_enabled=""0"" admin_label=""Image"" url=""https://docs.getdbt.com/blog/migrating-from-stored-procs?utm_content=215961102&utm_medium=social&utm_source=linkedin&hss_channel=lcp-10893210""][/et_pb_image][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" hover_enabled=""0"" sticky_enabled=""0"" admin_label=""Text""]<p><span style=""font-weight: 400;"">Stored procedures could turn into a source of stress for development teams as their intermediate steps aren’t obvious and most of the time you’ll find the same code repeated in more than one stored procedure. This lowers the efficiency of your teams massively. To be more practical, stored procedures could be the reason why it’s difficult to trace the primary origins of data in production reports and why your dashboards don’t refresh in a timely manner. </span></p>
<p>&nbsp;</p>
<h2><span style=""font-weight: 400;"">The Benefits of dbt as a Stored Procedures Alternative</span></h2>
<p><span style=""font-weight: 400;"">Modularity is key when working with dbt. Business objects are managed in separate models and organized into layers which make the data easier to be consumed and namely more testable and self-documenting. Also, this approach minimizes data duplication and simplifies code reuse. </span></p>
<p><span style=""font-weight: 400;"">Furthermore, dbt supports version control integration which helps data workers implement and test changes with git-based tools in their transformation pipelines in just a few clicks. We can say that the two most straightforward benefits of this migration are: </span></p>
<p>&nbsp;</p>
<h3><span style=""font-weight: 400;"">1. Solutions to New Use Cases</span></h3>
<p><span style=""font-weight: 400;"">Dbt uses a real-life scenario of a dbt Cloud use to illustrate the potential of this migration. As a result, after moving from using stored procedures to using dbt, the team could work with new use cases such as real-time data reporting with </span><a href=""https://docs.getdbt.com/blog/how-to-create-near-real-time-models-with-just-dbt-sql#what-are-lambda-views""><span style=""font-weight: 400;"">lambda views</span></a><span style=""font-weight: 400;"">. </span></p>
<h3><span style=""font-weight: 400;"">2. Uptime Enhancements</span></h3>
<p><span style=""font-weight: 400;"">The refreshing time can slow down whole processes in an organization if it doesn’t match the standards of other systems and clients’ expectations. After migrating from using stored procedures to dbt, the team we mentioned was able to spend less time on pipeline refreshes, improving the uptime to 99.99% (from 65%).</span></p>
<p>&nbsp;</p>
<p><span style=""font-weight: 400;"">Regardless of the SQL dialect, you’re working with (BTEQ, T-SQL, PL/SQL, etc.), the entire migration process can be summarized into four main steps. You can find this detailed step-by-step process in </span><a href=""https://docs.getdbt.com/blog/migrating-from-stored-procs?utm_content=215961102&amp;utm_medium=social&amp;utm_source=linkedin&amp;hss_channel=lcp-10893210#methodologies-for-migrating-from-stored-procedures-to-dbt""><span style=""font-weight: 400;"">dbt’s article</span></a><span style=""font-weight: 400;""> on migrating from stored procedures. But for you to have a clearer idea of how the final results, we found this illustration: </span></p>[/et_pb_text][et_pb_image _builder_version=""4.18.0"" _module_preset=""default"" title_text=""Migration diagram from Stored Procedures to dbt"" src=""https://blueorange.digital/wp-content/uploads/2022/08/Migration-diagram-from-Stored-Procedures-to-dbt.png"" hover_enabled=""0"" sticky_enabled=""0""][/et_pb_image][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" hover_enabled=""0"" sticky_enabled=""0""]<h2><span style=""font-weight: 400;"">Final Thoughts </span></h2>
<p><span style=""font-weight: 400;"">Migrating from stored procedures to dbt is definitely a much-needed investment if you want to help your teams become more productive and solve data testing and traceability issues. Your pipelines will get more elegant, clean, and resilient to frequent changes. Modular, well-documented, and testable code contributes to the improvement of all areas of your business. </span></p>
<p><span style=""font-weight: 400;"">At Blue Orange Digital, we assist </span><a href=""https://blueorange.digital/case-studies/""><span style=""font-weight: 400;"">our clients</span></a><span style=""font-weight: 400;""> from a wide range of industries including IoT, Real Estate, and Retail, in implementing measurable and more effective cloud solutions for their infrastructures. </span><a href=""https://blueorange.digital/contact-us/""><span style=""font-weight: 400;"">Schedule a free call</span></a><span style=""font-weight: 400;""> with our team today to learn how we can help your organization. </span></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/08/Migrate-Stored-Procedures-with-dbt.png|https://blueorange.digital/wp-content/uploads/2022/08/Stored-Procedures-to-dbt.png|https://blueorange.digital/wp-content/uploads/2022/08/Migration-diagram-from-Stored-Procedures-to-dbt.png,Migrate-Stored-Procedures-with-dbt.png|Stored-Procedures-to-dbt.png|Migration-diagram-from-Stored-Procedures-to-dbt.png,/www/blueorangem_500/public/wp-content/uploads/2022/08/Migrate-Stored-Procedures-with-dbt.png|/www/blueorangem_500/public/wp-content/uploads/2022/08/Stored-Procedures-to-dbt.png|/www/blueorangem_500/public/wp-content/uploads/2022/08/Migration-diagram-from-Stored-Procedures-to-dbt.png,5157|5155|5156,"Migrate Stored Procedures with dbt|Stored Procedures to dbt|Migration diagram from Stored Procedures to dbt",||,||,"|Stored Procedures to dbt|",https://blueorange.digital/wp-content/uploads/2022/08/Migrate-Stored-Procedures-with-dbt.png,,,,,,,,
5161,"Fivetran Data Unification","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.16"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" text_font_size=""18px"" global_colors_info=""{}""]<p><span style=""font-weight: 400;"">Guess who made it to the Forbes Cloud 100 list for the third time? Fivetran. The modern data integration giant persists in growing and maintaining a reliable reputation in the market. This time, they moved four spots up compared to the previous year (from #31 in 2021 to #27 in 2022). </span></p>
<p><span style=""font-weight: 400;"">Today, we’ll make sense of all the buzz that’s been around and uncover some of the most prominent milestones of the company. The ranking, which was accompanied by a breakthrough thanks to the recent acquisition of Fivetran, was quite surprising. These remain to be discussed below as we explore the story of these </span><a href=""https://www.fivetran.com/blog/the-5-6-billion-internet-plumbers""><span style=""font-weight: 400;"">‘internet plumbers’</span></a><span style=""font-weight: 400;"">.</span></p>
<h2> </h2>
<h2><span style=""font-weight: 400;"">The Journey of Fivetran </span></h2>
<p><span style=""font-weight: 400;"">They say that childhood friendships last a lifetime, and George Fraser and Taylor Brown have surely done well so far. Since ten years ago (2012), when they launched Fivetran, the company has had its ups and downs, but they’ve paved the way for massive fundraising. </span></p>
<p><span style=""font-weight: 400;"">Fivetran was based on the straightforward premise of helping companies gather data from separate sources and then manage it through other analytical services concerning big data, such as </span><a href=""https://blueorange.digital/databricks-lakehouse-for-financial-services/""><span style=""font-weight: 400;"">Databricks </span></a><span style=""font-weight: 400;"">or </span><a href=""https://blueorange.digital/why-people-are-excited-about-snowflake/""><span style=""font-weight: 400;"">Snowflake</span></a><span style=""font-weight: 400;"">. </span><span style=""font-weight: 400;"">They even managed to raise around $160 million and went through the Y Combinator. But even after these milestones, the company still didn’t have a proper product suitable for large enterprises, all this climbing had led them to a plateau. </span></p>
<p><i><span style=""font-weight: 400;"">“For years it was always the big problem we needed to solve. We were looking at a multiyear journey,” </span></i><a href=""https://www.forbes.com/sites/kenrickcai/2022/08/08/the-56-billion-internet-plumbers/?sh=7f0cbb083522""><span style=""font-weight: 400;"">says </span></a><span style=""font-weight: 400;"">George Fraser. </span></p>
<p><span style=""font-weight: 400;"">After falling under the pressure of his board members and the circumstances, Fraser thought of a classic solution to this problem. Even though it was executed in an urgent manner, the solution did spring them to their well-deserved spot. But first, what does Fivetran actually do? </span></p>[/et_pb_text][et_pb_image src=""https://blueorange.digital/wp-content/uploads/2022/08/Screen-Shot-2022-08-31-at-12.15.03-PM.png"" alt=""Fivetran Data Unification"" title_text=""Fivetran Data Unification"" url=""https://www.fivetran.com/blog/architecture-of-automated-data-integration"" _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""][/et_pb_image][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" text_font_size=""18px"" global_colors_info=""{}""]<h2><span style=""font-weight: 400;"">How Does Fivetran Work?</span></h2>
<p><span style=""font-weight: 400;"">Fivetran is a tool that took the market by surprise by providing a solution to </span><a href=""https://blueorange.digital/snowflake-unistore/""><span style=""font-weight: 400;"">data unification</span></a><span style=""font-weight: 400;"">. Companies working with data scattered in different sources had to find a way to bring it together. The traditional way of doing it required time and effort from more than one data engineer. That’s where Fivetran entered the scene. </span></p>
<p><span style=""font-weight: 400;"">As a competitive ELT tool, Fivetran simplified the work needed to unify all this data and move it into other tools used for marketing, analytics, or data warehousing. It significantly lowers the cost of hiring new staff to handle the workload of manually organizing data, and it has been successfully employed by large companies like Square, Lionsgate, and Strava. </span></p>
<p><span style=""font-weight: 400;"">Fivetran allows reliable, fast, and accurate access to data by providing ready-to-use connectors, automated in-warehouse </span><a href=""https://blueorange.digital/simplify-data-transformation/""><span style=""font-weight: 400;"">transformations</span></a><span style=""font-weight: 400;"">, and continuous synchronization of data access applications. But after this journey, where is Fivetran now? </span></p>[/et_pb_text][et_pb_image src=""https://blueorange.digital/wp-content/uploads/2022/08/Screen-Shot-2022-08-31-at-12.19.27-PM.png"" alt=""Fivetran and dbt"" title_text=""Fivetran and dbt"" url=""https://www.databricks.com/blog/2022/08/03/how-to-build-a-marketing-analytics-solution-using-fivetran-and-dbt-on-the-databricks-lakehouse.html"" _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""][/et_pb_image][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" text_font_size=""18px"" global_colors_info=""{}""]<h2><span style=""font-weight: 400;"">Fivetran in 2022 </span></h2>
<p><span style=""font-weight: 400;"">So what was the solution to the scaling problem Fivetran was facing? What was the path to landing more deals with bigger clients? What about building suitable products for the enterprise market? The solution was a bit old-school but effective: </span><i><span style=""font-weight: 400;"">acquire one of the biggest competitors</span></i><span style=""font-weight: 400;"">. </span></p>
<p><span style=""font-weight: 400;"">George Fraser concluded this to be the right decision to lift Fivetran to the next stage. HVR, the company that had landed most of the enterprises as clients, had a product they could improve and additional revenue to bring to the table. The purchase took the company to an evaluation of $5.6 billion and gave it access to a broader market. </span></p>
<h2> </h2>
<h2><span style=""font-weight: 400;"">Final Thoughts</span></h2>
<p><span style=""font-weight: 400;"">Fraser is truly determined to take the company further. In his own words: “</span><i><span style=""font-weight: 400;"">The unexpected consequence of starting this com­pany was that all these people knew about it. Now we really have to make this work, or we’ll never live it down.</span></i><span style=""font-weight: 400;"">”</span></p>
<p><span style=""font-weight: 400;"">At Blue Orange Digital we specialize in data integration and visualization, data transformation, data science, and advanced analytics. Even though we still can’t compare to Fivetran in size, we’ve helped </span><a href=""https://blueorange.digital/case-studies/""><span style=""font-weight: 400;"">clients</span></a><span style=""font-weight: 400;""> from a wide range of industries, and we can definitely help you too. </span><a href=""https://blueorange.digital/contact-us/""><span style=""font-weight: 400;"">Schedule </span></a><span style=""font-weight: 400;"">a short call today to find out how. </span></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/08/Fivetran-Data-Unification-Blue-Orange-Digital.png|https://blueorange.digital/wp-content/uploads/2022/08/Screen-Shot-2022-08-31-at-12.15.03-PM.png|https://blueorange.digital/wp-content/uploads/2022/08/Screen-Shot-2022-08-31-at-12.19.27-PM.png,Fivetran-Data-Unification-Blue-Orange-Digital.png|Screen-Shot-2022-08-31-at-12.15.03-PM.png|Screen-Shot-2022-08-31-at-12.19.27-PM.png,/www/blueorangem_500/public/wp-content/uploads/2022/08/Fivetran-Data-Unification-Blue-Orange-Digital.png|/www/blueorangem_500/public/wp-content/uploads/2022/08/Screen-Shot-2022-08-31-at-12.15.03-PM.png|/www/blueorangem_500/public/wp-content/uploads/2022/08/Screen-Shot-2022-08-31-at-12.19.27-PM.png,5166|5164|5165,"Fivetran Data Unification, Blue Orange Digital|Fivetran Data Unification|Fivetran and dbt",||,||,"Fivetran Data Unification, Blue Orange Digital|Fivetran Data Unification|Fivetran and dbt",https://blueorange.digital/wp-content/uploads/2022/08/Fivetran-Data-Unification-Blue-Orange-Digital.png,,,,,,,,
5175,"AWS Wickr Secures Communications","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.16"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" hover_enabled=""0"" sticky_enabled=""0""]<p><span style=""font-weight: 400;"">The battle for the most secure messaging app continues each day. Less prominent apps are slowly gaining traction as major platforms make the moves. </span><span style=""font-weight: 400;"">One of these platforms is Wickr, an encrypted messaging platform that intends to establish an authority in the communications field, helping organizations communicate safely. The not-so-popular platform was </span><a href=""https://aws.amazon.com/blogs/security/aws-welcomes-wickr-to-the-team/""><span style=""font-weight: 400;"">acquired</span></a><span style=""font-weight: 400;""> by Amazon in June of 2021 and is mostly focused on servicing government agencies and organizations. </span></p>
<p><span style=""font-weight: 400;"">In July 2022, a little over a year after the acquisition, Amazon presented the preview version of AWS Wickr. But what does this service entail and how can it help businesses collaborate and exchange assets more securely through the </span><a href=""https://blueorange.digital/7-aspects-that-make-the-cloud-a-safer-place-for-your-data/""><span style=""font-weight: 400;"">cloud</span></a><span style=""font-weight: 400;"">? </span></p>
<p><span style=""font-weight: 400;"">We’ll find out today. </span></p>
<p>&nbsp;</p>
<h2><span style=""font-weight: 400;"">What Is AWS Wickr? </span></h2>
<p><span style=""font-weight: 400;"">AWS Wickr allows enterprises to send messages, perform video and voice calls, screen sharing, and share files confidently with an end-to-end encrypted service. New random keys encrypt each of these actions, making decryption impossible, even for AWS itself. Only the respective recipients can securely decrypt them.</span></p>
<p><span style=""font-weight: 400;"">The company </span><a href=""https://wickr.com/about-us/""><span style=""font-weight: 400;"">emphasizes </span></a><span style=""font-weight: 400;"">its security, saying that “</span><i><span style=""font-weight: 400;"">Wickr does not have access to any encrypted communication conducted on our platform and conversations are never stored on our servers, thanks to our privacy-first architecture.</span></i><span style=""font-weight: 400;"">”</span></p>
<p><span style=""font-weight: 400;"">Users can select what information gets logged to their data store in order to address the auditing and compliance issues. This data store where they can accumulate data is fully controlled by them. </span><span style=""font-weight: 400;"">Their capabilities stretch further into being able to configure messaging options for ephemeral messages, setting permissions, and even defining security groups. Other services such as OpenID Connect (OIDC), Active Directory (AD), and single sign-on (SSO) can be integrated as well. </span></p>
<p>&nbsp;</p>
<h2><span style=""font-weight: 400;"">How Does Wickr Work &amp; Why Use It? </span></h2>
<p><span style=""font-weight: 400;"">The platform which primarily served mostly government agencies, and large enterprises, has been used by the U.S Department of Defense (DOD) to allow the Air Force, U.S Navy, and the Army to communicate and exchange information and unclassified data. This can be taken as stellar proof of its excellent security. </span><span style=""font-weight: 400;"">AWS Wickr relies on its 265-bit end-to-end encryption protocol to secure all the exchanged information. Every call, file, and message can be decrypted only by the intended recipients, which means less risk, </span><a href=""https://blueorange.digital/preventing-fraud-with-anomaly-detection/""><span style=""font-weight: 400;"">fraud</span></a><span style=""font-weight: 400;"">, and data breaches. We’re talking here about the exchange of vital information that can lead to massive disasters. </span></p>
<p><span style=""font-weight: 400;"">Let’s take one real-life example in the use of Wickr. Besides the Department of Defense, other organizations including law enforcement, use Wickr to securely organize and execute confidential operations. </span><span style=""font-weight: 400;"">Lieutenant Joe Bowers, who has been a law enforcement officer for over 30 years, has led tens and hundreds of operations concerned with searching and arresting criminals. He </span><a href=""https://aws.amazon.com/blogs/publicsector/wickr-aws-company-offers-secure-compliant-solution-protect-organizational-communications/""><span style=""font-weight: 400;"">says </span></a><span style=""font-weight: 400;"">that “</span><i><span style=""font-weight: 400;"">The first rule of planning and execution: Without communications, you have nothing. And if your communications plan is broken, it is one of the first things to fix.</span></i><span style=""font-weight: 400;"">” And Wickr has bridged their communications effectively.</span></p>
<p><span style=""font-weight: 400;"">Imagine, if law enforcement and DoD can trust their communications to Wickr, it means that their service can do wonders for your business. Stakeholders can exchange confidential information easily without the fear of complementation, and you can communicate with your teams securely while benefiting from 24/7/365 support that resolves all your issues. </span></p>
<p>&nbsp;</p>
<h2><span style=""font-weight: 400;"">Final Thoughts</span></h2>
<p><span style=""font-weight: 400;"">AWS adds another application under its umbrella of services, allowing business teams to not only manage and transform data but also chat securely with one another. Teams can now secure sensitive information, establish tighter data governance policies, collaborate securely internally and externally, as well as increase administrative control, and supervise large communication networks.</span></p>
<p><span style=""font-weight: 400;"">At Blue Orange Digital, as a </span><a href=""https://blueorange.digital/blue-orange-digital-joins-aws-partner-network/""><span style=""font-weight: 400;"">certified AWS partner</span></a><span style=""font-weight: 400;"">, we take care of your data transformation needs and build cloud infrastructures that are efficient, scalable, and easy to manage. Our experts include PhDs, data engineers, visualization experts, and data scientists who can take full charge of your data needs. </span></p>
<p><a href=""https://blueorange.digital/contact-us/""><span style=""font-weight: 400;"">Schedule a short call</span></a><span style=""font-weight: 400;""> and let’s talk about your company long and short term goals, and how we can assist.</span></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/09/AWS-Wickr.png,AWS-Wickr.png,/www/blueorangem_500/public/wp-content/uploads/2022/09/AWS-Wickr.png,5178,"AWS Wickr",,,"AWS Wickr",https://blueorange.digital/wp-content/uploads/2022/09/AWS-Wickr.png,,,,,,,,
5194,"Future Proof Your Modern Data Stack","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.16"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""]<p><span style=""font-weight: 400;"">Data stack has turned into a buzzword already in the data community. It’s a compass that determines whether a company heads towards becoming data-driven or not. </span><span style=""font-weight: 400;"">The proper data stack provides the necessary infrastructure that allows analysts to deliver value continuously and for data workers to be faster. In recent years we’ve seen </span><a href=""https://blueorange.digital/dataflow-automation-and-its-current-state/""><span style=""font-weight: 400;"">Modern Data Stack (MDS)</span></a><span style=""font-weight: 400;""> rise over the traditional monolithic solutions.</span></p>
<p><span style=""font-weight: 400;"">This modular system has its own fantastic features that bring benefits in both the short and long term. Enterprises can benefit by migrating their infrastructures to the modern data stack to sustain their architecture and data strategy to continue growing. </span></p>[/et_pb_text][et_pb_image src=""https://blueorange.digital/wp-content/uploads/2022/09/Screen-Shot-2022-09-15-at-4.22.55-PM.png"" alt=""Modern Data Stack History"" title_text=""Modern Data Stack History"" url=""https://continual.ai/post/the-future-of-the-modern-data-stack"" admin_label=""Image"" _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""][/et_pb_image][et_pb_text admin_label=""Text"" _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""]<h2><span style=""font-weight: 400;"">What’s Modern Data Stack (MDS) and Its Benefits? </span></h2>
<p><span style=""font-weight: 400;"">A modern data stack is nothing but a complex and flexible infrastructure of data that is made of modular tooling components such as BI layers, a data warehouse (often cloud-based), and data pipelines. All these components function together to produce realistic data insights. </span></p>
<p><span style=""font-weight: 400;"">The benefits of the modern data stack are several. First and foremost come flexibility and speed. Teams can improve the data stack further with ease and the workflow is immensely accelerated. There is no more vendor lock-in or need to be concerned about costly implementations, and it helps you improve data maturity.  </span></p>
<h2> </h2>
<h2><span style=""font-weight: 400;"">Why Modern Data Stacks Are Future-Proof and How Can Enterprises Benefit from Them?</span></h2>
<p><span style=""font-weight: 400;"">Large organizations can rely on modern data architecture regardless of having warehouses and existing data stacks. Moving to this architecture is not difficult as they can establish themselves with a wholesale migration or by presenting components of such a structure as instrumental in a longer-term migration strategy.</span></p>
<p><span style=""font-weight: 400;"">Are you biased about the longevity and effectiveness of </span><a href=""https://blueorange.digital/what-are-modern-data-stack-mds-technologies/""><span style=""font-weight: 400;"">modern data stacks?</span></a><span style=""font-weight: 400;""> We are bringing you four reasons why we believe they are future-proof: </span></p>
<h3> </h3>
<h3><span style=""font-weight: 400;"">1. They’re Modifiable to Adapt Your Scaling Intentions </span></h3>
<p><span style=""font-weight: 400;"">As companies grow, there’s a constant need for additional tools that allow the data stack to grow and match the rising needs. Modular stacks allow the integration of new tools whenever needed without dealing with technical debt. Also, thanks to custom integrations, every company can select to adopt only the tools that match their stack, which come with pre-built connectors to the popular business apps. </span></p>
<h3> </h3>
<h3><span style=""font-weight: 400;"">2. Provide Multiple Tools Depending on the Use Case </span></h3>
<p><span style=""font-weight: 400;"">Oftentimes, data is used in a variety of ways to answer different questions. Data teams are required to modify and analyze different sectors of data to present the proper conclusions. This is because there are certain factors at hand: </span></p>
<ul>
<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Which stakeholder asks for data </span></li>
<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">What languages does the analyst posses</span></li>
<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">The posed question </span></li>
</ul>
<p><span style=""font-weight: 400;"">Modern data stacks provide different sets of tools specific to each case. </span></p>
<h3> </h3>
<h3><span style=""font-weight: 400;"">3. They Offer Flexibility to Escape Vendor Lock-In </span></h3>
<p><span style=""font-weight: 400;"">Monolithic solutions are expensive and can drag down your innovation attempts. </span><span style=""font-weight: 400;"">With MDS, when you want to change vendors for a better alternative tool, you’re not stuck in a vendor lock-in anymore. There are no unbearable costs for you to be confused about or an obligation to keep using an inefficient tool.</span></p>
<h3> </h3>
<h3><span style=""font-weight: 400;"">4. Enabling Data Governance Is Feasible</span></h3>
<p><span style=""font-weight: 400;"">Making governed data accessible by all your new tools is now made much easier, and not accompanied by disruptions. Using tools like </span><a href=""https://blueorange.digital/materialize-and-dbt-transform-data-with-ease/""><span style=""font-weight: 400;"">dbt</span></a><span style=""font-weight: 400;"">, data teams can write scripts that transform data before loading it into a new solution so that the quality of data is not lost or compromised. </span></p>[/et_pb_text][et_pb_image src=""https://blueorange.digital/wp-content/uploads/2022/09/Screen-Shot-2022-09-15-at-4.27.05-PM.png"" alt=""Modern Open-Source Data Stack"" title_text=""Modern Open-Source Data Stack"" url=""https://www.datafold.com/blog/the-modern-data-stack-open-source-edition"" _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""][/et_pb_image][et_pb_text _builder_version=""4.18.0"" _module_preset=""default"" global_colors_info=""{}""]<h2><span style=""font-weight: 400;"">How Can Companies Migrate to Modern Data Stack? </span></h2>
<p><span style=""font-weight: 400;"">The process requires a bit of expertise but it can be done essentially in less than an hour. It takes only four major components for you to achieve it: </span></p>
<ul>
<li style=""font-weight: 400;"" aria-level=""1""><b>A data warehouse (cloud-based).</b><span style=""font-weight: 400;""> Here’s where your organization’s upcoming data will be stored. Examples of cloud-based warehouses include BigQuery, </span><a href=""https://blueorange.digital/why-people-are-excited-about-snowflake/""><span style=""font-weight: 400;"">Snowflake</span></a><span style=""font-weight: 400;"">, or Redshift. </span></li>
<li style=""font-weight: 400;"" aria-level=""1""><b>Data pipelines.</b><span style=""font-weight: 400;""> We’ve chosen where to store the data but next, we should pick a pipeline service that feds this data without much human intervention into the data warehouses. Examples include Airbyte, Fivetran, and Segment. </span></li>
<li style=""font-weight: 400;"" aria-level=""1""><b>A BI/analytics platform.</b><span style=""font-weight: 400;""> Now that the data is consolidated inside the data warehouse, we need a data science platform to properly analyze it. Examples include Mode, Metabase, and Looker. </span></li>
<li style=""font-weight: 400;"" aria-level=""1""><b>A transformation tool.</b><span style=""font-weight: 400;""> The last step of the process includes the use of a data transformation tool that can work with data within the cloud-based warehouse. Examples include dbt, Malloy, and Looker.  </span></li>
</ul>
<p><span style=""font-weight: 400;"">For a step-by-step visual guide of the process, you can watch </span><a href=""https://www.youtube.com/watch?v=WOSrRTaNIm0""><span style=""font-weight: 400;"">this video</span></a><span style=""font-weight: 400;"">. </span></p>
<h2> </h2>
<h2><span style=""font-weight: 400;"">Final Thoughts</span></h2>
<p><span style=""font-weight: 400;"">Obtaining critical insights faster is one step away. Migrating your data infrastructure to modern data stacks protects you from vendor lock-in, saves time in producing insights, enables global data governance, and facilitates scaling. </span><span style=""font-weight: 400;"">At Blue Orange Digital, our teams of data scientists, visualization experts, and data engineers work smart to boost your efforts in data transformation and establish more efficient cloud infrastructures. Schedule a short </span><a href=""https://blueorange.digital/contact-us/""><span style=""font-weight: 400;"">FREE call</span></a><span style=""font-weight: 400;""> with us today for more. </span></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2022/09/Future-Proof-Your-Modern-Data-Stack.png|https://blueorange.digital/wp-content/uploads/2022/09/Screen-Shot-2022-09-15-at-4.22.55-PM.png|https://blueorange.digital/wp-content/uploads/2022/09/Screen-Shot-2022-09-15-at-4.27.05-PM.png,Future-Proof-Your-Modern-Data-Stack.png|Screen-Shot-2022-09-15-at-4.22.55-PM.png|Screen-Shot-2022-09-15-at-4.27.05-PM.png,/www/blueorangem_500/public/wp-content/uploads/2022/09/Future-Proof-Your-Modern-Data-Stack.png|/www/blueorangem_500/public/wp-content/uploads/2022/09/Screen-Shot-2022-09-15-at-4.22.55-PM.png|/www/blueorangem_500/public/wp-content/uploads/2022/09/Screen-Shot-2022-09-15-at-4.27.05-PM.png,5199|5197|5198,"Future Proof Your Modern Data Stack|Modern Data Stack History|Modern Open-Source Data Stack",||,||,"|Modern Data Stack History|",https://blueorange.digital/wp-content/uploads/2022/09/Future-Proof-Your-Modern-Data-Stack.png,,,,,,,,
5881,"Webinar: What Your Data Team Needs to Know in 2023","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.16"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text _builder_version=""4.19.5"" _module_preset=""default"" hover_enabled=""0"" global_colors_info=""{}"" sticky_enabled=""0""]<p>As data continues to grow in importance for businesses, it’s essential to stay up-to-date on the latest trends and techniques for maximizing the value of your data.</p>
<p>In this webinar, you’ll learn:<br />– The role of data in business growth and success<br />– Key data trends to watch in 2023<br />– The importance of data quality<br />– Maximizing the value of your data<br />– Best practices for using data to drive business decisions<br />– Q&amp;A with our speakers</p>
<p>Watch Josh Miramant, CEO at Blue Orange Digital, and Gordon Wong, founder of Wong Decision Intelligence, as they discuss some of the key data trends for 2023 and provide insights for driving more net value from your data.</p>
<p><a href=""https://blueorange.digital/what-your-data-team-needs-to-know-in-2023-webinar-lp/"" target=""_blank"" rel=""noopener"">Access the full on-demand webinar here.</a></p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2023/02/BOD-webinar-thumb-data-trends-what-your-data-team-needs-to-know-in-2023.png|https://blueorange.digital/wp-content/uploads/2023/02/gordon-josh-webinar-banner1.jpg,BOD-webinar-thumb-data-trends-what-your-data-team-needs-to-know-in-2023.png|gordon-josh-webinar-banner1.jpg,/www/blueorangem_500/public/wp-content/uploads/2023/02/BOD-webinar-thumb-data-trends-what-your-data-team-needs-to-know-in-2023.png|/www/blueorangem_500/public/wp-content/uploads/2023/02/gordon-josh-webinar-banner1.jpg,5886|5885,"BOD webinar thumb - data trends what your data team needs to know in 2023|gordon josh webinar banner1",|,|,"BOD webinar thumb - data trends what your data team needs to know in 2023|gordon josh webinar banner1",https://blueorange.digital/wp-content/uploads/2023/02/BOD-webinar-thumb-data-trends-what-your-data-team-needs-to-know-in-2023.png,,,,,,,,
5924,"Blue Orange Digital Appoints Diana Bald as President","<h1><b>Blue Orange Digital Appoints Diana Bald as President</b></h1>
<i><span style=""font-weight: 400;"">Leading data transformation company Blue Orange Digital appoints Diana Bald as president, leveraging her extensive cross-industry experience to drive growth and innovation in data transformation, machine learning, and advanced analytics for enterprise clients.</span></i>

<span style=""font-weight: 400;"">[NEW YORK, March 2, 2023] –– </span><a href=""https://blueorange.digital/""><span style=""font-weight: 400;"">Blue Orange Digital</span></a><span style=""font-weight: 400;"">, a leading data transformation, machine learning, and advanced analytics company, is proud to announce the appointment of Diana Bald as its new president.</span>

<span style=""font-weight: 400;"">In this role, Bald will oversee the day-to-day operations of the company and drive its continued growth and innovation. Bald has more than 20 years of experience in technology, financial services, advertising, and media. Most recently, she served as CEO of thoughtbot. Bald has also held executive positions at several leading companies, including Liberty Mutual, MDC Partners (Assembly), IPG (ID Media), and Univision.</span>

<span style=""font-weight: 400;"">Across multiple industries, Bald has guided technology and business leaders on digital transformation and building sustainable products. Her knowledge in these areas will be instrumental in helping Blue Orange Digital achieve its goals and provide cutting-edge expertise to clients.</span><span style=""font-weight: 400;"">
</span>

<span style=""font-weight: 400;"">“I am excited to join the talented and creative team at Blue Orange to equip businesses with democratized modern data and help build the next generation of machine learning and data science applications,” Bald says. “As the need for data and digital transformation accelerates, Blue Orange is uniquely positioned to propel growth and make better decisions by simplifying access to data, learning from data, and identifying patterns.”</span><span style=""font-weight: 400;"">
</span>

<span style=""font-weight: 400;"">In addition to her professional career, Bald has been actively involved in the nonprofit sector. She has held leadership and board positions at Global Potential, AWNY (now She Runs It), Police Athletic League, Boy Scouts of America Cradle of Liberty Council, Philly Ad Club, and more. She has also served as an adjunct professor at Temple University. Bald holds an MBA from the University of Southern California Marshall School of Business and a Bachelor of Science in computer information systems, magna cum laude, from the University of Redlands.</span>

<span style=""font-weight: 400;"">“We are ecstatic to have Diana join Blue Orange Digital as our new president,” the CEO and founder, Josh Miramant, says. “Her extensive experience and leadership skills make her the perfect choice to take on this role. Diana will be an excellent resource for business leaders evaluating their data transformation decisions and will help us grow the next generation of data strategists.”</span>

<span style=""font-weight: 400;"">Bald’s appointment comes at an exciting time for Blue Orange Digital, as the company looks to provide top expertise to clients and develop the next generation of industry professionals. With her leadership and vision, Blue Orange Digital is well-positioned to remain a leader in data transformation, machine learning, and advanced analytics.</span>",https://blueorange.digital/wp-content/uploads/2023/03/BOD-Diana-Bald2.png|https://blueorange.digital/wp-content/uploads/2023/03/BOD-Diana-Bald.png,BOD-Diana-Bald2.png|BOD-Diana-Bald.png,/www/blueorangem_500/public/wp-content/uploads/2023/03/BOD-Diana-Bald2.png|/www/blueorangem_500/public/wp-content/uploads/2023/03/BOD-Diana-Bald.png,5929|5926,"BOD Diana Bald2|BOD Diana Bald",|,|,"Welcome Diana Bald Blue Orange Digital|Diana Bald 2",https://blueorange.digital/wp-content/uploads/2023/03/BOD-Diana-Bald2.png,,,,,,,,
6107,"Blockly-DS: Making Data Science Accessible for Non-Technical Folks","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px|||||"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.21.0"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" custom_margin=""0px||||false|false"" custom_padding=""0px||||false|false"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.16"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" custom_padding=""0px|||||"" global_colors_info=""{}""]<h1></h1>
<p>Learning to code can be a challenging and intimidating experience, especially for non-technical folks who are new to programming. It often requires a lot of time and effort to master the syntax, concepts, and tools of a programming language, and to apply them to real-world problems and projects. But what if there was a way to overcome the challenge of learning programming and creating software without having to master complex coding languages? This is where block coding comes in, providing a visual and intuitive interface that simplifies the programming process.</p>
<h2>The Problem: Complex Coding Languages for Non-Technical Folks</h2>
<p>In the early days of programming, coders had to work with complex languages like Assembly, C, and Fortran. These languages required a deep understanding of syntax, algorithms, and hardware specifications. With limited resources and guidance, learning and debugging code was a time-consuming and often frustrating process. As interest in data science grows across various fields, non-STEM students often face difficulties in programming. Visual tools like block coding can help them overcome these challenges and engage more effectively with data science concepts.</p>
<h2>What is Block Coding?</h2>
<p>Block coding platforms use a visual, drag-and-drop interface where users can assemble pre-built code blocks to create programs. This eliminates the need to memorize syntax and reduces the chances of errors, making coding more intuitive and user-friendly. The roots of block coding can be traced back to the late 1960s with the development of Logo, an educational programming language created by Seymour Papert and his team at MIT. Logo allowed users to control a virtual turtle to create shapes and patterns, making programming more accessible and engaging for children. Today, block coding has become a crucial tool for teaching programming concepts, making coding accessible to millions of people worldwide, regardless of their age or prior programming experience.</p>
<h2>Introducing Blockly-DS: A Tool Designed for Non-STEM Students</h2>
<p>[embed]https://www.youtube.com/watch?v=o31aaFu3P_I[/embed]</p>
<p>Blockly-DS is a prototype tool specifically designed to teach data science to non-STEM students. Built on the popular Blockly framework, it uses a visual programming approach that allows students to focus on data science concepts rather than getting bogged down by complex programming syntax. Each block in Blockly-DS represents a data science function, such as data import, cleaning, transformation, analysis, or visualization. By connecting these blocks, students can quickly and easily construct a data science pipeline and see the results in real-time. This hands-on approach helps students develop a deeper understanding of data science concepts without getting overwhelmed by programming.</p>
<blockquote>
<h3><em>I<span style=""font-size: medium;"">nstead of limiting ourselves to analyzing past data, we can start inferencing or forecasting future data. Once you understand the concept and have very basic coding skills, it's very easy to extend that and use it on your day-to-day, analyze your own data, do your own predictions, your own inferences.</span></em></h3>
<h3><span style=""font-size: medium;""><em>Luiz Barboza, Solutions Architect Manager at Blue Orange Digital</em></span></h3>
</blockquote>
<h2>Features of Blockly-DS</h2>
<p>Blockly-DS offers several features that cater to non-STEM students, such as:</p>
<ul>
<li>A user-friendly interface that promotes an easy learning curve</li>
<li>A library of pre-built blocks covering essential data science functions</li>
<li>The ability to export code for use in other programming environments</li>
</ul>
<p>Blockly-DS is currently being tested at two Brazilian institutions: IBMEC, where it is being used by undergraduate students in economics and administration, and Lumturo, a pre-university course. These trials aim to assess the effectiveness of Blockly-DS in teaching data science to non-STEM students. Initial feedback has been positive, with students expressing increased confidence in their data science abilities and a better understanding of key concepts. Educators have also praised Blockly-DS for its ability to engage students and promote active learning.</p>
<p><img class=""alignnone  wp-image-6108"" src=""https://blueorange.digital/wp-content/uploads/2023/05/blockly-ds-ui2-1024x709.png"" alt=""Blockly-DS UI"" width=""968"" height=""670"" /></p>
<h2>Future Development</h2>
<p>Based on the feedback from these trials, the Blockly-DS team plans to refine and expand the tool's functionality. Future developments include:</p>
<ul>
<li>Adding more advanced data science blocks to cover a wider range of topics</li>
<li>Integrating machine learning capabilities to introduce students to AI concepts</li>
<li>Developing resources and tutorials to support educators in implementing Blockly-DS in their curriculum</li>
</ul>
<p>Blockly-DS has the potential to revolutionize the way non-STEM students learn data science, making it more accessible and enjoyable. The success of block coding platforms like MIT App Inventor and Microsoft MakeCode, which have millions of registered users, demonstrates the effectiveness and popularity of visual programming interfaces.</p>
<p>By leveraging the power of block coding, non-technical individuals can gain a practical understanding of data science concepts without the barriers of complex programming languages. Blockly-DS, with its user-friendly interface and library of pre-built blocks, empowers students to explore data science pipelines and witness real-time results. This hands-on approach not only boosts confidence but also nurtures a deeper comprehension of data analysis, visualization, and manipulation.</p>
<p>The positive feedback from ongoing trials at educational institutions is a testament to the effectiveness of Blockly-DS. Students are embracing the tool as it enables them to actively engage with data science, without being overwhelmed by coding complexities. The tool's intuitive nature facilitates a smoother learning curve, ensuring that individuals from diverse academic backgrounds can participate and thrive in the data-driven world.</p>
<h2>Looking Ahead</h2>
<p>By incorporating advanced data science blocks and introducing machine learning capabilities, Blockly-DS will enable students to delve deeper into the realm of artificial intelligence and predictive analysis. Additionally, the development of comprehensive resources and tutorials will support educators in seamlessly integrating Blockly-DS into their curricula, further expanding the reach and impact of this powerful tool.</p>
<p>Block coding, with its visual and intuitive interface, is bridging the gap between programming and data science for non-technical individuals. Blockly-DS, as a pioneering tool, empowers students to harness the power of data, equipping them with the skills needed for success in a data-centric world. With continued development and support, Blockly-DS has the potential to transform data science education, unlocking new opportunities for students from diverse backgrounds and paving the way for innovation and insights in various industries.</p>[/et_pb_text][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2023/05/Luiz-Barboza-video-thumb-3.jpg|https://blueorange.digital/wp-content/uploads/2023/05/blockly-ds-ui2.png,Luiz-Barboza-video-thumb-3.jpg|blockly-ds-ui2.png,/www/blueorangem_500/public/wp-content/uploads/2023/05/Luiz-Barboza-video-thumb-3.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/05/blockly-ds-ui2.png,6117|6108,Luiz-Barboza-video-thumb-3|blockly-ds-ui2,|,|,"blockly-ds blog article featuring Luiz Barboza|Blockly-DS UI",https://blueorange.digital/wp-content/uploads/2023/05/Luiz-Barboza-video-thumb-3.jpg,,,,,,,,
6146,"Unriveted Podcast: Josh Miramant and Martin Miller","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" custom_padding=""0px|||||"" global_colors_info=""{}""][et_pb_row admin_label=""row"" _builder_version=""4.21.0"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" custom_margin=""0px||||false|false"" custom_padding=""0px||||false|false"" global_colors_info=""{}""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||""][et_pb_text admin_label=""Text"" _builder_version=""4.21.0"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" custom_padding=""0px|||||"" global_colors_info=""{}""]<p>In this episode we talk with Josh Miramant, CEO of Blue Orange Digital about LLM's and the future.</p>
<p><strong>Topics:</strong><br />🔥 OpenAI, and Large Language Models<br />🧠 Implication of Large Language Model … today and the future.<br />🧠 Examples of LLM’s and usage in solutions that can be delivered in 3 months or less<br />🧠 Unifying Large Language Models and Knowledge Graphs</p>[/et_pb_text][et_pb_video src=""https://www.youtube.com/watch?v=eMDAD2toZA0"" _builder_version=""4.21.0"" _module_preset=""default"" width=""65%"" module_alignment=""center"" global_colors_info=""{}""][/et_pb_video][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2023/07/Unriveted-podcast-graphic.png|https://blueorange.digital/wp-content/uploads/2023/05/Josh-Miramant-and-Martin-Miller-Podcast-EP-1-placeholder.jpg,Unriveted-podcast-graphic.png|Josh-Miramant-and-Martin-Miller-Podcast-EP-1-placeholder.jpg,/www/blueorangem_500/public/wp-content/uploads/2023/07/Unriveted-podcast-graphic.png|/www/blueorangem_500/public/wp-content/uploads/2023/05/Josh-Miramant-and-Martin-Miller-Podcast-EP-1-placeholder.jpg,6335|6147,"Unriveted podcast graphic|Josh Miramant and Martin Miller Podcast EP 1 placeholder",|,|,|,https://blueorange.digital/wp-content/uploads/2023/07/Unriveted-podcast-graphic.png,,,,,,,,
6155,"Benefits of a Data-First Culture: 3 Simple Strategies to Apply a Data-First Approach","When it comes to analytics solutions, centralization versus decentralization is one constant tension that’s plagued data architects for years now. Both options offer their own sets of advantages and disadvantages, as well. Centralized data design means building a data tool set controlled by a single IT department that serves external business units. This provides organizations with control, uniformity, simplification, and security. Decentralized data allows business units to be the owners of their data needs. This gives companies more flexibility, speed, and unique system designs to meet users’ needs.

It’s no wonder why discussions involving cross-departmental data often involve a forceful and adamant pull between these two valid approaches to one of the most valuable assets a business can hold. When all is said and done, the issue is almost always rooted in trust.

<i><span style=""font-weight: 400;"">Article written by Josh Miramant, published on <a href=""https://cloudtweaks.com/2023/04/3-simple-strategies-data-first/"">cloudtweaks.com</a></span></i>

<a href=""https://cloudtweaks.com/2023/04/3-simple-strategies-data-first/"">Click here to read the full article.</a>",https://blueorange.digital/wp-content/uploads/2023/05/josh-miramant-blue-orange-digital-article-cloudtweaks1.jpg,josh-miramant-blue-orange-digital-article-cloudtweaks1.jpg,/www/blueorangem_500/public/wp-content/uploads/2023/05/josh-miramant-blue-orange-digital-article-cloudtweaks1.jpg,6156,"josh miramant blue orange digital article cloudtweaks1",,,"josh miramant blue orange digital article cloudtweaks1",https://blueorange.digital/wp-content/uploads/2023/05/josh-miramant-blue-orange-digital-article-cloudtweaks1.jpg,,,,,,,,
6159,"What Will It Actually Take To Lead A Modern Data-First Organization?","Data is the cornerstone of modern business, with 79 zettabytes of data created, captured, copied, and consumed in 2021 alone. That volume is estimated to rise to 181 zettabytes by 2025, sparking businesses to shift to a data-first approach.

A data-first approach is a strategic organizational management framework where data and analytics drive decisions rather than intuition or traditional ways of doing things. This approach emphasizes using data to inform decisions and measure the impact of those decisions. A data-first approach focuses on data to drive business performance while ensuring clear governance, accessibility, and security.

<i><span style=""font-weight: 400;"">Article featuring by Josh Miramant, published on <a href=""https://www.forbes.com/sites/rhettpower/2023/02/12/what-will-it-actually-take-to-lead-a-modern-data-first-organization/?sh=349520a4f2ba"">forbes.com</a></span></i>

<a href=""https://www.forbes.com/sites/rhettpower/2023/02/12/what-will-it-actually-take-to-lead-a-modern-data-first-organization/?sh=349520a4f2ba"">Click here to read the full article.</a>",https://blueorange.digital/wp-content/uploads/2023/05/josh-miramant-blue-orange-digital-article-forbes-Feb-2023.jpg,josh-miramant-blue-orange-digital-article-forbes-Feb-2023.jpg,/www/blueorangem_500/public/wp-content/uploads/2023/05/josh-miramant-blue-orange-digital-article-forbes-Feb-2023.jpg,6160,"josh miramant blue orange digital article forbes Feb 2023",,,"josh miramant blue orange digital article forbes Feb 2023",https://blueorange.digital/wp-content/uploads/2023/05/josh-miramant-blue-orange-digital-article-forbes-Feb-2023.jpg,,,,,,,,
6162,"Oliver Wyman invests in data firm Blue Orange Digital","Management consultancy Oliver Wyman has acquired a minority stake in Blue Orange Digital, a New York-based data science consulting firm.

“We have worked with Blue Orange Digital on several projects and have been very impressed with their technical abilities,"" said Vivek Sen, a partner with Oliver Wyman and Americas head of digital. ""Our Digital practice is rapidly growing and investing in Blue Orange Digital will allow us to help our clients optimize and automate their businesses faster and more efficiently.""

As part of the deal Blue Orange’s expertise will be integrated into Oliver Wyman’s projects providing enhanced data transformation for clients. The two consultancies will work together to help clients advance data governance, update legacy systems, improve backend performance, and leverage advanced analytics and insights.<i></i>

<a href=""https://www.consulting.us/news/7509/oliver-wyman-invests-in-data-firm-blue-orange-digital"">Click here to read the full article.</a>",https://blueorange.digital/wp-content/uploads/2023/01/Oliver-Wyman-invests-in-data-firm-Blue-Orange-Digital1.jpg|https://blueorange.digital/wp-content/uploads/2023/05/Oliver-Wyman-invests-in-data-firm-Blue-Orange-Digital.jpg,Oliver-Wyman-invests-in-data-firm-Blue-Orange-Digital1.jpg|Oliver-Wyman-invests-in-data-firm-Blue-Orange-Digital.jpg,/www/blueorangem_500/public/wp-content/uploads/2023/01/Oliver-Wyman-invests-in-data-firm-Blue-Orange-Digital1.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/05/Oliver-Wyman-invests-in-data-firm-Blue-Orange-Digital.jpg,6165|6163,"Oliver Wyman invests in data firm Blue Orange Digital1|Oliver Wyman invests in data firm Blue Orange Digital",|,|,"Oliver Wyman invests in data firm Blue Orange Digital1|Oliver Wyman invests in data firm Blue Orange Digital",https://blueorange.digital/wp-content/uploads/2023/01/Oliver-Wyman-invests-in-data-firm-Blue-Orange-Digital1.jpg,,,,,,,,
6211,"Predictive Modeling with Machine Learning: Unleashing the Power of Advanced Analytics","Predictive modeling with machine learning has revolutionized the way businesses leverage data to make accurate predictions and informed decisions. By applying advanced analytics techniques, organizations can uncover hidden patterns, gain insights into future trends, and proactively address challenges. In this blog post, we will explore the world of predictive modeling, delve into best practices, address common concerns, and provide practical examples to help you harness the full potential of predictive modeling with machine learning.
<h1>Understanding Predictive Modeling</h1>
Predictive modeling is a powerful technique that utilizes historical data to make predictions about future outcomes. It is based on the assumption that past patterns and relationships can provide valuable insights into what might happen next. Machine learning algorithms play a crucial role in predictive modeling by automatically learning patterns from historical data and generating predictive models that can make accurate forecasts.

<img class=""alignnone size-large wp-image-6215"" src=""https://blueorange.digital/wp-content/uploads/2023/06/Understanding-Predictive-Modeling-1024x521.jpg"" alt="""" width=""1024"" height=""521"" />
<h1>Best Practices for Predictive Modeling</h1>
<ul>
 	<li>Define clear objectives: Clearly define the problem you want to solve and the outcomes you expect from your predictive model. Having a well-defined objective helps in selecting the appropriate algorithms and evaluation metrics.</li>
 	<li>Gather high-quality data: The accuracy of your predictions heavily depends on the quality of your data. Ensure that your dataset is comprehensive, representative, and free from errors or biases. Data preprocessing techniques, such as handling missing values, outliers, and data normalization, are essential to obtain reliable results.</li>
 	<li>Feature selection and engineering: Identify the most relevant features (variables) from your dataset that contribute significantly to the outcome. Feature engineering involves creating new features or transforming existing ones to extract more meaningful information. This process can enhance the predictive power of your models.</li>
 	<li>Choose the right algorithm: The selection of the machine learning algorithm depends on the nature of your data and the problem at hand. Regression, classification, and time series forecasting algorithms are commonly used for predictive modeling. Experiment with different algorithms and evaluate their performance to find the best fit for your specific task.</li>
 	<li>Split your data into training and testing sets: To assess the performance of your predictive model, it's crucial to split your data into training and testing sets. The training set is used to build the model, while the testing set evaluates its predictive accuracy. Cross-validation techniques, such as k-fold cross-validation, can help obtain robust estimates of performance.</li>
</ul>
<h1>Common Concerns and How to Address Them</h1>
<ul>
 	<li>Overfitting: Overfitting occurs when a model performs extremely well on the training data but fails to generalize to new, unseen data. To combat overfitting, use techniques like regularization, cross-validation, or ensembling methods such as random forests or gradient boosting.</li>
 	<li>Lack of interpretability: Some machine learning algorithms, such as deep neural networks, are inherently complex and lack interpretability. If interpretability is crucial, consider using simpler models like linear regression or decision trees. You can also explore model-agnostic interpretability techniques like LIME or SHAP values.</li>
 	<li>Imbalanced datasets: Imbalanced datasets, where one class dominates over others, can lead to biased predictions. Techniques like oversampling, undersampling, or using advanced algorithms like SMOTE (Synthetic Minority Over-sampling Technique) can help address this issue and improve predictive accuracy.</li>
</ul>
<img class=""alignnone size-large wp-image-6216"" src=""https://blueorange.digital/wp-content/uploads/2023/06/Predictive-Models-Common-Concerns-and-How-to-Address-Them-1024x521.jpg"" alt=""Predictive Models - Common Concerns and How to Address Them"" width=""1024"" height=""521"" />
<h1>Practical Examples</h1>
<ul>
 	<li>Customer churn prediction: By analyzing historical customer data, such as purchase history, demographics, and engagement metrics, you can build a predictive model to identify customers at risk of churn. This information can be used to design targeted retention strategies and prevent customer attrition.</li>
 	<li>Stock market forecasting: Predicting stock prices is a challenging task due to the inherent volatility of financial markets. By leveraging historical price data, trading volumes, and other relevant factors, machine learning models can capture patterns and trends to generate predictions that inform investment decisions.</li>
 	<li>Disease diagnosis: Predictive modeling can be used in the healthcare domain to predict the likelihood of diseases. For example, by analyzing patient demographics, medical history, and laboratory results, machine learning models can assist in early detection of diseases like diabetes or cancer, enabling timely intervention and personalized treatment plans.</li>
</ul>
<h1>Conclusion</h1>
Predictive modeling with machine learning empowers organizations to make accurate predictions and gain a competitive edge in today's data-driven world. By following best practices, addressing common concerns, and exploring practical examples, you can leverage advanced analytics to unlock valuable insights and make informed decisions. Embrace the power of predictive modeling, and let data guide you towards success!

Remember, the possibilities of predictive modeling are vast, and continuous learning and exploration will help you refine your skills and uncover even greater opportunities for leveraging machine learning to make predictions.",https://blueorange.digital/wp-content/uploads/2023/06/Predictive-Modeling-with-Machine-Learning.png|https://blueorange.digital/wp-content/uploads/2023/06/Understanding-Predictive-Modeling.jpg|https://blueorange.digital/wp-content/uploads/2023/06/Predictive-Models-Common-Concerns-and-How-to-Address-Them.jpg,Predictive-Modeling-with-Machine-Learning.png|Understanding-Predictive-Modeling.jpg|Predictive-Models-Common-Concerns-and-How-to-Address-Them.jpg,/www/blueorangem_500/public/wp-content/uploads/2023/06/Predictive-Modeling-with-Machine-Learning.png|/www/blueorangem_500/public/wp-content/uploads/2023/06/Understanding-Predictive-Modeling.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/06/Predictive-Models-Common-Concerns-and-How-to-Address-Them.jpg,6213|6215|6216,"Predictive Modeling with Machine Learning|Understanding Predictive Modeling|Predictive Models - Common Concerns and How to Address Them",||,||,"Predictive Modeling with Machine Learning||Predictive Models - Common Concerns and How to Address Them",https://blueorange.digital/wp-content/uploads/2023/06/Predictive-Modeling-with-Machine-Learning.png,,,,,,,,
6267,"Blue Orange Digital Partners With Octopai to Enhance Data Observability Capabilities","<h1><b>Blue Orange Digital Partners With Octopai to Enhance Data Observability Capabilities
</b></h1>
<i><span style=""font-weight: 400;"">The partnership advances clients' abilities, offering comprehensive solutions for improved data management.</span></i>

<span class=""legendSpanClass""><span class=""xn-location"">NEW YORK</span></span>, <span class=""legendSpanClass""><span class=""xn-chron"">June 27, 2023</span></span> /PRNewswire/ -- <u><a href=""https://blueorange.digital/"" target=""_blank"" rel=""nofollow noopener"">Blue Orange Digital</a></u>, a leading data transformation and advanced analytics firm, has partnered with <u><a href=""https://www.octopai.com/"" target=""_blank"" rel=""nofollow noopener"">Octopai</a></u>, a company developing leading automated data intelligence platforms and solutions. The strategic partnership will enable Blue Orange to expand its data observability capabilities, providing clients with best-in-class solutions to improve data governance, compliance, and deep systemwide data lineage.

Through the use of Octopai's observability platform, Blue Orange's clients benefit from a better understanding of the quality of their data, making it more viable and usable. The enhanced data lineage capabilities provide clients with better pipeline management, data engineering, audit, data lineage, and anomaly detection. Blue Orange is able to pick the types of data operations platforms that best suit its clients, increasing its chances of success.

""This partnership is a game-changer for our clients,"" said <u><a href=""https://www.linkedin.com/in/joshmiramant/"" target=""_blank"" rel=""nofollow noopener""><span class=""xn-person"">Josh Miramant</span></a></u>, CEO and founder of Blue Orange Digital. ""With Octopai's advanced data operation and lineage platform, we can provide end-to-end solutions that optimize data quality, governance, and compliance, enabling our clients to make more informed decisions and gain a competitive edge.""

The partnership allows Blue Orange to make use of the new universal connector for Octopai, making it easier to support most types of data landscapes used by organizations. The universal connector upgrades Blue Orange's data ingestion and machine learning capabilities, allowing it to pull tuned data into an observability platform and analyze it across the Octopai platform's broad spectrum of observability components.

""Octopai is an exceptional company with an impressive track record in the data operations space,"" said <span class=""xn-person"">Colin Van Dyke</span>, chief technology officer of Blue Orange Digital. ""Our partnership with them allows us to provide more robust solutions that address our clients' data observability needs, regardless of their infrastructure maturity. Together, we can help organizations unlock the full potential of their data assets.""

The collaboration includes components for system integration, co-selling opportunities, white-labeling options, and tailored development of unique features that are key enablers in clients' data journeys. This announcement broadens both companies' competencies, permitting them to provide clients with full data transformation and unification solutions.

<b>About Blue Orange Digital</b>

<u><a href=""https://blueorange.digital/"" target=""_blank"" rel=""nofollow noopener"">Blue Orange Digital</a></u> is a data transformation and cloud infrastructure company that specializes in assisting businesses with the implementation of data-driven analytics. The company is dedicated to utilizing cutting-edge technology to create transformational data solutions for clients while prioritizing the development of dedicated staff to assist clients in achieving their goals. Its objective is to create an active community of skilled individuals who can work independently but perform better as part of a networked team.

<b>About Octopai</b>

<u><a href=""https://www.octopai.com/"" target=""_blank"" rel=""nofollow noopener"">Octopai</a></u> is an automated data intelligence company. It provides an automated metadata management platform that continuously recognizes and categorizes data sources across an extended enterprise environment, allowing a company to comprehend, regulate, and optimize a complex, dynamic data environment. Octopai supports metadata scanning by obtaining data from tools automatically. Businesses can utilize this technology to store and manage their data in a centralized repository.",https://blueorange.digital/wp-content/uploads/2023/06/BOD-x-Octopai-Announcement-blog-img.jpg,BOD-x-Octopai-Announcement-blog-img.jpg,/www/blueorangem_500/public/wp-content/uploads/2023/06/BOD-x-Octopai-Announcement-blog-img.jpg,6268,"BOD x Octopai Announcement blog img",,,,https://blueorange.digital/wp-content/uploads/2023/06/BOD-x-Octopai-Announcement-blog-img.jpg,,,,,,,,
6272,"From Data to Insights: How Machine Learning is Transforming Marketing","<span style=""font-weight: 400;"">The world of marketing is rapidly evolving, and one of the most transformative forces behind this evolution is machine learning. Leveraging the power of data and intelligent algorithms, machine learning has become a game-changer for marketers worldwide. </span>
<h1>Unleashing the Power of Precision: Enhanced Customer Targeting</h1>
<img class=""alignnone wp-image-6274 size-large"" src=""https://blueorange.digital/wp-content/uploads/2023/07/BOD-blog-7.10.23-img1-1024x538.jpg"" alt=""Unleashing the Power of Precision: Enhanced Customer Targeting"" width=""1024"" height=""538"" />

<span style=""font-weight: 400;"">Understanding your audience, and machine learning has revolutionized the way marketers identify and target potential customers. Traditional demographic segmentation has given way to more sophisticated techniques, such as predictive modeling and customer clustering.</span>

<span style=""font-weight: 400;"">Machine learning algorithms can analyze vast amounts of customer data, including online behavior, purchase history, and social media interactions. By using this data, marketers can develop highly accurate customer profiles and predict individual preferences and buying behaviors. Allowing marketing campaigns to be tailored to specific customer segments, resulting in higher engagement and conversion rates.</span>
<h1>The Art of Optimization: Intelligent Campaign Optimization</h1>
<span style=""font-weight: 400;"">There’s no need to rely on manual A/B testing and guesswork to optimize marketing campaigns. Machine learning algorithms have empowered marketers to take data-driven approaches to campaign optimization, delivering significant improvements in efficiency and effectiveness.</span>

<span style=""font-weight: 400;"">By leveraging machine learning, marketers can automate the process of testing different variables, such as ad creatives, headlines, calls-to-action, and landing pages. These algorithms continuously analyze data, identify patterns, and make real-time adjustments to optimize campaign performance. Additionally, machine learning can enable marketers to dynamically allocate budgets across different channels and campaigns. By considering historical data, customer behavior, and market trends, algorithms can allocate resources where they are most likely to yield the highest return on investment (ROI). This automated optimization ensures that marketing efforts are continuously fine-tuned, leading to improved campaign results and cost efficiency.</span>
<h1>Personalized Customer Experiences</h1>
<img class=""alignnone wp-image-6275 size-large"" src=""https://blueorange.digital/wp-content/uploads/2023/07/BOD-blog-7.10.23-img2-1024x538.jpg"" alt=""Personalized Customer Experiences"" width=""1024"" height=""538"" />

<span style=""font-weight: 400;"">Customers expect personalized experiences tailored to their specific needs and preferences. Machine learning plays a vital role in delivering these personalized experiences, enabling marketers to create individualized customer journeys across various touchpoints.</span>

<span style=""font-weight: 400;"">By analyzing customer data, machine learning algorithms can provide real-time recommendations and personalized product suggestions. For example, e-commerce platforms can use collaborative filtering algorithms to offer relevant product recommendations based on a user's browsing and purchase history. This level of personalization enhances customer satisfaction, increases engagement, and drives repeat purchases.</span>

<span style=""font-weight: 400;"">Machine learning enables marketers to deliver personalized content at scale. Natural Language Processing (NLP) algorithms can analyze customer interactions and sentiment to generate personalized emails, chatbot conversations, and social media responses. These tailored communications foster stronger customer relationships and increase brand loyalty.</span>
<h1>Advanced Customer Lifetime Value Prediction</h1>
<span style=""font-weight: 400;"">Understanding the long-term value of customers is crucial for effective marketing strategies. Machine learning has transformed customer lifetime value (CLV) prediction, providing marketers with accurate insights into customer profitability and allowing them to make informed decisions.</span>

<span style=""font-weight: 400;"">By considering historical customer behavior, purchasing patterns, and other relevant data, machine learning algorithms can forecast the future value of individual customers. This information empowers marketers to segment customers based on their potential value, enabling targeted retention efforts and personalized loyalty programs. Furthermore, CLV prediction guides budget allocation, ensuring that resources are allocated appropriately to acquire and retain high-value customers.</span>
<h1>Embracing the Power of Machine Learning in Marketing</h1>
<img class=""alignnone wp-image-6276 size-large"" src=""https://blueorange.digital/wp-content/uploads/2023/07/BOD-blog-7.10.23-img3-1024x538.jpg"" alt=""Embracing the Power of Machine Learning in Marketing"" width=""1024"" height=""538"" />

<span style=""font-weight: 400;"">Machine learning has ushered in a new era of marketing, where data-driven insights and intelligent algorithms fuel campaign success. From enhanced customer targeting and intelligent campaign optimization to personalized experiences and advanced CLV prediction, machine learning has transformed the way marketers engage with their audience. As this technology continues to evolve, marketers must embrace these breakthroughs to stay ahead in an increasingly competitive landscape. By harnessing the power of machine learning, marketers can unlock new levels of efficiency, effectiveness, and customer satisfaction, propelling their organizations toward long-term success.</span>",https://blueorange.digital/wp-content/uploads/2023/07/BOD-blog-7.10.23-img4.jpg|https://blueorange.digital/wp-content/uploads/2023/07/BOD-blog-7.10.23-img1.jpg|https://blueorange.digital/wp-content/uploads/2023/07/BOD-blog-7.10.23-img2.jpg|https://blueorange.digital/wp-content/uploads/2023/07/BOD-blog-7.10.23-img3.jpg,BOD-blog-7.10.23-img4.jpg|BOD-blog-7.10.23-img1.jpg|BOD-blog-7.10.23-img2.jpg|BOD-blog-7.10.23-img3.jpg,/www/blueorangem_500/public/wp-content/uploads/2023/07/BOD-blog-7.10.23-img4.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/07/BOD-blog-7.10.23-img1.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/07/BOD-blog-7.10.23-img2.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/07/BOD-blog-7.10.23-img3.jpg,6278|6274|6275|6276,"BOD blog 7.10.23 img4|BOD blog 7.10.23 img1|BOD blog 7.10.23 img2|BOD blog 7.10.23 img3",|||,|||,"From Data to Insights: How Machine Learning is Transforming Marketing|||",https://blueorange.digital/wp-content/uploads/2023/07/BOD-blog-7.10.23-img4.jpg,,,,,,,,
6279,"Leveraging AI to Drive Digital Transformation: Empowering the Future","In today's rapidly evolving digital landscape, organizations across industries are seeking innovative ways to stay competitive and drive growth. One transformative technology that has emerged as a game-changer is Artificial Intelligence (AI). By harnessing the power of AI, businesses can unlock new possibilities, improve operational efficiency, enhance customer experiences, and achieve unprecedented levels of digital transformation. This article delves into the fascinating world of leveraging AI to drive digital transformation, exploring its key benefits, challenges, and best practices.
<h1>Understanding AI and Digital Transformation</h1>
<img class=""alignnone wp-image-6283 size-large"" src=""https://blueorange.digital/wp-content/uploads/2023/07/Understanding-AI-and-Digital-Transformation-1024x538.jpg"" alt=""Understanding AI and Digital Transformation"" width=""1024"" height=""538"" />

AI, broadly defined, refers to computer systems capable of performing tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and natural language processing. On the other hand, digital transformation involves the integration of digital technologies to fundamentally alter business processes, operations, and customer experiences.
<h1>Key Benefits of Leveraging AI for Digital Transformation</h1>
<ol>
 	<li><strong>Advanced Data Analytics</strong>
AI enables organizations to analyze vast volumes of structured and unstructured data, extracting valuable insights and patterns. Machine learning algorithms can identify trends, detect anomalies, and provide predictive analytics, empowering businesses to make data-driven decisions and optimize their operations.</li>
 	<li><strong>Enhanced Customer Experience</strong>
By leveraging AI-powered chatbots, virtual assistants, and recommendation engines, businesses can provide personalized and seamless customer experiences. AI algorithms can analyze customer preferences, behavior, and feedback to deliver tailored interactions, resulting in increased customer satisfaction and loyalty.</li>
 	<li><strong>Process Automation and Efficiency</strong>
AI technologies such as robotic process automation (RPA) can automate repetitive and rule-based tasks, freeing up human resources to focus on higher-value activities. This streamlines operations, reduces errors, and improves overall efficiency, resulting in cost savings and improved productivity.</li>
 	<li><strong>Predictive Maintenance</strong>
AI-driven predictive maintenance models can analyze sensor data, machine logs, and historical records to identify potential equipment failures before they occur. By proactively addressing maintenance issues, organizations can minimize downtime, optimize resource allocation, and prolong the lifespan of assets.</li>
 	<li><strong>Intelligent Decision-making</strong>
AI-powered algorithms can analyze complex datasets, identify patterns, and generate insights to support decision-making processes. By augmenting human intelligence with AI-driven analytics, organizations can make informed decisions faster, reduce risks, and gain a competitive edge.</li>
</ol>
<h1>Challenges and Considerations</h1>
<ol>
 	<li><strong>Data Quality and Privacy</strong>
To leverage AI effectively, organizations must ensure data quality, integrity, and compliance with privacy regulations. Implementing robust data governance practices, data anonymization techniques, and adopting transparent privacy policies are crucial for building trust and safeguarding sensitive information.</li>
 	<li><strong>Ethical AI</strong>
As AI becomes more sophisticated, ethical considerations become paramount. Organizations must establish guidelines and frameworks to address bias, fairness, transparency, and accountability in AI systems. Responsible AI development and deployment are essential to mitigate potential ethical risks.</li>
 	<li><strong>Skill Gaps and Workforce Transformation</strong>
AI implementation requires a skilled workforce capable of developing, deploying, and maintaining AI systems. Upskilling existing employees, fostering a culture of continuous learning, and attracting AI talent are vital for ensuring a successful digital transformation journey.</li>
</ol>
<h1>Best Practices for Leveraging AI in Digital Transformation</h1>
<ol>
 	<li><strong>Define Clear Objectives</strong>: Start by identifying specific business objectives and areas where AI can create value. Focus on targeted use cases that align with strategic goals and have measurable outcomes.</li>
 	<li><strong>Build a Robust Data Infrastructure</strong>: Establish a scalable and secure data infrastructure that can collect, store, and process data effectively. Ensure data quality, integrate disparate data sources, and implement data governance frameworks.</li>
 	<li><strong>Foster Collaboration</strong>: Encourage cross-functional collaboration between business units, data scientists, and IT teams. Effective collaboration promotes knowledge sharing, ideation, and seamless integration of AI technologies into existing processes.</li>
 	<li><strong>Start Small and Scale</strong>: Begin with pilot projects to validate AI use cases and measure their impact. Learn from early successes and failures, iterate, and gradually scale AI initiatives across the organization.</li>
 	<li><strong>Embrace Change Management</strong>: Digital transformation involving AI requires a cultural shift within the organization. Promote change management practices, communicate the benefits of AI adoption, and provide training and support to employees.</li>
</ol>
<h1>Conclusion</h1>
<img class=""alignnone wp-image-6284 size-large"" src=""https://blueorange.digital/wp-content/uploads/2023/07/Best-Practices-for-Leveraging-AI-in-Digital-Transformation-1024x538.jpg"" alt=""Best Practices for Leveraging AI in Digital Transformation"" width=""1024"" height=""538"" />

In an era of rapid digital transformation, leveraging AI technologies can empower organizations to unlock new opportunities and gain a competitive edge. By harnessing advanced analytics, automation, and intelligent decision-making capabilities, businesses can enhance customer experiences, streamline operations, and drive growth. However, organizations must also address ethical concerns, data quality, and skill gaps to navigate the AI-driven digital landscape successfully. By adopting best practices and fostering a culture of innovation, businesses can leverage AI as a transformative force and pave the way for a future powered by intelligent technologies.",https://blueorange.digital/wp-content/uploads/2023/07/Leveraging-AI-to-Drive-Digital-Transformation-Empowering-the-Future.jpg|https://blueorange.digital/wp-content/uploads/2023/07/Understanding-AI-and-Digital-Transformation.jpg|https://blueorange.digital/wp-content/uploads/2023/07/Best-Practices-for-Leveraging-AI-in-Digital-Transformation.jpg,Leveraging-AI-to-Drive-Digital-Transformation-Empowering-the-Future.jpg|Understanding-AI-and-Digital-Transformation.jpg|Best-Practices-for-Leveraging-AI-in-Digital-Transformation.jpg,/www/blueorangem_500/public/wp-content/uploads/2023/07/Leveraging-AI-to-Drive-Digital-Transformation-Empowering-the-Future.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/07/Understanding-AI-and-Digital-Transformation.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/07/Best-Practices-for-Leveraging-AI-in-Digital-Transformation.jpg,6282|6283|6284,"Leveraging AI to Drive Digital Transformation Empowering the Future|Understanding AI and Digital Transformation|Best Practices for Leveraging AI in Digital Transformation",||,||,"Leveraging AI to Drive Digital Transformation Empowering the Future||",https://blueorange.digital/wp-content/uploads/2023/07/Leveraging-AI-to-Drive-Digital-Transformation-Empowering-the-Future.jpg,,,,,,,,
6294,"Harnessing LLM Power: ChatGPT vs Google's BARD - Industry Insights and Use Case Comparison","[et_pb_section fb_built=""1"" admin_label=""section"" _builder_version=""4.16"" global_colors_info=""{}"" theme_builder_area=""post_content""][et_pb_row admin_label=""row"" _builder_version=""4.16"" background_size=""initial"" background_position=""top_left"" background_repeat=""repeat"" global_colors_info=""{}"" theme_builder_area=""post_content""][et_pb_column type=""4_4"" _builder_version=""4.16"" custom_padding=""|||"" global_colors_info=""{}"" custom_padding__hover=""|||"" theme_builder_area=""post_content""][et_pb_text _builder_version=""4.21.0"" _module_preset=""default"" hover_enabled=""0"" global_colors_info=""{}"" theme_builder_area=""post_content"" sticky_enabled=""0""]<p><span>Join us as we compare two powerful advanced language models - ChatGPT and Google's BARD. In this video, we provide industry insights and explore their applications in various use cases. </span></p>[/et_pb_text][et_pb_video src=""https://www.youtube.com/watch?v=zhYymrIoclI"" _builder_version=""4.21.0"" _module_preset=""default"" theme_builder_area=""post_content"" hover_enabled=""0"" sticky_enabled=""0""][/et_pb_video][/et_pb_column][/et_pb_row][/et_pb_section]",https://blueorange.digital/wp-content/uploads/2023/07/BOD-SME-vid-thumb-02.png,BOD-SME-vid-thumb-02.png,/www/blueorangem_500/public/wp-content/uploads/2023/07/BOD-SME-vid-thumb-02.png,6295,"BOD SME vid thumb 02",,,"Harnessing LLM Power: ChatGPT vs Google's BARD - Industry Insights and Use Case Comparison",https://blueorange.digital/wp-content/uploads/2023/07/BOD-SME-vid-thumb-02.png,,,,,,,,
6315,"Revolutionizing Data Applications: Key Highlights from Snowflake Summit 2023","<h1><b>Revolutionizing Data Applications: Key Highlights from Snowflake Summit 2023</b></h1>
<span style=""font-weight: 400;"">The Snowflake Summit in Las Vegas hosted over 12,000 participants, and showcased impressive growth in comparison to tech events such as AWS Re:invent, marking it a departure from community-centric gatherings like dbt Coalesce or Alteryx Inspire. Indicating Snowflake's expanding market footprint, offering substantial capital for pioneering industry innovations.</span>

<b>Unfolding the Future of Data Products and Applications</b>

<span style=""font-weight: 400;"">Snowflake made several keynote announcements, together outlining an exciting future for data products and applications under their umbrella term ""Data Cloud"". These announcements showcased their current achievements but also provided a road map for upcoming innovations, presenting an evolving landscape where data becomes more accessible and actionable. From the introduction of Native Applications to AI collaborations and Apache Iceberg support, it's evident that Snowflake is determined to revolutionize the way businesses utilize data, ensuring an optimal balance of performance, scalability, and security.</span>

<b>Embracing Native Applications</b>

<span style=""font-weight: 400;"">Introduced in 2022 and launched in Public Preview this year, Native Applications come bundled with features that streamline application release:</span>
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Improved security measures</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Simplified applications</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Pricing options</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Capacity drawdown</span></li>
</ul>
<span style=""font-weight: 400;"">With the incorporation of Snowflake’s Streamlit acquisition, building, deploying, and monetizing sophisticated data products has never been easier. At Blue Orange, we see a majority of data projects targeting internal business workflows and process improvements. Snowflake’s vision of a native data product being bundled so tightly with a secure, cost controlled data store again drives at core Snowflake value proposition, don’t replicate your data.</span>

<b>Introducing Snowpark Container Services and Registry</b>

<img class=""alignnone size-full wp-image-6318"" src=""https://blueorange.digital/wp-content/uploads/2023/07/BOD-at-Snowflake-Summit-2023_1.png"" alt=""BOD at Snowflake Summit 2023_1"" width=""620"" height=""460"" />

<span style=""font-weight: 400;"">The launch of Snowpark Container Services and Registry promises to be a game-changer. This service will allow users to directly deploy Docker containers onto Snowflake's robust infrastructure. By providing a high-performing, secure, and scalable environment, Snowflake has taken a major step towards liberating developers from the complexities of managing their own infrastructures, while promoting seamless and secure data connectivity. The introduction of this service underscores Snowflake's commitment to providing a comprehensive, user-friendly data ecosystem that caters to the needs of developers and data scientists alike.</span>

<span style=""font-weight: 400;"">The implications of this new service are profound, particularly for machine learning (ML) and large language models (LLMs). The ability to train these models directly on Snowflake data can dramatically streamline the application development process. As a result, the new service provides a unified framework for application development and deployment on Snowflake, contributing significantly to the simplification of complex applications and enabling easy sharing with other users. As data continues to play a vital role in shaping business decisions, Snowflake’s Snowpark Container Services and Registry are likely to become an essential tool for many organizations.</span>

<b>AI Innovations: Collaborating with Nvidia</b>

<span style=""font-weight: 400;"">The Snowflake Summit wouldn't be complete without a fair share of AI-focused announcements. The highlight of this year's AI narratives was the unveiling of a strategic partnership between Snowflake and Nvidia. With Nvidia's founder and CEO, Jensen Huang, at the helm, the partnership aims to integrate Nvidia's NeMo Framework into Snowflake's ecosystem. By doing so, they intend to GPU-enable virtual warehouses, which will significantly streamline the development of General AI (GenAI) and Large Language Models (LLMs).</span>

<span style=""font-weight: 400;"">Beyond the partnership announcement, the integration of the NeMo Framework could have far-reaching implications for businesses that depend on AI. The capacity to develop AI models directly on Snowflake's infrastructure, coupled with the prowess of Nvidia's technology, could result in faster development cycles and more efficient AI operations. With the increased interest in and usage of AI in various sectors, this partnership is poised to deliver substantial benefits to a wide range of Snowflake users.</span>

<span style=""font-weight: 400;"">Moreover, this collaboration also aligns with Snowflake's overall vision to provide a more inclusive, integrated data ecosystem. The partnership with Nvidia underscores their commitment to offer a platform that not only allows for secure, scalable data storage but also facilitates advanced AI development. Here at Blue Orange, we’ve been deploying LLMs in this exact use case for a number of clients. It’ll be powerful to have that running securely in your own data environment, trained on our custom datasets. </span>

<b>Unveiling Document AI</b>

<img class=""alignnone size-full wp-image-6319"" src=""https://blueorange.digital/wp-content/uploads/2023/07/BOD-at-Snowflake-Summit-2023_2.png"" alt="""" width=""611"" height=""456"" />

<span style=""font-weight: 400;"">Snowflake has broadened its AI arsenal with the introduction of Document AI. This innovative managed service uses a pre-trained Large Language Model (LLM) to delve into unstructured data within Snowflake, thereby opening the door to analyzing and extracting valuable insights from complex data forms. It allows an efficient interaction with an array of unstructured data like emails, social media posts, or images, offering transformative possibilities for business analytics and intelligence.</span>

https://www.youtube.com/watch?v=OTycMK18d2M

<span style=""font-weight: 400;"">Along with streamlining and automating data extraction, Document AI stands as a potent tool to generate a competitive advantage. With the surge in unstructured data generation and availability, Snowflake's Document AI plays a pivotal role in interpreting this data, leading to well-informed business strategies. The release of Document AI marks a key stride in Snowflake's journey of evolving AI within its ecosystem, reinforcing its commitment to deliver more intuitive and robust tools for users to unlock the full potential of their data.</span>

<b>Supporting Apache Iceberg Tables</b>

<span style=""font-weight: 400;"">In a move reflective of industry trends, Snowflake has embraced Apache Iceberg, the emerging standard for big data analytics and data lake management. By supporting Iceberg tables, Snowflake is aligning itself with a system that offers SQL table-like capabilities in an open, accessible manner. This enables multiple engines to operate on the same dataset and provides benefits such as transactional consistency, schema evolution, time travel for querying historical data, and advanced planning and filtering capabilities.</span>

<span style=""font-weight: 400;"">This support shows Snowflake's commitment to embracing standardized tools and contributing to a more collaborative big data landscape. Iceberg tables, known for handling large datasets with ease, allow Snowflake to offer a more efficient and scalable data management solution. It's a significant step towards the standardization of big data, ensuring that Snowflake users can take full advantage of the latest developments in big data management.</span>

<b>Revolutionizing Real-time Data Features</b>

<span style=""font-weight: 400;"">Snowflake introduced updates to critical features that are instrumental in real-time data design:</span>
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><i><span style=""font-weight: 400;"">Dynamic Tables</span></i><span style=""font-weight: 400;"">: Simplifies data transformations and reduces costs</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><i><span style=""font-weight: 400;"">Snowpipe Streaming</span></i><span style=""font-weight: 400;"">: A service designed to load data into Snowflake in real-time</span></li>
</ul>
<img class=""alignnone wp-image-6321 size-full"" src=""https://blueorange.digital/wp-content/uploads/2023/07/Colin-and-Josh-at-Snowflake-Summit-2023_1.png"" alt=""Colin and Josh at Snowflake Summit 2023"" width=""614"" height=""452"" />

<b>Additional Announcements</b>

<span style=""font-weight: 400;"">Snowflake also rolled out several other updates:</span>
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Improved monitoring and cost controls</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Performance enhancements</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Updated CLI and Python API</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Public preview release of dynamic tables</span></li>
</ul>
<b>Conclusion: A Comprehensive Vision for Data Ecosystem</b>

<span style=""font-weight: 400;"">The Snowflake Summit presented a compelling vision of a comprehensive data ecosystem, supported by numerous improvements and additions. While Snowflake has made a persuasive case for a more unified, controlled data environment, the future landscape of ML workloads remains a battleground. The team at Blue Orange Digital is ready to help businesses navigate these developments to unleash the full potential of their data.</span>",https://blueorange.digital/wp-content/uploads/2023/07/BOD-snowflake-summit-recap.png|https://blueorange.digital/wp-content/uploads/2023/07/Josh-at-Snowflake-Summit-2023.png|https://blueorange.digital/wp-content/uploads/2023/07/BOD-at-Snowflake-Summit-2023_1.png|https://blueorange.digital/wp-content/uploads/2023/07/BOD-at-Snowflake-Summit-2023_2.png|https://blueorange.digital/wp-content/uploads/2023/07/Colin-and-Josh-at-Snowflake-Summit-2023_1.png,BOD-snowflake-summit-recap.png|Josh-at-Snowflake-Summit-2023.png|BOD-at-Snowflake-Summit-2023_1.png|BOD-at-Snowflake-Summit-2023_2.png|Colin-and-Josh-at-Snowflake-Summit-2023_1.png,/www/blueorangem_500/public/wp-content/uploads/2023/07/BOD-snowflake-summit-recap.png|/www/blueorangem_500/public/wp-content/uploads/2023/07/Josh-at-Snowflake-Summit-2023.png|/www/blueorangem_500/public/wp-content/uploads/2023/07/BOD-at-Snowflake-Summit-2023_1.png|/www/blueorangem_500/public/wp-content/uploads/2023/07/BOD-at-Snowflake-Summit-2023_2.png|/www/blueorangem_500/public/wp-content/uploads/2023/07/Colin-and-Josh-at-Snowflake-Summit-2023_1.png,6316|6317|6318|6319|6321,"BOD snowflake summit recap|Josh at Snowflake Summit 2023|BOD at Snowflake Summit 2023_1|BOD at Snowflake Summit 2023_2|Colin and Josh at Snowflake Summit 2023_1",||||,||||,"BOD snowflake summit 2023 recap|Josh Miramant at Snowflake Summit 2023|||",https://blueorange.digital/wp-content/uploads/2023/07/BOD-snowflake-summit-recap.png,,,,,,,,
6379,"Unveiling the Value Add from Data Transformation: Harnessing the Power of Insights","In the contemporary landscape of data-driven environments, organizations are continuously amassing substantial volumes of data from diverse origins such as customer interactions, operational processes, and market trends. Nonetheless, the mere existence of raw data is insufficient for fully capitalizing on its inherent potential. To unleash valuable insights and facilitate well-informed decision-making, businesses must undertake a pivotal procedure called data transformation. Within this blog post, we will delve into the intricacies of the captivating realm of data transformation and elucidate the multifaceted approaches through which it contributes significant value to businesses.
<h1>Defining Data Transformation</h1>
Data transformation is a multifaceted procedure that involves a set of operations aimed at converting unprocessed and disorganized data into a structured and manipulable format, optimized for analysis purposes. The process encompasses several crucial steps, such as data cleaning, integration, and enrichment, which collectively ensure the accuracy, consistency, and compatibility of the transformed data.

Steps Include:

<b style=""color: #333333; font-size: 26px;"">1. Enhanced Data Quality and Consistency</b>

<span style=""font-weight: 400;"">Data transformation helps address common data quality issues such as missing values, inconsistencies, and errors. Clean and consistent data ensures that subsequent analyses are based on reliable information, leading to more accurate insights and better decision-making.</span>

<b style=""color: #333333; font-size: 26px;"">2. Data Integration and Compatibility</b>

<span style=""font-weight: 400;"">Modern enterprises often have diverse data sources, ranging from internal databases to external APIs and third-party systems. Data transformation facilitates the integration of these disparate data sources, enabling a unified view of information across the organization. By harmonizing data formats, resolving schema conflicts, and standardizing naming conventions, businesses can achieve data compatibility, paving the way for holistic analyses and a comprehensive understanding of their operations.</span>

<b style=""color: #333333; font-size: 26px;"">3. Enrichment with Contextual Information</b>

<span style=""font-weight: 400;"">Data transformation also allows organizations to enrich their datasets with additional contextual information. This process involves augmenting raw data with external data sources, such as demographic data, social media feeds, or market research insights. By integrating external data, businesses gain a more comprehensive view of their customers, market trends, and competitive landscapes. This contextual enrichment empowers organizations to derive deeper insights and uncover hidden patterns, leading to more targeted strategies and better customer experiences.</span>

<b style=""color: #333333; font-size: 26px;"">4. Improved Data Accessibility and Usability</b>

<span style=""font-weight: 400;"">Data transformation involves structuring data in a manner that enhances its accessibility and usability for analysis. This transformation can include activities such as data aggregation, summarization, and dimension reduction. By condensing complex and voluminous data into manageable formats, organizations can expedite their analytical processes, allowing stakeholders to extract insights quickly. Improved data accessibility facilitates self-service analytics, enabling decision-makers at all levels of the organization to interact with and interpret data effectively.</span>

<b style=""color: #333333; font-size: 26px;"">5. Empowering Advanced Analytical Techniques</b>

<span style=""font-weight: 400;"">Data transformation is a crucial precursor to advanced analytical techniques such as machine learning, predictive modeling, and data mining. These techniques require data to be in a specific format, with appropriate features and labels. By transforming data into the required format, businesses can leverage sophisticated algorithms to uncover hidden patterns, forecast future trends, and make accurate predictions. The application of these advanced techniques can provide a competitive edge, drive innovation, and identify new business opportunities.</span>

<img class=""alignnone size-large wp-image-6381"" src=""https://blueorange.digital/wp-content/uploads/2023/07/BOD-data-transformation-blog-img1-1024x538.jpg"" alt="""" width=""1024"" height=""538"" />

<span style=""font-weight: 400;"">Some key beneficiaries include:</span>
<ol>
 	<li><b>Data Analysts and Data Scientists:</b><span style=""font-weight: 400;""> Data transformation prepares data for analysis by cleaning, integrating, and aggregating it in a consistent format. Analysts and data scientists benefit from transformed data as it enables them to derive meaningful insights, build accurate models, and make informed decisions.</span></li>
 	<li><b>Business Leaders and Managers:</b><span style=""font-weight: 400;""> Data transformation helps business leaders and managers gain a clear and comprehensive view of their organization's operations, projects, spend, and performance. Transformed data allows them to identify patterns, trends, and anomalies, enabling them to make data-driven decisions and develop effective strategies.</span></li>
 	<li><b>Operations and Process Managers:</b><span style=""font-weight: 400;""> Data transformation can optimize operational processes by converting raw data into standardized formats. This enables operations managers to monitor and analyze key performance indicators (KPIs), identify inefficiencies, and improve overall productivity and efficiency.</span></li>
 	<li><b>IT and Data Engineering Teams:</b><span style=""font-weight: 400;""> Data transformation often involves tasks such as data cleaning, integration, and normalization. IT and data engineering teams benefit from data transformation as it helps them maintain data quality, ensure data consistency, and streamline data management processes.</span></li>
 	<li><b>Marketing and Sales Teams:</b><span style=""font-weight: 400;""> Transformed data provides valuable insights into customer behavior, preferences, and purchasing patterns. Marketing and sales teams can leverage this information to personalize marketing campaigns, improve targeting, optimize pricing strategies, and enhance customer engagement and satisfaction.</span></li>
 	<li><b>Compliance and Risk Management Professionals:</b><span style=""font-weight: 400;""> Data transformation plays a crucial role in ensuring compliance with regulations and managing risks. By transforming data into a standardized format, compliance officers and risk management professionals can accurately analyze and report on sensitive data, identify potential risks, and take appropriate measures to mitigate them.</span></li>
 	<li><b>Customers and End Users:</b><span style=""font-weight: 400;""> Data transformation indirectly benefits customers and end users by improving the overall quality and efficiency of products and services. Transformed data allows organizations to better understand customer needs, personalize experiences, and deliver tailored solutions, resulting in improved customer satisfaction.</span></li>
</ol>
<img class=""alignnone size-large wp-image-6382"" src=""https://blueorange.digital/wp-content/uploads/2023/07/BOD-data-transformation-blog-img2-1024x538.jpg"" alt="""" width=""1024"" height=""538"" />

<span style=""font-weight: 400;"">Data transformation benefits multiple stakeholders within an organization, enabling them to derive insights, make informed decisions, optimize processes, and enhance customer experiences. <a href=""https://blueorange.digital/contact-us/""><strong>So start your journey today, with Blue Orange Digital</strong>.</a></span>",https://blueorange.digital/wp-content/uploads/2023/07/BOD-data-transformation1.jpg|https://blueorange.digital/wp-content/uploads/2023/07/BOD-data-transformation-blog-img1.jpg|https://blueorange.digital/wp-content/uploads/2023/07/BOD-data-transformation-blog-img2.jpg,BOD-data-transformation1.jpg|BOD-data-transformation-blog-img1.jpg|BOD-data-transformation-blog-img2.jpg,/www/blueorangem_500/public/wp-content/uploads/2023/07/BOD-data-transformation1.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/07/BOD-data-transformation-blog-img1.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/07/BOD-data-transformation-blog-img2.jpg,6380|6381|6382,"BOD data transformation1|BOD data transformation blog img1|BOD data transformation blog img2",||,||,||,https://blueorange.digital/wp-content/uploads/2023/07/BOD-data-transformation1.jpg,,,,,,,,
6405,"Unraveling the Power of Data Fabric: Transforming Businesses with Unified Data Insights","In today's fast-paced business landscape, data is the key to unlocking insights, driving innovation, and staying ahead of the competition. However, the explosion of data from various sources and the increasing complexity of data ecosystems have posed significant challenges for organizations. Data Fabric is an innovative data management approach that aims to seamlessly connect and integrate diverse data sources within an organization. It enables businesses to break down data silos and create a unified, cohesive view of their data landscape. This allows for real-time access, analysis, and sharing of data, empowering businesses to make informed decisions, derive valuable insights, and optimize their data assets more effectively. Data Fabric plays a crucial role in enabling digital transformation and maximizing the potential of data-driven strategies for businesses of all sizes and industries. Listed below are ways in which Data Fabric is transforming businesses.
<h3><b>Benefits:</b></h3>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Improved data quality: </b></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Data fabric is revolutionizing businesses by breaking down data silos and providing a unified data environment. This seamless integration ensures accurate, reliable, and fresh data, empowering companies with a comprehensive view of their operations and customers.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Increased operational efficiency: </b></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">As businesses grow and evolve, so do their data requirements. With data fabric's powerful data integration capabilities, businesses can streamline their operations and decision-making processes. By consolidating and harmonizing data from various sources, teams can access critical information in real-time, leading to faster and more informed actions.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Better data management &amp; increased data agility:</b></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b> </b><span style=""font-weight: 400;"">With data scattered across multiple platforms, making informed managerial decisions can be slow and cumbersome. Data fabric empowers businesses with clear roles and responsibilities in managing data. Real-time analysis becomes a reality, allowing organizations to adapt swiftly to changing market dynamics and customer demands.</span></li>
</ul>
</li>
</ul>
<ul>
 	<li aria-level=""1""><b>Easier switch from data warehousing to a data lake: </b></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Data fabric's flexibility enables a seamless transition from traditional data warehousing to more agile data lake architectures. This transition enhances data insights and empowers data-driven decision-making across the organization.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Improved data integration and accessibility</b><span style=""font-weight: 400;"">: </span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Instead of dealing with scattered data silos that hinder collaboration and decision-making, With data fabric, organizations benefit from a unified view of data across the organization, simplified data access and streamlined data pipelines. This ensures that valuable data is readily available to relevant stakeholders, promoting collaboration and efficient data-driven processes.</span></li>
</ul>
<b>Enhancing Data Security and Compliance:</b>

<span style=""font-weight: 400;"">Data security and compliance are paramount concerns for businesses dealing with sensitive information. Data Fabric consolidates data into a single repository, improving access control and security measures. This centralized approach ensures that sensitive data is appropriately protected, safeguarding businesses against potential breaches and data leaks.</span>

<b>Unleashing the Potential of AI and Analytics:</b>

<span style=""font-weight: 400;"">Data Fabric provides a solid foundation for advanced analytics and AI-driven insights. By unifying data and having consistent datasets, businesses can leverage the full potential of AI and machine learning algorithms to uncover valuable patterns and trends.</span>

<img class=""alignnone wp-image-6408 size-large"" src=""https://blueorange.digital/wp-content/uploads/2023/08/BOD-data-fabric-img1-1024x538.jpg"" alt="""" width=""1024"" height=""538"" />
<h3><b>Challenges in Adopting Data Fabric:</b></h3>
<span style=""font-weight: 400;"">As businesses embark on their data fabric journey, they may encounter some challenges along the way. These may include:</span>
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Data Integration Complexity:</b><span style=""font-weight: 400;""> Integrating data from diverse sources can be complex and time-consuming, requiring a well-defined strategy and skilled resources.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Legacy System Integration:</b><span style=""font-weight: 400;""> Businesses with legacy systems may face challenges in seamlessly integrating them into the Data Fabric architecture.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Data Governance:</b><span style=""font-weight: 400;""> Maintaining data governance and ensuring compliance with data regulations can be a significant challenge in a centralized data environment.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Organizational Resistance:</b><span style=""font-weight: 400;""> Employees may resist adopting a new data fabric platform, requiring effective change management and training initiatives.</span></li>
</ul>
<img class=""alignnone wp-image-6407 size-large"" src=""https://blueorange.digital/wp-content/uploads/2023/08/BOD-data-fabric-img2-1024x538.jpg"" alt="""" width=""1024"" height=""538"" />

<span style=""font-weight: 400;"">Data Fabric has emerged as a transformative force in the world of data management, driving innovation and unleashing the true potential of businesses. With its array of benefits, from improved data quality to enhanced data analytics, Data Fabric empowers organizations to make data-driven decisions and stay ahead in an ever-evolving business landscape. However, embracing Data Fabric does come with its share of challenges, and companies must address them proactively to reap the full rewards of this revolutionary technology. By overcoming these hurdles and embracing a data-driven culture, businesses can unlock transformational growth and lead their industries into a brighter future.</span>",https://blueorange.digital/wp-content/uploads/2023/08/BOD-data-fabric-img3.jpg|https://blueorange.digital/wp-content/uploads/2023/08/BOD-data-fabric-img2.jpg|https://blueorange.digital/wp-content/uploads/2023/08/BOD-data-fabric-img1.jpg,BOD-data-fabric-img3.jpg|BOD-data-fabric-img2.jpg|BOD-data-fabric-img1.jpg,/www/blueorangem_500/public/wp-content/uploads/2023/08/BOD-data-fabric-img3.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/08/BOD-data-fabric-img2.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/08/BOD-data-fabric-img1.jpg,6409|6407|6408,"BOD data fabric img3|BOD data fabric img2|BOD data fabric img1",||,||,||,https://blueorange.digital/wp-content/uploads/2023/08/BOD-data-fabric-img3.jpg,,,,,,,,
6414,"Beyond the Spreadsheet: Data Visualization's Impact on Analytics","<span style=""font-weight: 400;"">Information is the currency that fuels innovation, decision-making, and progress. But raw data alone can be overwhelming, often resembling a tangled web of numbers and figures. This is where the power of data visualization comes into play, transforming complex datasets into visual stories that not only captivate the eyes but also unlock invaluable insights. </span>
<h3><b>Understanding Data Visualization in Analytics</b></h3>
<span style=""font-weight: 400;"">Data visualization in analytics is the art and science of transforming complex datasets into visual representations that facilitate comprehension and reveal insights. It involves selecting appropriate visual elements – such as charts, graphs, maps, and diagrams – to effectively communicate patterns, trends, correlations, and outliers present in the data. Through careful design choices, color coding, scaling, and labeling, data visualizations guide viewers' focus, making it easier to extract meaningful information from the data. This process not only enhances data understanding but also empowers decision-makers, analysts, and stakeholders to explore data from multiple angles, fostering a deeper grasp of the underlying information. By transcending the limitations of raw data, data visualization serves as a powerful tool to convey complex concepts and narratives, enabling data-driven storytelling and informed decision-making. Here's a closer look at the benefits that data visualizations bring to the world of analytics</span>

<img class=""alignnone size-large wp-image-6418"" src=""https://blueorange.digital/wp-content/uploads/2023/08/BOD-Data-Viz-img1-1024x538.jpg"" alt="""" width=""1024"" height=""538"" />
<h3><b>Benefits of Data Visualization in Analytics:</b></h3>
<b>Making Complex Data Digestible: Storytelling with Visuals</b>

<span style=""font-weight: 400;"">Human brains are wired to process visual information more efficiently than textual or numerical data. Data visualization bridges the gap between the complexity of data and the human mind's ability to comprehend patterns and relationships. Complex datasets are translated into visual representations like charts, graphs, and heatmaps, making it easier for analysts, decision-makers, and even the general public to grasp the underlying information. A well-constructed data visualization can evoke emotions, spark discussions, and drive action in ways that raw data cannot.</span>

<b>Unveiling Trends and Patterns: Insights at a Glance</b>

<span style=""font-weight: 400;"">The true power of data visualization lies in its ability to uncover hidden trends and patterns that might not be evident in raw data. A well-constructed visualization can reveal relationships, correlations, and anomalies that might have gone unnoticed. For instance, a line chart plotting sales over time can quickly indicate whether there's a seasonal pattern or a consistent upward trajectory.</span>

<b>Enhancing Decision-Making: From Intuition to Evidence-Based Choices</b>

<span style=""font-weight: 400;"">Data-driven decision-making is the cornerstone of successful businesses and institutions. Data visualizations provide decision-makers with the visual evidence they need to make their decisions quickly. Whether it's choosing the most effective marketing strategy or optimizing a supply chain, visualizations offer a clear picture of the potential outcomes, enabling informed and confident decisions.</span>

<b>Transcending Language Barriers: Universality of Visuals</b>

<span style=""font-weight: 400;"">Data visualization transcends language barriers, making it a universal language of insight. Whether a decision-maker speaks English, Mandarin, or Spanish, a well-designed visualization can convey complex information without relying solely on text. This universality makes data-driven insights accessible to a global audience.</span>

<img class=""alignnone size-large wp-image-6419"" src=""https://blueorange.digital/wp-content/uploads/2023/08/BOD-Data-Viz-img2-1024x538.jpg"" alt="""" width=""1024"" height=""538"" />
<h3><b>Challenges and Pitfalls: Navigating the Complex Terrain of Data Visualization</b></h3>
<span style=""font-weight: 400;"">While the benefits of data visualization in analytics are abundant, it's essential to tread carefully and be aware of the challenges and pitfalls that can arise in the process. Here are some key considerations to keep in mind:</span>

<b> Misleading Visuals: The Illusion of Accuracy</b>

<span style=""font-weight: 400;"">One of the primary challenges in data visualization is the potential to mislead. A visually appealing chart can sometimes present a distorted or incomplete picture of the data. This might occur due to improper scaling, skewed axes, or misrepresentative labeling. Ensuring that visualizations accurately depict the underlying data is crucial to avoid leading viewers to incorrect conclusions.</span>

<b>Selection Bias: The Danger of Cherry-Picked Data</b>

<span style=""font-weight: 400;"">Choosing specific subsets of data to support a particular narrative, while leaving out relevant context, can introduce selection bias. This bias can skew interpretations and lead to flawed decisions. Transparently presenting the full scope of data, even when it contradicts the desired outcome, is crucial for maintaining the integrity of the insights derived from visualizations.</span>

<b> Complexity Concealed as Simplicity: Simplification Gone Wrong</b>

<span style=""font-weight: 400;"">Simplifying complex data is a hallmark of effective visualization, but it's a fine line to walk. Oversimplification can lead to a loss of important nuances and details, thereby weakening the accuracy of the insights. Striking the right balance between simplicity and complexity requires a deep understanding of the data and the audience's needs.</span>

<b>Cognitive Load: Avoiding Information Overwhelm</b>

<span style=""font-weight: 400;"">Visualizations are meant to simplify data interpretation, but poorly designed visuals can overwhelm the viewer's cognitive capacity. Too many data points, excessive colors, or intricate layouts can lead to cognitive load, making it challenging for the audience to absorb the insights effectively. Clean, well-organized designs and intuitive layouts help mitigate this challenge.</span>

<img class=""alignnone size-large wp-image-6420"" src=""https://blueorange.digital/wp-content/uploads/2023/08/BOD-Data-Viz-img3-1024x538.jpg"" alt="""" width=""1024"" height=""538"" />
<h3><b>Best Practices for Leveraging Data Visualization in Analytics</b></h3>
<span style=""font-weight: 400;"">Here are key guidelines and best practices that ensure accuracy, clarity, and effectiveness of your data visualizations:</span>

<b>Understand Your Audience &amp; Choose the Right Visualization:</b><span style=""font-weight: 400;""> </span>

<span style=""font-weight: 400;"">Tailor your visualizations to the intended audience's expertise and interests. A well-crafted visualization should resonate with its viewers and convey insights in a manner that aligns with their level of comprehension. Select visualization types that best represent the patterns or relationships you intend to showcase. Line charts for time series data, bar graphs for comparisons, and heatmaps for spatial trends are just a few examples of matching the visualization to the data's nature.</span>

<b>Maintain Data Integrity: </b>

<span style=""font-weight: 400;"">Ensure the accuracy of your visualizations by accurately representing the data without distorting or exaggerating information. Be cautious of misleading scales, axes, and labeling that might misinterpret the data.</span>

<b>Simplicity is Key: </b>

<span style=""font-weight: 400;"">Keep your visualizations clean and clutter-free. Avoid unnecessary embellishments that could divert attention from the actual insights. Each element in the visualization should have a clear purpose and contribute to the narrative.</span>

<b>Regularly Update Visualizations: </b>

<span style=""font-weight: 400;"">Data is dynamic, and your visualizations should reflect this dynamism. Regularly update your visualizations to include the most recent data, ensuring the insights remain relevant and actionable.</span>
<h3><b>Conclusion</b></h3>
<span style=""font-weight: 400;"">The power of data visualization in analytics is not just about making data look appealing; it's about unlocking the hidden potential within raw data and presenting it in a way that resonates with human intuition. From aiding decision-making to sparking innovation, data visualization has become an essential tool for those seeking to harness the true power of their data. In a world where information overload is a constant challenge, data visualization acts as a guiding light, illuminating the path toward insights and understanding. So, whether you're a business leader, a data analyst, or a curious mind, embrace the art of data visualization, and witness the transformation of data into wisdom.</span>",https://blueorange.digital/wp-content/uploads/2023/08/BOD-Data-Viz-thumbnail.jpg|https://blueorange.digital/wp-content/uploads/2023/08/BOD-Data-Viz-img1.jpg|https://blueorange.digital/wp-content/uploads/2023/08/BOD-Data-Viz-img2.jpg|https://blueorange.digital/wp-content/uploads/2023/08/BOD-Data-Viz-img3.jpg,BOD-Data-Viz-thumbnail.jpg|BOD-Data-Viz-img1.jpg|BOD-Data-Viz-img2.jpg|BOD-Data-Viz-img3.jpg,/www/blueorangem_500/public/wp-content/uploads/2023/08/BOD-Data-Viz-thumbnail.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/08/BOD-Data-Viz-img1.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/08/BOD-Data-Viz-img2.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/08/BOD-Data-Viz-img3.jpg,6417|6418|6419|6420,"BOD Data Viz thumbnail|BOD Data Viz img1|BOD Data Viz img2|BOD Data Viz img3",|||,|||,|||,https://blueorange.digital/wp-content/uploads/2023/08/BOD-Data-Viz-thumbnail.jpg,,,,,,,,
6430,"Embarking on a Data Journey with Mountaineering Precision: Setting Clear Objectives","<span style=""font-weight: 400;"">Clear objectives are the strategic waypoints that define your data journey, ensuring every step taken contributes to overall success. In this blog, we delve into the significance of clear objectives in the data realm, drawing parallels from the world of mountaineering to shed light on their importance and implementation.</span>

<b>Setting Clear Objectives</b>

<span style=""font-weight: 400;"">Setting clear objectives serves as the compass that guides an impactful Data Journey. Much like how mountaineers identify their summit destination, clear objectives outline the desired outcomes and milestones of your data initiatives. These objectives encapsulate what you aim to achieve, how you plan to get there, and the timeframe within which these goals will be realized.</span>

<img class=""alignnone size-large wp-image-6434"" src=""https://blueorange.digital/wp-content/uploads/2023/08/setting-clear-objectives-1024x538.jpg"" alt="""" width=""1024"" height=""538"" />

<b>Navigating the Data Expedition: Implementing Clear Objectives</b>

<span style=""font-weight: 400;"">Similar to how mountaineers execute their carefully laid plans, the implementation of clear objectives in your data strategy requires a meticulous approach. As you set out on this data expedition, every step you take should be deliberate and purposeful. Let's explore the strategies that can guide you in effectively implementing clear objectives within your data strategy:</span>
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Peak-Defined Clarity: Precision in Objective Articulation</b><b>
</b><span style=""font-weight: 400;"">Just as a mountaineer's summit goal is well-defined, your data objectives must be crystal clear. Define your objectives with precision, ensuring that they are specific, measurable, achievable, relevant, and time-bound (SMART). These SMART objectives act as guiding stars, orienting your data initiatives toward a distinct direction.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Quantitative Metrics: Measuring Progress Ascent</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">Comparable to measuring elevation, clear objectives should offer quantifiable metrics to measure progress. By using key performance indicators (KPIs) that align with your objectives, you can systematically monitor and assess your advancement. These metrics provide valuable insights, helping you stay on course and identify areas that require adjustment.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Realistic Ascent: Scaling Achievable Heights</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">Just as mountaineers set realistic goals in accordance with their strengths and resources, your data objectives should also be achievable. Strive for objectives that are within the realm of feasibility, considering your organization's capacities, resources, and limitations. Overambitious goals may lead to frustration and burnout, while overly conservative goals could stunt growth. Strike the balance between challenge and attainability.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Strategic Alignment: Harmonizing with Organizational Goals</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">Similar to how mountaineers align their climb with the overall expedition goals, your data objectives should be in harmony with your organization's broader strategy. Each objective should contribute meaningfully to the overarching mission, ensuring that your data strategy drives value across various facets of the business. This alignment enhances the relevance and impact of your data initiatives.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Timely Reaching: Setting a Path for Time-Bound Success</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">Just as mountaineers set time limits for each stage of their ascent, your objectives should have defined timeframes. Time-bound objectives inject a sense of urgency into your data strategy, preventing the drift of objectives and maintaining a focused trajectory. Deadlines encourage proactive action.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Iterative Refinement: Navigating Dynamic Data Terrain</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">The data landscape, much like the terrain during a climb, is subject to change. Regularly revisit your objectives to assess their relevance and alignment with shifting business needs and technological advancements. Adaptability is key—just as mountaineers adjust their route in response to changing conditions, your data objectives should evolve to remain pertinent.</span></li>
</ul>
<img class=""alignnone size-large wp-image-6435"" src=""https://blueorange.digital/wp-content/uploads/2023/08/Advantages-of-Clear-Objectives-in-Data-Strategy-1024x538.jpg"" alt="""" width=""1024"" height=""538"" />

<b>Reaping the Rewards: Advantages of Clear Objectives in Data Strategy</b>

<span style=""font-weight: 400;"">Much like a mountaineer stands at the summit to behold a panoramic view, organizations that integrate clear objectives into their data strategy are rewarded with a vantage point that offers insights, direction, and a competitive edge. The benefits of establishing clear objectives resonate across the entire spectrum of data-driven initiatives, contributing to both short-term successes and long-term strategic growth.</span>
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Greater Focus and Alignment: Navigating with Precision</b><b>
</b><span style=""font-weight: 400;"">Just as mountaineers fix their gaze on the summit, clear objectives serve as focal points for your data endeavors. They align teams, departments, and stakeholders toward common goals, creating a collective sense of direction. This alignment minimizes distractions, prevents dispersion of efforts, and channels resources optimally. With clear objectives, everyone knows the desired destination, ensuring that actions are cohesive and contributions are synergized.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Measurable Progress: Scaling Data Heights with Metrics</b><b>
</b><span style=""font-weight: 400;"">Comparable to measuring altitude gained, clear objectives provide quantifiable metrics to gauge progress. These milestones offer a tangible and visual representation of your advancement. As key performance indicators (KPIs) are tracked and goals are met, your organization can see the data strategy's impact in real-time. These metrics empower decision-makers with insights to assess if they are on track to achieve their goals or need to recalibrate their efforts.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Efficient Resource Allocation: Optimizing Data Expedition Resources</b><b>
</b><span style=""font-weight: 400;"">Just as climbers manage their supplies wisely, clear objectives enable efficient resource allocation. Resources—be it time, finances, or personnel—are directed where they are most needed and can yield maximum returns. This optimization prevents wastage and ensures that your data strategy's implementation remains agile, responsive, and cost-effective, enhancing overall efficiency.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Adaptability &amp; Resilience: Navigating Dynamic Data Landscapes</b><b>
</b><span style=""font-weight: 400;"">Similar to how mountaineers adapt to changing weather conditions, clear objectives allow organizations to navigate evolving data landscapes with agility. As market dynamics shift, objectives can be modified to remain relevant. This adaptability ensures that your data strategy remains flexible, capable of incorporating new technologies, adjusting to unforeseen challenges, and seizing emerging opportunities.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Informed Decision-Making: Ascending with Insightful Choices</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">Much like mountaineers make decisions based on their proximity to the summit, clear objectives guide strategic choices. Organizations can confidently make data-driven decisions, aligned with their goals. The clarity of objectives aids in evaluating potential paths, assessing risks, and choosing strategies that are most likely to lead to success, ultimately enhancing the quality of decision-making processes.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Strategic Direction: Mapping Data Trajectories to Goals</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">Similar to how mountaineers meticulously plan their ascent, clear objectives provide strategic direction to your data initiatives. They ensure that each step taken, each data source harnessed, and each decision made contributes to the overarching goals. This alignment prevents aimless wandering and imparts purpose to every action, enabling your organization to navigate the data landscape with precision.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Accountability: Reaching Peaks of Responsibility</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">Just as climbers are accountable for their actions, clear objectives foster accountability within your organization. Teams are responsible for achieving specific objectives, creating a sense of ownership and dedication. This sense of responsibility permeates the organization, enhancing commitment, motivation, and a collective desire to reach the data-driven goals set forth.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Leadership Buy-In: Guiding with Unwavering Resolve</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">In the same way that mountaineering expeditions need strong leadership, securing buy-in from organizational leadership is crucial for data strategy implementation. Leadership endorsement ensures that the objectives are not only understood but also embraced throughout the organization. Their support fosters a culture of data-driven decision-making and paves the way for successful implementation.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Interdisciplinary Collaboration: Building Rope Teams Across Departments</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">Just as mountaineers work together as a unified team, clear objectives foster collaboration among teams, departments, and stakeholders. The shared vision provided by objectives encourages cross-functional communication, breaking down silos, and promoting a culture of collaboration. This cohesive teamwork enhances creativity, leverages diverse expertise, and leads to innovative solutions that address complex data challenges.</span></li>
</ul>
<img class=""alignnone size-large wp-image-6436"" src=""https://blueorange.digital/wp-content/uploads/2023/08/Navigating-Data-Strategy-1024x538.jpg"" alt="""" width=""1024"" height=""538"" />

<b>Challenges Along the Ascent: Navigating Data Strategy</b>

<span style=""font-weight: 400;"">Just as mountaineers encounter unforeseen obstacles during their ascent, the path to data strategy success is not without its challenges. Navigating these challenges requires a combination of strategic thinking and adaptability, mirroring the resilience climbers exhibit in the face of changing conditions. Let's delve into these challenges that can arise while defining clear objectives in your data strategy:</span>
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Data Complexity: Scaling Data Peaks Amid Complexity</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">Comparable to the intricate terrain that mountaineers navigate, data landscapes can be complex and multifaceted. Organizations often deal with a deluge of data from various sources, making it challenging to distill meaningful objectives. The complexity lies not only in the sheer volume of data but also in its diversity, quality, and relevance. Overcoming this challenge requires careful consideration and a strategic approach to identify which data points truly matter and align with the overarching goals.</span></li>
 	<li aria-level=""1""><b>Shifting Terrain: Adapting to the Changing Data Landscape</b></li>
</ul>
<span style=""font-weight: 400;"">As mountaineers encounter changing weather conditions and varying terrains, businesses too must adapt to evolving market dynamics, technological advancements, and customer preferences. This dynamism demands a level of agility in data strategy. The objectives set today might need adjustments tomorrow to remain relevant and effective. While clear objectives provide a steady course, flexibility in adjusting them as the data landscape evolves is essential to ensure continued alignment with business goals.</span>
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Stakeholder Alignment: Forging a Unified Data Rope Team</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">Similar to the collaborative spirit among a team of climbers, stakeholder alignment is crucial in data strategy. Achieving consensus and commitment from different departments, each with their own priorities, can be challenging. Disparate viewpoints, conflicting interests, and communication gaps can hinder the process of defining clear objectives that everyone supports. Effective communication and engagement strategies are vital to ensure all stakeholders understand the rationale behind the objectives and recognize how they contribute to the bigger picture.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Resource Allocation: Navigating Resource Scarcity</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">Just as mountaineers must carefully ration their resources for a successful ascent, organizations face resource constraints that need to be managed judiciously. Limited budget, time, and personnel can present challenges when implementing data strategies. Clear objectives, while essential, must be balanced with the available resources to avoid overextension. Striking this equilibrium requires a keen understanding of the organization’s capacity and a pragmatic approach to setting objectives that can be achieved without straining resources.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Data Quality and Integrity: Navigating Through Data Fog</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">Analogous to navigating through foggy conditions, data quality and integrity can create a cloudy landscape. Inaccurate, incomplete, or outdated data can lead to misguided objectives and skewed results. Ensuring data accuracy and maintaining its integrity is a critical challenge. Investing in data governance practices and data quality assurance measures is vital to minimize the risk of building strategies on flawed information.</span></li>
 	<li style=""font-weight: 400;"" aria-level=""1""><b>Change Management: Ascending Organizational Peaks</b><span style=""font-weight: 400;"">
</span><span style=""font-weight: 400;"">Just as a mountaineer needs to acclimate to higher altitudes, organizations may face resistance and inertia when introducing new data strategies and objectives. Change management becomes paramount to overcome resistance, foster a culture of data-driven decision-making, and ensure that the defined objectives are embraced across all levels of the organization. It requires effective communication, training, and clear explanations of how the new data strategy aligns with the broader organizational goals.</span></li>
</ul>
<b>Conclusion</b>

<span style=""font-weight: 400;"">Setting clear objectives is the North Star of your data journey, providing direction, purpose, and accountability. A successful ascent, like a successful data initiative, hinges on strategic planning, adaptability, and a unified team effort. By defining clear objectives out of business’s goals, mitigating implementation challenges, and setting continuous metrics to check and refine objectives will help organizations navigate the data landscape with confidence, and help them reach new heights of success.</span>

<span style=""font-weight: 400;"">Ready to embark on your data journey with precision? Blue Orange Digital is your guide to setting and achieving clear objectives that drive growth and innovation.</span>",https://blueorange.digital/wp-content/uploads/2023/08/Embarking-on-a-Data-Journey-with-Mountaineering-Precision-Setting-Clear-Objectives.jpg|https://blueorange.digital/wp-content/uploads/2023/08/setting-clear-objectives.jpg|https://blueorange.digital/wp-content/uploads/2023/08/Advantages-of-Clear-Objectives-in-Data-Strategy.jpg|https://blueorange.digital/wp-content/uploads/2023/08/Navigating-Data-Strategy.jpg,Embarking-on-a-Data-Journey-with-Mountaineering-Precision-Setting-Clear-Objectives.jpg|setting-clear-objectives.jpg|Advantages-of-Clear-Objectives-in-Data-Strategy.jpg|Navigating-Data-Strategy.jpg,/www/blueorangem_500/public/wp-content/uploads/2023/08/Embarking-on-a-Data-Journey-with-Mountaineering-Precision-Setting-Clear-Objectives.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/08/setting-clear-objectives.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/08/Advantages-of-Clear-Objectives-in-Data-Strategy.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/08/Navigating-Data-Strategy.jpg,6433|6434|6435|6436,"Embarking on a Data Journey with Mountaineering Precision Setting Clear Objectives|setting clear objectives|Advantages of Clear Objectives in Data Strategy|Navigating Data Strategy",|||,|||,|||,https://blueorange.digital/wp-content/uploads/2023/08/Embarking-on-a-Data-Journey-with-Mountaineering-Precision-Setting-Clear-Objectives.jpg,,,,,,,,
6440,"Navigating Data with Precision : Why Should You Take Data Inventory?","<span style=""font-weight: 400;"">In the journey of data management, the process of taking inventory plays a crucial role just as a mountaineer meticulously assesses their gear before embarking on a challenging expedition, ensuring they have the necessary equipment to conquer peaks. Data professionals also must conduct regular inventory checks to conquer the vast peaks of their data landscape. </span>

<span style=""font-weight: 400;"">Let’s delve into the importance of taking inventory in the data domain, explore the benefits it offers, address the challenges that can potentially arise, provide strategies for effective inventory management, and ultimately, draw parallels to the world of mountaineering.</span>
<h2><b>Importance of Taking Inventory</b></h2>
<span style=""font-weight: 400;"">Imagine setting off on a mountain ascent without knowing the resources available in your backpack. Similarly, embarking on data initiatives without a clear understanding of available resources can lead to inefficiency and redundancy. Taking inventory ensures that organizations have a comprehensive view of their data assets, preventing resource wastage, data duplication, and confusion. It forms the bedrock for efficient decision-making, enables resource allocation, and establishes a foundation for effective data governance.</span>

<img class=""alignnone size-large wp-image-6442"" src=""https://blueorange.digital/wp-content/uploads/2023/09/data-inventory-img1-1024x538.jpg"" alt="""" width=""1024"" height=""538"" />
<h2><b>Benefits of Taking Inventory</b></h2>
<span style=""font-weight: 400;"">Just as a mountaineer charts a path to success, an organized data inventory empowers organizations to navigate the intricate data landscape with precision. This section delves into the substantial advantages that stem from this meticulous inventory practice, shedding light on how taking inventory helps shape a resilient foundation for data-driven success.</span>

<b>1. Enhanced Decision-Making:</b>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Taking inventory of your data is like creating a compass that guides your organization's decisions. With a comprehensive understanding of your data landscape, you can identify the most relevant and valuable data sources. This, in turn, enables you to extract meaningful insights and patterns, leading to well-informed decision-making. By knowing what data is available, you can ask the right questions and uncover hidden correlations that might have otherwise gone unnoticed. </span></li>
</ul>
</li>
</ul>
<b>2. Resource Optimization:</b>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Imagine a mountaineer scaling a peak with an overburdened pack. Similarly, an organization that doesn't take inventory of its data assets might find itself carrying unnecessary data weight. An organized inventory helps identify data redundancies and obsolete datasets. By decluttering your data stores, you optimize your resources – both in terms of storage costs and data processing efforts. This optimization not only streamlines your operations but also frees up resources that can be channeled into more productive endeavors.</span></li>
</ul>
</li>
</ul>
<b>3. Risk Mitigation:</b>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Just as a mountaineer evaluates the risks of changing weather conditions, organizations must assess the risks within their data environment. Inaccurate or outdated data can lead to flawed insights and misguided decisions. Furthermore, mishandling sensitive data can result in security breaches and legal complications. A well-maintained inventory provides insights into data accuracy, quality, and sensitivity. By identifying potential risks and vulnerabilities, you can implement appropriate security measures and ensure compliance with data protection regulations. This proactive approach to risk management enhances your organization's data security, safeguarding its reputation and trustworthiness.</span></li>
</ul>
</li>
</ul>
<b>4. Improved Collaboration:</b>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Successful mountaineering expeditions hinge on effective teamwork, where each member's strengths are leveraged for collective success. Similarly, in an organization, data-driven decisions often involve collaboration across departments. An organized data inventory functions as a shared knowledge base, enabling teams to access the data they need efficiently. This minimizes information silos, reduces duplicated efforts, and fosters cross-functional collaboration. </span></li>
</ul>
</li>
</ul>
<b>5. Regulatory Compliance:</b>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">In the data landscape, compliance with regulations is paramount, much like adhering to safety protocols in mountaineering. Organizations must demonstrate responsible data management practices to meet legal and ethical requirements. A meticulously maintained data inventory acts as a trail of breadcrumbs, showcasing data lineage, usage, and retention policies. When regulatory authorities or auditors require documentation, a well-documented inventory streamlines the process. This not only ensures compliance but also enhances your organization's credibility and accountability.</span></li>
</ul>
</li>
</ul>
<b>6. Scalability and Innovation:</b>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Just as mountaineers build their skills by conquering increasingly challenging peaks, organizations grow by expanding their data capabilities. A well-structured data inventory facilitates scalability. It serves as a foundation that accommodates the integration of new data sources, technologies, and tools. With a clear understanding of existing assets, organizations can experiment with emerging technologies, such as AI and machine learning, to uncover new insights and drive innovation.</span></li>
</ul>
</li>
</ul>
<img class=""alignnone size-large wp-image-6443"" src=""https://blueorange.digital/wp-content/uploads/2023/09/data-governance-mountaineering1-1024x538.jpg"" alt="""" width=""1024"" height=""538"" />
<h2><b>Challenges: While inventorying data brings numerous advantages, it's not without challenges</b></h2>
<span style=""font-weight: 400;"">While the benefits of a well-maintained data inventory are compelling, the path to achieving these advantages is not without its challenges. Much like the obstacles faced by mountaineers as they ascend steep peaks, organizations venturing into the realm of data inventory encounter hurdles that demand careful navigation and strategic planning. Let’s understand how each hurdle shapes the journey towards effective data management.</span><b></b>

<b>1. Data Proliferation:</b>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">In the world of data, proliferation is akin to the vastness of mountain ranges. The volume of data generated daily can be overwhelming, making it difficult to keep track of all data sources and assets. Just as mountaineers must navigate through diverse landscapes, organizations must navigate through an array of data types – structured, semi-structured, and unstructured. This diversity makes maintaining an accurate and up-to-date inventory a challenging endeavor.</span></li>
</ul>
</li>
</ul>
<b>2. Data Diversity:</b>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Much like mountaineering involves adapting to various terrains, data management requires adapting to different data structures and formats. Data can exist in databases, spreadsheets, text files, images, and more. Managing and categorizing these diverse data types requires flexible inventory strategies that can accommodate a wide range of formats. Additionally, as new data technologies emerge, organizations must continuously evolve their inventory systems to include these innovative sources.</span></li>
</ul>
</li>
</ul>
<b>3. Changing Landscape:</b>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">The data landscape is in a constant state of flux, reminiscent of changing weather conditions in mountaineering. New data sources are introduced, existing sources evolve, and old sources become obsolete. This dynamic environment poses a challenge to maintaining an accurate inventory. Without regular updates, an inventory can quickly become outdated, leading to inaccurate insights and decisions.</span></li>
</ul>
</li>
</ul>
<b>4. Data Governance Challenges:</b>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Just as mountaineers adhere to safety protocols, organizations must adhere to data governance policies. Establishing and enforcing data governance rules requires aligning with industry regulations, company policies, and data quality standards. Balancing these requirements can be complex, especially in organizations where data responsibilities are dispersed across different departments or teams.</span></li>
</ul>
</li>
</ul>
<b>5. Technical Challenges:</b>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Technical challenges are the rocky paths in the data landscape. Creating and maintaining an inventory system often requires technical expertise, including the implementation of data cataloging tools, automated scanning mechanisms, and metadata management solutions. Integrating these tools with existing data systems can be complex, and selecting the right tools for the organization's needs is essential.</span></li>
</ul>
</li>
</ul>
<b>6. Data Privacy and Security:</b>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Maintaining an inventory that includes sensitive data requires implementing strong access controls, encryption, and masking mechanisms. Safeguarding this data from unauthorized access and breaches is crucial, as the consequences of data leaks can be severe.</span></li>
</ul>
</li>
</ul>
<b>7. Organizational Change Management:</b>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li style=""font-weight: 400;"" aria-level=""1""><span style=""font-weight: 400;"">Just as mountaineering requires adapting to changing circumstances, implementing a new inventory strategy often requires a shift in organizational culture and practices. Employees may need to change their data management behaviors, adopt new tools, and embrace new processes. Resistance to change can be a challenge, and effective change management strategies are essential to ensure the successful adoption of the inventory management approach.</span></li>
</ul>
</li>
</ul>
<img class=""alignnone size-large wp-image-6444"" src=""https://blueorange.digital/wp-content/uploads/2023/09/data-governance-compass1-1024x538.jpg"" alt="""" width=""1024"" height=""538"" />
<h2><b>How to Take Inventory: Navigating Data with Precision</b></h2>
<span style=""font-weight: 400;"">In the journey of data management, where insights are the compass and innovation is the destination, taking inventory stands as the pivotal stage that bridges aspirations with reality. Having explored the benefits and the challenges, we now turn our attention to the heart of the matter: how to effectively take inventory. This section unveils practical strategies and methodologies for orchestrating an efficient and insightful data inventory process. It's a journey that parallels the expertise of mountaineers who calibrate their gear and techniques for each climb. From setting clear goals and categorizing data to automating processes and ensuring scalability, these strategies constitute the toolkit for conquering the data landscape.</span>
<ol>
 	<li><b>Define Clear Inventory Objectives:</b></li>
</ol>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li><span style=""font-weight: 400;"">Much like mountaineers plan their ascent based on the peak they aim to conquer, your data inventory journey begins by setting clear objectives. Determine what data you need to catalog, the level of detail required, and the purpose of the inventory. Are you focusing on customer data, sales figures, or operational metrics? Defining goals helps you stay focused and ensures that the inventory aligns with your organization's data priorities.</span></li>
</ul>
</li>
</ul>
<ol start=""2"">
 	<li><b> Categorize Data:</b></li>
</ol>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li><span style=""font-weight: 400;"">Organize your data assets into logical categories, Develop a taxonomy that suits your organization's needs – this could be based on data type, business function, or any other relevant classification. Categorization simplifies data retrieval and enhances collaboration by making it easier for teams to locate the data they require.</span></li>
</ul>
</li>
</ul>
<ol start=""3"">
 	<li><b> Utilize Automation Tools:</b></li>
</ol>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li><span style=""font-weight: 400;"">Just as mountaineers rely on GPS and weather forecasts for navigation, leverage automation tools to streamline your inventory process. Data cataloging and management tools can automatically scan and tag data assets, capturing metadata such as data source, creation date, and data owner. These tools save time, reduce human error, and ensure consistency in data labeling, making it easier to manage and locate data assets efficiently.</span></li>
</ul>
</li>
</ul>
<ol start=""4"">
 	<li><b> Regular Audits:</b></li>
</ol>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li><span style=""font-weight: 400;"">Similar to mountaineers who periodically check their gear for wear and tear, conduct routine audits of your data inventory. Regularly assess the accuracy and relevance of the data you've cataloged. As data sources change and evolve, update your inventory accordingly. Consider implementing an audit schedule to ensure that your inventory remains up-to-date and continues to reflect the ever-changing data landscape.</span></li>
</ul>
</li>
</ul>
<ol start=""5"">
 	<li><b> Data Governance and Ownership:</b></li>
</ol>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li><span style=""font-weight: 400;"">Establish data governance policies that define data ownership, access controls, and data usage guidelines. This is akin to mountaineers adhering to safety protocols for group dynamics. Assign data stewards or owners who are responsible for the accuracy and quality of the data within their domains. Having clear ownership ensures accountability and maintains the integrity of your data inventory.</span></li>
</ul>
</li>
</ul>
<ol start=""6"">
 	<li><b> Data Documentation:</b></li>
</ol>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li><span style=""font-weight: 400;"">Create detailed documentation for each data asset, similar to how mountaineers meticulously document their expedition plans. Include metadata such as data description, source, format, quality assessment, and relevant business context. This documentation provides valuable context to users accessing the data, aiding their understanding and usage of the data asset.</span></li>
</ul>
</li>
</ul>
<ol start=""7"">
 	<li><b> Scalability and Integration:</b></li>
</ol>
<ul>
 	<li style=""list-style-type: none;"">
<ul>
 	<li><span style=""font-weight: 400;"">Just as mountaineers equip themselves for various terrains, design your inventory system to accommodate scalability and integration. As new data sources emerge and technology evolves, ensure that your inventory can easily incorporate these additions. Integrate your inventory system with existing data management tools and platforms for a seamless workflow.</span></li>
</ul>
</li>
</ul>
<h2><b>Conclusion</b></h2>
<span style=""font-weight: 400;"">Taking inventory in the world of data management is akin to the meticulous planning and execution undertaken by mountaineers. By recognizing the importance of having a comprehensive view of your data landscape, you can optimize your resources, minimize risks, and make informed decisions. While challenges may arise, with the right strategies and tools, you can successfully navigate the dynamic data terrain and reach new heights of data-driven success. Just as mountaineers conquer peaks, data experts conquer insights – both achieved through careful inventory management.</span>

<span style=""font-weight: 400;"">As you navigate your data landscape, consider partnering with experts who specialize in guiding organizations through the intricacies of data. At Blue Orange Digital, a Data Company, we are passionate about helping you harness the true potential of your data assets. Whether you're seeking to optimize operations, unravel insights, or innovate through data-driven strategies, our expertise can be your compass to success.</span>",https://blueorange.digital/wp-content/uploads/2023/09/data-governance-mountaineering1.jpg|https://blueorange.digital/wp-content/uploads/2023/09/data-inventory-img1.jpg|https://blueorange.digital/wp-content/uploads/2023/09/data-governance-compass1.jpg,data-governance-mountaineering1.jpg|data-inventory-img1.jpg|data-governance-compass1.jpg,/www/blueorangem_500/public/wp-content/uploads/2023/09/data-governance-mountaineering1.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/09/data-inventory-img1.jpg|/www/blueorangem_500/public/wp-content/uploads/2023/09/data-governance-compass1.jpg,6443|6442|6444,"data governance mountaineering1|data inventory img1|data governance compass1",||,||,||,https://blueorange.digital/wp-content/uploads/2023/09/data-governance-mountaineering1.jpg,,,,,,,,
